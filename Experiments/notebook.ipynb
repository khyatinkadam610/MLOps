{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a6fd28e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96442365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Red\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Red\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Red\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68345088",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Red\\Desktop\\mlops\\MlOps_practice\\Experiments\\spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "929f7911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'Message'], dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f925ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'Message'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad15a204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\red\\anaconda3\\envs\\mlops\\lib\\site-packages (from scikit-learn) (2.2.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\red\\anaconda3\\envs\\mlops\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.1/11.1 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.5/11.1 MB 11.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.6/11.1 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.1 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.5/11.1 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 10.1 MB/s eta 0:00:00\n",
      "Downloading scipy-1.15.2-cp313-cp313-win_amd64.whl (41.0 MB)\n",
      "   ---------------------------------------- 0.0/41.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.8/41.0 MB 8.9 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.4/41.0 MB 9.0 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 5.0/41.0 MB 7.9 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 6.0/41.0 MB 7.4 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 7.1/41.0 MB 7.0 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 8.4/41.0 MB 6.7 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 9.7/41.0 MB 6.6 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 10.7/41.0 MB 6.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 12.1/41.0 MB 6.4 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 13.1/41.0 MB 6.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 14.7/41.0 MB 6.4 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 16.3/41.0 MB 6.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 17.8/41.0 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 19.1/41.0 MB 6.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 20.7/41.0 MB 6.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 22.3/41.0 MB 6.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 23.9/41.0 MB 6.5 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 25.7/41.0 MB 6.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 27.5/41.0 MB 6.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 29.6/41.0 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 31.7/41.0 MB 7.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 33.8/41.0 MB 7.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 35.9/41.0 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.7/41.0 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.3/41.0 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.0/41.0 MB 7.1 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "606003df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "df['Category'] = encoder.fit_transform(df['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95825998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message\n",
       "0         0  Go until jurong point, crazy.. Available only ...\n",
       "1         0                      Ok lar... Joking wif u oni...\n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         0  U dun say so early hor... U c already then say...\n",
       "4         0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1c8ae6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(415)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "013ea9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bee08e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer\n",
    "\n",
    "import string\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca5711d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing WordCloud for text visualization\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Importing NLTK for natural language processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords  \n",
    "\n",
    "def transform_text(text):\n",
    "    # Transform the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenization using NLTK\n",
    "    text = nltk.word_tokenize(text)\n",
    "    print(\"AFter tokenizer: \",text)\n",
    "    # Removing special characters\n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "            \n",
    "    # Removing stop words and punctuation\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "\n",
    "    \n",
    "    # Loop through the tokens and remove stopwords and punctuation\n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "        \n",
    "    # Stemming using Porter Stemmer\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    \n",
    "    # Join the processed tokens back into a single string\n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "babf05ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFter tokenizer:  ['hey', 'man', '..', 'this', 'is', 'me', '.', 'its', 'been', 'a', 'long', 'time', 'since', 'we', 'talked', '.', 'i', 'just', 'wanted', 'you', 'to', 'know', 'that', 'i', 'still', 'think', 'about', 'you']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hey man long time sinc talk want know still think'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_text(\"Hey man..This is me. Its been a long time since we talked. i just wanted you to know that i still think about you\")\n",
    "# transform_text('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8cc48d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFter tokenizer:  ['go', 'until', 'jurong', 'point', ',', 'crazy', '..', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', '...', 'cine', 'there', 'got', 'amore', 'wat', '...']\n",
      "AFter tokenizer:  ['ok', 'lar', '...', 'joking', 'wif', 'u', 'oni', '...']\n",
      "AFter tokenizer:  ['free', 'entry', 'in', '2', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005.', 'text', 'fa', 'to', '87121', 'to', 'receive', 'entry', 'question', '(', 'std', 'txt', 'rate', ')', 't', '&', 'c', \"'s\", 'apply', '08452810075over18', \"'s\"]\n",
      "AFter tokenizer:  ['u', 'dun', 'say', 'so', 'early', 'hor', '...', 'u', 'c', 'already', 'then', 'say', '...']\n",
      "AFter tokenizer:  ['nah', 'i', 'do', \"n't\", 'think', 'he', 'goes', 'to', 'usf', ',', 'he', 'lives', 'around', 'here', 'though']\n",
      "AFter tokenizer:  ['freemsg', 'hey', 'there', 'darling', 'it', \"'s\", 'been', '3', 'week', \"'s\", 'now', 'and', 'no', 'word', 'back', '!', 'i', \"'d\", 'like', 'some', 'fun', 'you', 'up', 'for', 'it', 'still', '?', 'tb', 'ok', '!', 'xxx', 'std', 'chgs', 'to', 'send', ',', '£1.50', 'to', 'rcv']\n",
      "AFter tokenizer:  ['even', 'my', 'brother', 'is', 'not', 'like', 'to', 'speak', 'with', 'me', '.', 'they', 'treat', 'me', 'like', 'aids', 'patent', '.']\n",
      "AFter tokenizer:  ['as', 'per', 'your', 'request', \"'melle\", 'melle', '(', 'oru', 'minnaminunginte', 'nurungu', 'vettam', ')', \"'\", 'has', 'been', 'set', 'as', 'your', 'callertune', 'for', 'all', 'callers', '.', 'press', '*', '9', 'to', 'copy', 'your', 'friends', 'callertune']\n",
      "AFter tokenizer:  ['winner', '!', '!', 'as', 'a', 'valued', 'network', 'customer', 'you', 'have', 'been', 'selected', 'to', 'receivea', '£900', 'prize', 'reward', '!', 'to', 'claim', 'call', '09061701461.', 'claim', 'code', 'kl341', '.', 'valid', '12', 'hours', 'only', '.']\n",
      "AFter tokenizer:  ['had', 'your', 'mobile', '11', 'months', 'or', 'more', '?', 'u', 'r', 'entitled', 'to', 'update', 'to', 'the', 'latest', 'colour', 'mobiles', 'with', 'camera', 'for', 'free', '!', 'call', 'the', 'mobile', 'update', 'co', 'free', 'on', '08002986030']\n",
      "AFter tokenizer:  ['i', \"'m\", 'gon', 'na', 'be', 'home', 'soon', 'and', 'i', 'do', \"n't\", 'want', 'to', 'talk', 'about', 'this', 'stuff', 'anymore', 'tonight', ',', 'k', '?', 'i', \"'ve\", 'cried', 'enough', 'today', '.']\n",
      "AFter tokenizer:  ['six', 'chances', 'to', 'win', 'cash', '!', 'from', '100', 'to', '20,000', 'pounds', 'txt', '>', 'csh11', 'and', 'send', 'to', '87575.', 'cost', '150p/day', ',', '6days', ',', '16+', 'tsandcs', 'apply', 'reply', 'hl', '4', 'info']\n",
      "AFter tokenizer:  ['urgent', '!', 'you', 'have', 'won', 'a', '1', 'week', 'free', 'membership', 'in', 'our', '£100,000', 'prize', 'jackpot', '!', 'txt', 'the', 'word', ':', 'claim', 'to', 'no', ':', '81010', 't', '&', 'c', 'www.dbuk.net', 'lccltd', 'pobox', '4403ldnw1a7rw18']\n",
      "AFter tokenizer:  ['i', \"'ve\", 'been', 'searching', 'for', 'the', 'right', 'words', 'to', 'thank', 'you', 'for', 'this', 'breather', '.', 'i', 'promise', 'i', 'wont', 'take', 'your', 'help', 'for', 'granted', 'and', 'will', 'fulfil', 'my', 'promise', '.', 'you', 'have', 'been', 'wonderful', 'and', 'a', 'blessing', 'at', 'all', 'times', '.']\n",
      "AFter tokenizer:  ['i', 'have', 'a', 'date', 'on', 'sunday', 'with', 'will', '!', '!']\n",
      "AFter tokenizer:  ['xxxmobilemovieclub', ':', 'to', 'use', 'your', 'credit', ',', 'click', 'the', 'wap', 'link', 'in', 'the', 'next', 'txt', 'message', 'or', 'click', 'here', '>', '>', 'http', ':', '//wap', '.', 'xxxmobilemovieclub.com', '?', 'n=qjkgighjjgcbl']\n",
      "AFter tokenizer:  ['oh', 'k', '...', 'i', \"'m\", 'watching', 'here', ':', ')']\n",
      "AFter tokenizer:  ['eh', 'u', 'remember', 'how', '2', 'spell', 'his', 'name', '...', 'yes', 'i', 'did', '.', 'he', 'v', 'naughty', 'make', 'until', 'i', 'v', 'wet', '.']\n",
      "AFter tokenizer:  ['fine', 'if', 'that\\x92s', 'the', 'way', 'u', 'feel', '.', 'that\\x92s', 'the', 'way', 'its', 'gota', 'b']\n",
      "AFter tokenizer:  ['england', 'v', 'macedonia', '-', 'dont', 'miss', 'the', 'goals/team', 'news', '.', 'txt', 'ur', 'national', 'team', 'to', '87077', 'eg', 'england', 'to', '87077', 'try', ':', 'wales', ',', 'scotland', '4txt/ú1.20', 'poboxox36504w45wq', '16+']\n",
      "AFter tokenizer:  ['is', 'that', 'seriously', 'how', 'you', 'spell', 'his', 'name', '?']\n",
      "AFter tokenizer:  ['i', '‘', 'm', 'going', 'to', 'try', 'for', '2', 'months', 'ha', 'ha', 'only', 'joking']\n",
      "AFter tokenizer:  ['so', 'ü', 'pay', 'first', 'lar', '...', 'then', 'when', 'is', 'da', 'stock', 'comin', '...']\n",
      "AFter tokenizer:  ['aft', 'i', 'finish', 'my', 'lunch', 'then', 'i', 'go', 'str', 'down', 'lor', '.', 'ard', '3', 'smth', 'lor', '.', 'u', 'finish', 'ur', 'lunch', 'already', '?']\n",
      "AFter tokenizer:  ['ffffffffff', '.', 'alright', 'no', 'way', 'i', 'can', 'meet', 'up', 'with', 'you', 'sooner', '?']\n",
      "AFter tokenizer:  ['just', 'forced', 'myself', 'to', 'eat', 'a', 'slice', '.', 'i', \"'m\", 'really', 'not', 'hungry', 'tho', '.', 'this', 'sucks', '.', 'mark', 'is', 'getting', 'worried', '.', 'he', 'knows', 'i', \"'m\", 'sick', 'when', 'i', 'turn', 'down', 'pizza', '.', 'lol']\n",
      "AFter tokenizer:  ['lol', 'your', 'always', 'so', 'convincing', '.']\n",
      "AFter tokenizer:  ['did', 'you', 'catch', 'the', 'bus', '?', 'are', 'you', 'frying', 'an', 'egg', '?', 'did', 'you', 'make', 'a', 'tea', '?', 'are', 'you', 'eating', 'your', 'mom', \"'s\", 'left', 'over', 'dinner', '?', 'do', 'you', 'feel', 'my', 'love', '?']\n",
      "AFter tokenizer:  ['i', \"'m\", 'back', '&', 'amp', ';', 'we', \"'re\", 'packing', 'the', 'car', 'now', ',', 'i', \"'ll\", 'let', 'you', 'know', 'if', 'there', \"'s\", 'room']\n",
      "AFter tokenizer:  ['ahhh', '.', 'work', '.', 'i', 'vaguely', 'remember', 'that', '!', 'what', 'does', 'it', 'feel', 'like', '?', 'lol']\n",
      "AFter tokenizer:  ['wait', 'that', \"'s\", 'still', 'not', 'all', 'that', 'clear', ',', 'were', 'you', 'not', 'sure', 'about', 'me', 'being', 'sarcastic', 'or', 'that', 'that', \"'s\", 'why', 'x', 'does', \"n't\", 'want', 'to', 'live', 'with', 'us']\n",
      "AFter tokenizer:  ['yeah', 'he', 'got', 'in', 'at', '2', 'and', 'was', 'v', 'apologetic', '.', 'n', 'had', 'fallen', 'out', 'and', 'she', 'was', 'actin', 'like', 'spoilt', 'child', 'and', 'he', 'got', 'caught', 'up', 'in', 'that', '.', 'till', '2', '!', 'but', 'we', 'wo', \"n't\", 'go', 'there', '!', 'not', 'doing', 'too', 'badly', 'cheers', '.', 'you', '?']\n",
      "AFter tokenizer:  ['k', 'tell', 'me', 'anything', 'about', 'you', '.']\n",
      "AFter tokenizer:  ['for', 'fear', 'of', 'fainting', 'with', 'the', 'of', 'all', 'that', 'housework', 'you', 'just', 'did', '?', 'quick', 'have', 'a', 'cuppa']\n",
      "AFter tokenizer:  ['thanks', 'for', 'your', 'subscription', 'to', 'ringtone', 'uk', 'your', 'mobile', 'will', 'be', 'charged', '£5/month', 'please', 'confirm', 'by', 'replying', 'yes', 'or', 'no', '.', 'if', 'you', 'reply', 'no', 'you', 'will', 'not', 'be', 'charged']\n",
      "AFter tokenizer:  ['yup', '...', 'ok', 'i', 'go', 'home', 'look', 'at', 'the', 'timings', 'then', 'i', 'msg', 'ü', 'again', '...', 'xuhui', 'going', 'to', 'learn', 'on', '2nd', 'may', 'too', 'but', 'her', 'lesson', 'is', 'at', '8am']\n",
      "AFter tokenizer:  ['oops', ',', 'i', \"'ll\", 'let', 'you', 'know', 'when', 'my', 'roommate', \"'s\", 'done']\n",
      "AFter tokenizer:  ['i', 'see', 'the', 'letter', 'b', 'on', 'my', 'car']\n",
      "AFter tokenizer:  ['anything', 'lor', '...', 'u', 'decide', '...']\n",
      "AFter tokenizer:  ['hello', '!', 'how', \"'s\", 'you', 'and', 'how', 'did', 'saturday', 'go', '?', 'i', 'was', 'just', 'texting', 'to', 'see', 'if', 'you', \"'d\", 'decided', 'to', 'do', 'anything', 'tomo', '.', 'not', 'that', 'i', \"'m\", 'trying', 'to', 'invite', 'myself', 'or', 'anything', '!']\n",
      "AFter tokenizer:  ['pls', 'go', 'ahead', 'with', 'watts', '.', 'i', 'just', 'wanted', 'to', 'be', 'sure', '.', 'do', 'have', 'a', 'great', 'weekend', '.', 'abiola']\n",
      "AFter tokenizer:  ['did', 'i', 'forget', 'to', 'tell', 'you', '?', 'i', 'want', 'you', ',', 'i', 'need', 'you', ',', 'i', 'crave', 'you', '...', 'but', 'most', 'of', 'all', '...', 'i', 'love', 'you', 'my', 'sweet', 'arabian', 'steed', '...', 'mmmmmm', '...', 'yummy']\n",
      "AFter tokenizer:  ['07732584351', '-', 'rodger', 'burns', '-', 'msg', '=', 'we', 'tried', 'to', 'call', 'you', 're', 'your', 'reply', 'to', 'our', 'sms', 'for', 'a', 'free', 'nokia', 'mobile', '+', 'free', 'camcorder', '.', 'please', 'call', 'now', '08000930705', 'for', 'delivery', 'tomorrow']\n",
      "AFter tokenizer:  ['who', 'are', 'you', 'seeing', '?']\n",
      "AFter tokenizer:  ['great', '!', 'i', 'hope', 'you', 'like', 'your', 'man', 'well', 'endowed', '.', 'i', 'am', '&', 'lt', ';', '#', '&', 'gt', ';', 'inches', '...']\n",
      "AFter tokenizer:  ['no', 'calls', '..', 'messages', '..', 'missed', 'calls']\n",
      "AFter tokenizer:  ['did', \"n't\", 'you', 'get', 'hep', 'b', 'immunisation', 'in', 'nigeria', '.']\n",
      "AFter tokenizer:  ['fair', 'enough', ',', 'anything', 'going', 'on', '?']\n",
      "AFter tokenizer:  ['yeah', 'hopefully', ',', 'if', 'tyler', 'ca', \"n't\", 'do', 'it', 'i', 'could', 'maybe', 'ask', 'around', 'a', 'bit']\n",
      "AFter tokenizer:  ['u', 'do', \"n't\", 'know', 'how', 'stubborn', 'i', 'am', '.', 'i', 'did', \"n't\", 'even', 'want', 'to', 'go', 'to', 'the', 'hospital', '.', 'i', 'kept', 'telling', 'mark', 'i', \"'m\", 'not', 'a', 'weak', 'sucker', '.', 'hospitals', 'are', 'for', 'weak', 'suckers', '.']\n",
      "AFter tokenizer:  ['what', 'you', 'thinked', 'about', 'me', '.', 'first', 'time', 'you', 'saw', 'me', 'in', 'class', '.']\n",
      "AFter tokenizer:  ['a', 'gram', 'usually', 'runs', 'like', '&', 'lt', ';', '#', '&', 'gt', ';', ',', 'a', 'half', 'eighth', 'is', 'smarter', 'though', 'and', 'gets', 'you', 'almost', 'a', 'whole', 'second', 'gram', 'for', '&', 'lt', ';', '#', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['k', 'fyi', 'x', 'has', 'a', 'ride', 'early', 'tomorrow', 'morning', 'but', 'he', \"'s\", 'crashing', 'at', 'our', 'place', 'tonight']\n",
      "AFter tokenizer:  ['wow', '.', 'i', 'never', 'realized', 'that', 'you', 'were', 'so', 'embarassed', 'by', 'your', 'accomodations', '.', 'i', 'thought', 'you', 'liked', 'it', ',', 'since', 'i', 'was', 'doing', 'the', 'best', 'i', 'could', 'and', 'you', 'always', 'seemed', 'so', 'happy', 'about', '``', 'the', 'cave', \"''\", '.', 'i', \"'m\", 'sorry', 'i', 'did', \"n't\", 'and', 'do', \"n't\", 'have', 'more', 'to', 'give', '.', 'i', \"'m\", 'sorry', 'i', 'offered', '.', 'i', \"'m\", 'sorry', 'your', 'room', 'was', 'so', 'embarassing', '.']\n",
      "AFter tokenizer:  ['sms', '.', 'ac', 'sptv', ':', 'the', 'new', 'jersey', 'devils', 'and', 'the', 'detroit', 'red', 'wings', 'play', 'ice', 'hockey', '.', 'correct', 'or', 'incorrect', '?', 'end', '?', 'reply', 'end', 'sptv']\n",
      "AFter tokenizer:  ['do', 'you', 'know', 'what', 'mallika', 'sherawat', 'did', 'yesterday', '?', 'find', 'out', 'now', '@', '&', 'lt', ';', 'url', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['congrats', '!', '1', 'year', 'special', 'cinema', 'pass', 'for', '2', 'is', 'yours', '.', 'call', '09061209465', 'now', '!', 'c', 'suprman', 'v', ',', 'matrix3', ',', 'starwars3', ',', 'etc', 'all', '4', 'free', '!', 'bx420-ip4-5we', '.', '150pm', '.', 'dont', 'miss', 'out', '!']\n",
      "AFter tokenizer:  ['sorry', ',', 'i', \"'ll\", 'call', 'later', 'in', 'meeting', '.']\n",
      "AFter tokenizer:  ['tell', 'where', 'you', 'reached']\n",
      "AFter tokenizer:  ['yes', '..', 'gauti', 'and', 'sehwag', 'out', 'of', 'odi', 'series', '.']\n",
      "AFter tokenizer:  ['your', 'gon', 'na', 'have', 'to', 'pick', 'up', 'a', '$', '1', 'burger', 'for', 'yourself', 'on', 'your', 'way', 'home', '.', 'i', 'ca', \"n't\", 'even', 'move', '.', 'pain', 'is', 'killing', 'me', '.']\n",
      "AFter tokenizer:  ['ha', 'ha', 'ha', 'good', 'joke', '.', 'girls', 'are', 'situation', 'seekers', '.']\n",
      "AFter tokenizer:  ['its', 'a', 'part', 'of', 'checking', 'iq']\n",
      "AFter tokenizer:  ['sorry', 'my', 'roommates', 'took', 'forever', ',', 'it', 'ok', 'if', 'i', 'come', 'by', 'now', '?']\n",
      "AFter tokenizer:  ['ok', 'lar', 'i', 'double', 'check', 'wif', 'da', 'hair', 'dresser', 'already', 'he', 'said', 'wun', 'cut', 'v', 'short', '.', 'he', 'said', 'will', 'cut', 'until', 'i', 'look', 'nice', '.']\n",
      "AFter tokenizer:  ['as', 'a', 'valued', 'customer', ',', 'i', 'am', 'pleased', 'to', 'advise', 'you', 'that', 'following', 'recent', 'review', 'of', 'your', 'mob', 'no', '.', 'you', 'are', 'awarded', 'with', 'a', '£1500', 'bonus', 'prize', ',', 'call', '09066364589']\n",
      "AFter tokenizer:  ['today', 'is', '``', 'song', 'dedicated', 'day', '..', \"''\", 'which', 'song', 'will', 'u', 'dedicate', 'for', 'me', '?', 'send', 'this', 'to', 'all', 'ur', 'valuable', 'frnds', 'but', 'first', 'rply', 'me', '...']\n",
      "AFter tokenizer:  ['urgent', 'ur', 'awarded', 'a', 'complimentary', 'trip', 'to', 'eurodisinc', 'trav', ',', 'aco', '&', 'entry41', 'or', '£1000', '.', 'to', 'claim', 'txt', 'dis', 'to', '87121', '18+6', '*', '£1.50', '(', 'morefrmmob', '.', 'shracomorsglsuplt', ')', '10', ',', 'ls1', '3aj']\n",
      "AFter tokenizer:  ['did', 'you', 'hear', 'about', 'the', 'new', '``', 'divorce', 'barbie', \"''\", '?', 'it', 'comes', 'with', 'all', 'of', 'ken', \"'s\", 'stuff', '!']\n",
      "AFter tokenizer:  ['i', 'plane', 'to', 'give', 'on', 'this', 'month', 'end', '.']\n",
      "AFter tokenizer:  ['wah', 'lucky', 'man', '...', 'then', 'can', 'save', 'money', '...', 'hee', '...']\n",
      "AFter tokenizer:  ['finished', 'class', 'where', 'are', 'you', '.']\n",
      "AFter tokenizer:  ['hi', 'babe', 'im', 'at', 'home', 'now', 'wan', 'na', 'do', 'something', '?', 'xx']\n",
      "AFter tokenizer:  ['k', '..', 'k', ':', ')', 'where', 'are', 'you', '?', 'how', 'did', 'you', 'performed', '?']\n",
      "AFter tokenizer:  ['u', 'can', 'call', 'me', 'now', '...']\n",
      "AFter tokenizer:  ['i', 'am', 'waiting', 'machan', '.', 'call', 'me', 'once', 'you', 'free', '.']\n",
      "AFter tokenizer:  ['thats', 'cool', '.', 'i', 'am', 'a', 'gentleman', 'and', 'will', 'treat', 'you', 'with', 'dignity', 'and', 'respect', '.']\n",
      "AFter tokenizer:  ['i', 'like', 'you', 'peoples', 'very', 'much', ':', ')', 'but', 'am', 'very', 'shy', 'pa', '.']\n",
      "AFter tokenizer:  ['does', 'not', 'operate', 'after', '&', 'lt', ';', '#', '&', 'gt', ';', 'or', 'what']\n",
      "AFter tokenizer:  ['its', 'not', 'the', 'same', 'here', '.', 'still', 'looking', 'for', 'a', 'job', '.', 'how', 'much', 'do', 'ta', \"'s\", 'earn', 'there', '.']\n",
      "AFter tokenizer:  ['sorry', ',', 'i', \"'ll\", 'call', 'later']\n",
      "AFter tokenizer:  ['k.', 'did', 'you', 'call', 'me', 'just', 'now', 'ah', '?']\n",
      "AFter tokenizer:  ['ok', 'i', 'am', 'on', 'the', 'way', 'to', 'home', 'hi', 'hi']\n",
      "AFter tokenizer:  ['you', 'will', 'be', 'in', 'the', 'place', 'of', 'that', 'man']\n",
      "AFter tokenizer:  ['yup', 'next', 'stop', '.']\n",
      "AFter tokenizer:  ['i', 'call', 'you', 'later', ',', 'do', \"n't\", 'have', 'network', '.', 'if', 'urgnt', ',', 'sms', 'me', '.']\n",
      "AFter tokenizer:  ['for', 'real', 'when', 'u', 'getting', 'on', 'yo', '?', 'i', 'only', 'need', '2', 'more', 'tickets', 'and', 'one', 'more', 'jacket', 'and', 'i', \"'m\", 'done', '.', 'i', 'already', 'used', 'all', 'my', 'multis', '.']\n",
      "AFter tokenizer:  ['yes', 'i', 'started', 'to', 'send', 'requests', 'to', 'make', 'it', 'but', 'pain', 'came', 'back', 'so', 'i', \"'m\", 'back', 'in', 'bed', '.', 'double', 'coins', 'at', 'the', 'factory', 'too', '.', 'i', 'got', 'ta', 'cash', 'in', 'all', 'my', 'nitros', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'really', 'not', 'up', 'to', 'it', 'still', 'tonight', 'babe']\n",
      "AFter tokenizer:  ['ela', 'kano.', ',', 'il', 'download', ',', 'come', 'wen', 'ur', 'free', '..']\n",
      "AFter tokenizer:  ['yeah', 'do', '!', 'don', '‘', 't', 'stand', 'to', 'close', 'tho-', 'you', '‘', 'll', 'catch', 'something', '!']\n",
      "AFter tokenizer:  ['sorry', 'to', 'be', 'a', 'pain', '.', 'is', 'it', 'ok', 'if', 'we', 'meet', 'another', 'night', '?', 'i', 'spent', 'late', 'afternoon', 'in', 'casualty', 'and', 'that', 'means', 'i', 'have', \"n't\", 'done', 'any', 'of', 'y', 'stuff42moro', 'and', 'that', 'includes', 'all', 'my', 'time', 'sheets', 'and', 'that', '.', 'sorry', '.']\n",
      "AFter tokenizer:  ['smile', 'in', 'pleasure', 'smile', 'in', 'pain', 'smile', 'when', 'trouble', 'pours', 'like', 'rain', 'smile', 'when', 'sum1', 'hurts', 'u', 'smile', 'becoz', 'someone', 'still', 'loves', 'to', 'see', 'u', 'smiling', '!', '!']\n",
      "AFter tokenizer:  ['please', 'call', 'our', 'customer', 'service', 'representative', 'on', '0800', '169', '6031', 'between', '10am-9pm', 'as', 'you', 'have', 'won', 'a', 'guaranteed', '£1000', 'cash', 'or', '£5000', 'prize', '!']\n",
      "AFter tokenizer:  ['havent', 'planning', 'to', 'buy', 'later', '.', 'i', 'check', 'already', 'lido', 'only', 'got', '530', 'show', 'in', 'e', 'afternoon', '.', 'u', 'finish', 'work', 'already', '?']\n",
      "AFter tokenizer:  ['your', 'free', 'ringtone', 'is', 'waiting', 'to', 'be', 'collected', '.', 'simply', 'text', 'the', 'password', '``', 'mix', \"''\", 'to', '85069', 'to', 'verify', '.', 'get', 'usher', 'and', 'britney', '.', 'fml', ',', 'po', 'box', '5249', ',', 'mk17', '92h', '.', '450ppw', '16']\n",
      "AFter tokenizer:  ['watching', 'telugu', 'movie', '..', 'wat', 'abt', 'u', '?']\n",
      "AFter tokenizer:  ['i', 'see', '.', 'when', 'we', 'finish', 'we', 'have', 'loads', 'of', 'loans', 'to', 'pay']\n",
      "AFter tokenizer:  ['hi', '.', 'wk', 'been', 'ok', '-', 'on', 'hols', 'now', '!', 'yes', 'on', 'for', 'a', 'bit', 'of', 'a', 'run', '.', 'forgot', 'that', 'i', 'have', 'hairdressers', 'appointment', 'at', 'four', 'so', 'need', 'to', 'get', 'home', 'n', 'shower', 'beforehand', '.', 'does', 'that', 'cause', 'prob', 'for', 'u', '?', \"''\"]\n",
      "AFter tokenizer:  ['i', 'see', 'a', 'cup', 'of', 'coffee', 'animation']\n",
      "AFter tokenizer:  ['please', 'do', \"n't\", 'text', 'me', 'anymore', '.', 'i', 'have', 'nothing', 'else', 'to', 'say', '.']\n",
      "AFter tokenizer:  ['okay', 'name', 'ur', 'price', 'as', 'long', 'as', 'its', 'legal', '!', 'wen', 'can', 'i', 'pick', 'them', 'up', '?', 'y', 'u', 'ave', 'x', 'ams', 'xx']\n",
      "AFter tokenizer:  ['i', \"'m\", 'still', 'looking', 'for', 'a', 'car', 'to', 'buy', '.', 'and', 'have', 'not', 'gone', '4the', 'driving', 'test', 'yet', '.']\n",
      "AFter tokenizer:  ['wow', '.', 'you', \"'re\", 'right', '!', 'i', 'did', \"n't\", 'mean', 'to', 'do', 'that', '.', 'i', 'guess', 'once', 'i', 'gave', 'up', 'on', 'boston', 'men', 'and', 'changed', 'my', 'search', 'location', 'to', 'nyc', ',', 'something', 'changed', '.', 'cuz', 'on', 'my', 'signin', 'page', 'it', 'still', 'says', 'boston', '.']\n",
      "AFter tokenizer:  ['umma', 'my', 'life', 'and', 'vava', 'umma', 'love', 'you', 'lot', 'dear']\n",
      "AFter tokenizer:  ['thanks', 'a', 'lot', 'for', 'your', 'wishes', 'on', 'my', 'birthday', '.', 'thanks', 'you', 'for', 'making', 'my', 'birthday', 'truly', 'memorable', '.']\n",
      "AFter tokenizer:  ['aight', ',', 'i', \"'ll\", 'hit', 'you', 'up', 'when', 'i', 'get', 'some', 'cash']\n",
      "AFter tokenizer:  ['how', 'would', 'my', 'ip', 'address', 'test', 'that', 'considering', 'my', 'computer', 'is', \"n't\", 'a', 'minecraft', 'server']\n",
      "AFter tokenizer:  ['i', 'know', '!', 'grumpy', 'old', 'people', '.', 'my', 'mom', 'was', 'like', 'you', 'better', 'not', 'be', 'lying', '.', 'then', 'again', 'i', 'am', 'always', 'the', 'one', 'to', 'play', 'jokes', '...']\n",
      "AFter tokenizer:  ['dont', 'worry', '.', 'i', 'guess', 'he', \"'s\", 'busy', '.']\n",
      "AFter tokenizer:  ['what', 'is', 'the', 'plural', 'of', 'the', 'noun', 'research', '?']\n",
      "AFter tokenizer:  ['going', 'for', 'dinner.msg', 'you', 'after', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'ok', 'wif', 'it', 'cos', 'i', 'like', '2', 'try', 'new', 'things', '.', 'but', 'i', 'scared', 'u', 'dun', 'like', 'mah', '.', 'cos', 'u', 'said', 'not', 'too', 'loud', '.']\n",
      "AFter tokenizer:  ['gent', '!', 'we', 'are', 'trying', 'to', 'contact', 'you', '.', 'last', 'weekends', 'draw', 'shows', 'that', 'you', 'won', 'a', '£1000', 'prize', 'guaranteed', '.', 'call', '09064012160.', 'claim', 'code', 'k52', '.', 'valid', '12hrs', 'only', '.', '150ppm']\n",
      "AFter tokenizer:  ['wa', ',', 'ur', 'openin', 'sentence', 'very', 'formal', '...', 'anyway', ',', 'i', \"'m\", 'fine', 'too', ',', 'juz', 'tt', 'i', \"'m\", 'eatin', 'too', 'much', 'n', 'puttin', 'on', 'weight', '...', 'haha', '...', 'so', 'anythin', 'special', 'happened', '?']\n",
      "AFter tokenizer:  ['as', 'i', 'entered', 'my', 'cabin', 'my', 'pa', 'said', ',', '``', 'happy', \"b'day\", 'boss', '!', '!', \"''\", '.', 'i', 'felt', 'special', '.', 'she', 'askd', 'me', '4', 'lunch', '.', 'after', 'lunch', 'she', 'invited', 'me', 'to', 'her', 'apartment', '.', 'we', 'went', 'there', '.']\n",
      "AFter tokenizer:  ['you', 'are', 'a', 'winner', 'u', 'have', 'been', 'specially', 'selected', '2', 'receive', '£1000', 'or', 'a', '4', '*', 'holiday', '(', 'flights', 'inc', ')', 'speak', 'to', 'a', 'live', 'operator', '2', 'claim', '0871277810910p/min', '(', '18+', ')']\n",
      "AFter tokenizer:  ['goodo', '!', 'yes', 'we', 'must', 'speak', 'friday', '-', 'egg-potato', 'ratio', 'for', 'tortilla', 'needed', '!']\n",
      "AFter tokenizer:  ['hmm', '...', 'my', 'uncle', 'just', 'informed', 'me', 'that', 'he', \"'s\", 'paying', 'the', 'school', 'directly', '.', 'so', 'pls', 'buy', 'food', '.']\n",
      "AFter tokenizer:  ['private', '!', 'your', '2004', 'account', 'statement', 'for', '07742676969', 'shows', '786', 'unredeemed', 'bonus', 'points', '.', 'to', 'claim', 'call', '08719180248', 'identifier', 'code', ':', '45239', 'expires']\n",
      "AFter tokenizer:  ['urgent', '!', 'your', 'mobile', 'no', '.', 'was', 'awarded', '£2000', 'bonus', 'caller', 'prize', 'on', '5/9/03', 'this', 'is', 'our', 'final', 'try', 'to', 'contact', 'u', '!', 'call', 'from', 'landline', '09064019788', 'box42wr29c', ',', '150ppm']\n",
      "AFter tokenizer:  ['here', 'is', 'my', 'new', 'address', '-apples', '&', 'pairs', '&', 'all', 'that', 'malarky']\n",
      "AFter tokenizer:  ['todays', 'voda', 'numbers', 'ending', '7548', 'are', 'selected', 'to', 'receive', 'a', '$', '350', 'award', '.', 'if', 'you', 'have', 'a', 'match', 'please', 'call', '08712300220', 'quoting', 'claim', 'code', '4041', 'standard', 'rates', 'app']\n",
      "AFter tokenizer:  ['i', 'am', 'going', 'to', 'sao', 'mu', 'today', '.', 'will', 'be', 'done', 'only', 'at', '12']\n",
      "AFter tokenizer:  ['ü', 'predict', 'wat', 'time', 'ü', \"'ll\", 'finish', 'buying', '?']\n",
      "AFter tokenizer:  ['good', 'stuff', ',', 'will', 'do', '.']\n",
      "AFter tokenizer:  ['just', 'so', 'that', 'you', 'know', ',', 'yetunde', 'has', \"n't\", 'sent', 'money', 'yet', '.', 'i', 'just', 'sent', 'her', 'a', 'text', 'not', 'to', 'bother', 'sending', '.', 'so', 'its', 'over', ',', 'you', 'dont', 'have', 'to', 'involve', 'yourself', 'in', 'anything', '.', 'i', 'should', \"n't\", 'have', 'imposed', 'anything', 'on', 'you', 'in', 'the', 'first', 'place', 'so', 'for', 'that', ',', 'i', 'apologise', '.']\n",
      "AFter tokenizer:  ['are', 'you', 'there', 'in', 'room', '.']\n",
      "AFter tokenizer:  ['hey', 'girl', '.', 'how', 'r', 'u', '?', 'hope', 'u', 'r', 'well', 'me', 'an', 'del', 'r', 'bak', '!', 'again', 'long', 'time', 'no', 'c', '!', 'give', 'me', 'a', 'call', 'sum', 'time', 'from', 'lucyxx']\n",
      "AFter tokenizer:  ['k', '..', 'k', ':', ')', 'how', 'much', 'does', 'it', 'cost', '?']\n",
      "AFter tokenizer:  ['i', \"'m\", 'home', '.']\n",
      "AFter tokenizer:  ['dear', ',', 'will', 'call', 'tmorrow.pls', 'accomodate', '.']\n",
      "AFter tokenizer:  ['first', 'answer', 'my', 'question', '.']\n",
      "AFter tokenizer:  ['sunshine', 'quiz', 'wkly', 'q', '!', 'win', 'a', 'top', 'sony', 'dvd', 'player', 'if', 'u', 'know', 'which', 'country', 'the', 'algarve', 'is', 'in', '?', 'txt', 'ansr', 'to', '82277', '.', '£1.50', 'sp', ':', 'tyrone']\n",
      "AFter tokenizer:  ['want', '2', 'get', 'laid', 'tonight', '?', 'want', 'real', 'dogging', 'locations', 'sent', 'direct', '2', 'ur', 'mob', '?', 'join', 'the', 'uk', \"'s\", 'largest', 'dogging', 'network', 'bt', 'txting', 'gravel', 'to', '69888', '!', 'nt', '.', 'ec2a', '.', '31p.msg', '@', '150p']\n",
      "AFter tokenizer:  ['i', 'only', 'haf', 'msn', '.', 'it', \"'s\", 'yijue', '@', 'hotmail.com']\n",
      "AFter tokenizer:  ['he', 'is', 'there', '.', 'you', 'call', 'and', 'meet', 'him']\n",
      "AFter tokenizer:  ['no', 'no', '.', 'i', 'will', 'check', 'all', 'rooms', 'befor', 'activities']\n",
      "AFter tokenizer:  ['you', \"'ll\", 'not', 'rcv', 'any', 'more', 'msgs', 'from', 'the', 'chat', 'svc', '.', 'for', 'free', 'hardcore', 'services', 'text', 'go', 'to', ':', '69988', 'if', 'u', 'get', 'nothing', 'u', 'must', 'age', 'verify', 'with', 'yr', 'network', '&', 'try', 'again']\n",
      "AFter tokenizer:  ['got', 'c', '...', 'i', 'lazy', 'to', 'type', '...', 'i', 'forgot', 'ü', 'in', 'lect', '...', 'i', 'saw', 'a', 'pouch', 'but', 'like', 'not', 'v', 'nice', '...']\n",
      "AFter tokenizer:  ['k', ',', 'text', 'me', 'when', 'you', \"'re\", 'on', 'the', 'way']\n",
      "AFter tokenizer:  ['sir', ',', 'waiting', 'for', 'your', 'mail', '.']\n",
      "AFter tokenizer:  ['a', 'swt', 'thought', ':', '``', 'nver', 'get', 'tired', 'of', 'doing', 'little', 'things', '4', 'lovable', 'persons', '..', \"''\", 'coz', '..', 'somtimes', 'those', 'little', 'things', 'occupy', 'd', 'biggest', 'part', 'in', 'their', 'hearts', '..', 'gud', 'ni8']\n",
      "AFter tokenizer:  ['i', 'know', 'you', 'are', '.', 'can', 'you', 'pls', 'open', 'the', 'back', '?']\n",
      "AFter tokenizer:  ['yes', 'see', 'ya', 'not', 'on', 'the', 'dot']\n",
      "AFter tokenizer:  ['whats', 'the', 'staff', 'name', 'who', 'is', 'taking', 'class', 'for', 'us', '?']\n",
      "AFter tokenizer:  ['freemsg', 'why', 'have', \"n't\", 'you', 'replied', 'to', 'my', 'text', '?', 'i', \"'m\", 'randy', ',', 'sexy', ',', 'female', 'and', 'live', 'local', '.', 'luv', 'to', 'hear', 'from', 'u.', 'netcollex', 'ltd', '08700621170150p', 'per', 'msg', 'reply', 'stop', 'to', 'end']\n",
      "AFter tokenizer:  ['ummma.will', 'call', 'after', 'check', 'in.our', 'life', 'will', 'begin', 'from', 'qatar', 'so', 'pls', 'pray', 'very', 'hard', '.']\n",
      "AFter tokenizer:  ['k', '..', 'i', 'deleted', 'my', 'contact', 'that', 'why', '?']\n",
      "AFter tokenizer:  ['sindu', 'got', 'job', 'in', 'birla', 'soft', '..']\n",
      "AFter tokenizer:  ['the', 'wine', 'is', 'flowing', 'and', 'i', \"'m\", 'i', 'have', 'nevering', '..']\n",
      "AFter tokenizer:  ['yup', 'i', 'thk', 'cine', 'is', 'better', 'cos', 'no', 'need', '2', 'go', 'down', '2', 'plaza', 'mah', '.']\n",
      "AFter tokenizer:  ['ok', '...', 'ur', 'typical', 'reply', '...']\n",
      "AFter tokenizer:  ['you', 'are', 'everywhere', 'dirt', ',', 'on', 'the', 'floor', ',', 'the', 'windows', ',', 'even', 'on', 'my', 'shirt', '.', 'and', 'sometimes', 'when', 'i', 'open', 'my', 'mouth', ',', 'you', 'are', 'all', 'that', 'comes', 'flowing', 'out', '.', 'i', 'dream', 'of', 'my', 'world', 'without', 'you', ',', 'then', 'half', 'my', 'chores', 'are', 'out', 'too', '.', 'a', 'time', 'of', 'joy', 'for', 'me', ',', 'lots', 'of', 'tv', 'shows', 'i.ll', 'see', '.', 'but', 'i', 'guess', 'like', 'all', 'things', 'you', 'just', 'must', 'exist', ',', 'like', 'rain', ',', 'hail', 'and', 'mist', ',', 'and', 'when', 'my', 'time', 'here', 'is', 'done', ',', 'you', 'and', 'i', 'become', 'one', '.']\n",
      "AFter tokenizer:  ['aaooooright', 'are', 'you', 'at', 'work', '?']\n",
      "AFter tokenizer:  ['i', \"'m\", 'leaving', 'my', 'house', 'now', '...']\n",
      "AFter tokenizer:  ['hello', ',', 'my', 'love', '.', 'what', 'are', 'you', 'doing', '?', 'did', 'you', 'get', 'to', 'that', 'interview', 'today', '?', 'are', 'you', 'you', 'happy', '?', 'are', 'you', 'being', 'a', 'good', 'boy', '?', 'do', 'you', 'think', 'of', 'me', '?', 'are', 'you', 'missing', 'me', '?']\n",
      "AFter tokenizer:  ['customer', 'service', 'annoncement', '.', 'you', 'have', 'a', 'new', 'years', 'delivery', 'waiting', 'for', 'you', '.', 'please', 'call', '07046744435', 'now', 'to', 'arrange', 'delivery']\n",
      "AFter tokenizer:  ['you', 'are', 'a', 'winner', 'u', 'have', 'been', 'specially', 'selected', '2', 'receive', '£1000', 'cash', 'or', 'a', '4', '*', 'holiday', '(', 'flights', 'inc', ')', 'speak', 'to', 'a', 'live', 'operator', '2', 'claim', '0871277810810']\n",
      "AFter tokenizer:  ['keep', 'yourself', 'safe', 'for', 'me', 'because', 'i', 'need', 'you', 'and', 'i', 'miss', 'you', 'already', 'and', 'i', 'envy', 'everyone', 'that', 'see', \"'s\", 'you', 'in', 'real', 'life']\n",
      "AFter tokenizer:  ['new', 'car', 'and', 'house', 'for', 'my', 'parents', '.', ':', ')', 'i', 'have', 'only', 'new', 'job', 'in', 'hand', ':', ')']\n",
      "AFter tokenizer:  ['i', \"'m\", 'so', 'in', 'love', 'with', 'you', '.', 'i', \"'m\", 'excited', 'each', 'day', 'i', 'spend', 'with', 'you', '.', 'you', 'make', 'me', 'so', 'happy', '.']\n",
      "AFter tokenizer:  ['-pls', 'stop', 'bootydelious', '(', '32/f', ')', 'is', 'inviting', 'you', 'to', 'be', 'her', 'friend', '.', 'reply', 'yes-434', 'or', 'no-434', 'see', 'her', ':', 'www.sms.ac/u/bootydelious', 'stop', '?', 'send', 'stop', 'frnd', 'to', '62468']\n",
      "AFter tokenizer:  ['bangbabes', 'ur', 'order', 'is', 'on', 'the', 'way', '.', 'u', 'should', 'receive', 'a', 'service', 'msg', '2', 'download', 'ur', 'content', '.', 'if', 'u', 'do', 'not', ',', 'goto', 'wap', '.', 'bangb', '.', 'tv', 'on', 'ur', 'mobile', 'internet/service', 'menu']\n",
      "AFter tokenizer:  ['i', 'place', 'all', 'ur', 'points', 'on', 'e', 'cultures', 'module', 'already', '.']\n",
      "AFter tokenizer:  ['urgent', '!', 'we', 'are', 'trying', 'to', 'contact', 'you', '.', 'last', 'weekends', 'draw', 'shows', 'that', 'you', 'have', 'won', 'a', '£900', 'prize', 'guaranteed', '.', 'call', '09061701939.', 'claim', 'code', 's89', '.', 'valid', '12hrs', 'only']\n",
      "AFter tokenizer:  ['hi', 'frnd', ',', 'which', 'is', 'best', 'way', 'to', 'avoid', 'missunderstding', 'wit', 'our', 'beloved', 'one', \"'s\", '?']\n",
      "AFter tokenizer:  ['great', 'escape', '.', 'i', 'fancy', 'the', 'bridge', 'but', 'needs', 'her', 'lager', '.', 'see', 'you', 'tomo']\n",
      "AFter tokenizer:  ['yes', ':', ')', 'it', 'completely', 'in', 'out', 'of', 'form', ':', ')', 'clark', 'also', 'utter', 'waste', '.']\n",
      "AFter tokenizer:  ['sir', ',', 'i', 'need', 'axis', 'bank', 'account', 'no', 'and', 'bank', 'address', '.']\n",
      "AFter tokenizer:  ['hmmm', '..', 'thk', 'sure', 'got', 'time', 'to', 'hop', 'ard', '...', 'ya', ',', 'can', 'go', '4', 'free', 'abt', '...', 'muz', 'call', 'u', 'to', 'discuss', 'liao', '...']\n",
      "AFter tokenizer:  ['what', 'time', 'you', 'coming', 'down', 'later', '?']\n",
      "AFter tokenizer:  ['bloody', 'hell', ',', 'cant', 'believe', 'you', 'forgot', 'my', 'surname', 'mr', '.', 'ill', 'give', 'u', 'a', 'clue', ',', 'its', 'spanish', 'and', 'begins', 'with', 'm', '...']\n",
      "AFter tokenizer:  ['well', ',', 'i', \"'m\", 'gon', 'na', 'finish', 'my', 'bath', 'now', '.', 'have', 'a', 'good', '...', 'fine', 'night', '.']\n",
      "AFter tokenizer:  ['let', 'me', 'know', 'when', 'you', \"'ve\", 'got', 'the', 'money', 'so', 'carlos', 'can', 'make', 'the', 'call']\n",
      "AFter tokenizer:  ['u', 'still', 'going', 'to', 'the', 'mall', '?']\n",
      "AFter tokenizer:  ['turns', 'out', 'my', 'friends', 'are', 'staying', 'for', 'the', 'whole', 'show', 'and', 'wo', \"n't\", 'be', 'back', 'til', '~', '&', 'lt', ';', '#', '&', 'gt', ';', ',', 'so', 'feel', 'free', 'to', 'go', 'ahead', 'and', 'smoke', 'that', '$', '&', 'lt', ';', '#', '&', 'gt', ';', 'worth']\n",
      "AFter tokenizer:  ['text', 'her', '.', 'if', 'she', 'doesnt', 'reply', 'let', 'me', 'know', 'so', 'i', 'can', 'have', 'her', 'log', 'in']\n",
      "AFter tokenizer:  ['hi', '!', 'you', 'just', 'spoke', 'to', 'maneesha', 'v.', 'we', \"'d\", 'like', 'to', 'know', 'if', 'you', 'were', 'satisfied', 'with', 'the', 'experience', '.', 'reply', 'toll', 'free', 'with', 'yes', 'or', 'no', '.']\n",
      "AFter tokenizer:  ['you', 'lifted', 'my', 'hopes', 'with', 'the', 'offer', 'of', 'money', '.', 'i', 'am', 'in', 'need', '.', 'especially', 'when', 'the', 'end', 'of', 'the', 'month', 'approaches', 'and', 'it', 'hurts', 'my', 'studying', '.', 'anyways', 'have', 'a', 'gr8', 'weekend']\n",
      "AFter tokenizer:  ['lol', 'no', '.', 'u', 'can', 'trust', 'me', '.']\n",
      "AFter tokenizer:  ['ok.', 'i', 'am', 'a', 'gentleman', 'and', 'will', 'treat', 'you', 'with', 'dignity', 'and', 'respect', '.']\n",
      "AFter tokenizer:  ['he', 'will', ',', 'you', 'guys', 'close', '?']\n",
      "AFter tokenizer:  ['going', 'on', 'nothing', 'great.bye']\n",
      "AFter tokenizer:  ['hello', 'handsome', '!', 'are', 'you', 'finding', 'that', 'job', '?', 'not', 'being', 'lazy', '?', 'working', 'towards', 'getting', 'back', 'that', 'net', 'for', 'mummy', '?', 'where', \"'s\", 'my', 'boytoy', 'now', '?', 'does', 'he', 'miss', 'me', '?']\n",
      "AFter tokenizer:  ['haha', 'awesome', ',', 'be', 'there', 'in', 'a', 'minute']\n",
      "AFter tokenizer:  ['please', 'call', 'our', 'customer', 'service', 'representative', 'on', 'freephone', '0808', '145', '4742', 'between', '9am-11pm', 'as', 'you', 'have', 'won', 'a', 'guaranteed', '£1000', 'cash', 'or', '£5000', 'prize', '!']\n",
      "AFter tokenizer:  ['have', 'you', 'got', 'xmas', 'radio', 'times', '.', 'if', 'not', 'i', 'will', 'get', 'it', 'now']\n",
      "AFter tokenizer:  ['i', 'jus', 'reached', 'home', '.', 'i', 'go', 'bathe', 'first', '.', 'but', 'my', 'sis', 'using', 'net', 'tell', 'u', 'when', 'she', 'finishes', 'k', '...']\n",
      "AFter tokenizer:  ['are', 'you', 'unique', 'enough', '?', 'find', 'out', 'from', '30th', 'august', '.', 'www.areyouunique.co.uk']\n",
      "AFter tokenizer:  ['i', \"'m\", 'sorry', '.', 'i', \"'ve\", 'joined', 'the', 'league', 'of', 'people', 'that', 'dont', 'keep', 'in', 'touch', '.', 'you', 'mean', 'a', 'great', 'deal', 'to', 'me', '.', 'you', 'have', 'been', 'a', 'friend', 'at', 'all', 'times', 'even', 'at', 'great', 'personal', 'cost', '.', 'do', 'have', 'a', 'great', 'week.|']\n",
      "AFter tokenizer:  ['hi', ':', ')', 'finally', 'i', 'completed', 'the', 'course', ':', ')']\n",
      "AFter tokenizer:  ['it', 'will', 'stop', 'on', 'itself', '.', 'i', 'however', 'suggest', 'she', 'stays', 'with', 'someone', 'that', 'will', 'be', 'able', 'to', 'give', 'ors', 'for', 'every', 'stool', '.']\n",
      "AFter tokenizer:  ['how', 'are', 'you', 'doing', '?', 'hope', 'you', \"'ve\", 'settled', 'in', 'for', 'the', 'new', 'school', 'year', '.', 'just', 'wishin', 'you', 'a', 'gr8', 'day']\n",
      "AFter tokenizer:  ['gud', 'mrng', 'dear', 'hav', 'a', 'nice', 'day']\n",
      "AFter tokenizer:  ['did', 'u', 'got', 'that', 'persons', 'story']\n",
      "AFter tokenizer:  ['is', 'your', 'hamster', 'dead', '?', 'hey', 'so', 'tmr', 'i', 'meet', 'you', 'at', '1pm', 'orchard', 'mrt', '?']\n",
      "AFter tokenizer:  ['hi', 'its', 'kate', 'how', 'is', 'your', 'evening', '?', 'i', 'hope', 'i', 'can', 'see', 'you', 'tomorrow', 'for', 'a', 'bit', 'but', 'i', 'have', 'to', 'bloody', 'babyjontet', '!', 'txt', 'back', 'if', 'u', 'can', '.', ':', ')', 'xxx']\n",
      "AFter tokenizer:  ['found', 'it', ',', 'enc', '&', 'lt', ';', '#', '&', 'gt', ';', ',', 'where', 'you', 'at', '?']\n",
      "AFter tokenizer:  ['i', 'sent', 'you', '&', 'lt', ';', '#', '&', 'gt', ';', 'bucks']\n",
      "AFter tokenizer:  ['hello', 'darlin', 'ive', 'finished', 'college', 'now', 'so', 'txt', 'me', 'when', 'u', 'finish', 'if', 'u', 'can', 'love', 'kate', 'xxx']\n",
      "AFter tokenizer:  ['your', 'account', 'has', 'been', 'refilled', 'successfully', 'by', 'inr', '&', 'lt', ';', 'decimal', '&', 'gt', ';', '.', 'your', 'keralacircle', 'prepaid', 'account', 'balance', 'is', 'rs', '&', 'lt', ';', 'decimal', '&', 'gt', ';', '.', 'your', 'transaction', 'id', 'is', 'kr', '&', 'lt', ';', '#', '&', 'gt', ';', '.']\n",
      "AFter tokenizer:  ['goodmorning', 'sleeping', 'ga', '.']\n",
      "AFter tokenizer:  ['u', 'call', 'me', 'alter', 'at', '11', 'ok', '.']\n",
      "AFter tokenizer:  ['ü', 'say', 'until', 'like', 'dat', 'i', 'dun', 'buy', 'ericsson', 'oso', 'can', 'not', 'oredi', 'lar', '...']\n",
      "AFter tokenizer:  ['aight', 'yo', ',', 'dats', 'straight', 'dogg']\n",
      "AFter tokenizer:  ['you', 'please', 'give', 'us', 'connection', 'today', 'itself', 'before', '&', 'lt', ';', 'decimal', '&', 'gt', ';', 'or', 'refund', 'the', 'bill']\n",
      "AFter tokenizer:  ['both', ':', ')', 'i', 'shoot', 'big', 'loads', 'so', 'get', 'ready', '!']\n",
      "AFter tokenizer:  ['what', \"'s\", 'up', 'bruv', ',', 'hope', 'you', 'had', 'a', 'great', 'break', '.', 'do', 'have', 'a', 'rewarding', 'semester', '.']\n",
      "AFter tokenizer:  ['home', 'so', 'we', 'can', 'always', 'chat']\n",
      "AFter tokenizer:  ['k', ':', ')', 'k', ':', ')', 'good', ':', ')', 'study', 'well', '.']\n",
      "AFter tokenizer:  ['yup', '...', 'how', 'ü', 'noe', 'leh', '...']\n",
      "AFter tokenizer:  ['sounds', 'great', '!', 'are', 'you', 'home', 'now', '?']\n",
      "AFter tokenizer:  ['finally', 'the', 'match', 'heading', 'towards', 'draw', 'as', 'your', 'prediction', '.']\n",
      "AFter tokenizer:  ['tired', '.', 'i', 'have', \"n't\", 'slept', 'well', 'the', 'past', 'few', 'nights', '.']\n",
      "AFter tokenizer:  ['easy', 'ah', '?', 'sen', 'got', 'selected', 'means', 'its', 'good', '..']\n",
      "AFter tokenizer:  ['i', 'have', 'to', 'take', 'exam', 'with', 'march', '3']\n",
      "AFter tokenizer:  ['yeah', 'you', 'should', '.', 'i', 'think', 'you', 'can', 'use', 'your', 'gt', 'atm', 'now', 'to', 'register', '.', 'not', 'sure', 'but', 'if', 'there', \"'s\", 'anyway', 'i', 'can', 'help', 'let', 'me', 'know', '.', 'but', 'when', 'you', 'do', 'be', 'sure', 'you', 'are', 'ready', '.']\n",
      "AFter tokenizer:  ['ok', 'no', 'prob', '.', 'take', 'ur', 'time', '.']\n",
      "AFter tokenizer:  ['there', 'is', 'os', 'called', 'ubandu', 'which', 'will', 'run', 'without', 'installing', 'in', 'hard', 'disk', '...', 'you', 'can', 'use', 'that', 'os', 'to', 'copy', 'the', 'important', 'files', 'in', 'system', 'and', 'give', 'it', 'to', 'repair', 'shop', '..']\n",
      "AFter tokenizer:  ['u', 'say', 'leh', '...', 'of', 'course', 'nothing', 'happen', 'lar', '.', 'not', 'say', 'v', 'romantic', 'jus', 'a', 'bit', 'only', 'lor', '.', 'i', 'thk', 'e', 'nite', 'scenery', 'not', 'so', 'nice', 'leh', '.']\n",
      "AFter tokenizer:  ['500', 'new', 'mobiles', 'from', '2004', ',', 'must', 'go', '!', 'txt', ':', 'nokia', 'to', 'no', ':', '89545', '&', 'collect', 'yours', 'today', '!', 'from', 'only', '£1', 'www.4-tc.biz', '2optout', '087187262701.50gbp/mtmsg18']\n",
      "AFter tokenizer:  ['would', 'really', 'appreciate', 'if', 'you', 'call', 'me', '.', 'just', 'need', 'someone', 'to', 'talk', 'to', '.']\n",
      "AFter tokenizer:  ['will', 'u', 'meet', 'ur', 'dream', 'partner', 'soon', '?', 'is', 'ur', 'career', 'off', '2', 'a', 'flyng', 'start', '?', '2', 'find', 'out', 'free', ',', 'txt', 'horo', 'followed', 'by', 'ur', 'star', 'sign', ',', 'e.', 'g.', 'horo', 'aries']\n",
      "AFter tokenizer:  ['hey', 'company', 'elama', 'po', 'mudyadhu', '.']\n",
      "AFter tokenizer:  ['life', 'is', 'more', 'strict', 'than', 'teacher', '...', 'bcoz', 'teacher', 'teaches', 'lesson', '&', 'amp', ';', 'then', 'conducts', 'exam', ',', 'but', 'life', 'first', 'conducts', 'exam', '&', 'amp', ';', 'then', 'teaches', 'lessons', '.', 'happy', 'morning', '.', '.', '.']\n",
      "AFter tokenizer:  ['dear', 'good', 'morning', 'now', 'only', 'i', 'am', 'up']\n",
      "AFter tokenizer:  ['get', 'down', 'in', 'gandhipuram', 'and', 'walk', 'to', 'cross', 'cut', 'road', '.', 'right', 'side', '&', 'lt', ';', '#', '&', 'gt', ';', 'street', 'road', 'and', 'turn', 'at', 'first', 'right', '.']\n",
      "AFter tokenizer:  ['dear', 'we', 'are', 'going', 'to', 'our', 'rubber', 'place']\n",
      "AFter tokenizer:  ['sorry', 'battery', 'died', ',', 'yeah', 'i', \"'m\", 'here']\n",
      "AFter tokenizer:  ['yes', ':', ')', 'here', 'tv', 'is', 'always', 'available', 'in', 'work', 'place', '..']\n",
      "AFter tokenizer:  ['text', '&', 'meet', 'someone', 'sexy', 'today', '.', 'u', 'can', 'find', 'a', 'date', 'or', 'even', 'flirt', 'its', 'up', 'to', 'u.', 'join', '4', 'just', '10p', '.', 'reply', 'with', 'name', '&', 'age', 'eg', 'sam', '25', '.', '18', '-msg', 'recd', '@', 'thirtyeight', 'pence']\n",
      "AFter tokenizer:  ['i', 'have', 'printed', 'it', 'oh', '.', 'so', '&', 'lt', ';', '#', '&', 'gt', ';', 'come', 'upstairs']\n",
      "AFter tokenizer:  ['or', 'ill', 'be', 'a', 'little', 'closer', 'like', 'at', 'the', 'bus', 'stop', 'on', 'the', 'same', 'street']\n",
      "AFter tokenizer:  ['where', 'are', 'you', '?', 'when', 'wil', 'you', 'reach', 'here', '?']\n",
      "AFter tokenizer:  ['new', 'theory', ':', 'argument', 'wins', 'd', 'situation', ',', 'but', 'loses', 'the', 'person', '.', 'so', 'dont', 'argue', 'with', 'ur', 'friends', 'just', '..', '.', '.', '.', 'kick', 'them', '&', 'amp', ';', 'say', ',', 'i', \"'m\", 'always', 'correct', '.', '!']\n",
      "AFter tokenizer:  ['u', '447801259231', 'have', 'a', 'secret', 'admirer', 'who', 'is', 'looking', '2', 'make', 'contact', 'with', 'u-find', 'out', 'who', 'they', 'r', '*', 'reveal', 'who', 'thinks', 'ur', 'so', 'special-call', 'on', '09058094597']\n",
      "AFter tokenizer:  ['tomarrow', 'final', 'hearing', 'on', 'my', 'laptop', 'case', 'so', 'i', 'cant', '.']\n",
      "AFter tokenizer:  ['pleassssssseeeeee', 'tel', 'me', 'v', 'avent', 'done', 'sportsx']\n",
      "AFter tokenizer:  ['okay', '.', 'no', 'no', ',', 'just', 'shining', 'on', '.', 'that', 'was', 'meant', 'to', 'be', 'signing', ',', 'but', 'that', 'sounds', 'better', '.']\n",
      "AFter tokenizer:  ['although', 'i', 'told', 'u', 'dat', 'i', \"'m\", 'into', 'baig', 'face', 'watches', 'now', 'but', 'i', 'really', 'like', 'e', 'watch', 'u', 'gave', 'cos', 'it', \"'s\", 'fr', 'u.', 'thanx', '4', 'everything', 'dat', 'u', \"'ve\", 'done', 'today', ',', 'i', \"'m\", 'touched', '...']\n",
      "AFter tokenizer:  ['u', 'do', \"n't\", 'remember', 'that', 'old', 'commercial', '?']\n",
      "AFter tokenizer:  ['too', 'late', '.', 'i', 'said', 'i', 'have', 'the', 'website', '.', 'i', 'did', \"n't\", 'i', 'have', 'or', 'dont', 'have', 'the', 'slippers']\n",
      "AFter tokenizer:  ['i', 'asked', 'you', 'to', 'call', 'him', 'now', 'ok']\n",
      "AFter tokenizer:  ['kallis', 'wont', 'bat', 'in', '2nd', 'innings', '.']\n",
      "AFter tokenizer:  ['it', 'didnt', 'work', 'again', 'oh', '.', 'ok', 'goodnight', 'then', '.', 'i.ll', 'fix', 'and', 'have', 'it', 'ready', 'by', 'the', 'time', 'you', 'wake', 'up', '.', 'you', 'are', 'very', 'dearly', 'missed', 'have', 'a', 'good', 'night', 'sleep', '.']\n",
      "AFter tokenizer:  ['congratulations', 'ur', 'awarded', '500', 'of', 'cd', 'vouchers', 'or', '125gift', 'guaranteed', '&', 'free', 'entry', '2', '100', 'wkly', 'draw', 'txt', 'music', 'to', '87066', 'tncs', 'www.ldew.com1win150ppmx3age16']\n",
      "AFter tokenizer:  ['ranjith', 'cal', 'drpd', 'deeraj', 'and', 'deepak', '5min', 'hold']\n",
      "AFter tokenizer:  ['wen', 'ur', 'lovable', 'bcums', 'angry', 'wid', 'u', ',', 'dnt', 'take', 'it', 'seriously', '..', 'coz', 'being', 'angry', 'is', 'd', 'most', 'childish', 'n', 'true', 'way', 'of', 'showing', 'deep', 'affection', ',', 'care', 'n', 'luv', '!', '..', 'kettoda', 'manda', '...', 'have', 'nice', 'day', 'da', '.']\n",
      "AFter tokenizer:  ['what', 'you', 'doing', '?', 'how', 'are', 'you', '?']\n",
      "AFter tokenizer:  ['ups', 'which', 'is', '3days', 'also', ',', 'and', 'the', 'shipping', 'company', 'that', 'takes', '2wks', '.', 'the', 'other', 'way', 'is', 'usps', 'which', 'takes', 'a', 'week', 'but', 'when', 'it', 'gets', 'to', 'lag', 'you', 'may', 'have', 'to', 'bribe', 'nipost', 'to', 'get', 'your', 'stuff', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'back', ',', 'lem', 'me', 'know', 'when', 'you', \"'re\", 'ready']\n",
      "AFter tokenizer:  ['do', \"n't\", 'necessarily', 'expect', 'it', 'to', 'be', 'done', 'before', 'you', 'get', 'back', 'though', 'because', 'i', \"'m\", 'just', 'now', 'headin', 'out']\n",
      "AFter tokenizer:  ['mmm', 'so', 'yummy', 'babe', '...', 'nice', 'jolt', 'to', 'the', 'suzy']\n",
      "AFter tokenizer:  ['where', 'are', 'you', 'lover', '?', 'i', 'need', 'you', '...']\n",
      "AFter tokenizer:  ['we', 'tried', 'to', 'contact', 'you', 're', 'your', 'reply', 'to', 'our', 'offer', 'of', 'a', 'video', 'handset', '?', '750', 'anytime', 'networks', 'mins', '?', 'unlimited', 'text', '?', 'camcorder', '?', 'reply', 'or', 'call', '08000930705', 'now']\n",
      "AFter tokenizer:  ['i', '‘', 'm', 'parked', 'next', 'to', 'a', 'mini', '!', '!', '!', '!', 'when', 'are', 'you', 'coming', 'in', 'today', 'do', 'you', 'think', '?']\n",
      "AFter tokenizer:  ['yup']\n",
      "AFter tokenizer:  ['anyway', 'i', \"'m\", 'going', 'shopping', 'on', 'my', 'own', 'now', '.', 'cos', 'my', 'sis', 'not', 'done', 'yet', '.', 'dun', 'disturb', 'u', 'liao', '.']\n",
      "AFter tokenizer:  ['my', 'no', '.', 'in', 'luton', '0125698789', 'ring', 'me', 'if', 'ur', 'around', '!', 'h', '*']\n",
      "AFter tokenizer:  ['hey', 'i', 'am', 'really', 'horny', 'want', 'to', 'chat', 'or', 'see', 'me', 'naked', 'text', 'hot', 'to', '69698', 'text', 'charged', 'at', '150pm', 'to', 'unsubscribe', 'text', 'stop', '69698']\n",
      "AFter tokenizer:  ['why', 'you', 'dint', 'come', 'with', 'us', '.']\n",
      "AFter tokenizer:  ['same', '.', 'wana', 'plan', 'a', 'trip', 'sometme', 'then']\n",
      "AFter tokenizer:  ['not', 'sure', 'yet', ',', 'still', 'trying', 'to', 'get', 'a', 'hold', 'of', 'him']\n",
      "AFter tokenizer:  ['ur', 'ringtone', 'service', 'has', 'changed', '!', '25', 'free', 'credits', '!', 'go', 'to', 'club4mobiles.com', 'to', 'choose', 'content', 'now', '!', 'stop', '?', 'txt', 'club', 'stop', 'to', '87070', '.', '150p/wk', 'club4', 'po', 'box1146', 'mk45', '2wt']\n",
      "AFter tokenizer:  ['the', 'evo', '.', 'i', 'just', 'had', 'to', 'download', 'flash', '.', 'jealous', '?']\n",
      "AFter tokenizer:  ['ringtone', 'club', ':', 'get', 'the', 'uk', 'singles', 'chart', 'on', 'your', 'mobile', 'each', 'week', 'and', 'choose', 'any', 'top', 'quality', 'ringtone', '!', 'this', 'message', 'is', 'free', 'of', 'charge', '.']\n",
      "AFter tokenizer:  ['come', 'to', 'mu', ',', 'we', \"'re\", 'sorting', 'out', 'our', 'narcotics', 'situation']\n",
      "AFter tokenizer:  ['night', 'has', 'ended', 'for', 'another', 'day', ',', 'morning', 'has', 'come', 'in', 'a', 'special', 'way', '.', 'may', 'you', 'smile', 'like', 'the', 'sunny', 'rays', 'and', 'leaves', 'your', 'worries', 'at', 'the', 'blue', 'blue', 'bay', '.']\n",
      "AFter tokenizer:  ['hmv', 'bonus', 'special', '500', 'pounds', 'of', 'genuine', 'hmv', 'vouchers', 'to', 'be', 'won', '.', 'just', 'answer', '4', 'easy', 'questions', '.', 'play', 'now', '!', 'send', 'hmv', 'to', '86688', 'more', 'info', ':', 'www.100percent-real.com']\n",
      "AFter tokenizer:  ['usf', 'i', 'guess', ',', 'might', 'as', 'well', 'take', '1', 'car']\n",
      "AFter tokenizer:  ['no', 'objection', '.', 'my', 'bf', 'not', 'coming', '.']\n",
      "AFter tokenizer:  ['thanx', '...']\n",
      "AFter tokenizer:  ['tell', 'rob', 'to', 'mack', 'his', 'gf', 'in', 'the', 'theater']\n",
      "AFter tokenizer:  ['awesome', ',', 'i', \"'ll\", 'see', 'you', 'in', 'a', 'bit']\n",
      "AFter tokenizer:  ['just', 'sent', 'it', '.', 'so', 'what', 'type', 'of', 'food', 'do', 'you', 'like', '?']\n",
      "AFter tokenizer:  ['all', 'done', '?', 'all', 'handed', 'in', '?', 'celebrations', 'in', 'full', 'swing', 'yet', '?']\n",
      "AFter tokenizer:  ['you', 'got', 'called', 'a', 'tool', '?']\n",
      "AFter tokenizer:  ['wen', 'u', 'miss', 'someone', ',', 'the', 'person', 'is', 'definitely', 'special', 'for', 'u', '.....', 'but', 'if', 'the', 'person', 'is', 'so', 'special', ',', 'why', 'to', 'miss', 'them', ',', 'just', 'keep-in-touch', 'gdeve', '..']\n",
      "AFter tokenizer:  ['ok.', 'i', 'asked', 'for', 'money', 'how', 'far']\n",
      "AFter tokenizer:  ['okie', '...']\n",
      "AFter tokenizer:  ['yeah', 'i', 'think', 'my', 'usual', 'guy', \"'s\", 'still', 'passed', 'out', 'from', 'last', 'night', ',', 'if', 'you', 'get', 'ahold', 'of', 'anybody', 'let', 'me', 'know', 'and', 'i', \"'ll\", 'throw', 'down']\n",
      "AFter tokenizer:  ['k', ',', 'i', 'might', 'come', 'by', 'tonight', 'then', 'if', 'my', 'class', 'lets', 'out', 'early']\n",
      "AFter tokenizer:  ['ok', '..']\n",
      "AFter tokenizer:  ['hi', 'baby', 'im', 'cruisin', 'with', 'my', 'girl', 'friend', 'what', 'r', 'u', 'up', '2', '?', 'give', 'me', 'a', 'call', 'in', 'and', 'hour', 'at', 'home', 'if', 'thats', 'alright', 'or', 'fone', 'me', 'on', 'this', 'fone', 'now', 'love', 'jenny', 'xxx']\n",
      "AFter tokenizer:  ['my', 'life', 'means', 'a', 'lot', 'to', 'me', ',', 'not', 'because', 'i', 'love', 'my', 'life', ',', 'but', 'because', 'i', 'love', 'the', 'people', 'in', 'my', 'life', ',', 'the', 'world', 'calls', 'them', 'friends', ',', 'i', 'call', 'them', 'my', 'world', ':', '-', ')', '..', 'ge', ':', '-', ')', '..']\n",
      "AFter tokenizer:  ['dear', ',', 'shall', 'mail', 'tonite.busy', 'in', 'the', 'street', ',', 'shall', 'update', 'you', 'tonite.things', 'are', 'looking', 'ok.varunnathu', 'edukkukayee', 'raksha', 'ollu.but', 'a', 'good', 'one', 'in', 'real', 'sense', '.']\n",
      "AFter tokenizer:  ['hey', 'you', 'told', 'your', 'name', 'to', 'gautham', 'ah', '?']\n",
      "AFter tokenizer:  ['haf', 'u', 'found', 'him', '?', 'i', 'feel', 'so', 'stupid', 'da', 'v', 'cam', 'was', 'working', '.']\n",
      "AFter tokenizer:  ['oops', '.', '4', 'got', 'that', 'bit', '.']\n",
      "AFter tokenizer:  ['are', 'you', 'this', 'much', 'buzy']\n",
      "AFter tokenizer:  ['i', 'accidentally', 'deleted', 'the', 'message', '.', 'resend', 'please', '.']\n",
      "AFter tokenizer:  ['t-mobile', 'customer', 'you', 'may', 'now', 'claim', 'your', 'free', 'camera', 'phone', 'upgrade', '&', 'a', 'pay', '&', 'go', 'sim', 'card', 'for', 'your', 'loyalty', '.', 'call', 'on', '0845', '021', '3680.offer', 'ends', '28thfeb.t', '&', 'c', \"'s\", 'apply']\n",
      "AFter tokenizer:  ['unless', 'it', \"'s\", 'a', 'situation', 'where', 'you', 'go', 'gurl', 'would', 'be', 'more', 'appropriate']\n",
      "AFter tokenizer:  ['hurt', 'me', '...', 'tease', 'me', '...', 'make', 'me', 'cry', '...', 'but', 'in', 'the', 'end', 'of', 'my', 'life', 'when', 'i', 'die', 'plz', 'keep', 'one', 'rose', 'on', 'my', 'grave', 'and', 'say', 'stupid', 'i', 'miss', 'u', '..', 'have', 'a', 'nice', 'day', 'bslvyl']\n",
      "AFter tokenizer:  ['i', 'cant', 'pick', 'the', 'phone', 'right', 'now', '.', 'pls', 'send', 'a', 'message']\n",
      "AFter tokenizer:  ['need', 'a', 'coffee', 'run', 'tomo', '?', 'ca', \"n't\", 'believe', 'it', \"'s\", 'that', 'time', 'of', 'week', 'already']\n",
      "AFter tokenizer:  ['awesome', ',', 'i', 'remember', 'the', 'last', 'time', 'we', 'got', 'somebody', 'high', 'for', 'the', 'first', 'time', 'with', 'diesel', ':', 'v']\n",
      "AFter tokenizer:  ['shit', 'that', 'is', 'really', 'shocking', 'and', 'scary', ',', 'cant', 'imagine', 'for', 'a', 'second', '.', 'def', 'up', 'for', 'night', 'out', '.', 'do', 'u', 'think', 'there', 'is', 'somewhere', 'i', 'could', 'crash', 'for', 'night', ',', 'save', 'on', 'taxi', '?']\n",
      "AFter tokenizer:  ['oh', 'and', 'by', 'the', 'way', 'you', 'do', 'have', 'more', 'food', 'in', 'your', 'fridge', '!', 'want', 'to', 'go', 'out', 'for', 'a', 'meal', 'tonight', '?']\n",
      "AFter tokenizer:  ['he', 'is', 'a', 'womdarfull', 'actor']\n",
      "AFter tokenizer:  ['sms', '.', 'ac', 'blind', 'date', '4u', '!', ':', 'rodds1', 'is', '21/m', 'from', 'aberdeen', ',', 'united', 'kingdom', '.', 'check', 'him', 'out', 'http', ':', '//img', '.', 'sms', '.', 'ac/w/icmb3cktz8r7', '!', '-4', 'no', 'blind', 'dates', 'send', 'hide']\n",
      "AFter tokenizer:  ['yup', '...', 'from', 'what', 'i', 'remb', '...', 'i', 'think', 'should', 'be', 'can', 'book', '...']\n",
      "AFter tokenizer:  ['jos', 'ask', 'if', 'u', 'wana', 'meet', 'up', '?']\n",
      "AFter tokenizer:  ['lol', 'yes', '.', 'our', 'friendship', 'is', 'hanging', 'on', 'a', 'thread', 'cause', 'u', 'wo', \"n't\", 'buy', 'stuff', '.']\n",
      "AFter tokenizer:  ['themob', '>', 'check', 'out', 'our', 'newest', 'selection', 'of', 'content', ',', 'games', ',', 'tones', ',', 'gossip', ',', 'babes', 'and', 'sport', ',', 'keep', 'your', 'mobile', 'fit', 'and', 'funky', 'text', 'wap', 'to', '82468']\n",
      "AFter tokenizer:  ['where', 'are', 'the', 'garage', 'keys', '?', 'they', 'are', \"n't\", 'on', 'the', 'bookshelf']\n",
      "AFter tokenizer:  ['today', 'is', 'accept', 'day', '..', 'u', 'accept', 'me', 'as', '?', 'brother', 'sister', 'lover', 'dear1', 'best1', 'clos1', 'lvblefrnd', 'jstfrnd', 'cutefrnd', 'lifpartnr', 'belovd', 'swtheart', 'bstfrnd', 'no', 'rply', 'means', 'enemy']\n",
      "AFter tokenizer:  ['think', 'ur', 'smart', '?', 'win', '£200', 'this', 'week', 'in', 'our', 'weekly', 'quiz', ',', 'text', 'play', 'to', '85222', 'now', '!', 't', '&', 'cs', 'winnersclub', 'po', 'box', '84', ',', 'm26', '3uz', '.', '16+', '.', 'gbp1.50/week']\n",
      "AFter tokenizer:  ['he', 'says', 'he', \"'ll\", 'give', 'me', 'a', 'call', 'when', 'his', 'friend', \"'s\", 'got', 'the', 'money', 'but', 'that', 'he', \"'s\", 'definitely', 'buying', 'before', 'the', 'end', 'of', 'the', 'week']\n",
      "AFter tokenizer:  ['hi', 'the', 'way', 'i', 'was', 'with', 'u', '2day', ',', 'is', 'the', 'normal', 'way', '&', 'this', 'is', 'the', 'real', 'me', '.', 'ur', 'unique', '&', 'i', 'hope', 'i', 'know', 'u', '4', 'the', 'rest', 'of', 'mylife', '.', 'hope', 'u', 'find', 'wot', 'was', 'lost', '.']\n",
      "AFter tokenizer:  ['you', 'made', 'my', 'day', '.', 'do', 'have', 'a', 'great', 'day', 'too', '.']\n",
      "AFter tokenizer:  ['k.k', ':', ')', 'advance', 'happy', 'pongal', '.']\n",
      "AFter tokenizer:  ['hmmm', '...', 'guess', 'we', 'can', 'go', '4', 'kb', 'n', 'power', 'yoga', '...', 'haha', ',', 'dunno', 'we', 'can', 'tahan', 'power', 'yoga', 'anot', '...', 'thk', 'got', 'lo', 'oso', ',', 'forgot', 'liao', '...']\n",
      "AFter tokenizer:  ['not', 'really', 'dude', ',', 'have', 'no', 'friends', 'i', \"'m\", 'afraid', ':', '(']\n",
      "AFter tokenizer:  ['december', 'only', '!', 'had', 'your', 'mobile', '11mths+', '?', 'you', 'are', 'entitled', 'to', 'update', 'to', 'the', 'latest', 'colour', 'camera', 'mobile', 'for', 'free', '!', 'call', 'the', 'mobile', 'update', 'co', 'free', 'on', '08002986906']\n",
      "AFter tokenizer:  ['coffee', 'cake', ',', 'i', 'guess', '...']\n",
      "AFter tokenizer:  ['merry', 'christmas', 'to', 'you', 'too', 'babe', ',', 'i', 'love', 'ya', '*', 'kisses', '*']\n",
      "AFter tokenizer:  ['hey', '...', 'why', 'dont', 'we', 'just', 'go', 'watch', 'x', 'men', 'and', 'have', 'lunch', '...', 'haha']\n",
      "AFter tokenizer:  ['cud', 'u', 'tell', 'ppl', 'im', 'gona', 'b', 'a', 'bit', 'l8', 'cos', '2', 'buses', 'hav', 'gon', 'past', 'cos', 'they', 'were', 'full', '&', 'im', 'still', 'waitin', '4', '1.', 'pete', 'x']\n",
      "AFter tokenizer:  ['that', 'would', 'be', 'great', '.', 'we', \"'ll\", 'be', 'at', 'the', 'guild', '.', 'could', 'meet', 'on', 'bristol', 'road', 'or', 'somewhere', '-', 'will', 'get', 'in', 'touch', 'over', 'weekend', '.', 'our', 'plans', 'take', 'flight', '!', 'have', 'a', 'good', 'week']\n",
      "AFter tokenizer:  ['no', 'problem', '.', 'how', 'are', 'you', 'doing', '?']\n",
      "AFter tokenizer:  ['hi', 'da', ':', ')', 'how', 'is', 'the', 'todays', 'class', '?']\n",
      "AFter tokenizer:  ['i', \"'d\", 'say', 'that', \"'s\", 'a', 'good', 'sign', 'but', ',', 'well', ',', 'you', 'know', 'my', 'track', 'record', 'at', 'reading', 'women']\n",
      "AFter tokenizer:  ['cool', ',', 'text', 'me', 'when', 'you', \"'re\", 'parked']\n",
      "AFter tokenizer:  ['i', \"'m\", 'reading', 'the', 'text', 'i', 'just', 'sent', 'you', '.', 'its', 'meant', 'to', 'be', 'a', 'joke', '.', 'so', 'read', 'it', 'in', 'that', 'light']\n",
      "AFter tokenizer:  ['k.k', ':', ')', 'apo', 'k.good', 'movie', '.']\n",
      "AFter tokenizer:  ['maybe', 'i', 'could', 'get', 'book', 'out', 'tomo', 'then', 'return', 'it', 'immediately', '..', '?', 'or', 'something', '.']\n",
      "AFter tokenizer:  ['call', 'germany', 'for', 'only', '1', 'pence', 'per', 'minute', '!', 'call', 'from', 'a', 'fixed', 'line', 'via', 'access', 'number', '0844', '861', '85', '85.', 'no', 'prepayment', '.', 'direct', 'access', '!']\n",
      "AFter tokenizer:  ['any', 'chance', 'you', 'might', 'have', 'had', 'with', 'me', 'evaporated', 'as', 'soon', 'as', 'you', 'violated', 'my', 'privacy', 'by', 'stealing', 'my', 'phone', 'number', 'from', 'your', 'employer', \"'s\", 'paperwork', '.', 'not', 'cool', 'at', 'all', '.', 'please', 'do', 'not', 'contact', 'me', 'again', 'or', 'i', 'will', 'report', 'you', 'to', 'your', 'supervisor', '.']\n",
      "AFter tokenizer:  ['valentines', 'day', 'special', '!', 'win', 'over', '£1000', 'in', 'our', 'quiz', 'and', 'take', 'your', 'partner', 'on', 'the', 'trip', 'of', 'a', 'lifetime', '!', 'send', 'go', 'to', '83600', 'now', '.', '150p/msg', 'rcvd', '.', 'custcare:08718720201', '.']\n",
      "AFter tokenizer:  ['ta-daaaaa', '!', 'i', 'am', 'home', 'babe', ',', 'are', 'you', 'still', 'up', '?']\n",
      "AFter tokenizer:  ['cool', '.', 'so', 'how', 'come', 'you', 'havent', 'been', 'wined', 'and', 'dined', 'before', '?']\n",
      "AFter tokenizer:  ['just', 'sleeping', '..', 'and', 'surfing']\n",
      "AFter tokenizer:  ['u', 'calling', 'me', 'right', '?', 'call', 'my', 'hand', 'phone', '...']\n",
      "AFter tokenizer:  ['ok', 'that', \"'s\", 'great', 'thanx', 'a', 'lot', '.']\n",
      "AFter tokenizer:  ['i', 'take', 'it', 'the', 'post', 'has', 'come', 'then', '!', 'you', 'must', 'have', '1000s', 'of', 'texts', 'now', '!', 'happy', 'reading', '.', 'my', 'one', 'from', 'wiv', 'hello', 'caroline', 'at', 'the', 'end', 'is', 'my', 'favourite', '.', 'bless', 'him']\n",
      "AFter tokenizer:  ['where', 'u', 'been', 'hiding', 'stranger', '?']\n",
      "AFter tokenizer:  ['am', 'not', 'interested', 'to', 'do', 'like', 'that', '.']\n",
      "AFter tokenizer:  ['my', 'sister', 'cleared', 'two', 'round', 'in', 'birla', 'soft', 'yesterday', '.']\n",
      "AFter tokenizer:  ['gudnite', '....', 'tc', '...', 'practice', 'going', 'on']\n",
      "AFter tokenizer:  ['dis', 'is', 'yijue', '.', 'i', 'jus', 'saw', 'ur', 'mail', '.', 'in', 'case', 'huiming', 'havent', 'sent', 'u', 'my', 'num', '.', 'dis', 'is', 'my', 'num', '.']\n",
      "AFter tokenizer:  ['one', 'small', 'prestige', 'problem', 'now', '.']\n",
      "AFter tokenizer:  ['fancy', 'a', 'shag', '?', 'i', 'do.interested', '?', 'sextextuk.com', 'txt', 'xxuk', 'suzy', 'to', '69876.', 'txts', 'cost', '1.50', 'per', 'msg', '.', 'tncs', 'on', 'website', '.', 'x']\n",
      "AFter tokenizer:  ['just', 'checking', 'in', 'on', 'you', '.', 'really', 'do', 'miss', 'seeing', 'jeremiah', '.', 'do', 'have', 'a', 'great', 'month']\n",
      "AFter tokenizer:  ['nah', 'ca', \"n't\", 'help', 'you', 'there', ',', 'i', \"'ve\", 'never', 'had', 'an', 'iphone']\n",
      "AFter tokenizer:  ['if', 'you', \"'re\", 'not', 'in', 'my', 'car', 'in', 'an', 'hour', 'and', 'a', 'half', 'i', \"'m\", 'going', 'apeshit']\n",
      "AFter tokenizer:  ['today', 'is', 'sorry', 'day.', '!', 'if', 'ever', 'i', 'was', 'angry', 'with', 'you', ',', 'if', 'ever', 'i', 'misbehaved', 'or', 'hurt', 'you', '?', 'plz', 'plz', 'just', 'slap', 'urself', 'bcoz', ',', 'its', 'ur', 'fault', ',', 'i', \"'m\", 'basically', 'good']\n",
      "AFter tokenizer:  ['yo', 'you', 'guys', 'ever', 'figure', 'out', 'how', 'much', 'we', 'need', 'for', 'alcohol', '?', 'jay', 'and', 'i', 'are', 'trying', 'to', 'figure', 'out', 'how', 'much', 'we', 'can', 'safely', 'spend', 'on', 'weed']\n",
      "AFter tokenizer:  ['&', 'lt', ';', '#', '&', 'gt', ';', 'ish', 'minutes', 'was', '5', 'minutes', 'ago', '.', 'wtf', '.']\n",
      "AFter tokenizer:  ['thank', 'you', 'for', 'calling.forgot', 'to', 'say', 'happy', 'onam', 'to', 'you', 'sirji.i', 'am', 'fine', 'here', 'and', 'remembered', 'you', 'when', 'i', 'met', 'an', 'insurance', 'person.meet', 'you', 'in', 'qatar', 'insha', 'allah.rakhesh', ',', 'ex', 'tata', 'aig', 'who', 'joined', 'tissco', ',', 'tayseer', '.']\n",
      "AFter tokenizer:  ['ur', 'cash-balance', 'is', 'currently', '500', 'pounds', '-', 'to', 'maximize', 'ur', 'cash-in', 'now', 'send', 'cash', 'to', '86688', 'only', '150p/msg', '.', 'cc', ':', '08708800282', 'hg/suite342/2lands', 'row/w1j6hl']\n",
      "AFter tokenizer:  ['i', \"'m\", 'an', 'actor', '.', 'when', 'i', 'work', ',', 'i', 'work', 'in', 'the', 'evening', 'and', 'sleep', 'late', '.', 'since', 'i', \"'m\", 'unemployed', 'at', 'the', 'moment', ',', 'i', 'always', 'sleep', 'late', '.', 'when', 'you', \"'re\", 'unemployed', ',', 'every', 'day', 'is', 'saturday', '.']\n",
      "AFter tokenizer:  ['hello', '!', 'just', 'got', 'here', ',', 'st', 'andrews-boy', 'its', 'a', 'long', 'way', '!', 'its', 'cold', '.', 'i', 'will', 'keep', 'you', 'posted']\n",
      "AFter tokenizer:  ['ha', 'ha', 'cool', 'cool', 'chikku', 'chikku', ':', '-', ')', ':', '-db-', ')']\n",
      "AFter tokenizer:  ['oh', 'ok', 'no', 'prob', '..']\n",
      "AFter tokenizer:  ['check', 'audrey', \"'s\", 'status', 'right', 'now']\n",
      "AFter tokenizer:  ['busy', 'here', '.', 'trying', 'to', 'finish', 'for', 'new', 'year', '.', 'i', 'am', 'looking', 'forward', 'to', 'finally', 'meeting', 'you', '...']\n",
      "AFter tokenizer:  ['good', 'afternoon', 'sunshine', '!', 'how', 'dawns', 'that', 'day', '?', 'are', 'we', 'refreshed', 'and', 'happy', 'to', 'be', 'alive', '?', 'do', 'we', 'breathe', 'in', 'the', 'air', 'and', 'smile', '?', 'i', 'think', 'of', 'you', ',', 'my', 'love', '...', 'as', 'always']\n",
      "AFter tokenizer:  ['well', 'i', 'know', 'z', 'will', 'take', 'care', 'of', 'me', '.', 'so', 'no', 'worries', '.']\n",
      "AFter tokenizer:  ['update_now', '-', 'xmas', 'offer', '!', 'latest', 'motorola', ',', 'sonyericsson', '&', 'nokia', '&', 'free', 'bluetooth', '!', 'double', 'mins', '&', '1000', 'txt', 'on', 'orange', '.', 'call', 'mobileupd8', 'on', '08000839402', 'or', 'call2optout/f4q=']\n",
      "AFter tokenizer:  ['here', 'is', 'your', 'discount', 'code', 'rp176781', '.', 'to', 'stop', 'further', 'messages', 'reply', 'stop', '.', 'www.regalportfolio.co.uk', '.', 'customer', 'services', '08717205546']\n",
      "AFter tokenizer:  ['wat', 'uniform', '?', 'in', 'where', 'get', '?']\n",
      "AFter tokenizer:  ['cool', ',', 'text', 'me', 'when', 'you', \"'re\", 'ready']\n",
      "AFter tokenizer:  ['hello', 'my', 'boytoy', '...', 'geeee', 'i', 'miss', 'you', 'already', 'and', 'i', 'just', 'woke', 'up', '.', 'i', 'wish', 'you', 'were', 'here', 'in', 'bed', 'with', 'me', ',', 'cuddling', 'me', '.', 'i', 'love', 'you', '...']\n",
      "AFter tokenizer:  ['i', 'will', 'spoil', 'you', 'in', 'bed', 'as', 'well', ':', ')']\n",
      "AFter tokenizer:  ['i', \"'m\", 'going', 'for', 'bath', 'will', 'msg', 'you', 'next', '&', 'lt', ';', '#', '&', 'gt', ';', 'min', '..']\n",
      "AFter tokenizer:  ['i', 'cant', 'keep', 'talking', 'to', 'people', 'if', 'am', 'not', 'sure', 'i', 'can', 'pay', 'them', 'if', 'they', 'agree', 'to', 'price', '.', 'so', 'pls', 'tell', 'me', 'what', 'you', 'want', 'to', 'really', 'buy', 'and', 'how', 'much', 'you', 'are', 'willing', 'to', 'pay']\n",
      "AFter tokenizer:  ['thanks', 'for', 'your', 'ringtone', 'order', ',', 'reference', 't91', '.', 'you', 'will', 'be', 'charged', 'gbp', '4', 'per', 'week', '.', 'you', 'can', 'unsubscribe', 'at', 'anytime', 'by', 'calling', 'customer', 'services', 'on', '09057039994']\n",
      "AFter tokenizer:  ['can', 'you', 'say', 'what', 'happen']\n",
      "AFter tokenizer:  ['you', 'could', 'have', 'seen', 'me', '..', 'i', \"did't\", 'recognise', 'you', 'face', '.', ':', ')']\n",
      "AFter tokenizer:  ['well', 'there', \"'s\", 'not', 'a', 'lot', 'of', 'things', 'happening', 'in', 'lindsay', 'on', 'new', 'years', '*', 'sighs', '*', 'some', 'bars', 'in', 'ptbo', 'and', 'the', 'blue', 'heron', 'has', 'something', 'going']\n",
      "AFter tokenizer:  ['keep', 'my', 'payasam', 'there', 'if', 'rinu', 'brings']\n",
      "AFter tokenizer:  ['i', 'taught', 'that', 'ranjith', 'sir', 'called', 'me', '.', 'so', 'only', 'i', 'sms', 'like', 'that', '.', 'becaus', 'hes', 'verifying', 'about', 'project', '.', 'prabu', 'told', 'today', 'so', 'only', 'pa', 'dont', 'mistake', 'me', '..']\n",
      "AFter tokenizer:  ['i', 'guess', 'that', \"'s\", 'why', 'you', 're', 'worried', '.', 'you', 'must', 'know', 'that', 'there', \"'s\", 'a', 'way', 'the', 'body', 'repairs', 'itself', '.', 'and', 'i', \"'m\", 'quite', 'sure', 'you', 'should', \"n't\", 'worry', '.', 'we', \"'ll\", 'take', 'it', 'slow', '.', 'first', 'the', 'tests', ',', 'they', 'will', 'guide', 'when', 'your', 'ovulation', 'is', 'then', 'just', 'relax', '.', 'nothing', 'you', \"'ve\", 'said', 'is', 'a', 'reason', 'to', 'worry', 'but', 'i.ll', 'keep', 'on', 'followin', 'you', 'up', '.']\n",
      "AFter tokenizer:  ['yeah', 'sure', ',', 'give', 'me', 'a', 'couple', 'minutes', 'to', 'track', 'down', 'my', 'wallet']\n",
      "AFter tokenizer:  ['hey', 'leave', 'it', '.', 'not', 'a', 'big', 'deal', ':', '-', ')', 'take', 'care', '.']\n",
      "AFter tokenizer:  ['hey', 'i', 'will', 'be', 'late', 'ah', '...', 'meet', 'you', 'at', '945+']\n",
      "AFter tokenizer:  ['double', 'mins', 'and', 'txts', '4', '6months', 'free', 'bluetooth', 'on', 'orange', '.', 'available', 'on', 'sony', ',', 'nokia', 'motorola', 'phones', '.', 'call', 'mobileupd8', 'on', '08000839402', 'or', 'call2optout/n9dx']\n",
      "AFter tokenizer:  ['it', 'took', 'mr', 'owl', '3', 'licks']\n",
      "AFter tokenizer:  ['customer', 'place', 'i', 'will', 'call', 'you', '.']\n",
      "AFter tokenizer:  ['mm', 'that', 'time', 'you', 'dont', 'like', 'fun']\n",
      "AFter tokenizer:  ['4mths', 'half', 'price', 'orange', 'line', 'rental', '&', 'latest', 'camera', 'phones', '4', 'free', '.', 'had', 'your', 'phone', '11mths', '?', 'call', 'mobilesdirect', 'free', 'on', '08000938767', 'to', 'update', 'now', '!', 'or2stoptxt']\n",
      "AFter tokenizer:  ['yup', 'having', 'my', 'lunch', 'buffet', 'now', '..', 'u', 'eat', 'already', '?']\n",
      "AFter tokenizer:  ['huh', 'so', 'late', '...', 'fr', 'dinner', '?']\n",
      "AFter tokenizer:  ['hey', 'so', 'this', 'sat', 'are', 'we', 'going', 'for', 'the', 'intro', 'pilates', 'only', '?', 'or', 'the', 'kickboxing', 'too', '?']\n",
      "AFter tokenizer:  ['morning', 'only', 'i', 'can', 'ok', '.']\n",
      "AFter tokenizer:  ['yes', 'i', 'think', 'so', '.', 'i', 'am', 'in', 'office', 'but', 'my', 'lap', 'is', 'in', 'room', 'i', 'think', 'thats', 'on', 'for', 'the', 'last', 'few', 'days', '.', 'i', 'didnt', 'shut', 'that', 'down']\n",
      "AFter tokenizer:  ['pick', 'you', 'up', 'bout', '7.30ish', '?', 'what', 'time', 'are', 'and', 'that', 'going', '?']\n",
      "AFter tokenizer:  ['from', 'here', 'after', 'the', 'performance', 'award', 'is', 'calculated', 'every', 'two', 'month.not', 'for', 'current', 'one', 'month', 'period', '..']\n",
      "AFter tokenizer:  ['was', 'actually', 'sleeping', 'and', 'still', 'might', 'when', 'u', 'call', 'back', '.', 'so', 'a', 'text', 'is', 'gr8', '.', 'you', 'rock', 'sis', '.', 'will', 'send', 'u', 'a', 'text', 'wen', 'i', 'wake', '.']\n",
      "AFter tokenizer:  ['you', 'are', 'always', 'putting', 'your', 'business', 'out', 'there', '.', 'you', 'put', 'pictures', 'of', 'your', 'ass', 'on', 'facebook', '.', 'you', 'are', 'one', 'of', 'the', 'most', 'open', 'people', 'i', \"'ve\", 'ever', 'met', '.', 'why', 'would', 'i', 'think', 'a', 'picture', 'of', 'your', 'room', 'would', 'hurt', 'you', ',', 'make', 'you', 'feel', 'violated', '.']\n",
      "AFter tokenizer:  ['good', 'evening', 'sir', ',', 'al', 'salam', 'wahleykkum.sharing', 'a', 'happy', 'news.by', 'the', 'grace', 'of', 'god', ',', 'i', 'got', 'an', 'offer', 'from', 'tayseer', ',', 'tissco', 'and', 'i', 'joined.hope', 'you', 'are', 'fine.inshah', 'allah', ',', 'meet', 'you', 'sometime.rakhesh', ',', 'visitor', 'from', 'india', '.']\n",
      "AFter tokenizer:  ['hmmm', '...', 'k', '...', 'but', 'i', 'want', 'to', 'change', 'the', 'field', 'quickly', 'da', ':', '-', ')', 'i', 'wan', 'na', 'get', 'system', 'administrator', 'or', 'network', 'administrator', '..']\n",
      "AFter tokenizer:  ['free', 'ringtone', 'text', 'first', 'to', '87131', 'for', 'a', 'poly', 'or', 'text', 'get', 'to', '87131', 'for', 'a', 'true', 'tone', '!', 'help', '?', '0845', '2814032', '16', 'after', '1st', 'free', ',', 'tones', 'are', '3x£150pw', 'to', 'e£nd', 'txt', 'stop']\n",
      "AFter tokenizer:  ['dear', 'how', 'is', 'chechi', '.', 'did', 'you', 'talk', 'to', 'her']\n",
      "AFter tokenizer:  ['the', 'hair', 'cream', 'has', 'not', 'been', 'shipped', '.']\n",
      "AFter tokenizer:  ['none', 'of', 'that', \"'s\", 'happening', 'til', 'you', 'get', 'here', 'though']\n",
      "AFter tokenizer:  ['yep', ',', 'the', 'great', 'loxahatchee', 'xmas', 'tree', 'burning', 'of', '&', 'lt', ';', '#', '&', 'gt', ';', 'starts', 'in', 'an', 'hour']\n",
      "AFter tokenizer:  ['haha', 'get', 'used', 'to', 'driving', 'to', 'usf', 'man', ',', 'i', 'know', 'a', 'lot', 'of', 'stoners']\n",
      "AFter tokenizer:  ['all', 'was', 'well', 'until', 'slightly', 'disastrous', 'class', 'this', 'pm', 'with', 'my', 'fav', 'darlings', '!', 'hope', 'day', 'off', 'ok.', 'coffee', 'wld', 'be', 'good', 'as', 'ca', \"n't\", 'stay', 'late', 'tomorrow', '.', 'same', 'time', '+', 'place', 'as', 'always', '?']\n",
      "AFter tokenizer:  ['hello', '!', 'good', 'week', '?', 'fancy', 'a', 'drink', 'or', 'something', 'later', '?']\n",
      "AFter tokenizer:  ['headin', 'towards', 'busetop']\n",
      "AFter tokenizer:  ['message', ':', 'some', 'text', 'missing', '*', 'sender', ':', 'name', 'missing', '*', '*', 'number', 'missing', '*', 'sent', ':', 'date', 'missing', '*', 'missing', 'u', 'a', 'lot', 'thats', 'y', 'everything', 'is', 'missing', 'sent', 'via', 'fullonsms.com']\n",
      "AFter tokenizer:  ['come', 'by', 'our', 'room', 'at', 'some', 'point', 'so', 'we', 'can', 'iron', 'out', 'the', 'plan', 'for', 'this', 'weekend']\n",
      "AFter tokenizer:  ['cos', 'i', 'want', 'it', 'to', 'be', 'your', 'thing']\n",
      "AFter tokenizer:  ['okies', '...', 'i', \"'ll\", 'go', 'yan', 'jiu', 'too', '...', 'we', 'can', 'skip', 'ard', 'oso', ',', 'go', 'cine', 'den', 'go', 'mrt', 'one', ',', 'blah', 'blah', 'blah', '...']\n",
      "AFter tokenizer:  ['bring', 'home', 'some', 'wendy', '=d']\n",
      "AFter tokenizer:  ['100', 'dating', 'service', 'cal', ';', 'l', '09064012103', 'box334sk38ch']\n",
      "AFter tokenizer:  ['whatsup', 'there', '.', 'dont', 'u', 'want', 'to', 'sleep']\n",
      "AFter tokenizer:  ['alright', 'i', 'have', 'a', 'new', 'goal', 'now']\n",
      "AFter tokenizer:  ['free', 'entry', 'into', 'our', '£250', 'weekly', 'competition', 'just', 'text', 'the', 'word', 'win', 'to', '80086', 'now', '.', '18', 't', '&', 'c', 'www.txttowin.co.uk']\n",
      "AFter tokenizer:  ['alright', ',', 'i', \"'ll\", 'head', 'out', 'in', 'a', 'few', 'minutes', ',', 'text', 'me', 'where', 'to', 'meet', 'you']\n",
      "AFter tokenizer:  ['send', 'a', 'logo', '2', 'ur', 'lover', '-', '2', 'names', 'joined', 'by', 'a', 'heart', '.', 'txt', 'love', 'name1', 'name2', 'mobno', 'eg', 'love', 'adam', 'eve', '07123456789', 'to', '87077', 'yahoo', '!', 'pobox36504w45wq', 'txtno', '4', 'no', 'ads', '150p']\n",
      "AFter tokenizer:  ['yes', ':', ')', 'from', 'last', 'week', 'itself', 'i', \"'m\", 'taking', 'live', 'call', '.']\n",
      "AFter tokenizer:  ['someone', 'has', 'contacted', 'our', 'dating', 'service', 'and', 'entered', 'your', 'phone', 'because', 'they', 'fancy', 'you', '!', 'to', 'find', 'out', 'who', 'it', 'is', 'call', 'from', 'a', 'landline', '09111032124', '.', 'pobox12n146tf150p']\n",
      "AFter tokenizer:  ['siva', 'is', 'in', 'hostel', 'aha', ':', '-', '.']\n",
      "AFter tokenizer:  ['urgent', '!', 'your', 'mobile', 'number', 'has', 'been', 'awarded', 'with', 'a', '£2000', 'prize', 'guaranteed', '.', 'call', '09058094455', 'from', 'land', 'line', '.', 'claim', '3030.', 'valid', '12hrs', 'only']\n",
      "AFter tokenizer:  ['send', 'this', 'to', 'ur', 'friends', 'and', 'receive', 'something', 'about', 'ur', 'voice', '.....', 'how', 'is', 'my', 'speaking', 'expression', '?', '1.childish', '2.naughty', '3.sentiment', '4.rowdy', '5.ful', 'of', 'attitude', '6.romantic', '7.shy', '8.attractive', '9.funny', '&', 'lt', ';', '#', '&', 'gt', ';', '.irritating', '&', 'lt', ';', '#', '&', 'gt', ';', '.lovable', '.', 'reply', 'me', '..']\n",
      "AFter tokenizer:  ['ok.', 'she', \"'ll\", 'be', 'ok.', 'i', 'guess']\n",
      "AFter tokenizer:  ['aathi', '..', 'where', 'are', 'you', 'dear', '..']\n",
      "AFter tokenizer:  ['any', 'pain', 'on', 'urination', 'any', 'thing', 'else', '?']\n",
      "AFter tokenizer:  ['7', 'at', 'esplanade', '..', 'do', 'ü', 'mind', 'giving', 'me', 'a', 'lift', 'cos', 'i', 'got', 'no', 'car', 'today', '..']\n",
      "AFter tokenizer:  ['i', 'wnt', 'to', 'buy', 'a', 'bmw', 'car', 'urgently', '..', 'its', 'vry', 'urgent.but', 'hv', 'a', 'shortage', 'of', '&', 'lt', ';', '#', '&', 'gt', ';', 'lacs.there', 'is', 'no', 'source', 'to', 'arng', 'dis', 'amt', '.', '&', 'lt', ';', '#', '&', 'gt', ';', 'lacs', '..', 'thats', 'my', 'prob']\n",
      "AFter tokenizer:  ['at', 'home', 'watching', 'tv', 'lor', '.']\n",
      "AFter tokenizer:  ['does', 'she', 'usually', 'take', 'fifteen', 'fucking', 'minutes', 'to', 'respond', 'to', 'a', 'yes', 'or', 'no', 'question']\n",
      "AFter tokenizer:  ['congrats', '!', 'nokia', '3650', 'video', 'camera', 'phone', 'is', 'your', 'call', '09066382422', 'calls', 'cost', '150ppm', 'ave', 'call', '3mins', 'vary', 'from', 'mobiles', '16+', 'close', '300603', 'post', 'bcm4284', 'ldn', 'wc1n3xx']\n",
      "AFter tokenizer:  ['booked', 'ticket', 'for', 'pongal', '?']\n",
      "AFter tokenizer:  ['you', 'available', 'now', '?', 'i', \"'m\", 'like', 'right', 'around', 'hillsborough', '&', 'amp', ';', '&', 'lt', ';', '#', '&', 'gt', ';', 'th']\n",
      "AFter tokenizer:  ['the', 'message', 'sent', 'is', 'askin', 'for', '&', 'lt', ';', '#', '&', 'gt', ';', 'dollars', '.', 'shoul', 'i', 'pay', '&', 'lt', ';', '#', '&', 'gt', ';', 'or', '&', 'lt', ';', '#', '&', 'gt', ';', '?']\n",
      "AFter tokenizer:  ['ask', 'g', 'or', 'iouri', ',', 'i', \"'ve\", 'told', 'the', 'story', 'like', 'ten', 'times', 'already']\n",
      "AFter tokenizer:  ['how', 'long', 'does', 'applebees', 'fucking', 'take']\n",
      "AFter tokenizer:  ['hi', 'hope', 'u', 'get', 'this', 'txt~journey', 'hasnt', 'been', 'gd', ',', 'now', 'about', '50', 'mins', 'late', 'i', 'think', '.']\n",
      "AFter tokenizer:  ['but', 'i', 'have', 'to', '.', 'i', 'like', 'to', 'have', 'love', 'and', 'arrange', '.']\n",
      "AFter tokenizer:  ['yes', '..', 'he', 'is', 'really', 'great', '..', 'bhaji', 'told', 'kallis', 'best', 'cricketer', 'after', 'sachin', 'in', 'world', ':', ')', '.very', 'tough', 'to', 'get', 'out', '.']\n",
      "AFter tokenizer:  ['you', 'were', 'supposed', 'to', 'wake', 'me', 'up', '&', 'gt', ';', ':', '(']\n",
      "AFter tokenizer:  ['oic', '...', 'i', 'saw', 'him', 'too', 'but', 'i', 'tot', 'he', 'din', 'c', 'me', '...', 'i', 'found', 'a', 'group', 'liao', '...']\n",
      "AFter tokenizer:  ['hey', 'hey', 'werethe', 'monkeespeople', 'say', 'we', 'monkeyaround', '!', 'howdy', 'gorgeous', ',', 'howu', 'doin', '?', 'foundurself', 'a', 'jobyet', 'sausage', '?', 'love', 'jen', 'xxx']\n",
      "AFter tokenizer:  ['sorry', ',', 'my', 'battery', 'died', ',', 'i', 'can', 'come', 'by', 'but', 'i', \"'m\", 'only', 'getting', 'a', 'gram', 'for', 'now', ',', 'where', \"'s\", 'your', 'place', '?']\n",
      "AFter tokenizer:  ['well', 'done', ',', 'blimey', ',', 'exercise', ',', 'yeah', ',', 'i', 'kinda', 'remember', 'wot', 'that', 'is', ',', 'hmm', '.']\n",
      "AFter tokenizer:  ['i', 'wont', 'get', 'concentration', 'dear', 'you', 'know', 'you', 'are', 'my', 'mind', 'and', 'everything', ':', '-', ')']\n",
      "AFter tokenizer:  ['lol', '...', 'have', 'you', 'made', 'plans', 'for', 'new', 'years', '?']\n",
      "AFter tokenizer:  ['10', 'min', 'later', 'k', '...']\n",
      "AFter tokenizer:  ['hanks', 'lotsly', '!']\n",
      "AFter tokenizer:  ['thanks', 'for', 'this', 'hope', 'you', 'had', 'a', 'good', 'day', 'today']\n",
      "AFter tokenizer:  ['k', ':', ')', 'k', ':', ')', 'what', 'are', 'detail', 'you', 'want', 'to', 'transfer', '?', 'acc', 'no', 'enough', '?']\n",
      "AFter tokenizer:  ['ok', 'i', 'will', 'tell', 'her', 'to', 'stay', 'out', '.', 'yeah', 'its', 'been', 'tough', 'but', 'we', 'are', 'optimistic', 'things', 'will', 'improve', 'this', 'month', '.']\n",
      "AFter tokenizer:  ['loan', 'for', 'any', 'purpose', '£500', '-', '£75,000', '.', 'homeowners', '+', 'tenants', 'welcome', '.', 'have', 'you', 'been', 'previously', 'refused', '?', 'we', 'can', 'still', 'help', '.', 'call', 'free', '0800', '1956669', 'or', 'text', 'back', \"'help\", \"'\"]\n",
      "AFter tokenizer:  ['si', 'si', '.', 'i', 'think', 'ill', 'go', 'make', 'those', 'oreo', 'truffles', '.']\n",
      "AFter tokenizer:  ['look', 'at', 'amy', 'ure', 'a', 'beautiful', ',', 'intelligent', 'woman', 'and', 'i', 'like', 'u', 'a', 'lot', '.', 'i', 'know', 'u', 'don\\x92t', 'like', 'me', 'like', 'that', 'so', 'don\\x92t', 'worry', '.']\n",
      "AFter tokenizer:  ['i', 'hope', 'you', 'that', \"'s\", 'the', 'result', 'of', 'being', 'consistently', 'intelligent', 'and', 'kind', '.', 'start', 'asking', 'him', 'about', 'practicum', 'links', 'and', 'keep', 'your', 'ears', 'open', 'and', 'all', 'the', 'best', '.', 'ttyl']\n",
      "AFter tokenizer:  ['1.20', 'that', 'call', 'cost', '.', 'which', 'i', 'guess', 'isnt', 'bad', '.', 'miss', 'ya', ',', 'need', 'ya', ',', 'want', 'ya', ',', 'love', 'ya']\n",
      "AFter tokenizer:  ['going', 'thru', 'a', 'very', 'different', 'feeling.wavering', 'decisions', 'and', 'coping', 'up', 'with', 'the', 'same', 'is', 'the', 'same', 'individual.time', 'will', 'heal', 'everything', 'i', 'believe', '.']\n",
      "AFter tokenizer:  ['where', 'did', 'u', 'go', '?', 'my', 'phone', 'is', 'gon', 'na', 'die', 'you', 'have', 'to', 'stay', 'in', 'here']\n",
      "AFter tokenizer:  ['great', '.', 'never', 'been', 'better', '.', 'each', 'day', 'gives', 'even', 'more', 'reasons', 'to', 'thank', 'god']\n",
      "AFter tokenizer:  ['upgrdcentre', 'orange', 'customer', ',', 'you', 'may', 'now', 'claim', 'your', 'free', 'camera', 'phone', 'upgrade', 'for', 'your', 'loyalty', '.', 'call', 'now', 'on', '0207', '153', '9153.', 'offer', 'ends', '26th', 'july', '.', 't', '&', 'c', \"'s\", 'apply', '.', 'opt-out', 'available']\n",
      "AFter tokenizer:  ['sorry', ',', 'i', \"'ll\", 'call', 'later', 'ok', 'bye']\n",
      "AFter tokenizer:  ['ok', 'i', 'am', 'on', 'the', 'way', 'to', 'railway']\n",
      "AFter tokenizer:  ['great', 'princess', '!', 'i', 'love', 'giving', 'and', 'receiving', 'oral', '.', 'doggy', 'style', 'is', 'my', 'fave', 'position', '.', 'how', 'about', 'you', '?', 'i', 'enjoy', 'making', 'love', '&', 'lt', ';', '#', '&', 'gt', ';', 'times', 'per', 'night', ':', ')']\n",
      "AFter tokenizer:  ['they', 'do', \"n't\", 'put', 'that', 'stuff', 'on', 'the', 'roads', 'to', 'keep', 'it', 'from', 'getting', 'slippery', 'over', 'there', '?']\n",
      "AFter tokenizer:  ['when', 'are', 'you', 'going', 'to', 'ride', 'your', 'bike', '?']\n",
      "AFter tokenizer:  ['yup', ',', 'no', 'need', '.', 'i', \"'ll\", 'jus', 'wait', '4', 'e', 'rain', '2', 'stop', '.']\n",
      "AFter tokenizer:  ['there', 'are', 'many', 'company', '.', 'tell', 'me', 'the', 'language', '.']\n",
      "AFter tokenizer:  ['okmail', ':', 'dear', 'dave', 'this', 'is', 'your', 'final', 'notice', 'to', 'collect', 'your', '4', '*', 'tenerife', 'holiday', 'or', '#', '5000', 'cash', 'award', '!', 'call', '09061743806', 'from', 'landline', '.', 'tcs', 'sae', 'box326', 'cw25wx', '150ppm']\n",
      "AFter tokenizer:  ['how', 'long', 'has', 'it', 'been', 'since', 'you', 'screamed', ',', 'princess', '?']\n",
      "AFter tokenizer:  ['nothing', '.', 'i', 'meant', 'that', 'once', 'the', 'money', 'enters', 'your', 'account', 'here', ',', 'the', 'bank', 'will', 'remove', 'its', 'flat', 'rate', '.', 'someone', 'transfered', '&', 'lt', ';', '#', '&', 'gt', ';', 'to', 'my', 'account', 'and', '&', 'lt', ';', '#', '&', 'gt', ';', 'dollars', 'got', 'removed', '.', 'so', 'the', 'banks', 'differ', 'and', 'charges', 'also', 'differ.be', 'sure', 'you', 'trust', 'the', '9ja', 'person', 'you', 'are', 'sending', 'account', 'details', 'to', 'cos', '...']\n",
      "AFter tokenizer:  ['want', '2', 'get', 'laid', 'tonight', '?', 'want', 'real', 'dogging', 'locations', 'sent', 'direct', '2', 'ur', 'mob', '?', 'join', 'the', 'uk', \"'s\", 'largest', 'dogging', 'network', 'by', 'txting', 'moan', 'to', '69888nyt', '.', 'ec2a', '.', '31p.msg', '@', '150p']\n",
      "AFter tokenizer:  ['nice', 'line', 'said', 'by', 'a', 'broken', 'heart-', 'plz', 'do', \"n't\", 'cum', '1', 'more', 'times', 'infront', 'of', 'me', '...', 'other', 'wise', 'once', 'again', 'i', 'll', 'trust', 'u', '...', 'good', '9t', ':', ')']\n",
      "AFter tokenizer:  ['ok', 'i', \"'m\", 'gon', 'na', 'head', 'up', 'to', 'usf', 'in', 'like', 'fifteen', 'minutes']\n",
      "AFter tokenizer:  ['love', 'you', 'aathi', '..', 'love', 'u', 'lot', '..']\n",
      "AFter tokenizer:  ['tension', 'ah', '?', 'what', 'machi', '?', 'any', 'problem', '?']\n",
      "AFter tokenizer:  ['k', ',', 'can', 'i', 'pick', 'up', 'another', '8th', 'when', 'you', \"'re\", 'done', '?']\n",
      "AFter tokenizer:  ['when', \"'re\", 'you', 'guys', 'getting', 'back', '?', 'g', 'said', 'you', 'were', 'thinking', 'about', 'not', 'staying', 'for', 'mcr']\n",
      "AFter tokenizer:  ['almost', 'there', ',', 'see', 'u', 'in', 'a', 'sec']\n",
      "AFter tokenizer:  ['yo', 'carlos', ',', 'a', 'few', 'friends', 'are', 'already', 'asking', 'me', 'about', 'you', ',', 'you', 'working', 'at', 'all', 'this', 'weekend', '?']\n",
      "AFter tokenizer:  ['watching', 'tv', 'lor', '...']\n",
      "AFter tokenizer:  ['thank', 'you', 'baby', '!', 'i', 'cant', 'wait', 'to', 'taste', 'the', 'real', 'thing', '...']\n",
      "AFter tokenizer:  ['you', 'should', 'change', 'your', 'fb', 'to', 'jaykwon', 'thuglyfe', 'falconerf']\n",
      "AFter tokenizer:  ['if', 'we', 'win', 'its', 'really', 'no', '1', 'side', 'for', 'long', 'time', '.']\n",
      "AFter tokenizer:  ['free', 'message', 'activate', 'your', '500', 'free', 'text', 'messages', 'by', 'replying', 'to', 'this', 'message', 'with', 'the', 'word', 'free', 'for', 'terms', '&', 'conditions', ',', 'visit', 'www.07781482378.com']\n",
      "AFter tokenizer:  ['dear', 'reached', 'railway', '.', 'what', 'happen', 'to', 'you']\n",
      "AFter tokenizer:  ['depends', 'on', 'quality', '.', 'if', 'you', 'want', 'the', 'type', 'i', 'sent', 'boye', ',', 'faded', 'glory', ',', 'then', 'about', '6.', 'if', 'you', 'want', 'ralphs', 'maybe', '2']\n",
      "AFter tokenizer:  ['i', 'think', 'i', \"'ve\", 'fixed', 'it', 'can', 'you', 'send', 'a', 'test', 'message', '?']\n",
      "AFter tokenizer:  ['sorry', 'man', 'my', 'account', \"'s\", 'dry', 'or', 'i', 'would', ',', 'if', 'you', 'want', 'we', 'could', 'trade', 'back', 'half', 'or', 'i', 'could', 'buy', 'some', 'shit', 'with', 'my', 'credit', 'card']\n",
      "AFter tokenizer:  ['sorry', ',', 'in', 'meeting', 'i', \"'ll\", 'call', 'later']\n",
      "AFter tokenizer:  ['what', 'class', 'of', '&', 'lt', ';', '#', '&', 'gt', ';', 'reunion', '?']\n",
      "AFter tokenizer:  ['are', 'you', 'free', 'now', '?', 'can', 'i', 'call', 'now', '?']\n",
      "AFter tokenizer:  ['got', 'meh', '...', 'when', '?']\n",
      "AFter tokenizer:  ['nope', '...', 'think', 'i', 'will', 'go', 'for', 'it', 'on', 'monday', '...', 'sorry', 'i', 'replied', 'so', 'late']\n",
      "AFter tokenizer:  ['some', 'of', 'them', 'told', 'accenture', 'is', 'not', 'confirm', '.', 'is', 'it', 'true', '.']\n",
      "AFter tokenizer:  ['kate', 'jackson', 'rec', 'center', 'before', '7ish', ',', 'right', '?']\n",
      "AFter tokenizer:  ['dear', 'i', 'have', 'reache', 'room']\n",
      "AFter tokenizer:  ['fighting', 'with', 'the', 'world', 'is', 'easy', ',', 'u', 'either', 'win', 'or', 'lose', 'bt', 'fightng', 'with', 'some1', 'who', 'is', 'close', 'to', 'u', 'is', 'dificult', 'if', 'u', 'lose', '-', 'u', 'lose', 'if', 'u', 'win', '-', 'u', 'still', 'lose', '.']\n",
      "AFter tokenizer:  ['when', 'can', 'ü', 'come', 'out', '?']\n",
      "AFter tokenizer:  ['check', 'with', 'nuerologist', '.']\n",
      "AFter tokenizer:  ['lolnice', '.', 'i', 'went', 'from', 'a', 'fish', 'to', '..', 'water', '.', '?']\n",
      "AFter tokenizer:  ['#', 'error', '!']\n",
      "AFter tokenizer:  ['no', 'it', \"'s\", 'waiting', 'in', 'e', 'car', 'dat', \"'s\", 'bored', 'wat', '.', 'cos', 'wait', 'outside', 'got', 'nothing', '2', 'do', '.', 'at', 'home', 'can', 'do', 'my', 'stuff', 'or', 'watch', 'tv', 'wat', '.']\n",
      "AFter tokenizer:  ['maybe', 'westshore', 'or', 'hyde', 'park', 'village', ',', 'the', 'place', 'near', 'my', 'house', '?']\n",
      "AFter tokenizer:  ['you', 'should', 'know', 'now', '.', 'so', 'how', \"'s\", 'anthony', '.', 'are', 'you', 'bringing', 'money', '.', 'i', \"'ve\", 'school', 'fees', 'to', 'pay', 'and', 'rent', 'and', 'stuff', 'like', 'that', '.', 'thats', 'why', 'i', 'need', 'your', 'help', '.', 'a', 'friend', 'in', 'need', '....', '|']\n",
      "AFter tokenizer:  ['what', \"'s\", 'the', 'significance', '?']\n",
      "AFter tokenizer:  ['your', 'opinion', 'about', 'me', '?', '1.', 'over', '2.', 'jada', '3.', 'kusruthi', '4.', 'lovable', '5.', 'silent', '6.', 'spl', 'character', '7.', 'not', 'matured', '8.', 'stylish', '9.', 'simple', 'pls', 'reply', '..']\n",
      "AFter tokenizer:  ['8', 'at', 'the', 'latest', ',', 'g', \"'s\", 'still', 'there', 'if', 'you', 'can', 'scrounge', 'up', 'some', 'ammo', 'and', 'want', 'to', 'give', 'the', 'new', 'ak', 'a', 'try']\n",
      "AFter tokenizer:  ['prabha', '..', 'i', \"'m\", 'soryda', '..', 'realy', '..', 'frm', 'heart', 'i', \"'m\", 'sory']\n",
      "AFter tokenizer:  ['lol', 'ok', 'your', 'forgiven', ':', ')']\n",
      "AFter tokenizer:  ['no', '..', 'jst', 'change', 'tat', 'only', '..']\n",
      "AFter tokenizer:  ['you', 'are', 'guaranteed', 'the', 'latest', 'nokia', 'phone', ',', 'a', '40gb', 'ipod', 'mp3', 'player', 'or', 'a', '£500', 'prize', '!', 'txt', 'word', ':', 'collect', 'to', 'no', ':', '83355', '!', 'ibhltd', 'ldnw15h', '150p/mtmsgrcvd18+']\n",
      "AFter tokenizer:  ['s', ':', ')', 'no', 'competition', 'for', 'him', '.']\n",
      "AFter tokenizer:  ['boltblue', 'tones', 'for', '150p', 'reply', 'poly', '#', 'or', 'mono', '#', 'eg', 'poly3', '1.', 'cha', 'cha', 'slide', '2.', 'yeah', '3.', 'slow', 'jamz', '6.', 'toxic', '8.', 'come', 'with', 'me', 'or', 'stop', '4', 'more', 'tones', 'txt', 'more']\n",
      "AFter tokenizer:  ['your', 'credits', 'have', 'been', 'topped', 'up', 'for', 'http', ':', '//www.bubbletext.com', 'your', 'renewal', 'pin', 'is', 'tgxxrz']\n",
      "AFter tokenizer:  ['that', 'way', 'transport', 'is', 'less', 'problematic', 'than', 'on', 'sat', 'night', '.', 'by', 'the', 'way', ',', 'if', 'u', 'want', 'to', 'ask', 'n', 'to', 'join', 'my', 'bday', ',', 'feel', 'free', '.', 'but', 'need', 'to', 'know', 'definite', 'nos', 'as', 'booking', 'on', 'fri', '.']\n",
      "AFter tokenizer:  ['usually', 'the', 'person', 'is', 'unconscious', 'that', \"'s\", 'in', 'children', 'but', 'in', 'adults', 'they', 'may', 'just', 'behave', 'abnormally', '.', 'i.ll', 'call', 'you', 'now']\n",
      "AFter tokenizer:  ['but', 'that', \"'s\", 'on', 'ebay', 'it', 'might', 'be', 'less', 'elsewhere', '.']\n",
      "AFter tokenizer:  ['shall', 'i', 'come', 'to', 'get', 'pickle']\n",
      "AFter tokenizer:  ['were', 'gon', 'na', 'go', 'get', 'some', 'tacos']\n",
      "AFter tokenizer:  ['that', \"'s\", 'very', 'rude', ',', 'you', 'on', 'campus', '?']\n",
      "AFter tokenizer:  ['urgent', '!', ':', 'your', 'mobile', 'no', '.', 'was', 'awarded', 'a', '£2,000', 'bonus', 'caller', 'prize', 'on', '02/09/03', '!', 'this', 'is', 'our', '2nd', 'attempt', 'to', 'contact', 'you', '!', 'call', '0871-872-9755', 'box95qu']\n",
      "AFter tokenizer:  ['hi', 'i', 'wo', \"n't\", 'b', 'ard', '4', 'christmas', '.', 'but', 'do', 'enjoy', 'n', 'merry', \"x'mas\", '.']\n",
      "AFter tokenizer:  ['today', \"'s\", 'offer', '!', 'claim', 'ur', '£150', 'worth', 'of', 'discount', 'vouchers', '!', 'text', 'yes', 'to', '85023', 'now', '!', 'savamob', ',', 'member', 'offers', 'mobile', '!', 't', 'cs', '08717898035', '.', '£3.00', 'sub', '.', '16', '.', 'unsub', 'reply', 'x']\n",
      "AFter tokenizer:  ['yes', '!', 'how', 'is', 'a', 'pretty', 'lady', 'like', 'you', 'single', '?']\n",
      "AFter tokenizer:  ['you', 'will', 'recieve', 'your', 'tone', 'within', 'the', 'next', '24hrs', '.', 'for', 'terms', 'and', 'conditions', 'please', 'see', 'channel', 'u', 'teletext', 'pg', '750']\n",
      "AFter tokenizer:  ['jay', 'says', 'that', 'you', \"'re\", 'a', 'double-faggot']\n",
      "AFter tokenizer:  ['private', '!', 'your', '2003', 'account', 'statement', 'for', '07815296484', 'shows', '800', 'un-redeemed', 's.i.m', '.', 'points', '.', 'call', '08718738001', 'identifier', 'code', '41782', 'expires', '18/11/04']\n",
      "AFter tokenizer:  ['what', 'today-sunday', '..', 'sunday', 'is', 'holiday', '..', 'so', 'no', 'work', '..']\n",
      "AFter tokenizer:  ['i', \"'ll\", 'be', 'late', '...']\n",
      "AFter tokenizer:  ['i', \"'ve\", 'not', 'called', 'you', 'in', 'a', 'while', '.', 'this', 'is', 'hoping', 'it', 'was', 'l8r', 'malaria', 'and', 'that', 'you', 'know', 'that', 'we', 'miss', 'you', 'guys', '.', 'i', 'miss', 'bani', 'big', ',', 'so', 'pls', 'give', 'her', 'my', 'love', 'especially', '.', 'have', 'a', 'great', 'day', '.']\n",
      "AFter tokenizer:  ['good', 'afternoon', ',', 'my', 'love', '!', 'how', 'goes', 'that', 'day', '?', 'i', 'hope', 'maybe', 'you', 'got', 'some', 'leads', 'on', 'a', 'job', '.', 'i', 'think', 'of', 'you', ',', 'boytoy', 'and', 'send', 'you', 'a', 'passionate', 'kiss', 'from', 'across', 'the', 'sea']\n",
      "AFter tokenizer:  ['probably', 'gon', 'na', 'be', 'here', 'for', 'a', 'while', ',', 'see', 'you', 'later', 'tonight', '&', 'lt', ';', ')']\n",
      "AFter tokenizer:  ['or', 'maybe', 'my', 'fat', 'fingers', 'just', 'press', 'all', 'these', 'buttons', 'and', 'it', 'does', \"n't\", 'know', 'what', 'to', 'do', '.']\n",
      "AFter tokenizer:  ['ummmmmaah', 'many', 'many', 'happy', 'returns', 'of', 'd', 'day', 'my', 'dear', 'sweet', 'heart', '..', 'happy', 'birthday', 'dear']\n",
      "AFter tokenizer:  ['i', 'am', 'in', 'tirupur', 'da', ',', 'once', 'you', 'started', 'from', 'office', 'call', 'me', '.']\n",
      "AFter tokenizer:  ['from', 'www.applausestore.com', 'monthlysubscription', '@', '50p/msg', 'max6/month', 't', '&', 'csc', 'web', 'age16', '2stop', 'txt', 'stop']\n",
      "AFter tokenizer:  ['a', 'famous', 'quote', ':', 'when', 'you', 'develop', 'the', 'ability', 'to', 'listen', 'to', \"'anything\", \"'\", 'unconditionally', 'without', 'losing', 'your', 'temper', 'or', 'self', 'confidence', ',', 'it', 'means', 'you', 'are', '.........', \"'married\", \"'\"]\n",
      "AFter tokenizer:  ['but', 'am', 'going', 'to', 'college', 'pa.', 'what', 'to', 'do', '.', 'are', 'else', 'ill', 'come', 'there', 'it', 'self', '.', 'pa', '.']\n",
      "AFter tokenizer:  ['4', 'oclock', 'at', 'mine', '.', 'just', 'to', 'bash', 'out', 'a', 'flat', 'plan', '.']\n",
      "AFter tokenizer:  ['this', 'girl', 'does', 'not', 'stay', 'in', 'bed', '.', 'this', 'girl', 'does', \"n't\", 'need', 'recovery', 'time', '.', 'id', 'rather', 'pass', 'out', 'while', 'having', 'fun', 'then', 'be', 'cooped', 'up', 'in', 'bed']\n",
      "AFter tokenizer:  ['then', 'any', 'special', 'there', '?']\n",
      "AFter tokenizer:  ['i', 'know', 'but', 'you', 'need', 'to', 'get', 'hotel', 'now', '.', 'i', 'just', 'got', 'my', 'invitation', 'but', 'i', 'had', 'to', 'apologise', '.', 'cali', 'is', 'to', 'sweet', 'for', 'me', 'to', 'come', 'to', 'some', 'english', 'bloke', \"'s\", 'weddin']\n",
      "AFter tokenizer:  ['sorry', 'that', 'took', 'so', 'long', ',', 'omw', 'now']\n",
      "AFter tokenizer:  ['wait', '&', 'lt', ';', '#', '&', 'gt', ';', 'min', '..']\n",
      "AFter tokenizer:  ['ok', 'give', 'me', '5', 'minutes', 'i', 'think', 'i', 'see', 'her', '.', 'btw', 'you', \"'re\", 'my', 'alibi', '.', 'you', 'were', 'cutting', 'my', 'hair', 'the', 'whole', 'time', '.']\n",
      "AFter tokenizer:  ['imagine', 'you', 'finally', 'get', 'to', 'sink', 'into', 'that', 'bath', 'after', 'i', 'have', 'put', 'you', 'through', 'your', 'paces', ',', 'maybe', 'even', 'having', 'you', 'eat', 'me', 'for', 'a', 'while', 'before', 'i', 'left', '...', 'but', 'also', 'imagine', 'the', 'feel', 'of', 'that', 'cage', 'on', 'your', 'cock', 'surrounded', 'by', 'the', 'bath', 'water', ',', 'reminding', 'you', 'always', 'who', 'owns', 'you', '...', 'enjoy', ',', 'my', 'cuck']\n",
      "AFter tokenizer:  ['hurry', 'up', ',', 'i', \"'ve\", 'been', 'weed-deficient', 'for', 'like', 'three', 'days']\n",
      "AFter tokenizer:  ['sure', ',', 'if', 'i', 'get', 'an', 'acknowledgement', 'from', 'you', 'that', 'it', \"'s\", 'astoundingly', 'tactless', 'and', 'generally', 'faggy', 'to', 'demand', 'a', 'blood', 'oath', 'fo']\n",
      "AFter tokenizer:  ['ok.', 'every', 'night', 'take', 'a', 'warm', 'bath', 'drink', 'a', 'cup', 'of', 'milk', 'and', 'you', \"'ll\", 'see', 'a', 'work', 'of', 'magic', '.', 'you', 'still', 'need', 'to', 'loose', 'weight', '.', 'just', 'so', 'that', 'you', 'know']\n",
      "AFter tokenizer:  ['i', '‘', 'll', 'have', 'a', 'look', 'at', 'the', 'frying', 'pan', 'in', 'case', 'it', '‘', 's', 'cheap', 'or', 'a', 'book', 'perhaps', '.', 'no', 'that', '‘', 's', 'silly', 'a', 'frying', 'pan', 'isn', '‘', 't', 'likely', 'to', 'be', 'a', 'book']\n",
      "AFter tokenizer:  ['o.', 'well', 'uv', 'causes', 'mutations', '.', 'sunscreen', 'is', 'like', 'essential', 'thesedays']\n",
      "AFter tokenizer:  ['having', 'lunch', ':', ')', 'you', 'are', 'not', 'in', 'online', '?', 'why', '?']\n",
      "AFter tokenizer:  ['i', 'know', 'that', 'my', 'friend', 'already', 'told', 'that', '.']\n",
      "AFter tokenizer:  ['hi', 'princess', '!', 'thank', 'you', 'for', 'the', 'pics', '.', 'you', 'are', 'very', 'pretty', '.', 'how', 'are', 'you', '?']\n",
      "AFter tokenizer:  ['aiyo', '...', 'u', 'always', 'c', 'our', 'ex', 'one', '...', 'i', 'dunno', 'abt', 'mei', ',', 'she', 'haven', 'reply', '...', 'first', 'time', 'u', 'reply', 'so', 'fast', '...', 'y', 'so', 'lucky', 'not', 'workin', 'huh', ',', 'got', 'bao', 'by', 'ur', 'sugardad', 'ah', '...', 'gee', '..']\n",
      "AFter tokenizer:  ['hi', 'msg', 'me', ':', ')', 'i', \"'m\", 'in', 'office', '..']\n",
      "AFter tokenizer:  ['thanx', '4', 'e', 'brownie', 'it', \"'s\", 'v', 'nice', '...']\n",
      "AFter tokenizer:  ['geeeee', '...', 'i', 'love', 'you', 'so', 'much', 'i', 'can', 'barely', 'stand', 'it']\n",
      "AFter tokenizer:  ['fuck', 'babe', '...', 'i', 'miss', 'you', 'already', ',', 'you', 'know', '?', 'ca', \"n't\", 'you', 'let', 'me', 'send', 'you', 'some', 'money', 'towards', 'your', 'net', '?', 'i', 'need', 'you', '...', 'i', 'want', 'you', '...', 'i', 'crave', 'you', '...']\n",
      "AFter tokenizer:  ['ill', 'call', 'u', '2mrw', 'at', 'ninish', ',', 'with', 'my', 'address', 'that', 'icky', 'american', 'freek', 'wont', 'stop', 'callin', 'me', '2', 'bad', 'jen', 'k', 'eh', '?']\n",
      "AFter tokenizer:  ['oooh', 'bed', 'ridden', 'ey', '?', 'what', 'are', 'you', 'thinking', 'of', '?']\n",
      "AFter tokenizer:  ['so', 'anyways', ',', 'you', 'can', 'just', 'go', 'to', 'your', 'gym', 'or', 'whatever', ',', 'my', 'love', '*', 'smiles', '*', 'i', 'hope', 'your', 'ok', 'and', 'having', 'a', 'good', 'day', 'babe', '...', 'i', 'miss', 'you', 'so', 'much', 'already']\n",
      "AFter tokenizer:  ['love', 'it', '!', 'daddy', 'will', 'make', 'you', 'scream', 'with', 'pleasure', '!', 'i', 'am', 'going', 'to', 'slap', 'your', 'ass', 'with', 'my', 'dick', '!']\n",
      "AFter tokenizer:  ['wot', 'u', 'wan', 'na', 'do', 'then', 'missy', '?']\n",
      "AFter tokenizer:  ['yar', 'lor', 'wait', '4', 'my', 'mum', '2', 'finish', 'sch', 'then', 'have', 'lunch', 'lor', '...', 'i', 'whole', 'morning', 'stay', 'at', 'home', 'clean', 'my', 'room', 'now', 'my', 'room', 'quite', 'clean', '...', 'hee', '...']\n",
      "AFter tokenizer:  ['do', 'you', 'know', 'where', 'my', 'lab', 'goggles', 'went']\n",
      "AFter tokenizer:  ['can', 'you', 'open', 'the', 'door', '?']\n",
      "AFter tokenizer:  ['waiting', 'for', 'your', 'call', '.']\n",
      "AFter tokenizer:  ['nope', 'i', 'waiting', 'in', 'sch', '4', 'daddy', '...']\n",
      "AFter tokenizer:  ['you', 'have', 'won', '?', '1,000', 'cash', 'or', 'a', '?', '2,000', 'prize', '!', 'to', 'claim', ',', 'call09050000327']\n",
      "AFter tokenizer:  ['i', \"'m\", 'tired', 'of', 'arguing', 'with', 'you', 'about', 'this', 'week', 'after', 'week', '.', 'do', 'what', 'you', 'want', 'and', 'from', 'now', 'on', ',', 'i', \"'ll\", 'do', 'the', 'same', '.']\n",
      "AFter tokenizer:  ['ü', 'wait', '4', 'me', 'in', 'sch', 'i', 'finish', 'ard', '5', '..']\n",
      "AFter tokenizer:  ['our', 'mobile', 'number', 'has', 'won', '£5000', ',', 'to', 'claim', 'calls', 'us', 'back', 'or', 'ring', 'the', 'claims', 'hot', 'line', 'on', '09050005321', '.']\n",
      "AFter tokenizer:  ['arngd', 'marriage', 'is', 'while', 'u', 'r', 'walkin', 'unfortuntly', 'a', 'snake', 'bites', 'u.', 'bt', 'love', 'marriage', 'is', 'dancing', 'in', 'frnt', 'of', 'd', 'snake', '&', 'amp', ';', 'sayin', 'bite', 'me', ',', 'bite', 'me', '.']\n",
      "AFter tokenizer:  ['huh', 'so', 'early', '..', 'then', 'ü', 'having', 'dinner', 'outside', 'izzit', '?']\n",
      "AFter tokenizer:  ['ok', 'anyway', 'no', 'need', 'to', 'change', 'with', 'what', 'you', 'said']\n",
      "AFter tokenizer:  ['we', 'tried', 'to', 'contact', 'you', 're', 'your', 'reply', 'to', 'our', 'offer', 'of', '750', 'mins', '150', 'textand', 'a', 'new', 'video', 'phone', 'call', '08002988890', 'now', 'or', 'reply', 'for', 'free', 'delivery', 'tomorrow']\n",
      "AFter tokenizer:  ['my', 'ex-wife', 'was', 'not', 'able', 'to', 'have', 'kids', '.', 'do', 'you', 'want', 'kids', 'one', 'day', '?']\n",
      "AFter tokenizer:  ['so', 'how', \"'s\", 'scotland', '.', 'hope', 'you', 'are', 'not', 'over', 'showing', 'your', 'jjc', 'tendencies', '.', 'take', 'care', '.', 'live', 'the', 'dream']\n",
      "AFter tokenizer:  ['tell', 'them', 'u', 'have', 'a', 'headache', 'and', 'just', 'want', 'to', 'use', '1', 'hour', 'of', 'sick', 'time', '.']\n",
      "AFter tokenizer:  ['i', 'dun', 'thk', 'i', \"'ll\", 'quit', 'yet', '...', 'hmmm', ',', 'can', 'go', 'jazz', '?', 'yogasana', 'oso', 'can', '...', 'we', 'can', 'go', 'meet', 'em', 'after', 'our', 'lessons', 'den', '...']\n",
      "AFter tokenizer:  ['pete', 'can', 'you', 'please', 'ring', 'meive', 'hardly', 'gotany', 'credit']\n",
      "AFter tokenizer:  ['ya', 'srsly', 'better', 'than', 'yi', 'tho']\n",
      "AFter tokenizer:  ['i', \"'m\", 'in', 'a', 'meeting', ',', 'call', 'me', 'later', 'at']\n",
      "AFter tokenizer:  ['for', 'ur', 'chance', 'to', 'win', 'a', '£250', 'wkly', 'shopping', 'spree', 'txt', ':', 'shop', 'to', '80878.', 't', \"'s\", '&', 'c', \"'s\", 'www.txt-2-shop.com', 'custcare', '08715705022', ',', '1x150p/wk']\n",
      "AFter tokenizer:  ['you', 'have', 'been', 'specially', 'selected', 'to', 'receive', 'a', '2000', 'pound', 'award', '!', 'call', '08712402050', 'before', 'the', 'lines', 'close', '.', 'cost', '10ppm', '.', '16+', '.', 't', '&', 'cs', 'apply', '.', 'ag', 'promo']\n",
      "AFter tokenizer:  ['private', '!', 'your', '2003', 'account', 'statement', 'for', '07753741225', 'shows', '800', 'un-redeemed', 's.', 'i.', 'm.', 'points', '.', 'call', '08715203677', 'identifier', 'code', ':', '42478', 'expires', '24/10/04']\n",
      "AFter tokenizer:  ['you', 'still', 'at', 'grand', 'prix', '?']\n",
      "AFter tokenizer:  ['i', 'met', 'you', 'as', 'a', 'stranger', 'and', 'choose', 'you', 'as', 'my', 'friend', '.', 'as', 'long', 'as', 'the', 'world', 'stands', ',', 'our', 'friendship', 'never', 'ends', '.', 'lets', 'be', 'friends', 'forever', '!', '!', '!', 'gud', 'nitz', '...']\n",
      "AFter tokenizer:  ['i', 'am', 'great', '!', 'how', 'are', 'you', '?']\n",
      "AFter tokenizer:  ['gud', 'mrng', 'dear', 'have', 'a', 'nice', 'day']\n",
      "AFter tokenizer:  ['you', 'have', 'an', 'important', 'customer', 'service', 'announcement', '.', 'call', 'freephone', '0800', '542', '0825', 'now', '!']\n",
      "AFter tokenizer:  ['will', 'do', '.', 'was', 'exhausted', 'on', 'train', 'this', 'morning', '.', 'too', 'much', 'wine', 'and', 'pie', '.', 'you', 'sleep', 'well', 'too']\n",
      "AFter tokenizer:  ['i', \"'m\", 'going', 'out', 'to', 'buy', 'mum', \"'s\", 'present', 'ar', '.']\n",
      "AFter tokenizer:  ['mind', 'blastin', '..', 'no', 'more', 'tsunamis', 'will', 'occur', 'from', 'now', 'on', '..', 'rajnikant', 'stopped', 'swimming', 'in', 'indian', 'ocean', '..', ':', '-d']\n",
      "AFter tokenizer:  ['if', 'u', 'sending', 'her', 'home', 'first', 'it', \"'s\", 'ok', 'lor', '.', 'i', \"'m\", 'not', 'ready', 'yet', '.']\n",
      "AFter tokenizer:  ['speaking', 'of', 'does', 'he', 'have', 'any', 'cash', 'yet', '?']\n",
      "AFter tokenizer:  ['be', 'happy', 'there', '.', 'i', 'will', 'come', 'after', 'noon']\n",
      "AFter tokenizer:  ['meet', 'after', 'lunch', 'la', '...']\n",
      "AFter tokenizer:  ['take', 'care', 'n', 'get', 'well', 'soon']\n",
      "AFter tokenizer:  ['xclusive', '@', 'clubsaisai', '2morow', '28/5', 'soiree', 'speciale', 'zouk', 'with', 'nichols', 'from', 'paris.free', 'roses', '2', 'all', 'ladies', '!', '!', '!', 'info', ':', '07946746291/07880867867']\n",
      "AFter tokenizer:  ['what', 'i', 'meant', 'to', 'say', 'is', 'cant', 'wait', 'to', 'see', 'u', 'again', 'getting', 'bored', 'of', 'this', 'bridgwater', 'banter']\n",
      "AFter tokenizer:  ['neva', 'mind', 'it', \"'s\", 'ok', '..']\n",
      "AFter tokenizer:  ['it', \"'s\", 'fine', ',', 'imma', 'get', 'a', 'drink', 'or', 'somethin', '.', 'want', 'me', 'to', 'come', 'find', 'you', '?']\n",
      "AFter tokenizer:  ['22', 'days', 'to', 'kick', 'off', '!', 'for', 'euro2004', 'u', 'will', 'be', 'kept', 'up', 'to', 'date', 'with', 'the', 'latest', 'news', 'and', 'results', 'daily', '.', 'to', 'be', 'removed', 'send', 'get', 'txt', 'stop', 'to', '83222']\n",
      "AFter tokenizer:  ['its', 'a', 'valentine', 'game', '.', '.', '.', 'send', 'dis', 'msg', 'to', 'all', 'ur', 'friends', '.', '..', 'if', '5', 'answers', 'r', 'd', 'same', 'then', 'someone', 'really', 'loves', 'u.', 'ques-', 'which', 'colour', 'suits', 'me', 'the', 'best', '?', 'rply', 'me']\n",
      "AFter tokenizer:  ['i', 'have', 'many', 'dependents']\n",
      "AFter tokenizer:  ['thanx4', 'today', 'cer', 'it', 'was', 'nice', '2', 'catch', 'up', 'but', 'we', 'ave', '2', 'find', 'more', 'time', 'more', 'often', 'oh', 'well', 'take', 'care', 'c', 'u', 'soon.c']\n",
      "AFter tokenizer:  ['i', 'called', 'and', 'said', 'all', 'to', 'him', ':', ')', 'then', 'he', 'have', 'to', 'choose', 'this', 'future', '.']\n",
      "AFter tokenizer:  ['happy', 'valentines', 'day', 'i', 'know', 'its', 'early', 'but', 'i', 'have', 'hundreds', 'of', 'handsomes', 'and', 'beauties', 'to', 'wish', '.', 'so', 'i', 'thought', 'to', 'finish', 'off', 'aunties', 'and', 'uncles', '1st', '...']\n",
      "AFter tokenizer:  ['he', 'like', 'not', 'v', 'shock', 'leh', '.', 'cos', 'telling', 'shuhui', 'is', 'like', 'telling', 'leona', 'also', '.', 'like', 'dat', 'almost', 'all', 'know', 'liao', '.', 'he', 'got', 'ask', 'me', 'abt', 'ur', 'reaction', 'lor', '.']\n",
      "AFter tokenizer:  ['for', 'my', 'family', 'happiness', '..']\n",
      "AFter tokenizer:  ['i', 'come', 'n', 'pick', 'ü', 'up', '...', 'come', 'out', 'immediately', 'aft', 'ur', 'lesson', '...']\n",
      "AFter tokenizer:  ['let', 'there', 'be', 'snow', '.', 'let', 'there', 'be', 'snow', '.', 'this', 'kind', 'of', 'weather', 'brings', 'ppl', 'together', 'so', 'friendships', 'can', 'grow', '.']\n",
      "AFter tokenizer:  ['dear', 'we', 'got', '&', 'lt', ';', '#', '&', 'gt', ';', 'dollars', 'hi', 'hi']\n",
      "AFter tokenizer:  ['good', 'words', '....', 'but', 'words', 'may', 'leave', 'u', 'in', 'dismay', 'many', 'times', '.']\n",
      "AFter tokenizer:  ['make', 'sure', 'alex', 'knows', 'his', 'birthday', 'is', 'over', 'in', 'fifteen', 'minutes', 'as', 'far', 'as', 'you', \"'re\", 'concerned']\n",
      "AFter tokenizer:  ['sorry', ',', 'no', ',', 'have', 'got', 'few', 'things', 'to', 'do', '.', 'may', 'be', 'in', 'pub', 'later', '.']\n",
      "AFter tokenizer:  ['nah', 'it', \"'s\", 'straight', ',', 'if', 'you', 'can', 'just', 'bring', 'bud', 'or', 'drinks', 'or', 'something', 'that', \"'s\", 'actually', 'a', 'little', 'more', 'useful', 'than', 'straight', 'cash']\n",
      "AFter tokenizer:  ['haha', 'good', 'to', 'hear', ',', 'i', \"'m\", 'officially', 'paid', 'and', 'on', 'the', 'market', 'for', 'an', '8th']\n",
      "AFter tokenizer:  ['how', 'many', 'licks', 'does', 'it', 'take', 'to', 'get', 'to', 'the', 'center', 'of', 'a', 'tootsie', 'pop', '?']\n",
      "AFter tokenizer:  ['yup', 'i', 'thk', 'they', 'r', 'e', 'teacher', 'said', 'that', 'will', 'make', 'my', 'face', 'look', 'longer', '.', 'darren', 'ask', 'me', 'not', '2', 'cut', 'too', 'short', '.']\n",
      "AFter tokenizer:  ['new', 'textbuddy', 'chat', '2', 'horny', 'guys', 'in', 'ur', 'area', '4', 'just', '25p', 'free', '2', 'receive', 'search', 'postcode', 'or', 'at', 'gaytextbuddy.com', '.', 'txt', 'one', 'name', 'to', '89693']\n",
      "AFter tokenizer:  ['todays', 'vodafone', 'numbers', 'ending', 'with', '4882', 'are', 'selected', 'to', 'a', 'receive', 'a', '£350', 'award', '.', 'if', 'your', 'number', 'matches', 'call', '09064019014', 'to', 'receive', 'your', '£350', 'award', '.']\n",
      "AFter tokenizer:  ['please', 'dont', 'say', 'like', 'that', '.', 'hi', 'hi', 'hi']\n",
      "AFter tokenizer:  ['thank', 'u', '!']\n",
      "AFter tokenizer:  ['oh', 'that', 'was', 'a', 'forwarded', 'message', '.', 'i', 'thought', 'you', 'send', 'that', 'to', 'me']\n",
      "AFter tokenizer:  ['got', 'it', '.', 'seventeen', 'pounds', 'for', 'seven', 'hundred', 'ml', '–', 'hope', 'ok', '.']\n",
      "AFter tokenizer:  ['dear', 'voucher', 'holder', ',', '2', 'claim', 'this', 'weeks', 'offer', ',', 'at', 'your', 'pc', 'go', 'to', 'http', ':', '//www.e-tlp.co.uk/expressoffer', 'ts', '&', 'cs', 'apply.2', 'stop', 'texts', 'txt', 'stop', 'to', '80062', '.']\n",
      "AFter tokenizer:  ['me', 'n', 'him', 'so', 'funny', '...']\n",
      "AFter tokenizer:  ['sweetheart', ',', 'hope', 'you', 'are', 'not', 'having', 'that', 'kind', 'of', 'day', '!', 'have', 'one', 'with', 'loads', 'of', 'reasons', 'to', 'smile', '.', 'biola']\n",
      "AFter tokenizer:  ['when', 'ü', 'login', 'dat', 'time', '...', 'dad', 'fetching', 'ü', 'home', 'now', '?']\n",
      "AFter tokenizer:  ['what', 'will', 'we', 'do', 'in', 'the', 'shower', ',', 'baby', '?']\n",
      "AFter tokenizer:  ['i', 'had', 'askd', 'u', 'a', 'question', 'some', 'hours', 'before', '.', 'its', 'answer']\n",
      "AFter tokenizer:  ['well', 'imma', 'definitely', 'need', 'to', 'restock', 'before', 'thanksgiving', ',', 'i', \"'ll\", 'let', 'you', 'know', 'when', 'i', \"'m\", 'out']\n",
      "AFter tokenizer:  ['said', 'kiss', ',', 'kiss', ',', 'i', 'ca', \"n't\", 'do', 'the', 'sound', 'effects', '!', 'he', 'is', 'a', 'gorgeous', 'man', 'is', \"n't\", 'he', '!', 'kind', 'of', 'person', 'who', 'needs', 'a', 'smile', 'to', 'brighten', 'his', 'day', '!']\n",
      "AFter tokenizer:  ['probably', 'gon', 'na', 'swing', 'by', 'in', 'a', 'wee', 'bit']\n",
      "AFter tokenizer:  ['ya', 'very', 'nice', '.', '.', '.be', 'ready', 'on', 'thursday']\n",
      "AFter tokenizer:  ['allo', '!', 'we', 'have', 'braved', 'the', 'buses', 'and', 'taken', 'on', 'the', 'trains', 'and', 'triumphed', '.', 'i', 'mean', 'we', '‘', 're', 'in', 'b', '‘', 'ham', '.', 'have', 'a', 'jolly', 'good', 'rest', 'of', 'week']\n",
      "AFter tokenizer:  ['watching', 'cartoon', ',', 'listening', 'music', '&', 'amp', ';', 'at', 'eve', 'had', 'to', 'go', 'temple', '&', 'amp', ';', 'church', '..', 'what', 'about', 'u', '?']\n",
      "AFter tokenizer:  ['do', 'you', 'mind', 'if', 'i', 'ask', 'what', 'happened', '?', 'you', 'dont', 'have', 'to', 'say', 'if', 'it', 'is', 'uncomfortable', '.']\n",
      "AFter tokenizer:  ['private', '!', 'your', '2003', 'account', 'statement', 'for', 'shows', '800', 'un-redeemed', 's.', 'i.', 'm.', 'points', '.', 'call', '08715203694', 'identifier', 'code', ':', '40533', 'expires', '31/10/04']\n",
      "AFter tokenizer:  ['no', 'prob', '.', 'i', 'will', 'send', 'to', 'your', 'email', '.']\n",
      "AFter tokenizer:  ['you', 'have', 'won', '?', '1,000', 'cash', 'or', 'a', '?', '2,000', 'prize', '!', 'to', 'claim', ',', 'call09050000327', '.', 't', '&', 'c', ':', 'rstm', ',', 'sw7', '3ss', '.', '150ppm']\n",
      "AFter tokenizer:  ['thats', 'cool', '!', 'sometimes', 'slow', 'and', 'gentle', '.', 'sonetimes', 'rough', 'and', 'hard', ':', ')']\n",
      "AFter tokenizer:  ['i', \"'m\", 'gon', 'na', 'say', 'no', '.', 'sorry', '.', 'i', 'would', 'but', 'as', 'normal', 'am', 'starting', 'to', 'panic', 'about', 'time', '.', 'sorry', 'again', '!', 'are', 'you', 'seeing', 'on', 'tuesday', '?']\n",
      "AFter tokenizer:  ['wait', ',', 'do', 'you', 'know', 'if', 'wesleys', 'in', 'town', '?', 'i', 'bet', 'she', 'does', 'hella', 'drugs', '!']\n",
      "AFter tokenizer:  ['fine', 'i', 'miss', 'you', 'very', 'much', '.']\n",
      "AFter tokenizer:  ['tell', 'them', 'the', 'drug', 'dealer', \"'s\", 'getting', 'impatient']\n",
      "AFter tokenizer:  ['sun', 'cant', 'come', 'to', 'earth', 'but', 'send', 'luv', 'as', 'rays', '.', 'cloud', 'cant', 'come', 'to', 'river', 'but', 'send', 'luv', 'as', 'rain', '.', 'i', 'cant', 'come', 'to', 'meet', 'u', ',', 'but', 'can', 'send', 'my', 'care', 'as', 'msg', 'to', 'u.', 'gud', 'evng']\n",
      "AFter tokenizer:  ['it', 'doesnt', 'make', 'sense', 'to', 'take', 'it', 'there', 'unless', 'its', 'free', '.', 'if', 'you', 'need', 'to', 'know', 'more', ',', 'wikipedia.com']\n",
      "AFter tokenizer:  ['88800', 'and', '89034', 'are', 'premium', 'phone', 'services', 'call', '08718711108']\n",
      "AFter tokenizer:  ['under', 'the', 'sea', ',', 'there', 'lays', 'a', 'rock', '.', 'in', 'the', 'rock', ',', 'there', 'is', 'an', 'envelope', '.', 'in', 'the', 'envelope', ',', 'there', 'is', 'a', 'paper', '.', 'on', 'the', 'paper', ',', 'there', 'are', '3', 'words', '...', \"'\"]\n",
      "AFter tokenizer:  ['then', 'mum', \"'s\", 'repent', 'how', '?']\n",
      "AFter tokenizer:  ['sorry', 'me', 'going', 'home', 'first', '...', 'daddy', 'come', 'fetch', 'ü', 'later', '...']\n",
      "AFter tokenizer:  ['leave', 'it', 'de', ':', '-', ')', '.', 'start', 'prepare', 'for', 'next', ':', '-', ')', '..']\n",
      "AFter tokenizer:  ['yes', 'baby', '!', 'we', 'can', 'study', 'all', 'the', 'positions', 'of', 'the', 'kama', 'sutra', ';', ')']\n",
      "AFter tokenizer:  ['en', 'chikku', 'nange', 'bakra', 'msg', 'kalstiya', '..', 'then', 'had', 'tea/coffee', '?']\n",
      "AFter tokenizer:  ['carlos', \"'ll\", 'be', 'here', 'in', 'a', 'minute', 'if', 'you', 'still', 'need', 'to', 'buy']\n",
      "AFter tokenizer:  ['this', 'pay', 'is', '&', 'lt', ';', 'decimal', '&', 'gt', ';', 'lakhs', ':', ')']\n",
      "AFter tokenizer:  ['have', 'a', 'good', 'evening', '!', 'ttyl']\n",
      "AFter tokenizer:  ['did', 'u', 'receive', 'my', 'msg', '?']\n",
      "AFter tokenizer:  ['ho', 'ho', '-', 'big', 'belly', 'laugh', '!', 'see', 'ya', 'tomo']\n",
      "AFter tokenizer:  ['sms', '.', 'ac', 'sun0819', 'posts', 'hello', ':', \"''\", 'you', 'seem', 'cool', ',', 'wanted', 'to', 'say', 'hi', '.', 'hi', '!', '!', '!', \"''\", 'stop', '?', 'send', 'stop', 'to', '62468']\n",
      "AFter tokenizer:  ['get', 'ur', '1st', 'ringtone', 'free', 'now', '!', 'reply', 'to', 'this', 'msg', 'with', 'tone', '.', 'gr8', 'top', '20', 'tones', 'to', 'your', 'phone', 'every', 'week', 'just', '£1.50', 'per', 'wk', '2', 'opt', 'out', 'send', 'stop', '08452810071', '16']\n",
      "AFter tokenizer:  ['ditto', '.', 'and', 'you', 'wo', \"n't\", 'have', 'to', 'worry', 'about', 'me', 'saying', 'anything', 'to', 'you', 'anymore', '.', 'like', 'i', 'said', 'last', 'night', ',', 'you', 'do', 'whatever', 'you', 'want', 'and', 'i', \"'ll\", 'do', 'the', 'same', '.', 'peace', '.']\n",
      "AFter tokenizer:  ['i', \"'ve\", 'got', '&', 'lt', ';', '#', '&', 'gt', ';', ',', 'any', 'way', 'i', 'could', 'pick', 'up', '?']\n",
      "AFter tokenizer:  ['i', 'dont', 'knw', 'pa', ',', 'i', 'just', 'drink', 'milk', '..']\n",
      "AFter tokenizer:  ['maybe', '?', '!', 'say', 'hi', 'to', 'and', 'find', 'out', 'if', 'got', 'his', 'card', '.', 'great', 'escape', 'or', 'wetherspoons', '?']\n",
      "AFter tokenizer:  ['piggy', ',', 'r', 'u', 'awake', '?', 'i', 'bet', 'u', \"'re\", 'still', 'sleeping', '.', 'i', \"'m\", 'going', '4', 'lunch', 'now', '...']\n",
      "AFter tokenizer:  ['cause', 'i', \"'m\", 'not', 'freaky', 'lol']\n",
      "AFter tokenizer:  ['missed', 'your', 'call', 'cause', 'i', 'was', 'yelling', 'at', 'scrappy', '.', 'miss', 'u.', 'ca', \"n't\", 'wait', 'for', 'u', 'to', 'come', 'home', '.', 'i', \"'m\", 'so', 'lonely', 'today', '.']\n",
      "AFter tokenizer:  ['what', 'is', 'this', \"'hex\", \"'\", 'place', 'you', 'talk', 'of', '?', 'explain', '!']\n",
      "AFter tokenizer:  ['ü', 'log', 'off', '4', 'wat', '.', 'it', \"'s\", 'sdryb8i']\n",
      "AFter tokenizer:  ['is', 'xy', 'going', '4', 'e', 'lunch', '?']\n",
      "AFter tokenizer:  ['hi', 'i', \"'m\", 'sue', '.', 'i', 'am', '20', 'years', 'old', 'and', 'work', 'as', 'a', 'lapdancer', '.', 'i', 'love', 'sex', '.', 'text', 'me', 'live', '-', 'i', \"'m\", 'i', 'my', 'bedroom', 'now', '.', 'text', 'sue', 'to', '89555.', 'by', 'textoperator', 'g2', '1da', '150ppmsg', '18+']\n",
      "AFter tokenizer:  ['i', 'wanted', 'to', 'ask', 'ü', 'to', 'wait', '4', 'me', 'to', 'finish', 'lect', '.', 'cos', 'my', 'lect', 'finishes', 'in', 'an', 'hour', 'anyway', '.']\n",
      "AFter tokenizer:  ['have', 'you', 'finished', 'work', 'yet', '?', ':', ')']\n",
      "AFter tokenizer:  ['every', 'king', 'was', 'once', 'a', 'crying', 'baby', 'and', 'every', 'great', 'building', 'was', 'once', 'a', 'map', '..', 'not', 'imprtant', 'where', 'u', 'r', 'today', ',', 'but', 'where', 'u', 'wil', 'reach', 'tomorw', '.', 'gud', 'ni8']\n",
      "AFter tokenizer:  ['dear', ',', 'me', 'at', 'cherthala.in', 'case', 'u', 'r', 'coming', 'cochin', 'pls', 'call', 'bfore', 'u', 'start.i', 'shall', 'also', 'reach', 'accordingly.or', 'tell', 'me', 'which', 'day', 'u', 'r', 'coming.tmorow', 'i', 'am', 'engaged', 'ans', 'its', 'holiday', '.']\n",
      "AFter tokenizer:  ['thanks', 'love', '.', 'but', 'am', 'i', 'doing', 'torch', 'or', 'bold', '.']\n",
      "AFter tokenizer:  ['<', 'forwarded', 'from', '448712404000', '>', 'please', 'call', '08712404000', 'immediately', 'as', 'there', 'is', 'an', 'urgent', 'message', 'waiting', 'for', 'you', '.']\n",
      "AFter tokenizer:  ['was', 'the', 'farm', 'open', '?']\n",
      "AFter tokenizer:  ['sorry', 'to', 'trouble', 'u', 'again', '.', 'can', 'buy', '4d', 'for', 'my', 'dad', 'again', '?', '1405', ',', '1680', ',', '1843.', 'all', '2', 'big', '1', 'small', ',', 'sat', 'n', 'sun', '.', 'thanx', '.']\n",
      "AFter tokenizer:  ['my', 'sister', 'in', 'law', ',', 'hope', 'you', 'are', 'having', 'a', 'great', 'month', '.', 'just', 'saying', 'hey', '.', 'abiola']\n",
      "AFter tokenizer:  ['will', 'purchase', 'd', 'stuff', 'today', 'and', 'mail', 'to', 'you', '.', 'do', 'you', 'have', 'a', 'po', 'box', 'number', '?']\n",
      "AFter tokenizer:  ['ah', 'poop', '.', 'looks', 'like', 'ill', 'prob', 'have', 'to', 'send', 'in', 'my', 'laptop', 'to', 'get', 'fixed', 'cuz', 'it', 'has', 'a', 'gpu', 'problem']\n",
      "AFter tokenizer:  ['good', '.', 'good', 'job', '.', 'i', 'like', 'entrepreneurs']\n",
      "AFter tokenizer:  ['aight', ',', 'you', 'close', 'by', 'or', 'still', 'down', 'around', 'alex', \"'s\", 'place', '?']\n",
      "AFter tokenizer:  ['meet', 'you', 'in', 'corporation', 'st', 'outside', 'gap', '…', 'you', 'can', 'see', 'how', 'my', 'mind', 'is', 'working', '!']\n",
      "AFter tokenizer:  ['mum', 'ask', 'ü', 'to', 'buy', 'food', 'home', '...']\n",
      "AFter tokenizer:  ['k', '..', 'u', 'also', 'dont', 'msg', 'or', 'reply', 'to', 'his', 'msg', '..']\n",
      "AFter tokenizer:  ['how', 'much', 'r', 'ü', 'willing', 'to', 'pay', '?']\n",
      "AFter tokenizer:  ['what', 'is', 'important', 'is', 'that', 'you', 'prevent', 'dehydration', 'by', 'giving', 'her', 'enough', 'fluids']\n",
      "AFter tokenizer:  ['thats', 'a', 'bit', 'weird', ',', 'even', '?', '-', 'where', 'is', 'the', 'do', 'supposed', 'to', 'be', 'happening', '?', 'but', 'good', 'idea', ',', 'sure', 'they', 'will', 'be', 'in', 'pub', '!']\n",
      "AFter tokenizer:  ['true', 'dear', '..', 'i', 'sat', 'to', 'pray', 'evening', 'and', 'felt', 'so.so', 'i', 'sms', \"'d\", 'you', 'in', 'some', 'time', '...']\n",
      "AFter tokenizer:  ['i', 'do', \"n't\", 'think', 'i', 'can', 'get', 'away', 'for', 'a', 'trek', 'that', 'long', 'with', 'family', 'in', 'town', ',', 'sorry']\n",
      "AFter tokenizer:  ['so', 'when', 'do', 'you', 'wan', 'na', 'gym', 'harri']\n",
      "AFter tokenizer:  ['quite', 'late', 'lar', '...', 'ard', '12', 'anyway', 'i', 'wun', 'b', 'drivin', '...']\n",
      "AFter tokenizer:  ['to', 'review', 'and', 'keep', 'the', 'fantastic', 'nokia', 'n-gage', 'game', 'deck', 'with', 'club', 'nokia', ',', 'go', '2', 'www.cnupdates.com/newsletter', '.', 'unsubscribe', 'from', 'alerts', 'reply', 'with', 'the', 'word', 'out']\n",
      "AFter tokenizer:  ['4mths', 'half', 'price', 'orange', 'line', 'rental', '&', 'latest', 'camera', 'phones', '4', 'free', '.', 'had', 'your', 'phone', '11mths+', '?', 'call', 'mobilesdirect', 'free', 'on', '08000938767', 'to', 'update', 'now', '!', 'or2stoptxt', 't', '&', 'cs']\n",
      "AFter tokenizer:  ['height', 'of', 'confidence', ':', 'all', 'the', 'aeronautics', 'professors', 'wer', 'calld', '&', 'amp', ';', 'they', 'wer', 'askd', '2', 'sit', 'in', 'an', 'aeroplane', '.', 'aftr', 'they', 'sat', 'they', 'wer', 'told', 'dat', 'the', 'plane', 'ws', 'made', 'by', 'their', 'students', '.', 'dey', 'all', 'hurried', 'out', 'of', 'd', 'plane', '..', 'bt', 'only', '1', 'didnt', 'move', '...', 'he', 'said', ':', \"''\", 'if', 'it', 'is', 'made', 'by', 'my', 'students', ',', 'this', 'wont', 'even', 'start', '........', 'datz', 'confidence', '..']\n",
      "AFter tokenizer:  ['it', 'just', 'seems', 'like', 'weird', 'timing', 'that', 'the', 'night', 'that', 'all', 'you', 'and', 'g', 'want', 'is', 'for', 'me', 'to', 'come', 'smoke', 'is', 'the', 'same', 'day', 'as', 'when', 'a', 'shitstorm', 'is', 'attributed', 'to', 'me', 'always', 'coming', 'over', 'and', 'making', 'everyone', 'smoke']\n",
      "AFter tokenizer:  ['08714712388', 'between', '10am-7pm', 'cost', '10p']\n",
      "AFter tokenizer:  ['save', 'yourself', 'the', 'stress', '.', 'if', 'the', 'person', 'has', 'a', 'dorm', 'account', ',', 'just', 'send', 'your', 'account', 'details', 'and', 'the', 'money', 'will', 'be', 'sent', 'to', 'you', '.']\n",
      "AFter tokenizer:  ['he', 'also', 'knows', 'about', 'lunch', 'menu', 'only', 'da', '.', '.', 'i', 'know']\n",
      "AFter tokenizer:  ['when', 'i', 'have', 'stuff', 'to', 'sell', 'i.ll', 'tell', 'you']\n",
      "AFter tokenizer:  ['book', 'which', 'lesson', '?', 'then', 'you', 'msg', 'me', '...', 'i', 'will', 'call', 'up', 'after', 'work', 'or', 'sth', '...', 'i', \"'m\", 'going', 'to', 'get', 'specs', '.', 'my', 'membership', 'is', 'px3748']\n",
      "AFter tokenizer:  ['you', 'have', 'won', 'a', 'guaranteed', '£1000', 'cash', 'or', 'a', '£2000', 'prize', '.', 'to', 'claim', 'yr', 'prize', 'call', 'our', 'customer', 'service', 'representative', 'on', '08714712394', 'between', '10am-7pm']\n",
      "AFter tokenizer:  ['macha', 'dont', 'feel', 'upset.i', 'can', 'assume', 'your', 'mindset.believe', 'me', 'one', 'evening', 'with', 'me', 'and', 'i', 'have', 'some', 'wonderful', 'plans', 'for', 'both', 'of', 'us.let', 'life', 'begin', 'again.call', 'me', 'anytime']\n",
      "AFter tokenizer:  ['oh', 'is', 'it', '?', 'send', 'me', 'the', 'address']\n",
      "AFter tokenizer:  [\"s'fine\", '.', 'anytime', '.', 'all', 'the', 'best', 'with', 'it', '.']\n",
      "AFter tokenizer:  ['that', 'is', 'wondar', 'full', 'flim', '.']\n",
      "AFter tokenizer:  ['ya', 'even', 'those', 'cookies', 'have', 'jelly', 'on', 'them']\n",
      "AFter tokenizer:  ['the', 'world', 'is', 'running', 'and', 'i', 'am', 'still.maybe', 'all', 'are', 'feeling', 'the', 'same', ',', 'so', 'be', 'it.or', 'i', 'have', 'to', 'admit', ',', 'i', 'am', 'mad.then', 'where', 'is', 'the', 'correction', '?', 'or', 'let', 'me', 'call', 'this', 'is', 'life.and', 'keep', 'running', 'with', 'the', 'world', ',', 'may', 'be', 'u', 'r', 'also', 'running.lets', 'run', '.']\n",
      "AFter tokenizer:  ['got', 'it', '!', 'it', 'looks', 'scrumptious', '...', 'daddy', 'wants', 'to', 'eat', 'you', 'all', 'night', 'long', '!']\n",
      "AFter tokenizer:  ['of', 'cos', 'can', 'lar', 'i', \"'m\", 'not', 'so', 'ba', 'dao', 'ok', '...', '1', 'pm', 'lor', '...', 'y', 'u', 'never', 'ask', 'where', 'we', 'go', 'ah', '...', 'i', 'said', 'u', 'would', 'ask', 'on', 'fri', 'but', 'he', 'said', 'u', 'will', 'ask', 'today', '...']\n",
      "AFter tokenizer:  ['alright', 'omw', ',', 'got', 'ta', 'change', 'my', 'order', 'to', 'a', 'half8th']\n",
      "AFter tokenizer:  ['exactly', '.', 'anyways', 'how', 'far', '.', 'is', 'jide', 'her', 'to', 'study', 'or', 'just', 'visiting']\n",
      "AFter tokenizer:  ['dunno', 'y', 'u', 'ask', 'me', '.']\n",
      "AFter tokenizer:  ['email', 'alertfrom', ':', 'jeri', 'stewartsize', ':', '2kbsubject', ':', 'low-cost', 'prescripiton', 'drvgsto', 'listen', 'to', 'email', 'call', '123']\n",
      "AFter tokenizer:  ['no', 'he', 'did', \"n't\", '.', 'spring', 'is', 'coming', 'early', 'yay', '!']\n",
      "AFter tokenizer:  ['lol', 'you', 'wo', \"n't\", 'feel', 'bad', 'when', 'i', 'use', 'her', 'money', 'to', 'take', 'you', 'out', 'to', 'a', 'steak', 'dinner', '=d']\n",
      "AFter tokenizer:  ['even', 'u', 'dont', 'get', 'in', 'trouble', 'while', 'convincing', '..', 'just', 'tel', 'him', 'once', 'or', 'twice', 'and', 'just', 'tel', 'neglect', 'his', 'msgs', 'dont', 'c', 'and', 'read', 'it', '..', 'just', 'dont', 'reply']\n",
      "AFter tokenizer:  ['leaving', 'to', 'qatar', 'tonite', 'in', 'search', 'of', 'an', 'opportunity.all', 'went', 'fast.pls', 'add', 'me', 'in', 'ur', 'prayers', 'dear.rakhesh']\n",
      "AFter tokenizer:  ['then', 'why', 'no', 'one', 'talking', 'to', 'me']\n",
      "AFter tokenizer:  ['thanks', 'for', 'looking', 'out', 'for', 'me', '.', 'i', 'really', 'appreciate', '.']\n",
      "AFter tokenizer:  ['hi', '.', 'customer', 'loyalty', 'offer', ':', 'the', 'new', 'nokia6650', 'mobile', 'from', 'only', '£10', 'at', 'txtauction', '!', 'txt', 'word', ':', 'start', 'to', 'no', ':', '81151', '&', 'get', 'yours', 'now', '!', '4t', '&', 'ctxt', 'tc', '150p/mtmsg']\n",
      "AFter tokenizer:  ['wish', 'i', 'were', 'with', 'you', 'now', '!']\n",
      "AFter tokenizer:  ['haha', 'mayb', 'u', \"'re\", 'rite', '...', 'u', 'know', 'me', 'well', '.', 'da', 'feeling', 'of', 'being', 'liked', 'by', 'someone', 'is', 'gd', 'lor', '.', 'u', 'faster', 'go', 'find', 'one', 'then', 'all', 'gals', 'in', 'our', 'group', 'attached', 'liao', '.']\n",
      "AFter tokenizer:  ['yes', 'i', 'will', 'be', 'there', '.', 'glad', 'you', 'made', 'it', '.']\n",
      "AFter tokenizer:  ['do', 'well', ':', ')', 'all', 'will', 'for', 'little', 'time', '.', 'thing', 'of', 'good', 'times', 'ahead', ':']\n",
      "AFter tokenizer:  ['just', 'got', 'up', '.', 'have', 'to', 'be', 'out', 'of', 'the', 'room', 'very', 'soon', '.', '…', '.', 'i', 'had', \"n't\", 'put', 'the', 'clocks', 'back', 'til', 'at', '8', 'i', 'shouted', 'at', 'everyone', 'to', 'get', 'up', 'and', 'then', 'realised', 'it', 'was', '7.', 'wahay', '.', 'another', 'hour', 'in', 'bed', '.']\n",
      "AFter tokenizer:  ['ok.', 'there', 'may', 'be', 'a', 'free', 'gym', 'about', '.']\n",
      "AFter tokenizer:  ['men', 'like', 'shorter', 'ladies', '.', 'gaze', 'up', 'into', 'his', 'eyes', '.']\n",
      "AFter tokenizer:  ['dunno', 'he', 'jus', 'say', 'go', 'lido', '.', 'same', 'time', '930', '.']\n",
      "AFter tokenizer:  ['i', 'promise', 'to', 'take', 'good', 'care', 'of', 'you', ',', 'princess', '.', 'i', 'have', 'to', 'run', 'now', '.', 'please', 'send', 'pics', 'when', 'you', 'get', 'a', 'chance', '.', 'ttyl', '!']\n",
      "AFter tokenizer:  ['u', 'are', 'subscribed', 'to', 'the', 'best', 'mobile', 'content', 'service', 'in', 'the', 'uk', 'for', '£3', 'per', '10', 'days', 'until', 'you', 'send', 'stop', 'to', '82324.', 'helpline', '08706091795']\n",
      "AFter tokenizer:  ['is', 'there', 'a', 'reason', 'we', \"'ve\", 'not', 'spoken', 'this', 'year', '?', 'anyways', 'have', 'a', 'great', 'week', 'and', 'all', 'the', 'best', 'in', 'your', 'exam']\n",
      "AFter tokenizer:  ['by', 'monday', 'next', 'week', '.', 'give', 'me', 'the', 'full', 'gist']\n",
      "AFter tokenizer:  ['do', 'you', 'realize', 'that', 'in', 'about', '40', 'years', ',', 'we', \"'ll\", 'have', 'thousands', 'of', 'old', 'ladies', 'running', 'around', 'with', 'tattoos', '?']\n",
      "AFter tokenizer:  ['you', 'have', 'an', 'important', 'customer', 'service', 'announcement', 'from', 'premier', '.']\n",
      "AFter tokenizer:  ['dont', 'gim', 'me', 'that', 'lip', 'caveboy']\n",
      "AFter tokenizer:  ['when', 'did', 'you', 'get', 'to', 'the', 'library']\n",
      "AFter tokenizer:  ['realy', 'sorry-i', 'do', \"n't\", 'recognise', 'this', 'number', 'and', 'am', 'now', 'confused', ':', ')', 'who', 'r', 'u', 'please', '?', '!']\n",
      "AFter tokenizer:  ['so', 'why', 'didnt', 'you', 'holla', '?']\n",
      "AFter tokenizer:  ['cant', 'think', 'of', 'anyone', 'with', '*', 'spare', 'room', 'off', '*', 'top', 'of', 'my', 'head']\n",
      "AFter tokenizer:  ['faith', 'makes', 'things', 'possible', ',', 'hope', 'makes', 'things', 'work', ',', 'love', 'makes', 'things', 'beautiful', ',', 'may', 'you', 'have', 'all', 'three', 'this', 'christmas', '!', 'merry', 'christmas', '!']\n",
      "AFter tokenizer:  ['u', 'should', 'have', 'made', 'an', 'appointment']\n",
      "AFter tokenizer:  ['call', 'me', 'when', 'you/carlos', 'is/are', 'here', ',', 'my', 'phone', \"'s\", 'vibrate', 'is', 'acting', 'up', 'and', 'i', 'might', 'not', 'hear', 'texts']\n",
      "AFter tokenizer:  ['romantic', 'paris', '.', '2', 'nights', ',', '2', 'flights', 'from', '£79', 'book', 'now', '4', 'next', 'year', '.', 'call', '08704439680ts', '&', 'cs', 'apply', '.']\n",
      "AFter tokenizer:  ['we', 'are', 'at', 'grandmas', '.', 'oh', 'dear', ',', 'u', 'still', 'ill', '?', 'i', 'felt', 'shit', 'this', 'morning', 'but', 'i', 'think', 'i', 'am', 'just', 'hungover', '!', 'another', 'night', 'then', '.', 'we', 'leave', 'on', 'sat', '.']\n",
      "AFter tokenizer:  ['urgent', 'ur', '£500', 'guaranteed', 'award', 'is', 'still', 'unclaimed', '!', 'call', '09066368327', 'now', 'closingdate04/09/02', 'claimcode', 'm39m51', '£1.50pmmorefrommobile2bremoved-mobypobox734ls27yf']\n",
      "AFter tokenizer:  ['nothing', 'but', 'we', 'jus', 'tot', 'u', 'would', 'ask', 'cos', 'u', 'ba', 'gua', '...', 'but', 'we', 'went', 'mt', 'faber', 'yest', '...', 'yest', 'jus', 'went', 'out', 'already', 'mah', 'so', 'today', 'not', 'going', 'out', '...', 'jus', 'call', 'lor', '...']\n",
      "AFter tokenizer:  ['wishing', 'you', 'and', 'your', 'family', 'merry', '``', 'x', \"''\", 'mas', 'and', 'happy', 'new', 'year', 'in', 'advance', '..']\n",
      "AFter tokenizer:  ['ur', 'awarded', 'a', 'city', 'break', 'and', 'could', 'win', 'a', '£200', 'summer', 'shopping', 'spree', 'every', 'wk', '.', 'txt', 'store', 'to', '88039', '.', 'skilgme', '.', 'tscs087147403231winawk', '!', 'age16', '£1.50perwksub']\n",
      "AFter tokenizer:  ['i', \"'m\", 'nt', 'goin', ',', 'got', 'somethin', 'on', ',', 'unless', 'they', 'meetin', '4', 'dinner', 'lor', '...', 'haha', ',', 'i', 'wonder', 'who', 'will', 'go', 'tis', 'time', '...']\n",
      "AFter tokenizer:  ['lol', 'i', 'know', '!', 'they', \"'re\", 'so', 'dramatic', '.', 'schools', 'already', 'closed', 'for', 'tomorrow', '.', 'apparently', 'we', 'ca', \"n't\", 'drive', 'in', 'the', 'inch', 'of', 'snow', 'were', 'supposed', 'to', 'get', '.']\n",
      "AFter tokenizer:  ['not', 'getting', 'anywhere', 'with', 'this', 'damn', 'job', 'hunting', 'over', 'here', '!']\n",
      "AFter tokenizer:  ['lol', '!', 'u', 'drunkard', '!', 'just', 'doing', 'my', 'hair', 'at', 'd', 'moment', '.', 'yeah', 'still', 'up', '4', 'tonight', '.', 'wats', 'the', 'plan', '?']\n",
      "AFter tokenizer:  ['idc', 'get', 'over', 'here', ',', 'you', 'are', 'not', 'weaseling', 'your', 'way', 'out', 'of', 'this', 'shit', 'twice', 'in', 'a', 'row']\n",
      "AFter tokenizer:  ['i', 'wil', 'be', 'there', 'with', 'in', '&', 'lt', ';', '#', '&', 'gt', ';', 'minutes', '.', 'got', 'any', 'space']\n",
      "AFter tokenizer:  ['thanks', 'for', 'picking', 'up', 'the', 'trash', '.']\n",
      "AFter tokenizer:  ['why', 'do', \"n't\", 'you', 'go', 'tell', 'your', 'friend', 'you', \"'re\", 'not', 'sure', 'you', 'want', 'to', 'live', 'with', 'him', 'because', 'he', 'smokes', 'too', 'much', 'then', 'spend', 'hours', 'begging', 'him', 'to', 'come', 'smoke']\n",
      "AFter tokenizer:  ['hi', 'its', 'kate', 'it', 'was', 'lovely', 'to', 'see', 'you', 'tonight', 'and', 'ill', 'phone', 'you', 'tomorrow', '.', 'i', 'got', 'to', 'sing', 'and', 'a', 'guy', 'gave', 'me', 'his', 'card', '!', 'xxx']\n",
      "AFter tokenizer:  ['happy', 'new', 'year', 'my', 'dear', 'brother', '.', 'i', 'really', 'do', 'miss', 'you', '.', 'just', 'got', 'your', 'number', 'and', 'decided', 'to', 'send', 'you', 'this', 'text', 'wishing', 'you', 'only', 'happiness', '.', 'abiola']\n",
      "AFter tokenizer:  ['that', 'means', 'get', 'the', 'door']\n",
      "AFter tokenizer:  ['hmmm', '...', 'i', 'thought', 'we', 'said', '2', 'hours', 'slave', ',', 'not', '3', '...', 'you', 'are', 'late', '...', 'how', 'should', 'i', 'punish', 'you', '?']\n",
      "AFter tokenizer:  ['beerage', '?']\n",
      "AFter tokenizer:  ['you', 'have', 'an', 'important', 'customer', 'service', 'announcement', 'from', 'premier', '.', 'call', 'freephone', '0800', '542', '0578', 'now', '!']\n",
      "AFter tokenizer:  ['dont', 'think', 'so', '.', 'it', 'turns', 'off', 'like', 'randomlly', 'within', '5min', 'of', 'opening']\n",
      "AFter tokenizer:  ['she', 'was', 'supposed', 'to', 'be', 'but', 'could', \"n't\", 'make', 'it', ',', 'she', \"'s\", 'still', 'in', 'town', 'though']\n",
      "AFter tokenizer:  ['it', 'does', 'it', 'on', 'its', 'own', '.', 'most', 'of', 'the', 'time', 'it', 'fixes', 'my', 'spelling', '.', 'but', 'sometimes', 'it', 'gets', 'a', 'completely', 'diff', 'word', '.', 'go', 'figure']\n",
      "AFter tokenizer:  ['ever', 'thought', 'about', 'living', 'a', 'good', 'life', 'with', 'a', 'perfect', 'partner', '?', 'just', 'txt', 'back', 'name', 'and', 'age', 'to', 'join', 'the', 'mobile', 'community', '.', '(', '100p/sms', ')']\n",
      "AFter tokenizer:  ['5', 'free', 'top', 'polyphonic', 'tones', 'call', '087018728737', ',', 'national', 'rate', '.', 'get', 'a', 'toppoly', 'tune', 'sent', 'every', 'week', ',', 'just', 'text', 'subpoly', 'to', '81618', ',', '£3', 'per', 'pole', '.', 'unsub', '08718727870', '.']\n",
      "AFter tokenizer:  ['this', 'is', 'hoping', 'you', 'enjoyed', 'your', 'game', 'yesterday', '.', 'sorry', 'i', \"'ve\", 'not', 'been', 'in', 'touch', 'but', 'pls', 'know', 'that', 'you', 'are', 'fondly', 'bein', 'thot', 'off', '.', 'have', 'a', 'great', 'week', '.', 'abiola']\n",
      "AFter tokenizer:  ['all', 'e', 'best', '4', 'ur', 'driving', 'tmr', ':', '-', ')']\n",
      "AFter tokenizer:  ['y', '?', 'where', 'u', 'at', 'dogbreath', '?', 'its', 'just', 'sounding', 'like', 'jan', 'c', 'that\\x92s', 'al', '!', '!', '!', '!', '!', '!', '!', '!', '!']\n",
      "AFter tokenizer:  ['omg', 'i', 'want', 'to', 'scream', '.', 'i', 'weighed', 'myself', 'and', 'i', 'lost', 'more', 'weight', '!', 'woohoo', '!']\n",
      "AFter tokenizer:  ['there', 'generally', 'is', \"n't\", 'one', '.', 'it', \"'s\", 'an', 'uncountable', 'noun', '-', 'u', 'in', 'the', 'dictionary', '.', 'pieces', 'of', 'research', '?']\n",
      "AFter tokenizer:  ['it', \"'s\", 'really', 'getting', 'me', 'down', 'just', 'hanging', 'around', '.']\n",
      "AFter tokenizer:  ['orange', 'customer', ',', 'you', 'may', 'now', 'claim', 'your', 'free', 'camera', 'phone', 'upgrade', 'for', 'your', 'loyalty', '.', 'call', 'now', 'on', '0207', '153', '9996.', 'offer', 'ends', '14thmarch', '.', 't', '&', 'c', \"'s\", 'apply', '.', 'opt-out', 'availa']\n",
      "AFter tokenizer:  ['petey', 'boy', 'whereare', 'you', 'me', 'and', 'all', 'your', 'friendsare', 'in', 'thekingshead', 'come', 'down', 'if', 'you', 'canlove', 'nic']\n",
      "AFter tokenizer:  ['ok', 'i', 'msg', 'u', 'b4', 'i', 'leave', 'my', 'house', '.']\n",
      "AFter tokenizer:  ['gim', 'me', 'a', 'few', 'was', '&', 'lt', ';', '#', '&', 'gt', ';', 'minutes', 'ago']\n",
      "AFter tokenizer:  ['last', 'chance', '!', 'claim', 'ur', '£150', 'worth', 'of', 'discount', 'vouchers', 'today', '!', 'text', 'shop', 'to', '85023', 'now', '!', 'savamob', ',', 'offers', 'mobile', '!', 't', 'cs', 'savamob', 'pobox84', ',', 'm263uz', '.', '£3.00', 'sub', '.', '16']\n",
      "AFter tokenizer:  ['appt', 'is', 'at', '&', 'lt', ';', 'time', '&', 'gt', ';', 'am', '.', 'not', 'my', 'fault', 'u', 'do', \"n't\", 'listen', '.', 'i', 'told', 'u', 'twice']\n",
      "AFter tokenizer:  ['free', 'for', '1st', 'week', '!', 'no1', 'nokia', 'tone', '4', 'ur', 'mobile', 'every', 'week', 'just', 'txt', 'nokia', 'to', '8077', 'get', 'txting', 'and', 'tell', 'ur', 'mates', '.', 'www.getzed.co.uk', 'pobox', '36504', 'w45wq', '16+', 'norm150p/tone']\n",
      "AFter tokenizer:  ['you', 'have', 'won', 'a', 'guaranteed', '£200', 'award', 'or', 'even', '£1000', 'cashto', 'claim', 'ur', 'award', 'call', 'free', 'on', '08000407165', '(', '18+', ')', '2', 'stop', 'getstop', 'on', '88222', 'php', '.', 'rg21', '4jx']\n",
      "AFter tokenizer:  ['k', 'i', \"'ll\", 'be', 'there', 'before', '4', '.']\n",
      "AFter tokenizer:  ['i', 'dled', '3d', 'its', 'very', 'imp']\n",
      "AFter tokenizer:  ['sure', ',', 'but', 'make', 'sure', 'he', 'knows', 'we', 'ai', \"n't\", 'smokin', 'yet']\n",
      "AFter tokenizer:  ['boooo', 'you', 'always', 'work', '.', 'just', 'quit', '.']\n",
      "AFter tokenizer:  ['i', 'am', 'taking', 'half', 'day', 'leave', 'bec', 'i', 'am', 'not', 'well']\n",
      "AFter tokenizer:  ['ugh', 'i', 'do', \"n't\", 'wan', 'na', 'get', 'out', 'of', 'bed', '.', 'it', \"'s\", 'so', 'warm', '.']\n",
      "AFter tokenizer:  ['s', ':', ')', 's.nervous', '&', 'lt', ';', '#', '&', 'gt', ';', ':', ')']\n",
      "AFter tokenizer:  ['so', 'there', \"'s\", 'a', 'ring', 'that', 'comes', 'with', 'the', 'guys', 'costumes', '.', 'it', \"'s\", 'there', 'so', 'they', 'can', 'gift', 'their', 'future', 'yowifes', '.', 'hint', 'hint']\n",
      "AFter tokenizer:  ['congratulations', 'ur', 'awarded', 'either', '£500', 'of', 'cd', 'gift', 'vouchers', '&', 'free', 'entry', '2', 'our', '£100', 'weekly', 'draw', 'txt', 'music', 'to', '87066', 'tncs', 'www.ldew.com1win150ppmx3age16']\n",
      "AFter tokenizer:  ['i', 'borrow', 'ur', 'bag', 'ok', '.']\n",
      "AFter tokenizer:  ['u', 'were', 'outbid', 'by', 'simonwatson5120', 'on', 'the', 'shinco', 'dvd', 'plyr', '.', '2', 'bid', 'again', ',', 'visit', 'sms', '.', 'ac/smsrewards', '2', 'end', 'bid', 'notifications', ',', 'reply', 'end', 'out']\n",
      "AFter tokenizer:  ['where', \"'s\", 'my', 'boytoy', '?', 'i', 'miss', 'you', '...', 'what', 'happened', '?']\n",
      "AFter tokenizer:  ['he', 'has', 'lots', 'of', 'used', 'ones', 'babe', ',', 'but', 'the', 'model', 'does', \"n't\", 'help', '.', 'youi', 'have', 'to', 'bring', 'it', 'over', 'and', 'he', \"'ll\", 'match', 'it', 'up']\n",
      "AFter tokenizer:  ['also', 'are', 'you', 'bringing', 'galileo', 'or', 'dobby']\n",
      "AFter tokenizer:  ['then', 'why', 'you', 'not', 'responding']\n",
      "AFter tokenizer:  ['boo', 'babe', '!', 'u', 'enjoyin', 'yourjob', '?', 'u', 'seemed', '2', 'b', 'gettin', 'on', 'well', 'hunny', '!', 'hope', 'ure', 'ok', '?', 'take', 'care', '&', 'i\\x92llspeak', '2u', 'soonlots', 'of', 'loveme', 'xxxx', '.']\n",
      "AFter tokenizer:  ['good', 'afternoon', 'starshine', '!', 'how', \"'s\", 'my', 'boytoy', '?', 'does', 'he', 'crave', 'me', 'yet', '?', 'ache', 'to', 'fuck', 'me', '?', '*', 'sips', 'cappuccino', '*', 'i', 'miss', 'you', 'babe', '*', 'teasing', 'kiss', '*']\n",
      "AFter tokenizer:  ['on', 'the', 'road', 'so', 'cant', 'txt']\n",
      "AFter tokenizer:  ['smsservices', '.', 'for', 'yourinclusive', 'text', 'credits', ',', 'pls', 'goto', 'www.comuk.net', 'login=', '3qxj9', 'unsubscribe', 'with', 'stop', ',', 'no', 'extra', 'charge', '.', 'help', '08702840625.comuk', '.', '220-cm2', '9ae']\n",
      "AFter tokenizer:  ['25p', '4', 'alfie', 'moon', \"'s\", 'children', 'in', 'need', 'song', 'on', 'ur', 'mob', '.', 'tell', 'ur', 'm8s', '.', 'txt', 'tone', 'charity', 'to', '8007', 'for', 'nokias', 'or', 'poly', 'charity', 'for', 'polys', ':', 'zed', '08701417012', 'profit', '2', 'charity', '.']\n",
      "AFter tokenizer:  ['hmm', '..', 'bits', 'and', 'pieces', 'lol', '...', '*', 'sighs', '*', '...']\n",
      "AFter tokenizer:  ['hahaha', '..', 'use', 'your', 'brain', 'dear']\n",
      "AFter tokenizer:  ['hey', '.', 'you', 'got', 'any', 'mail', '?']\n",
      "AFter tokenizer:  ['sorry', 'light', 'turned', 'green', ',', 'i', 'meant', 'another', 'friend', 'wanted', '&', 'lt', ';', '#', '&', 'gt', ';', 'worth', 'but', 'he', 'may', 'not', 'be', 'around']\n",
      "AFter tokenizer:  ['thanks', 'for', 'yesterday', 'sir', '.', 'you', 'have', 'been', 'wonderful', '.', 'hope', 'you', 'enjoyed', 'the', 'burial', '.', 'mojibiola']\n",
      "AFter tokenizer:  ['u', 'have', 'a', 'secret', 'admirer', '.', 'reveal', 'who', 'thinks', 'u', 'r', 'so', 'special', '.', 'call', '09065174042.', 'to', 'opt', 'out', 'reply', 'reveal', 'stop', '.', '1.50', 'per', 'msg', 'recd', '.', 'cust', 'care', '07821230901']\n",
      "AFter tokenizer:  ['hi', 'mate', 'its', 'rv', 'did', 'u', 'hav', 'a', 'nice', 'hol', 'just', 'a', 'message', '3', 'say', 'hello', 'coz', 'haven\\x92t', 'sent', 'u', '1', 'in', 'ages', 'started', 'driving', 'so', 'stay', 'off', 'roads', '!', 'rvx']\n",
      "AFter tokenizer:  ['dear', 'voucher', 'holder', ',', 'to', 'claim', 'this', 'weeks', 'offer', ',', 'at', 'you', 'pc', 'please', 'go', 'to', 'http', ':', '//www.e-tlp.co.uk/expressoffer', 'ts', '&', 'cs', 'apply', '.', 'to', 'stop', 'texts', ',', 'txt', 'stop', 'to', '80062']\n",
      "AFter tokenizer:  ['thank', 'you', 'so', 'much', '.', 'when', 'we', 'skyped', 'wit', 'kz', 'and', 'sura', ',', 'we', 'didnt', 'get', 'the', 'pleasure', 'of', 'your', 'company', '.', 'hope', 'you', 'are', 'good', '.', 'we', \"'ve\", 'given', 'you', 'ultimatum', 'oh', '!', 'we', 'are', 'countin', 'down', 'to', 'aburo', '.', 'enjoy', '!', 'this', 'is', 'the', 'message', 'i', 'sent', 'days', 'ago']\n",
      "AFter tokenizer:  ['surely', 'result', 'will', 'offer', ':', ')']\n",
      "AFter tokenizer:  ['good', 'morning', 'my', 'dear', '...........', 'have', 'a', 'great', '&', 'amp', ';', 'successful', 'day', '.']\n",
      "AFter tokenizer:  ['do', 'you', 'want', '750', 'anytime', 'any', 'network', 'mins', '150', 'text', 'and', 'a', 'new', 'video', 'phone', 'for', 'only', 'five', 'pounds', 'per', 'week', 'call', '08002888812', 'or', 'reply', 'for', 'delivery', 'tomorrow']\n",
      "AFter tokenizer:  ['sir', ',', 'i', 'have', 'been', 'late', 'in', 'paying', 'rent', 'for', 'the', 'past', 'few', 'months', 'and', 'had', 'to', 'pay', 'a', '$', '&', 'lt', ';', '#', '&', 'gt', ';', 'charge', '.', 'i', 'felt', 'it', 'would', 'be', 'inconsiderate', 'of', 'me', 'to', 'nag', 'about', 'something', 'you', 'give', 'at', 'great', 'cost', 'to', 'yourself', 'and', 'that', \"'s\", 'why', 'i', 'didnt', 'speak', 'up', '.', 'i', 'however', 'am', 'in', 'a', 'recession', 'and', 'wont', 'be', 'able', 'to', 'pay', 'the', 'charge', 'this', 'month', 'hence', 'my', 'askin', 'well', 'ahead', 'of', 'month', \"'s\", 'end', '.', 'can', 'you', 'please', 'help', '.', 'thanks']\n",
      "AFter tokenizer:  ['we', 'tried', 'to', 'contact', 'you', 're', 'our', 'offer', 'of', 'new', 'video', 'phone', '750', 'anytime', 'any', 'network', 'mins', 'half', 'price', 'rental', 'camcorder', 'call', '08000930705', 'or', 'reply', 'for', 'delivery', 'wed']\n",
      "AFter tokenizer:  ['last', 'chance', '2', 'claim', 'ur', '£150', 'worth', 'of', 'discount', 'vouchers-text', 'yes', 'to', '85023', 'now', '!', 'savamob-member', 'offers', 'mobile', 't', 'cs', '08717898035', '.', '£3.00', 'sub', '.', '16', '.', 'remove', 'txt', 'x', 'or', 'stop']\n",
      "AFter tokenizer:  ['i', 'luv', 'u', 'soo', 'much', 'u', 'don\\x92t', 'understand', 'how', 'special', 'u', 'r', '2', 'me', 'ring', 'u', '2morrow', 'luv', 'u', 'xxx']\n",
      "AFter tokenizer:  ['pls', 'send', 'me', 'a', 'comprehensive', 'mail', 'about', 'who', 'i', \"'m\", 'paying', ',', 'when', 'and', 'how', 'much', '.']\n",
      "AFter tokenizer:  ['our', 'prashanthettan', \"'s\", 'mother', 'passed', 'away', 'last', 'night', '.', 'pray', 'for', 'her', 'and', 'family', '.']\n",
      "AFter tokenizer:  ['urgent', '!', 'call', '09066350750', 'from', 'your', 'landline', '.', 'your', 'complimentary', '4', '*', 'ibiza', 'holiday', 'or', '10,000', 'cash', 'await', 'collection', 'sae', 't', '&', 'cs', 'po', 'box', '434', 'sk3', '8wp', '150', 'ppm', '18+']\n",
      "AFter tokenizer:  ['k.k', ':', ')', 'when', 'are', 'you', 'going', '?']\n",
      "AFter tokenizer:  ['meanwhile', 'in', 'the', 'shit', 'suite', ':', 'xavier', 'decided', 'to', 'give', 'us', '&', 'lt', ';', '#', '&', 'gt', ';', 'seconds', 'of', 'warning', 'that', 'samantha', 'was', 'coming', 'over', 'and', 'is', 'playing', 'jay', \"'s\", 'guitar', 'to', 'impress', 'her', 'or', 'some', 'shit', '.', 'also', 'i', 'do', \"n't\", 'think', 'doug', 'realizes', 'i', 'do', \"n't\", 'live', 'here', 'anymore']\n",
      "AFter tokenizer:  ['my', 'stomach', 'has', 'been', 'thru', 'so', 'much', 'trauma', 'i', 'swear', 'i', 'just', 'ca', \"n't\", 'eat', '.', 'i', 'better', 'lose', 'weight', '.']\n",
      "AFter tokenizer:  ['i', 'am', 'in', 'office', ':', ')', 'whats', 'the', 'matter', '..', 'msg', 'me', 'now.i', 'will', 'call', 'you', 'at', 'break', ':', ')', '.']\n",
      "AFter tokenizer:  ['yeah', 'there', \"'s\", 'barely', 'enough', 'room', 'for', 'the', 'two', 'of', 'us', ',', 'x', 'has', 'too', 'many', 'fucking', 'shoes', '.', 'sorry', 'man', ',', 'see', 'you', 'later']\n",
      "AFter tokenizer:  ['u', 'reach', 'orchard', 'already', '?', 'u', 'wan', '2', 'go', 'buy', 'tickets', 'first', '?']\n",
      "AFter tokenizer:  ['i', 'am', 'real', ',', 'baby', '!', 'i', 'want', 'to', 'bring', 'out', 'your', 'inner', 'tigress', '...']\n",
      "AFter tokenizer:  ['no', 'da', 'if', 'you', 'run', 'that', 'it', 'activate', 'the', 'full', 'version', 'da', '.']\n",
      "AFter tokenizer:  ['ah', 'poor', 'baby', '!', 'hope', 'urfeeling', 'bettersn', 'luv', '!', 'probthat', 'overdose', 'of', 'work', 'hey', 'go', 'careful', 'spk', '2', 'u', 'sn', 'lots', 'of', 'lovejen', 'xxx', '.']\n",
      "AFter tokenizer:  ['stop', 'the', 'story', '.', 'i', \"'ve\", 'told', 'him', 'i', \"'ve\", 'returned', 'it', 'and', 'he', \"'s\", 'saying', 'i', 'should', 'not', 're', 'order', 'it', '.']\n",
      "AFter tokenizer:  ['talk', 'sexy', '!', '!', 'make', 'new', 'friends', 'or', 'fall', 'in', 'love', 'in', 'the', 'worlds', 'most', 'discreet', 'text', 'dating', 'service', '.', 'just', 'text', 'vip', 'to', '83110', 'and', 'see', 'who', 'you', 'could', 'meet', '.']\n",
      "AFter tokenizer:  ['going', 'to', 'take', 'your', 'babe', 'out', '?']\n",
      "AFter tokenizer:  ['hai', 'ana', 'tomarrow', 'am', 'coming', 'on', 'morning', '.', '&', 'lt', ';', 'decimal', '&', 'gt', ';', 'ill', 'be', 'there', 'in', 'sathy', 'then', 'we', 'll', 'go', 'to', 'rto', 'office', '.', 'reply', 'me', 'after', 'came', 'to', 'home', '.']\n",
      "AFter tokenizer:  ['spoons', 'it', 'is', 'then', 'okay', '?']\n",
      "AFter tokenizer:  ['did', 'he', 'just', 'say', 'somebody', 'is', 'named', 'tampa']\n",
      "AFter tokenizer:  ['in', 'work', 'now', '.', 'going', 'have', 'in', 'few', 'min', '.']\n",
      "AFter tokenizer:  ['your', 'brother', 'is', 'a', 'genius']\n",
      "AFter tokenizer:  ['sorry', ',', 'i', 'guess', 'whenever', 'i', 'can', 'get', 'a', 'hold', 'of', 'my', 'connections', ',', 'maybe', 'an', 'hour', 'or', 'two', '?', 'i', \"'ll\", 'text', 'you']\n",
      "AFter tokenizer:  ['did', 'u', 'find', 'out', 'what', 'time', 'the', 'bus', 'is', 'at', 'coz', 'i', 'need', 'to', 'sort', 'some', 'stuff', 'out', '.']\n",
      "AFter tokenizer:  ['dude', 'ive', 'been', 'seeing', 'a', 'lotta', 'corvettes', 'lately']\n",
      "AFter tokenizer:  ['congratulations', 'ur', 'awarded', 'either', 'a', 'yrs', 'supply', 'of', 'cds', 'from', 'virgin', 'records', 'or', 'a', 'mystery', 'gift', 'guaranteed', 'call', '09061104283', 'ts', '&', 'cs', 'www.smsco.net', '£1.50pm', 'approx', '3mins']\n",
      "AFter tokenizer:  ['same', 'here', ',', 'but', 'i', 'consider', 'walls', 'and', 'bunkers', 'and', 'shit', 'important', 'just', 'because', 'i', 'never', 'play', 'on', 'peaceful', 'but', 'i', 'guess', 'your', 'place', 'is', 'high', 'enough', 'that', 'it', 'do', \"n't\", 'matter']\n",
      "AFter tokenizer:  ['private', '!', 'your', '2003', 'account', 'statement', 'for', '07808', 'xxxxxx', 'shows', '800', 'un-redeemed', 's.', 'i.', 'm.', 'points', '.', 'call', '08719899217', 'identifier', 'code', ':', '41685', 'expires', '07/11/04']\n",
      "AFter tokenizer:  ['hello', '.', 'we', 'need', 'some', 'posh', 'birds', 'and', 'chaps', 'to', 'user', 'trial', 'prods', 'for', 'champneys', '.', 'can', 'i', 'put', 'you', 'down', '?', 'i', 'need', 'your', 'address', 'and', 'dob', 'asap', '.', 'ta', 'r']\n",
      "AFter tokenizer:  ['what', 'do', 'u', 'want', 'for', 'xmas', '?', 'how', 'about', '100', 'free', 'text', 'messages', '&', 'a', 'new', 'video', 'phone', 'with', 'half', 'price', 'line', 'rental', '?', 'call', 'free', 'now', 'on', '0800', '0721072', 'to', 'find', 'out', 'more', '!']\n",
      "AFter tokenizer:  ['well', 'am', 'officially', 'in', 'a', 'philosophical', 'hole', ',', 'so', 'if', 'u', 'wan', 'na', 'call', 'am', 'at', 'home', 'ready', 'to', 'be', 'saved', '!']\n",
      "AFter tokenizer:  ['its', 'going', 'good', '...', 'no', 'problem', '..', 'but', 'still', 'need', 'little', 'experience', 'to', 'understand', 'american', 'customer', 'voice', '...']\n",
      "AFter tokenizer:  ['i', \"'ll\", 'text', 'you', 'when', 'i', 'drop', 'x', 'off']\n",
      "AFter tokenizer:  ['ugh', 'its', 'been', 'a', 'long', 'day', '.', 'i', \"'m\", 'exhausted', '.', 'just', 'want', 'to', 'cuddle', 'up', 'and', 'take', 'a', 'nap']\n",
      "AFter tokenizer:  ['talk', 'with', 'yourself', 'atleast', 'once', 'in', 'a', 'day', '...', '!', '!', '!', 'otherwise', 'you', 'will', 'miss', 'your', 'best', 'friend', 'in', 'this', 'world', '...', '!', '!', '!', '-shakespeare-', 'shesil', '&', 'lt', ';', '#', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['shop', 'till', 'u', 'drop', ',', 'is', 'it', 'you', ',', 'either', '10k', ',', '5k', ',', '£500', 'cash', 'or', '£100', 'travel', 'voucher', ',', 'call', 'now', ',', '09064011000.', 'ntt', 'po', 'box', 'cr01327bt', 'fixedline', 'cost', '150ppm', 'mobile', 'vary']\n",
      "AFter tokenizer:  ['are', 'you', 'in', 'castor', '?', 'you', 'need', 'to', 'see', 'something']\n",
      "AFter tokenizer:  ['sunshine', 'quiz', 'wkly', 'q', '!', 'win', 'a', 'top', 'sony', 'dvd', 'player', 'if', 'u', 'know', 'which', 'country', 'liverpool', 'played', 'in', 'mid', 'week', '?', 'txt', 'ansr', 'to', '82277', '.', '£1.50', 'sp', ':', 'tyrone']\n",
      "AFter tokenizer:  ['u', 'have', 'a', 'secret', 'admirer', 'who', 'is', 'looking', '2', 'make', 'contact', 'with', 'u-find', 'out', 'who', 'they', 'r', '*', 'reveal', 'who', 'thinks', 'ur', 'so', 'special-call', 'on', '09058094565']\n",
      "AFter tokenizer:  ['u', 'have', 'a', 'secret', 'admirer', 'who', 'is', 'looking', '2', 'make', 'contact', 'with', 'u-find', 'out', 'who', 'they', 'r', '*', 'reveal', 'who', 'thinks', 'ur', 'so', 'special-call', 'on', '09065171142-stopsms-08']\n",
      "AFter tokenizer:  ['reminder', ':', 'you', 'have', 'not', 'downloaded', 'the', 'content', 'you', 'have', 'already', 'paid', 'for', '.', 'goto', 'http', ':', '//doit', '.', 'mymoby', '.', 'tv/', 'to', 'collect', 'your', 'content', '.']\n",
      "AFter tokenizer:  ['see', ',', 'i', 'knew', 'giving', 'you', 'a', 'break', 'a', 'few', 'times', 'woul', 'lead', 'to', 'you', 'always', 'wanting', 'to', 'miss', 'curfew', '.', 'i', 'was', 'gon', 'na', 'gibe', 'you', \"'til\", 'one', ',', 'but', 'a', 'midnight', 'movie', 'is', 'not', 'gon', 'na', 'get', 'out', 'til', 'after', '2.', 'you', 'need', 'to', 'come', 'home', '.', 'you', 'need', 'to', 'getsleep', 'and', ',', 'if', 'anything', ',', 'you', 'need', 'to', 'b', 'studdying', 'ear', 'training', '.']\n",
      "AFter tokenizer:  ['i', 'love', 'to', 'give', 'massages', '.', 'i', 'use', 'lots', 'of', 'baby', 'oil', '...', 'what', 'is', 'your', 'fave', 'position', '?']\n",
      "AFter tokenizer:  ['dude', 'we', 'should', 'go', 'sup', 'again']\n",
      "AFter tokenizer:  ['yoyyooo', 'u', 'know', 'how', 'to', 'change', 'permissions', 'for', 'a', 'drive', 'in', 'mac', '.', 'my', 'usb', 'flash', 'drive']\n",
      "AFter tokenizer:  ['gibbs', 'unsold.mike', 'hussey']\n",
      "AFter tokenizer:  ['i', 'like', 'to', 'talk', 'pa', 'but', 'am', 'not', 'able', 'to', '.', 'i', 'dont', 'know', 'y', '.']\n",
      "AFter tokenizer:  ['y', 'dun', 'cut', 'too', 'short', 'leh', '.', 'u', 'dun', 'like', 'ah', '?', 'she', 'failed', '.', 'she', \"'s\", 'quite', 'sad', '.']\n",
      "AFter tokenizer:  ['you', 'unbelievable', 'faglord']\n",
      "AFter tokenizer:  ['wife.how', 'she', 'knew', 'the', 'time', 'of', 'murder', 'exactly']\n",
      "AFter tokenizer:  ['why', 'do', 'you', 'ask', 'princess', '?']\n",
      "AFter tokenizer:  ['i', 'am', 'great', 'princess', '!', 'what', 'are', 'you', 'thinking', 'about', 'me', '?', ':', ')']\n",
      "AFter tokenizer:  ['nutter', '.', 'cutter', '.', 'ctter', '.', 'cttergg', '.', 'cttargg', '.', 'ctargg', '.', 'ctagg', '.', 'ie', 'you']\n",
      "AFter tokenizer:  ['it', \"'s\", 'ok', 'i', 'noe', 'u', \"'re\", 'busy', 'but', 'i', \"'m\", 'really', 'too', 'bored', 'so', 'i', 'msg', 'u.', 'i', 'oso', 'dunno', 'wat', 'colour', 'she', 'choose', '4', 'me', 'one', '.']\n",
      "AFter tokenizer:  ['does', \"n't\", 'g', 'have', 'class', 'early', 'tomorrow', 'and', 'thus', 'should', \"n't\", 'be', 'trying', 'to', 'smoke', 'at', '&', 'lt', ';', '#', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['superb', 'thought-', '``', 'be', 'grateful', 'that', 'u', 'dont', 'have', 'everything', 'u', 'want', '.', 'that', 'means', 'u', 'still', 'have', 'an', 'opportunity', 'to', 'be', 'happier', 'tomorrow', 'than', 'u', 'are', 'today', '.', '``', ':', '-', ')']\n",
      "AFter tokenizer:  ['hope', 'you', 'are', 'having', 'a', 'good', 'week', '.', 'just', 'checking', 'in']\n",
      "AFter tokenizer:  ['i', \"'m\", 'used', 'to', 'it', '.', 'i', 'just', 'hope', 'my', 'agents', 'do', \"n't\", 'drop', 'me', 'since', 'i', \"'ve\", 'only', 'booked', 'a', 'few', 'things', 'this', 'year', '.', 'this', 'whole', 'me', 'in', 'boston', ',', 'them', 'in', 'nyc', 'was', 'an', 'experiment', '.']\n",
      "AFter tokenizer:  ['thursday', 'night', '?', 'yeah', ',', 'sure', 'thing', ',', 'we', \"'ll\", 'work', 'it', 'out', 'then']\n",
      "AFter tokenizer:  ['probably', 'money', 'worries', '.', 'things', 'are', 'coming', 'due', 'and', 'i', 'have', 'several', 'outstanding', 'invoices', 'for', 'work', 'i', 'did', 'two', 'and', 'three', 'months', 'ago', '.']\n",
      "AFter tokenizer:  ['how', 'is', 'it', 'possible', 'to', 'teach', 'you', '.', 'and', 'where', '.']\n",
      "AFter tokenizer:  ['i', 'wonder', 'if', 'your', 'phone', 'battery', 'went', 'dead', '?', 'i', 'had', 'to', 'tell', 'you', ',', 'i', 'love', 'you', 'babe']\n",
      "AFter tokenizer:  ['lovely', 'smell', 'on', 'this', 'bus', 'and', 'it', 'ai', \"n't\", 'tobacco', '...']\n",
      "AFter tokenizer:  ['we', \"'re\", 'all', 'getting', 'worried', 'over', 'here', ',', 'derek', 'and', 'taylor', 'have', 'already', 'assumed', 'the', 'worst']\n",
      "AFter tokenizer:  ['hey', 'what', \"'s\", 'up', 'charles', 'sorry', 'about', 'the', 'late', 'reply', '.']\n",
      "AFter tokenizer:  ['all', 'the', 'lastest', 'from', 'stereophonics', ',', 'marley', ',', 'dizzee', 'racal', ',', 'libertines', 'and', 'the', 'strokes', '!', 'win', 'nookii', 'games', 'with', 'flirt', '!', '!', 'click', 'themob', 'wap', 'bookmark', 'or', 'text', 'wap', 'to', '82468']\n",
      "AFter tokenizer:  ['i.ll', 'give', 'her', 'once', 'i', 'have', 'it', '.', 'plus', 'she', 'said', 'grinule', 'greet', 'you', 'whenever', 'we', 'speak']\n",
      "AFter tokenizer:  ['white', 'fudge', 'oreos', 'are', 'in', 'stores']\n",
      "AFter tokenizer:  ['january', 'male', 'sale', '!', 'hot', 'gay', 'chat', 'now', 'cheaper', ',', 'call', '08709222922.', 'national', 'rate', 'from', '1.5p/min', 'cheap', 'to', '7.8p/min', 'peak', '!', 'to', 'stop', 'texts', 'call', '08712460324', '(', '10p/min', ')']\n",
      "AFter tokenizer:  ['my', 'love', '!', 'how', 'come', 'it', 'took', 'you', 'so', 'long', 'to', 'leave', 'for', 'zaher', \"'s\", '?', 'i', 'got', 'your', 'words', 'on', 'ym', 'and', 'was', 'happy', 'to', 'see', 'them', 'but', 'was', 'sad', 'you', 'had', 'left', '.', 'i', 'miss', 'you']\n",
      "AFter tokenizer:  ['i', 'am', 'sorry', 'it', 'hurt', 'you', '.']\n",
      "AFter tokenizer:  ['ca', \"n't\", '.', 'i', 'feel', 'nauseous', '.', 'i', \"'m\", 'so', 'pissed', '.', 'i', 'did', \"n't\", 'eat', 'any', 'sweets', 'all', 'week', 'cause', 'today', 'i', 'was', 'planning', 'to', 'pig', 'out', '.', 'i', 'was', 'dieting', 'all', 'week', '.', 'and', 'now', 'i', \"'m\", 'not', 'hungry', ':', '/']\n",
      "AFter tokenizer:  ['ok', 'lor', 'but', 'not', 'too', 'early', '.', 'me', 'still', 'having', 'project', 'meeting', 'now', '.']\n",
      "AFter tokenizer:  ['call', 'me', 'da', ',', 'i', 'am', 'waiting', 'for', 'your', 'call', '.']\n",
      "AFter tokenizer:  ['i', 'could', 'ask', 'carlos', 'if', 'we', 'could', 'get', 'more', 'if', 'anybody', 'else', 'can', 'chip', 'in']\n",
      "AFter tokenizer:  ['was', 'actually', 'about', 'to', 'send', 'you', 'a', 'reminder', 'today', '.', 'have', 'a', 'wonderful', 'weekend']\n",
      "AFter tokenizer:  ['when', 'people', 'see', 'my', 'msgs', ',', 'they', 'think', 'iam', 'addicted', 'to', 'msging', '...', 'they', 'are', 'wrong', ',', 'bcoz', 'they', \"don\\\\'t\", 'know', 'that', 'iam', 'addicted', 'to', 'my', 'sweet', 'friends', '..', '!', '!', 'bslvyl']\n",
      "AFter tokenizer:  ['hey', 'you', 'gave', 'them', 'your', 'photo', 'when', 'you', 'registered', 'for', 'driving', 'ah', '?', 'tmr', 'wan', 'na', 'meet', 'at', 'yck', '?']\n",
      "AFter tokenizer:  ['dont', 'talk', 'to', 'him', 'ever', 'ok', 'its', 'my', 'word', '.']\n",
      "AFter tokenizer:  ['when', 'u', 'wana', 'see', 'it', 'then']\n",
      "AFter tokenizer:  ['on', 'ma', 'way', 'to', 'school', '.', 'can', 'you', 'pls', 'send', 'me', 'ashley', \"'s\", 'number']\n",
      "AFter tokenizer:  ['it', 'shall', 'be', 'fine', '.', 'i', 'have', 'avalarr', 'now', '.', 'will', 'hollalater']\n",
      "AFter tokenizer:  ['she', 'went', 'to', 'attend', 'another', 'two', 'rounds', 'today', '..', 'but', 'still', \"did't\", 'reach', 'home', '..']\n",
      "AFter tokenizer:  ['actually', 'i', 'deleted', 'my', 'old', 'website', '..', 'now', 'i', 'm', 'blogging', 'at', 'magicalsongs.blogspot.com']\n",
      "AFter tokenizer:  ['k', ',', 'wait', 'chikku', '..', 'il', 'send', 'aftr', '&', 'lt', ';', '#', '&', 'gt', ';', 'mins']\n",
      "AFter tokenizer:  ['but', 'i', \"'m\", 'on', 'a', 'diet', '.', 'and', 'i', 'ate', '1', 'too', 'many', 'slices', 'of', 'pizza', 'yesterday', '.', 'ugh', 'i', \"'m\", 'always', 'on', 'a', 'diet', '.']\n",
      "AFter tokenizer:  ['k', ':', ')', 'i', 'will', 'give', 'my', 'kvb', 'acc', 'details', ':', ')']\n",
      "AFter tokenizer:  ['oh', 'all', 'have', 'to', 'come', 'ah', '?']\n",
      "AFter tokenizer:  ['money', '!', '!', '!', 'you', 'r', 'a', 'lucky', 'winner', '!', '2', 'claim', 'your', 'prize', 'text', 'money', '2', '88600', 'over', '£1million', 'to', 'give', 'away', '!', 'ppt150x3+normal', 'text', 'rate', 'box403', 'w1t1jy']\n",
      "AFter tokenizer:  ['i', \"'m\", 'really', 'sorry', 'i', 'wo', \"n't\", 'b', 'able', '2', 'do', 'this', 'friday.hope', 'u', 'can', 'find', 'an', 'alternative.hope', 'yr', 'term', \"'s\", 'going', 'ok', ':', '-', ')']\n",
      "AFter tokenizer:  ['congratulations', 'ore', 'mo', 'owo', 're', 'wa', '.', 'enjoy', 'it', 'and', 'i', 'wish', 'you', 'many', 'happy', 'moments', 'to', 'and', 'fro', 'wherever', 'you', 'go']\n",
      "AFter tokenizer:  ['so', 'do', 'you', 'have', 'samus', 'shoulders', 'yet']\n",
      "AFter tokenizer:  ['what', 'time', 'you', 'think', 'you', \"'ll\", 'have', 'it', '?', 'need', 'to', 'know', 'when', 'i', 'should', 'be', 'near', 'campus']\n",
      "AFter tokenizer:  ['dear', 'matthew', 'please', 'call', '09063440451', 'from', 'a', 'landline', ',', 'your', 'complimentary', '4', '*', 'lux', 'tenerife', 'holiday', 'or', '£1000', 'cash', 'await', 'collection', '.', 'ppm150', 'sae', 't', '&', 'cs', 'box334', 'sk38xh', '.']\n",
      "AFter tokenizer:  ['then', 'dun', 'wear', 'jeans', 'lor', '...']\n",
      "AFter tokenizer:  ['since', 'when', ',', 'which', 'side', ',', 'any', 'fever', ',', 'any', 'vomitin', '.']\n",
      "AFter tokenizer:  ['k', ':', ')', 'k.are', 'you', 'in', 'college', '?']\n",
      "AFter tokenizer:  ['urgent', '!', 'call', '09061749602', 'from', 'landline', '.', 'your', 'complimentary', '4', '*', 'tenerife', 'holiday', 'or', '£10,000', 'cash', 'await', 'collection', 'sae', 't', '&', 'cs', 'box', '528', 'hp20', '1yf', '150ppm', '18+']\n",
      "AFter tokenizer:  ['better', '.', 'made', 'up', 'for', 'friday', 'and', 'stuffed', 'myself', 'like', 'a', 'pig', 'yesterday', '.', 'now', 'i', 'feel', 'bleh', '.', 'but', 'at', 'least', 'its', 'not', 'writhing', 'pain', 'kind', 'of', 'bleh', '.']\n",
      "AFter tokenizer:  ['no', 'we', 'sell', 'it', 'all', 'so', 'we', \"'ll\", 'have', 'tons', 'if', 'coins', '.', 'then', 'sell', 'our', 'coins', 'to', 'someone', 'thru', 'paypal', '.', 'voila', '!', 'money', 'back', 'in', 'life', 'pockets', ':', ')']\n",
      "AFter tokenizer:  ['theyre', 'doing', 'it', 'to', 'lots', 'of', 'places', '.', 'only', 'hospitals', 'and', 'medical', 'places', 'are', 'safe', '.']\n",
      "AFter tokenizer:  ['how', 'about', 'getting', 'in', 'touch', 'with', 'folks', 'waiting', 'for', 'company', '?', 'just', 'txt', 'back', 'your', 'name', 'and', 'age', 'to', 'opt', 'in', '!', 'enjoy', 'the', 'community', '(', '150p/sms', ')']\n",
      "AFter tokenizer:  ['and', 'also', 'i', \"'ve\", 'sorta', 'blown', 'him', 'off', 'a', 'couple', 'times', 'recently', 'so', 'id', 'rather', 'not', 'text', 'him', 'out', 'of', 'the', 'blue', 'looking', 'for', 'weed']\n",
      "AFter tokenizer:  ['i', 'sent', 'my', 'scores', 'to', 'sophas', 'and', 'i', 'had', 'to', 'do', 'secondary', 'application', 'for', 'a', 'few', 'schools', '.', 'i', 'think', 'if', 'you', 'are', 'thinking', 'of', 'applying', ',', 'do', 'a', 'research', 'on', 'cost', 'also', '.', 'contact', 'joke', 'ogunrinde', ',', 'her', 'school', 'is', 'one', 'me', 'the', 'less', 'expensive', 'ones']\n",
      "AFter tokenizer:  ['i', 'cant', 'wait', 'to', 'see', 'you', '!', 'how', 'were', 'the', 'photos', 'were', 'useful', '?', ':', ')']\n",
      "AFter tokenizer:  ['ur', 'cash-balance', 'is', 'currently', '500', 'pounds', '-', 'to', 'maximize', 'ur', 'cash-in', 'now', 'send', 'go', 'to', '86688', 'only', '150p/msg', '.', 'cc', ':', '08718720201', 'po', 'box', '114/14', 'tcr/w1']\n",
      "AFter tokenizer:  ['hey', 'i', 'booked', 'the', 'kb', 'on', 'sat', 'already', '...', 'what', 'other', 'lessons', 'are', 'we', 'going', 'for', 'ah', '?', 'keep', 'your', 'sat', 'night', 'free', 'we', 'need', 'to', 'meet', 'and', 'confirm', 'our', 'lodging']\n",
      "AFter tokenizer:  ['chk', 'in', 'ur', 'belovd', 'ms', 'dict']\n",
      "AFter tokenizer:  ['is', 'that', 'what', 'time', 'you', 'want', 'me', 'to', 'come', '?']\n",
      "AFter tokenizer:  ['awesome', ',', 'lem', 'me', 'know', 'whenever', 'you', \"'re\", 'around']\n",
      "AFter tokenizer:  ['shb', 'b', 'ok', 'lor', '...', 'thanx', '...']\n",
      "AFter tokenizer:  ['beautiful', 'truth', 'against', 'gravity', '..', 'read', 'carefully', ':', '``', 'our', 'heart', 'feels', 'light', 'when', 'someone', 'is', 'in', 'it', '..', 'but', 'it', 'feels', 'very', 'heavy', 'when', 'someone', 'leaves', 'it', '..', \"''\", 'good', 'night']\n",
      "AFter tokenizer:  ['also', 'remember', 'to', 'get', 'dobby', \"'s\", 'bowl', 'from', 'your', 'car']\n",
      "AFter tokenizer:  ['filthy', 'stories', 'and', 'girls', 'waiting', 'for', 'your']\n",
      "AFter tokenizer:  ['sorry', 'i', 'now', 'then', 'c', 'ur', 'msg', '...', 'yar', 'lor', 'so', 'poor', 'thing', '...', 'but', 'only', '4', 'one', 'night', '...', 'tmr', 'u', \"'ll\", 'have', 'a', 'brand', 'new', 'room', '2', 'sleep', 'in', '...']\n",
      "AFter tokenizer:  ['love', 'is', \"n't\", 'a', 'decision', ',', 'it', \"'s\", 'a', 'feeling', '.', 'if', 'we', 'could', 'decide', 'who', 'to', 'love', ',', 'then', ',', 'life', 'would', 'be', 'much', 'simpler', ',', 'but', 'then', 'less', 'magical']\n",
      "AFter tokenizer:  ['welp', 'apparently', 'he', 'retired']\n",
      "AFter tokenizer:  ['my', 'sort', 'code', 'is', 'and', 'acc', 'no', 'is', '.', 'the', 'bank', 'is', 'natwest', '.', 'can', 'you', 'reply', 'to', 'confirm', 'i', \"'ve\", 'sent', 'this', 'to', 'the', 'right', 'person', '!']\n",
      "AFter tokenizer:  ['where', '@']\n",
      "AFter tokenizer:  ['u', 'sure', 'u', 'ca', \"n't\", 'take', 'any', 'sick', 'time', '?']\n",
      "AFter tokenizer:  ['urgent', '!', 'we', 'are', 'trying', 'to', 'contact', 'u.', 'todays', 'draw', 'shows', 'that', 'you', 'have', 'won', 'a', '£800', 'prize', 'guaranteed', '.', 'call', '09050001808', 'from', 'land', 'line', '.', 'claim', 'm95', '.', 'valid12hrs', 'only']\n",
      "AFter tokenizer:  ['yo', 'chad', 'which', 'gymnastics', 'class', 'do', 'you', 'wan', 'na', 'take', '?', 'the', 'site', 'says', 'christians', 'class', 'is', 'full', '..']\n",
      "AFter tokenizer:  ['or', 'better', 'still', 'can', 'you', 'catch', 'her', 'and', 'let', 'ask', 'her', 'if', 'she', 'can', 'sell', '&', 'lt', ';', '#', '&', 'gt', ';', 'for', 'me', '.']\n",
      "AFter tokenizer:  ['i', 'am', 'not', 'sure', 'about', 'night', 'menu', '.', '.', '.', 'i', 'know', 'only', 'about', 'noon', 'menu']\n",
      "AFter tokenizer:  ['what', 'do', 'u', 'want', 'when', 'i', 'come', 'back', '?', '.a', 'beautiful', 'necklace', 'as', 'a', 'token', 'of', 'my', 'heart', 'for', 'you.thats', 'what', 'i', 'will', 'give', 'but', 'only', 'to', 'my', 'wife', 'of', 'my', 'liking.be', 'that', 'and', 'see', '..', 'no', 'one', 'can', 'give', 'you', 'that.dont', 'call', 'me.i', 'will', 'wait', 'till', 'i', 'come', '.']\n",
      "AFter tokenizer:  ['are', 'you', 'willing', 'to', 'go', 'for', 'aptitude', 'class', '.']\n",
      "AFter tokenizer:  ['it', 'wont', 'b', 'until', '2.15', 'as', 'trying', '2', 'sort', 'house', 'out', ',', 'is', 'that', 'ok', '?']\n",
      "AFter tokenizer:  ['yar', 'lor', 'he', 'wan', '2', 'go', 'c', 'horse', 'racing', 'today', 'mah', ',', 'so', 'eat', 'earlier', 'lor', '.', 'i', 'ate', 'chicken', 'rice', '.', 'u', '?']\n",
      "AFter tokenizer:  ['haha', 'awesome', ',', 'omw', 'back', 'now', 'then']\n",
      "AFter tokenizer:  ['yup', 'i', 'thk', 'so', 'until', 'e', 'shop', 'closes', 'lor', '.']\n",
      "AFter tokenizer:  ['what', 'is', 'your', 'account', 'number', '?']\n",
      "AFter tokenizer:  ['eh', 'u', 'send', 'wrongly', 'lar', '...']\n",
      "AFter tokenizer:  ['hey', 'no', 'i', 'ad', 'a', 'crap', 'nite', 'was', 'borin', 'without', 'ya', '2', 'boggy', 'with', 'me', 'u', 'boring', 'biatch', '!', 'thanx', 'but', 'u', 'wait', 'til', 'nxt', 'time', 'il', 'ave', 'ya']\n",
      "AFter tokenizer:  ['ok', 'i', 'shall', 'talk', 'to', 'him']\n",
      "AFter tokenizer:  ['dont', 'hesitate', '.', 'you', 'know', 'this', 'is', 'the', 'second', 'time', 'she', 'has', 'had', 'weakness', 'like', 'that', '.', 'so', 'keep', 'i', 'notebook', 'of', 'what', 'she', 'eat', 'and', 'did', 'the', 'day', 'before', 'or', 'if', 'anything', 'changed', 'the', 'day', 'before', 'so', 'that', 'we', 'can', 'be', 'sure', 'its', 'nothing']\n",
      "AFter tokenizer:  ['hey', 'you', 'can', 'pay', '.', 'with', 'salary', 'de', '.', 'only', '&', 'lt', ';', '#', '&', 'gt', ';', '.']\n",
      "AFter tokenizer:  ['another', 'month', '.', 'i', 'need', 'chocolate', 'weed', 'and', 'alcohol', '.']\n",
      "AFter tokenizer:  ['if', 'he', 'started', 'searching', 'he', 'will', 'get', 'job', 'in', 'few', 'days.he', 'have', 'great', 'potential', 'and', 'talent', '.']\n",
      "AFter tokenizer:  ['reckon', 'need', 'to', 'be', 'in', 'town', 'by', 'eightish', 'to', 'walk', 'from', '*', 'carpark', '.']\n",
      "AFter tokenizer:  ['congrats', '!', '2', 'mobile', '3g', 'videophones', 'r', 'yours', '.', 'call', '09063458130', 'now', '!', 'videochat', 'wid', 'your', 'mates', ',', 'play', 'java', 'games', ',', 'dload', 'polyph', 'music', ',', 'noline', 'rentl', '.']\n",
      "AFter tokenizer:  ['look', 'at', 'the', 'fuckin', 'time', '.', 'what', 'the', 'fuck', 'you', 'think', 'is', 'up']\n",
      "AFter tokenizer:  ['yo', 'guess', 'what', 'i', 'just', 'dropped']\n",
      "AFter tokenizer:  ['carlos', 'says', 'he', \"'ll\", 'be', 'at', 'mu', 'in', '&', 'lt', ';', '#', '&', 'gt', ';', 'minutes']\n",
      "AFter tokenizer:  ['i', \"'m\", 'in', 'office', 'now', '.', 'i', 'will', 'call', 'you', '&', 'lt', ';', '#', '&', 'gt', ';', 'min', ':', ')']\n",
      "AFter tokenizer:  ['geeee', '...', 'i', 'miss', 'you', 'already', ',', 'you', 'know', '?', 'your', 'all', 'i', 'can', 'think', 'about', '.', 'fuck', ',', 'i', 'ca', \"n't\", 'wait', 'till', 'next', 'year', 'when', 'we', 'will', 'be', 'together', '...', '*', 'loving', 'kiss', '*']\n",
      "AFter tokenizer:  ['yun', 'ah.the', 'ubi', 'one', 'say', 'if', 'ü', 'wan', 'call', 'by', 'tomorrow.call', '67441233', 'look', 'for', 'irene.ere', 'only', 'got', 'bus8,22,65,61,66,382', '.', 'ubi', 'cres', ',', 'ubi', 'tech', 'park.6ph', 'for', '1st', '5wkg', 'days.èn']\n",
      "AFter tokenizer:  ['ugh', '.', 'got', 'ta', 'drive', 'back', 'to', 'sd', 'from', 'la', '.', 'my', 'butt', 'is', 'sore', '.']\n",
      "AFter tokenizer:  ['26th', 'of', 'july']\n",
      "AFter tokenizer:  ['hi', 'im', 'having', 'the', 'most', 'relaxing', 'time', 'ever', '!', 'we', 'have', 'to', 'get', 'up', 'at', '7am', 'every', 'day', '!', 'was', 'the', 'party', 'good', 'the', 'other', 'night', '?', 'i', 'get', 'home', 'tomorrow', 'at', '5ish', '.']\n",
      "AFter tokenizer:  ['up', 'to', 'ü', '...', 'ü', 'wan', 'come', 'then', 'come', 'lor', '...', 'but', 'i', 'din', 'c', 'any', 'stripes', 'skirt', '...']\n",
      "AFter tokenizer:  ['the', 'xmas', 'story', 'is', 'peace', '..', 'the', 'xmas', 'msg', 'is', 'love', '..', 'the', 'xmas', 'miracle', 'is', 'jesus', '..', 'hav', 'a', 'blessed', 'month', 'ahead', '&', 'amp', ';', 'wish', 'u', 'merry', 'xmas', '...']\n",
      "AFter tokenizer:  ['i', 'ca', \"n't\", ',', 'i', 'do', \"n't\", 'have', 'her', 'number', '!']\n",
      "AFter tokenizer:  ['change', 'again', '...', 'it', \"'s\", 'e', 'one', 'next', 'to', 'escalator', '...']\n",
      "AFter tokenizer:  ['yetunde', 'i', \"'m\", 'in', 'class', 'can', 'you', 'not', 'run', 'water', 'on', 'it', 'to', 'make', 'it', 'ok.', 'pls', 'now', '.']\n",
      "AFter tokenizer:  ['not', 'a', 'lot', 'has', 'happened', 'here', '.', 'feels', 'very', 'quiet', '.', 'beth', 'is', 'at', 'her', 'aunts', 'and', 'charlie', 'is', 'working', 'lots', '.', 'just', 'me', 'and', 'helen', 'in', 'at', 'the', 'mo', '.', 'how', 'have', 'you', 'been', '?']\n",
      "AFter tokenizer:  ['then', 'ü', 'wait', '4', 'me', 'at', 'bus', 'stop', 'aft', 'ur', 'lect', 'lar', '.', 'if', 'i', 'dun', 'c', 'ü', 'then', 'i', 'go', 'get', 'my', 'car', 'then', 'come', 'back', 'n', 'pick', 'ü', '.']\n",
      "AFter tokenizer:  ['aight', 'will', 'do', ',', 'thanks', 'again', 'for', 'comin', 'out']\n",
      "AFter tokenizer:  ['no', '..', 'but', 'heard', 'abt', 'tat', '..']\n",
      "AFter tokenizer:  ['&', 'lt', ';', '#', '&', 'gt', ';', 'am', 'i', 'think', '?', 'should', 'say', 'on', 'syllabus']\n",
      "AFter tokenizer:  ['umma', '.', 'did', 'she', 'say', 'anything']\n",
      "AFter tokenizer:  ['give', 'me', 'a', 'sec', 'to', 'think', 'think', 'about', 'it']\n",
      "AFter tokenizer:  ['panasonic', '&', 'bluetoothhdset', 'free', '.', 'nokia', 'free', '.', 'motorola', 'free', '&', 'doublemins', '&', 'doubletxt', 'on', 'orange', 'contract', '.', 'call', 'mobileupd8', 'on', '08000839402', 'or', 'call', '2optout']\n",
      "AFter tokenizer:  ['i', 'do', \"n't\", 'quite', 'know', 'what', 'to', 'do', '.', 'i', 'still', 'ca', \"n't\", 'get', 'hold', 'of', 'anyone', '.', 'i', 'cud', 'pick', 'you', 'up', 'bout', '7.30pm', 'and', 'we', 'can', 'see', 'if', 'they', \"'re\", 'in', 'the', 'pub', '?']\n",
      "AFter tokenizer:  ['poyyarikatur', ',', 'kolathupalayam', ',', 'unjalur', 'post', ',', 'erode', 'dis', ',', '&', 'lt', ';', '#', '&', 'gt', ';', '.']\n",
      "AFter tokenizer:  ['dear', 'hero', ',', 'i', 'am', 'leaving', 'to', 'qatar', 'tonite', 'for', 'an', 'apt', 'opportunity.pls', 'do', 'keep', 'in', 'touch', 'at', '&', 'lt', ';', 'email', '&', 'gt', ';', ',', 'kerala']\n",
      "AFter tokenizer:  ['lol', 'i', 'would', 'but', 'my', 'mom', 'would', 'have', 'a', 'fit', 'and', 'tell', 'the', 'whole', 'family', 'how', 'crazy', 'and', 'terrible', 'i', 'am']\n",
      "AFter tokenizer:  ['i', 'just', 'got', 'home', 'babe', ',', 'are', 'you', 'still', 'awake', '?']\n",
      "AFter tokenizer:  ['i', 'dunno', 'they', 'close', 'oredi', 'not', '...', 'ü', 'v', 'ma', 'fan', '...']\n",
      "AFter tokenizer:  ['just', 'buy', 'a', 'pizza', '.', 'meat', 'lovers', 'or', 'supreme', '.', 'u', 'get', 'to', 'pick', '.']\n",
      "AFter tokenizer:  ['ya', ',', 'told', '..', 'she', 'was', 'asking', 'wats', 'matter', '?']\n",
      "AFter tokenizer:  ['dear', ',', 'regret', 'i', 'cudnt', 'pick', 'call.drove', 'down', 'frm', 'ctla', 'now', 'at', 'cochin', 'home.left', 'mobile', 'in', 'car', '..', 'ente', 'style', 'ishtamayoo', '?', 'happy', 'bakrid', '!']\n",
      "AFter tokenizer:  ['free', 'for', '1st', 'week', '!', 'no1', 'nokia', 'tone', '4', 'ur', 'mob', 'every', 'week', 'just', 'txt', 'nokia', 'to', '8007', 'get', 'txting', 'and', 'tell', 'ur', 'mates', 'www.getzed.co.uk', 'pobox', '36504', 'w45wq', 'norm150p/tone', '16+']\n",
      "AFter tokenizer:  ['shall', 'i', 'send', 'that', 'exe', 'to', 'your', 'mail', 'id', '.']\n",
      "AFter tokenizer:  ['nope', 'watching', 'tv', 'at', 'home', '...', 'not', 'going', 'out', '.', 'v', 'bored', '...']\n",
      "AFter tokenizer:  ['don', 'know', '..', 'wait', 'i', 'will', 'check', 'it', '.']\n",
      "AFter tokenizer:  ['good', 'afternoon', 'on', 'this', 'glorious', 'anniversary', 'day', ',', 'my', 'sweet', 'j', '!', '!', 'i', 'hope', 'this', 'finds', 'you', 'happy', 'and', 'content', ',', 'my', 'prey', '.', 'i', 'think', 'of', 'you', 'and', 'send', 'a', 'teasing', 'kiss', 'from', 'across', 'the', 'sea', 'coaxing', 'images', 'of', 'fond', 'souveniers', '...', 'you', 'cougar-pen']\n",
      "AFter tokenizer:  ['guess', 'what', '!', 'somebody', 'you', 'know', 'secretly', 'fancies', 'you', '!', 'wan', 'na', 'find', 'out', 'who', 'it', 'is', '?', 'give', 'us', 'a', 'call', 'on', '09065394514', 'from', 'landline', 'datebox1282essexcm61xn', '150p/min', '18']\n",
      "AFter tokenizer:  ['we', 'still', 'on', 'for', 'tonight', '?']\n",
      "AFter tokenizer:  ['may', 'i', 'call', 'you', 'later', 'pls']\n",
      "AFter tokenizer:  ['has', \"n't\", 'that', 'been', 'the', 'pattern', 'recently', 'crap', 'weekends', '?']\n",
      "AFter tokenizer:  ['i', 'have', 'a', 'sore', 'throat', '.', 'it', \"'s\", 'scratches', 'when', 'i', 'talk']\n",
      "AFter tokenizer:  ['yes', 'da', '.', 'any', 'plm', 'at', 'ur', 'office']\n",
      "AFter tokenizer:  ['are', 'you', 'not', 'around', 'or', 'just', 'still', 'asleep', '?', ':', 'v']\n",
      "AFter tokenizer:  ['lol', 'you', 'forgot', 'it', 'eh', '?', 'yes', ',', 'i', \"'ll\", 'bring', 'it', 'in', 'babe']\n",
      "AFter tokenizer:  ['its', 'good', ',', 'we', \"'ll\", 'find', 'a', 'way']\n",
      "AFter tokenizer:  ['can', 'not', 'use', 'foreign', 'stamps', 'in', 'this', 'country', '.', 'good', 'lecture', '.']\n",
      "AFter tokenizer:  ['yup', 'bathe', 'liao', '...']\n",
      "AFter tokenizer:  ['happy', 'new', 'year', 'my', 'no.1', 'man']\n",
      "AFter tokenizer:  ['oh', 'mr', 'sheffield', '!', 'you', 'wan', 'na', 'play', 'that', 'game', ',', 'okay', '.', 'you', \"'re\", 'the', 'boss', 'and', 'i', \"'m\", 'the', 'nanny', '.', 'you', 'give', 'me', 'a', 'raise', 'and', 'i', \"'ll\", 'give', 'you', 'one', '!', '!']\n",
      "AFter tokenizer:  ['zoe', 'it', 'just', 'hit', 'me', '2', 'im', 'fucking', 'shitin', 'myself', 'il', 'defo', 'try', 'my', 'hardest', '2', 'cum', '2morow', 'luv', 'u', 'millions', 'lekdog']\n",
      "AFter tokenizer:  ['hello', 'baby', ',', 'did', 'you', 'get', 'back', 'to', 'your', 'mom', \"'s\", '?', 'are', 'you', 'setting', 'up', 'the', 'computer', 'now', '?', 'filling', 'your', 'belly', '?', 'how', 'goes', 'it', 'loverboy', '?', 'i', 'miss', 'you', 'already', '...', '*', 'sighs', '*']\n",
      "AFter tokenizer:  ['no', 'my', 'blankets', 'are', 'sufficient', ',', 'thx']\n",
      "AFter tokenizer:  ['naughty', 'little', 'thought', ':', \"'its\", 'better', 'to', 'flirt', ',', 'flirt', 'n', 'flirt', ',', 'rather', 'than', 'loving', 'someone', 'n', 'gettin', 'hurt', ',', 'hurt', 'n', 'hurt', '...', ':', '-', ')', 'gud', 'nyt']\n",
      "AFter tokenizer:  ['edison', 'has', 'rightly', 'said', ',', '``', 'a', 'fool', 'can', 'ask', 'more', 'questions', 'than', 'a', 'wise', 'man', 'can', 'answer', \"''\", 'now', 'you', 'know', 'why', 'all', 'of', 'us', 'are', 'speechless', 'during', 'viva', '..', 'gm', ',', 'gn', ',', 'ge', ',', 'gnt', ':', '-', ')']\n",
      "AFter tokenizer:  ['they', 'just', 'talking', 'thats', 'it', 'de', '.', 'they', 'wont', 'any', 'other', '.']\n",
      "AFter tokenizer:  ['today', 'am', 'going', 'to', 'college', 'so', 'am', 'not', 'able', 'to', 'atten', 'the', 'class', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'in', 'class', '.', 'will', 'holla', 'later']\n",
      "AFter tokenizer:  ['mmm', 'thats', 'better', 'now', 'i', 'got', 'a', 'roast', 'down', 'me', '!', 'i\\x92d', 'b', 'better', 'if', 'i', 'had', 'a', 'few', 'drinks', 'down', 'me', '2', '!', 'good', 'indian', '?']\n",
      "AFter tokenizer:  ['we', 'know', 'someone', 'who', 'you', 'know', 'that', 'fancies', 'you', '.', 'call', '09058097218', 'to', 'find', 'out', 'who', '.', 'pobox', '6', ',', 'ls15hb', '150p']\n",
      "AFter tokenizer:  ['come', 'round', ',', 'it', \"'s\", '.']\n",
      "AFter tokenizer:  ['do', '1', 'thing', '!', 'change', 'that', 'sentence', 'into', ':', '``', 'because', 'i', 'want', '2', 'concentrate', 'in', 'my', 'educational', 'career', 'im', 'leaving', 'here', '..', \"''\"]\n",
      "AFter tokenizer:  ['1000', \"'s\", 'flirting', 'now', '!', 'txt', 'girl', 'or', 'bloke', '&', 'ur', 'name', '&', 'age', ',', 'eg', 'girl', 'zoe', '18', 'to', '8007', 'to', 'join', 'and', 'get', 'chatting', '!']\n",
      "AFter tokenizer:  ['i', 'walked', 'an', 'hour', '2', 'c', 'u', '!', 'doesn\\x92t', 'that', 'show', 'i', 'care', 'y', 'wont', 'u', 'believe', 'im', 'serious', '?']\n",
      "AFter tokenizer:  ['18', 'days', 'to', 'euro2004', 'kickoff', '!', 'u', 'will', 'be', 'kept', 'informed', 'of', 'all', 'the', 'latest', 'news', 'and', 'results', 'daily', '.', 'unsubscribe', 'send', 'get', 'euro', 'stop', 'to', '83222', '.']\n",
      "AFter tokenizer:  ['are', 'you', 'available', 'for', 'soiree', 'on', 'june', '3rd', '?']\n",
      "AFter tokenizer:  ['do', 'u', 'noe', 'wat', 'time', 'e', 'place', 'dat', 'sells', '4d', 'closes', '?']\n",
      "AFter tokenizer:  ['i', 'got', 'another', 'job', '!', 'the', 'one', 'at', 'the', 'hospital', 'doing', 'data', 'analysis', 'or', 'something', ',', 'starts', 'on', 'monday', '!', 'not', 'sure', 'when', 'my', 'thesis', 'will', 'got', 'finished']\n",
      "AFter tokenizer:  ['jay', \"'s\", 'getting', 'really', 'impatient', 'and', 'belligerent']\n",
      "AFter tokenizer:  ['hiya', 'comin', '2', 'bristol', '1', 'st', 'week', 'in', 'april', '.', 'les', 'got', 'off', '+', 'rudi', 'on', 'new', 'yrs', 'eve', 'but', 'i', 'was', 'snoring.they', 'were', 'drunk', '!', 'u', 'bak', 'at', 'college', 'yet', '?', 'my', 'work', 'sends', 'ink', '2', 'bath', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'at', 'work', '.', 'please', 'call']\n",
      "AFter tokenizer:  ['then', 'u', 'drive', 'lor', '.']\n",
      "AFter tokenizer:  ['ard', '515', 'like', 'dat', '.', 'y', '?']\n",
      "AFter tokenizer:  ['tell', 'me', 'they', \"'re\", 'female', ':', 'v', 'how', \"'re\", 'you', 'throwing', 'in', '?', 'we', \"'re\", 'deciding', 'what', 'all', 'to', 'get', 'now']\n",
      "AFter tokenizer:  ['eastenders', 'tv', 'quiz', '.', 'what', 'flower', 'does', 'dot', 'compare', 'herself', 'to', '?', 'd=', 'violet', 'e=', 'tulip', 'f=', 'lily', 'txt', 'd', 'e', 'or', 'f', 'to', '84025', 'now', '4', 'chance', '2', 'win', '£100', 'cash', 'wkent/150p16+']\n",
      "AFter tokenizer:  ['i', \"'m\", 'working', 'technical', 'support', ':', ')', 'voice', 'process.networking', 'field', '.']\n",
      "AFter tokenizer:  ['i', 'might', 'come', 'to', 'kerala', 'for', '2', 'days.so', 'you', 'can', 'be', 'prepared', 'to', 'take', 'a', 'leave', 'once', 'i', 'finalise', '.dont', 'plan', 'any', 'travel', 'during', 'my', 'visit.need', 'to', 'finish', 'urgent', 'works', '.']\n",
      "AFter tokenizer:  ['ok.', 'not', 'sure', 'what', 'time', 'tho', 'as', 'not', 'sure', 'if', 'can', 'get', 'to', 'library', 'before', 'class', '.', 'will', 'try', '.', 'see', 'you', 'at', 'some', 'point', '!', 'have', 'good', 'eve', '.']\n",
      "AFter tokenizer:  ['we', 'have', 'new', 'local', 'dates', 'in', 'your', 'area', '-', 'lots', 'of', 'new', 'people', 'registered', 'in', 'your', 'area', '.', 'reply', 'date', 'to', 'start', 'now', '!', '18', 'only', 'www.flirtparty.us', 'replys150']\n",
      "AFter tokenizer:  ['that', \"'s\", 'fine', ',', 'i', \"'ll\", 'bitch', 'at', 'you', 'about', 'it', 'later', 'then']\n",
      "AFter tokenizer:  ['no', 'my', 'mum', 'went', '2', 'dentist', '.']\n",
      "AFter tokenizer:  ['once', 'free', 'call', 'me', 'sir', '.', 'i', 'am', 'waiting', 'for', 'you', '.']\n",
      "AFter tokenizer:  ['meeting', 'u', 'is', 'my', 'work', '.', '.', '.', 'tel', 'me', 'when', 'shall', 'i', 'do', 'my', 'work', 'tomorrow']\n",
      "AFter tokenizer:  ['someone', 'u', 'know', 'has', 'asked', 'our', 'dating', 'service', '2', 'contact', 'you', '!', 'cant', 'guess', 'who', '?', 'call', '09058091854', 'now', 'all', 'will', 'be', 'revealed', '.', 'po', 'box385', 'm6', '6wu']\n",
      "AFter tokenizer:  ['jus', 'finish', 'bathing', '...']\n",
      "AFter tokenizer:  ['alright', ',', 'i', \"'ll\", 'make', 'sure', 'the', 'car', 'is', 'back', 'tonight']\n",
      "AFter tokenizer:  ['urgent', '!', 'we', 'are', 'trying', 'to', 'contact', 'u.', 'todays', 'draw', 'shows', 'that', 'you', 'have', 'won', 'a', '£800', 'prize', 'guaranteed', '.', 'call', '09050003091', 'from', 'land', 'line', '.', 'claim', 'c52', '.', 'valid12hrs', 'only']\n",
      "AFter tokenizer:  ['dear', 'u', \"'ve\", 'been', 'invited', 'to', 'xchat', '.', 'this', 'is', 'our', 'final', 'attempt', 'to', 'contact', 'u', '!', 'txt', 'chat', 'to', '86688']\n",
      "AFter tokenizer:  ['lul', 'im', 'gettin', 'some', 'juicy', 'gossip', 'at', 'the', 'hospital', '.', 'two', 'nurses', 'are', 'talking', 'about', 'how', 'fat', 'they', 'are', 'gettin', '.', 'and', 'one', 'thinks', 'shes', 'obese', '.', 'oyea', '.']\n",
      "AFter tokenizer:  ['aight', 'ill', 'get', 'on', 'fb', 'in', 'a', 'couple', 'minutes']\n",
      "AFter tokenizer:  ['oi', '.', 'ami', 'parchi', 'na', 're', '.', 'kicchu', 'kaaj', 'korte', 'iccha', 'korche', 'na', '.', 'phone', 'ta', 'tul', 'na', '.', 'plz', '.', 'plz', '.']\n",
      "AFter tokenizer:  ['where', 'can', 'download', 'clear', 'movies', '.', 'dvd', 'copies', '.']\n",
      "AFter tokenizer:  ['yep', ',', 'by', 'the', 'pretty', 'sculpture']\n",
      "AFter tokenizer:  ['convey', 'my', 'regards', 'to', 'him']\n",
      "AFter tokenizer:  ['me', 'too', 'watching', 'surya', 'movie', 'only', '.', '.', '.after', '6', 'pm', 'vijay', 'movie', 'pokkiri']\n",
      "AFter tokenizer:  ['you', 'tell', 'what', 'happen', 'dont', 'behave', 'like', 'this', 'to', 'me', '.', 'ok', 'no', 'need', 'to', 'say']\n",
      "AFter tokenizer:  ['can', 'u', 'get', 'pic', 'msgs', 'to', 'your', 'phone', '?']\n",
      "AFter tokenizer:  ['send', 'to', 'someone', 'else', ':', '-', ')']\n",
      "AFter tokenizer:  ['wat', 'makes', 'some', 'people', 'dearer', 'is', 'not', 'just', 'de', 'happiness', 'dat', 'u', 'feel', 'when', 'u', 'meet', 'them', 'but', 'de', 'pain', 'u', 'feel', 'when', 'u', 'miss', 'dem', '!', '!', '!']\n",
      "AFter tokenizer:  ['for', 'me', 'the', 'love', 'should', 'start', 'with', 'attraction.i', 'should', 'feel', 'that', 'i', 'need', 'her', 'every', 'time', 'around', 'me.she', 'should', 'be', 'the', 'first', 'thing', 'which', 'comes', 'in', 'my', 'thoughts.i', 'would', 'start', 'the', 'day', 'and', 'end', 'it', 'with', 'her.she', 'should', 'be', 'there', 'every', 'time', 'i', 'dream.love', 'will', 'be', 'then', 'when', 'my', 'every', 'breath', 'has', 'her', 'name.my', 'life', 'should', 'happen', 'around', 'her.my', 'life', 'will', 'be', 'named', 'to', 'her.i', 'would', 'cry', 'for', 'her.will', 'give', 'all', 'my', 'happiness', 'and', 'take', 'all', 'her', 'sorrows.i', 'will', 'be', 'ready', 'to', 'fight', 'with', 'anyone', 'for', 'her.i', 'will', 'be', 'in', 'love', 'when', 'i', 'will', 'be', 'doing', 'the', 'craziest', 'things', 'for', 'her.love', 'will', 'be', 'when', 'i', 'do', \"n't\", 'have', 'to', 'proove', 'anyone', 'that', 'my', 'girl', 'is', 'the', 'most', 'beautiful', 'lady', 'on', 'the', 'whole', 'planet.i', 'will', 'always', 'be', 'singing', 'praises', 'for', 'her.love', 'will', 'be', 'when', 'i', 'start', 'up', 'making', 'chicken', 'curry', 'and', 'end', 'up', 'makiing', 'sambar.life', 'will', 'be', 'the', 'most', 'beautiful', 'then.will', 'get', 'every', 'morning', 'and', 'thank', 'god', 'for', 'the', 'day', 'because', 'she', 'is', 'with', 'me.i', 'would', 'like', 'to', 'say', 'a', 'lot', '..', 'will', 'tell', 'later', '..']\n",
      "AFter tokenizer:  [\"fr'ndship\", 'is', 'like', 'a', 'needle', 'of', 'a', 'clock', '.', 'though', 'v', 'r', 'in', 'd', 'same', 'clock', ',', 'v', 'r', 'nt', 'able', '2', 'met', '.', 'evn', 'if', 'v', 'meet', ',', 'itz', 'only', '4few', 'seconds', '.', 'bt', 'v', 'alwys', 'stay', 'conected', '.', 'gud', '9t', ';', '-', ')']\n",
      "AFter tokenizer:  ['i', 'do', \"n't\", 'think', 'he', 'has', 'spatula', 'hands', '!']\n",
      "AFter tokenizer:  ['you', 'can', 'never', 'do', 'nothing']\n",
      "AFter tokenizer:  ['you', 'are', 'awarded', 'a', 'sipix', 'digital', 'camera', '!', 'call', '09061221061', 'from', 'landline', '.', 'delivery', 'within', '28days', '.', 't', 'cs', 'box177', '.', 'm221bp', '.', '2yr', 'warranty', '.', '150ppm', '.', '16', '.', 'p', 'p£3.99']\n",
      "AFter tokenizer:  ['goodmorning', 'today', 'i', 'am', 'late', 'for', '&', 'lt', ';', 'decimal', '&', 'gt', ';', 'min', '.']\n",
      "AFter tokenizer:  ['win', 'urgent', '!', 'your', 'mobile', 'number', 'has', 'been', 'awarded', 'with', 'a', '£2000', 'prize', 'guaranteed', 'call', '09061790121', 'from', 'land', 'line', '.', 'claim', '3030', 'valid', '12hrs', 'only', '150ppm']\n",
      "AFter tokenizer:  ['please', 'da', 'call', 'me', 'any', 'mistake', 'from', 'my', 'side', 'sorry', 'da', '.', 'pls', 'da', 'goto', 'doctor', '.']\n",
      "AFter tokenizer:  ['where', 'r', 'we', 'meeting', '?']\n",
      "AFter tokenizer:  ['well', 'the', 'weather', 'in', 'cali', \"'s\", 'great', '.', 'but', 'its', 'complexities', 'are', 'great', '.', 'you', 'need', 'a', 'car', 'to', 'move', 'freely', ',', 'its', 'taxes', 'are', 'outrageous', '.', 'but', 'all', 'in', 'all', 'its', 'a', 'great', 'place', '.', 'the', 'sad', 'part', 'is', 'i', 'missing', 'home', '.']\n",
      "AFter tokenizer:  ['now', 'only', 'i', 'reached', 'home', '.', '.', '.', 'i', 'am', 'very', 'tired', 'now', '.', '.', 'i', 'will', 'come', 'tomorro']\n",
      "AFter tokenizer:  ['ryder', 'unsold.now', 'gibbs', '.']\n",
      "AFter tokenizer:  ['dear', 'subscriber', 'ur', 'draw', '4', '£100', 'gift', 'voucher', 'will', 'b', 'entered', 'on', 'receipt', 'of', 'a', 'correct', 'ans', '.', 'when', 'was', 'elvis', 'presleys', 'birthday', '?', 'txt', 'answer', 'to', '80062']\n",
      "AFter tokenizer:  ['do', \"n't\", 'fret', '.', 'i', \"'ll\", 'buy', 'the', 'ovulation', 'test', 'strips', 'and', 'send', 'them', 'to', 'you', '.', 'you', 'wont', 'get', 'them', 'til', 'like', 'march', '.', 'can', 'you', 'send', 'me', 'your', 'postal', 'address.u', \"'ll\", 'be', 'alright.okay', '.']\n",
      "AFter tokenizer:  ['no', 'gifts', '!', '!', 'you', 'trying', 'to', 'get', 'me', 'to', 'throw', 'myself', 'off', 'a', 'cliff', 'or', 'something', '?']\n",
      "AFter tokenizer:  ['been', 'up', 'to', 'ne', 'thing', 'interesting', '.', 'did', 'you', 'have', 'a', 'good', 'birthday', '?', 'when', 'are', 'u', 'wrking', 'nxt', '?', 'i', 'started', 'uni', 'today', '.']\n",
      "AFter tokenizer:  ['you', 'busy', 'or', 'can', 'i', 'come', 'by', 'at', 'some', 'point', 'and', 'figure', 'out', 'what', 'we', \"'re\", 'doing', 'tomorrow']\n",
      "AFter tokenizer:  ['yeah', 'go', 'on', 'then', ',', 'bored', 'and', 'depressed', 'sittin', 'waitin', 'for', 'phone', 'to', 'ring', '...', 'hope', 'the', 'wind', 'drops', 'though', ',', 'scary']\n",
      "AFter tokenizer:  ['black', 'shirt', 'n', 'blue', 'jeans', '...', 'i', 'thk', 'i', 'c', 'ü', '...']\n",
      "AFter tokenizer:  ['aiyah', 'sorry', 'lor', '...', 'i', 'watch', 'tv', 'watch', 'until', 'i', 'forgot', '2', 'check', 'my', 'phone', '.']\n",
      "AFter tokenizer:  ['message', 'important', 'information', 'for', 'o2', 'user', '.', 'today', 'is', 'your', 'lucky', 'day', '!', '2', 'find', 'out', 'why', 'log', 'onto', 'http', ':', '//www.urawinner.com', 'there', 'is', 'a', 'fantastic', 'surprise', 'awaiting', 'you']\n",
      "AFter tokenizer:  ['on', 'hen', 'night', '.', 'going', 'with', 'a', 'swing']\n",
      "AFter tokenizer:  ['good', 'afternoon', ',', 'my', 'love', '.', 'how', 'goes', 'your', 'day', '?', 'what', 'are', 'you', 'up', 'to', '?', 'i', 'woke', 'early', 'and', 'am', 'online', 'waiting', 'for', 'you', '...', 'hmmm', '...', 'italian', 'boy', 'is', 'online', 'i', 'see', '.', '*', 'grins', '*']\n",
      "AFter tokenizer:  ['from', 'someone', 'not', 'to', 'smoke', 'when', 'every', 'time', 'i', \"'ve\", 'smoked', 'in', 'the', 'last', 'two', 'weeks', 'is', 'because', 'of', 'you', 'calling', 'or', 'texting', 'me', 'that', 'you', 'wanted', 'to', 'smoke']\n",
      "AFter tokenizer:  ['no', 'you', \"'ll\", 'just', 'get', 'a', 'headache', 'trying', 'to', 'figure', 'it', 'out', '.', 'u', 'can', 'trust', 'me', 'to', 'do', 'the', 'math', '.', 'i', 'promise', '.', 'o', ':', '-', ')']\n",
      "AFter tokenizer:  ['s', 's', '..', 'first', 'time', '..', 'dhoni', 'rocks', '...']\n",
      "AFter tokenizer:  ['ok', 'ill', 'tell', 'the', 'company']\n",
      "AFter tokenizer:  ['awesome', ',', 'think', 'we', 'can', 'get', 'an', '8th', 'at', 'usf', 'some', 'time', 'tonight', '?']\n",
      "AFter tokenizer:  ['so', 'that', 'means', 'you', 'still', 'think', 'of', 'teju']\n",
      "AFter tokenizer:  ['no', 'i', \"'m\", 'good', 'for', 'the', 'movie', ',', 'is', 'it', 'ok', 'if', 'i', 'leave', 'in', 'an', 'hourish', '?']\n",
      "AFter tokenizer:  ['no', 'no', ':', ')', 'this', 'is', 'kallis', 'home', 'ground.amla', 'home', 'town', 'is', 'durban', ':', ')']\n",
      "AFter tokenizer:  ['so', 'lets', 'make', 'it', 'saturday', 'or', 'monday', 'as', 'per', 'convenience', '.']\n",
      "AFter tokenizer:  ['hey', '...', 'what', 'time', 'is', 'your', 'driving', 'on', 'fri', '?', 'we', 'go', 'for', 'evaluation', 'on', 'fri', '?']\n",
      "AFter tokenizer:  ['449050000301', 'you', 'have', 'won', 'a', '£2,000', 'price', '!', 'to', 'claim', ',', 'call', '09050000301', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'going', '4', 'lunch', 'now', 'wif', 'my', 'family', 'then', 'aft', 'dat', 'i', 'go', 'str', '2', 'orchard', 'lor', '.']\n",
      "AFter tokenizer:  ['bored', 'of', 'speed', 'dating', '?', 'try', 'speedchat', ',', 'txt', 'speedchat', 'to', '80155', ',', 'if', 'you', 'do', \"n't\", 'like', 'em', 'txt', 'swap', 'and', 'get', 'a', 'new', 'chatter', '!', 'chat80155', 'pobox36504w45wq', '150p/msg', 'rcd', '16']\n",
      "AFter tokenizer:  ['cancel', 'cheyyamo', '?', 'and', 'get', 'some', 'money', 'back', '?']\n",
      "AFter tokenizer:  ['do', 'you', 'want', '750', 'anytime', 'any', 'network', 'mins', '150', 'text', 'and', 'a', 'new', 'video', 'phone', 'for', 'only', 'five', 'pounds', 'per', 'week', 'call', '08000776320', 'now', 'or', 'reply', 'for', 'delivery', 'tomorrow']\n",
      "AFter tokenizer:  ['ok.ok', 'ok', '..', 'then', '..', 'whats', 'ur', 'todays', 'plan']\n",
      "AFter tokenizer:  ['good', 'morning', 'princess', '!', 'how', 'are', 'you', '?']\n",
      "AFter tokenizer:  ['aiyar', 'sorry', 'lor', 'forgot', '2', 'tell', 'u', '...']\n",
      "AFter tokenizer:  ['for', 'taking', 'part', 'in', 'our', 'mobile', 'survey', 'yesterday', '!', 'you', 'can', 'now', 'have', '500', 'texts', '2', 'use', 'however', 'you', 'wish', '.', '2', 'get', 'txts', 'just', 'send', 'txt', 'to', '80160', 't', '&', 'c', 'www.txt43.com', '1.50p']\n",
      "AFter tokenizer:  ['not', 'tonight', 'mate', '.', 'catching', 'up', 'on', 'some', 'sleep', '.', 'this', 'is', 'my', 'new', 'number', 'by', 'the', 'way', '.']\n",
      "AFter tokenizer:  ['height', 'of', '``', 'oh', 'shit', '....', '!', '!', \"''\", 'situation', ':', 'a', 'guy', 'throws', 'a', 'luv', 'letter', 'on', 'a', 'gal', 'but', 'falls', 'on', 'her', 'brothers', 'head', 'whos', 'a', 'gay', ',', '.', ';', '-', ')', ':', '-d']\n",
      "AFter tokenizer:  ['ur', 'hmv', 'quiz', 'cash-balance', 'is', 'currently', '£500', '-', 'to', 'maximize', 'ur', 'cash-in', 'now', 'send', 'hmv1', 'to', '86688', 'only', '150p/msg']\n",
      "AFter tokenizer:  ['so', 'check', 'your', 'errors', 'and', 'if', 'you', 'had', 'difficulties', ',', 'do', 'correction', '.']\n",
      "AFter tokenizer:  ['howz', 'pain', '?', 'hope', 'u', 'r', 'fine', '..']\n",
      "AFter tokenizer:  ['u', 'wake', 'up', 'already', '?', 'thanx', '4', 'e', 'tau', 'sar', 'piah', 'it', \"'s\", 'quite', 'nice', '.']\n",
      "AFter tokenizer:  ['k', 'do', 'i', 'need', 'a', 'login', 'or', 'anything']\n",
      "AFter tokenizer:  ['dont', 'forget', 'you', 'can', 'place', 'as', 'many', 'free', 'requests', 'with', '1stchoice.co.uk', 'as', 'you', 'wish', '.', 'for', 'more', 'information', 'call', '08707808226', '.']\n",
      "AFter tokenizer:  ['lol', '...', 'no', 'just', 'was', 'busy']\n",
      "AFter tokenizer:  ['what', '*', 'u', 'wearing', '?']\n",
      "AFter tokenizer:  ['oh', ':', ')', 'as', 'usual', 'vijay', 'film', 'or', 'its', 'different', '?']\n",
      "AFter tokenizer:  ['i', 'do', \"n't\", 'know', 'u', 'and', 'u', 'do', \"n't\", 'know', 'me', '.', 'send', 'chat', 'to', '86688', 'now', 'and', 'let', \"'s\", 'find', 'each', 'other', '!', 'only', '150p/msg', 'rcvd', '.', 'hg/suite342/2lands/row/w1j6hl', 'ldn', '.', '18', 'years', 'or', 'over', '.']\n",
      "AFter tokenizer:  ['have', 'you', 'had', 'a', 'good', 'day', '?', 'mine', 'was', 'really', 'busy', 'are', 'you', 'up', 'to', 'much', 'tomorrow', 'night', '?']\n",
      "AFter tokenizer:  ['and', 'is', 'there', 'a', 'way', 'you', 'can', 'send', 'shade', \"'s\", 'stuff', 'to', 'her', '.', 'and', 'she', 'has', 'been', 'wonderful', 'too', '.']\n",
      "AFter tokenizer:  ['really', '...', 'i', 'tot', 'ur', 'paper', 'ended', 'long', 'ago', '...', 'but', 'wat', 'u', 'copied', 'jus', 'now', 'got', 'use', '?', 'u', 'happy', 'lar', '...', 'i', 'still', 'haf', '2', 'study', ':', '-', '(']\n",
      "AFter tokenizer:  ['thank', 'you', ',', 'winner', 'notified', 'by', 'sms', '.', 'good', 'luck', '!', 'no', 'future', 'marketing', 'reply', 'stop', 'to', '84122', 'customer', 'services', '08450542832']\n",
      "AFter tokenizer:  ['babe', '?', 'i', 'lost', 'you', '...', ':', '-', '(']\n",
      "AFter tokenizer:  ['ok', '...', 'help', 'me', 'ask', 'if', 'she', \"'s\", 'working', 'tmr', 'a', 'not', '?']\n",
      "AFter tokenizer:  ['i', \"'m\", 'not', 'driving', '...', 'raining', '!', 'then', 'i', \"'ll\", 'get', 'caught', 'at', 'e', 'mrt', 'station', 'lor', '.']\n",
      "AFter tokenizer:  ['not', 'a', 'drop', 'in', 'the', 'tank']\n",
      "AFter tokenizer:  ['(', 'that', 'said', 'can', 'you', 'text', 'him', 'one', 'more', 'time', '?', ')']\n",
      "AFter tokenizer:  ['ok', 'i', 'go', 'change', 'also', '...']\n",
      "AFter tokenizer:  ['1000', \"'s\", 'of', 'girls', 'many', 'local', '2', 'u', 'who', 'r', 'virgins', '2', 'this', '&', 'r', 'ready', '2', '4fil', 'ur', 'every', 'sexual', 'need', '.', 'can', 'u', '4fil', 'theirs', '?', 'text', 'cute', 'to', '69911', '(', '£1.50p', '.', 'm', ')']\n",
      "AFter tokenizer:  ['did', 'u', 'find', 'a', 'sitter', 'for', 'kaitlyn', '?', 'i', 'was', 'sick', 'and', 'slept', 'all', 'day', 'yesterday', '.']\n",
      "AFter tokenizer:  ['sorry', 'man', ',', 'accidentally', 'left', 'my', 'phone', 'on', 'silent', 'last', 'night', 'and', 'did', \"n't\", 'check', 'it', 'til', 'i', 'got', 'up']\n",
      "AFter tokenizer:  ['hey', '..', 'something', 'came', 'up', 'last', 'min', '..', 'think', 'i', 'wun', 'be', 'signing', 'up', 'tmr', '..', 'hee']\n",
      "AFter tokenizer:  ['he', \"'s\", 'an', 'adult', 'and', 'would', 'learn', 'from', 'the', 'experience', '.', 'there', \"'s\", 'no', 'real', 'danger', '.', 'i', 'just', 'dont', 'like', 'peeps', 'using', 'drugs', 'they', 'dont', 'need', '.', 'but', 'no', 'comment']\n",
      "AFter tokenizer:  ['hey', '!', 'there', \"'s\", 'veggie', 'pizza', '...', ':', '/']\n",
      "AFter tokenizer:  ['yun', 'buying', '...', 'but', 'school', 'got', 'offer', '2000', 'plus', 'only', '...']\n",
      "AFter tokenizer:  ['you', 'sure', 'your', 'neighbors', 'didnt', 'pick', 'it', 'up']\n",
      "AFter tokenizer:  ['k.', 'i', 'will', 'sent', 'it', 'again']\n",
      "AFter tokenizer:  ['well', '.', 'im', 'computerless', '.', 'time', 'to', 'make', 'some', 'oreo', 'truffles']\n",
      "AFter tokenizer:  ['haha', 'yeah', 'i', 'see', 'that', 'now', ',', 'be', 'there', 'in', 'a', 'sec']\n",
      "AFter tokenizer:  ['i', 'am', 'not', 'having', 'her', 'number', 'sir']\n",
      "AFter tokenizer:  ['lol', 'now', 'i', \"'m\", 'after', 'that', 'hot', 'air', 'balloon', '!']\n",
      "AFter tokenizer:  ['ok', '.', '.', 'now', 'i', 'am', 'in', 'bus', '.', '.', 'if', 'i', 'come', 'soon', 'i', 'will', 'come', 'otherwise', 'tomorrow']\n",
      "AFter tokenizer:  ['msgs', 'r', 'not', 'time', 'pass.they', 'silently', 'say', 'that', 'i', 'am', 'thinking', 'of', 'u', 'right', 'now', 'and', 'also', 'making', 'u', 'think', 'of', 'me', 'at', 'least', '4', 'a', 'moment', '.', 'gd', 'nt.swt', 'drms', '@', 'shesil']\n",
      "AFter tokenizer:  ['yeah', ',', 'we', 'can', 'probably', 'swing', 'by', 'once', 'my', 'roommate', 'finishes', 'up', 'with', 'his', 'girl']\n",
      "AFter tokenizer:  ['got', 'what', 'it', 'takes', '2', 'take', 'part', 'in', 'the', 'wrc', 'rally', 'in', 'oz', '?', 'u', 'can', 'with', 'lucozade', 'energy', '!', 'text', 'rally', 'le', 'to', '61200', '(', '25p', ')', ',', 'see', 'packs', 'or', 'lucozade.co.uk/wrc', '&', 'itcould', 'be', 'u', '!']\n",
      "AFter tokenizer:  ['happy', 'new', 'years', 'melody', '!']\n",
      "AFter tokenizer:  ['ü', 'dun', 'need', 'to', 'pick', 'ur', 'gf', '?']\n",
      "AFter tokenizer:  ['yay', '!', 'you', 'better', 'not', 'have', 'told', 'that', 'to', '5', 'other', 'girls', 'either', '.']\n",
      "AFter tokenizer:  ['horrible', 'u', 'eat', 'macs', 'eat', 'until', 'u', 'forgot', 'abt', 'me', 'already', 'rite', '...', 'u', 'take', 'so', 'long', '2', 'reply', '.', 'i', 'thk', 'it', \"'s\", 'more', 'toot', 'than', 'b4', 'so', 'b', 'prepared', '.', 'now', 'wat', 'shall', 'i', 'eat', '?']\n",
      "AFter tokenizer:  ['did', 'he', 'say', 'how', 'fantastic', 'i', 'am', 'by', 'any', 'chance', ',', 'or', 'anything', 'need', 'a', 'bigger', 'life', 'lift', 'as', 'losing', 'the', 'will', '2', 'live', ',', 'do', 'you', 'think', 'i', 'would', 'be', 'the', 'first', 'person', '2', 'die', 'from', 'n', 'v', 'q', '?']\n",
      "AFter tokenizer:  ['just', 'nw', 'i', 'came', 'to', 'hme', 'da', '..']\n",
      "AFter tokenizer:  ['i', \"'m\", 'outside', 'islands', ',', 'head', 'towards', 'hard', 'rock', 'and', 'you', \"'ll\", 'run', 'into', 'me']\n",
      "AFter tokenizer:  ['to', 'day', 'class', 'is', 'there', 'are', 'no', 'class', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'in', 'chennai', 'velachery', ':', ')']\n",
      "AFter tokenizer:  ['you', 'flippin', 'your', 'shit', 'yet', '?']\n",
      "AFter tokenizer:  ['k', 'give', 'me', 'a', 'sec', ',', 'breaking', 'a', '&', 'lt', ';', '#', '&', 'gt', ';', 'at', 'cstore']\n",
      "AFter tokenizer:  ['am', 'i', 'that', 'much', 'bad', 'to', 'avoid', 'like', 'this', '?']\n",
      "AFter tokenizer:  ['yo', ',', 'you', 'around', '?', 'just', 'got', 'my', 'car', 'back']\n",
      "AFter tokenizer:  ['annoying', 'is', \"n't\", 'it', '.']\n",
      "AFter tokenizer:  ['goodmorning', ',', 'today', 'i', 'am', 'late', 'for', '&', 'lt', ';', '#', '&', 'gt', ';', 'min', '.']\n",
      "AFter tokenizer:  ['there', \"'s\", 'no', 'point', 'hangin', 'on', 'to', 'mr', 'not', 'right', 'if', 'he', \"'s\", 'not', 'makin', 'u', 'happy']\n",
      "AFter tokenizer:  ['all', 'will', 'come', 'alive.better', 'correct', 'any', 'good', 'looking', 'figure', 'there', 'itself', '..']\n",
      "AFter tokenizer:  ['in', 'that', 'case', 'i', 'guess', 'i', \"'ll\", 'see', 'you', 'at', 'campus', 'lodge']\n",
      "AFter tokenizer:  ['we', \"'re\", 'done', '...']\n",
      "AFter tokenizer:  ['come', 'to', 'my', 'home', 'for', 'one', 'last', 'time', 'i', 'wont', 'do', 'anything', '.', 'trust', 'me', '.']\n",
      "AFter tokenizer:  ['i', 'was', 'up', 'all', 'night', 'too', 'worrying', 'about', 'this', 'appt', '.', 'it', \"'s\", 'a', 'shame', 'we', 'missed', 'a', 'girls', 'night', 'out', 'with', 'quizzes', 'popcorn', 'and', 'you', 'doing', 'my', 'hair', '.']\n",
      "AFter tokenizer:  ['sex', 'up', 'ur', 'mobile', 'with', 'a', 'free', 'sexy', 'pic', 'of', 'jordan', '!', 'just', 'text', 'babe', 'to', '88600.', 'then', 'every', 'wk', 'get', 'a', 'sexy', 'celeb', '!', 'pocketbabe.co.uk', '4', 'more', 'pics', '.', '16', '£3/wk', '087016248']\n",
      "AFter tokenizer:  ['ok', '...', 'c', 'ya', '...']\n",
      "AFter tokenizer:  ['you', 'have', '1', 'new', 'voicemail', '.', 'please', 'call', '08719181503']\n",
      "AFter tokenizer:  ['what', 'he', 'said', 'is', 'not', 'the', 'matter', '.', 'my', 'mind', 'saying', 'some', 'other', 'matter', 'is', 'there', '.']\n",
      "AFter tokenizer:  ['al', 'he', 'does', 'is', 'moan', 'at', 'me', 'if', 'n', 'e', 'thin', 'goes', 'wrong', 'its', 'my', 'fault', '&', 'al', 'de', 'arguments', 'r', 'my', 'fault', '&', 'fed', 'up', 'of', 'him', 'of', 'himso', 'y', 'bother', '?', 'hav', '2go', ',', 'thanx.xx']\n",
      "AFter tokenizer:  ['neft', 'transaction', 'with', 'reference', 'number', '&', 'lt', ';', '#', '&', 'gt', ';', 'for', 'rs', '.', '&', 'lt', ';', 'decimal', '&', 'gt', ';', 'has', 'been', 'credited', 'to', 'the', 'beneficiary', 'account', 'on', '&', 'lt', ';', '#', '&', 'gt', ';', 'at', '&', 'lt', ';', 'time', '&', 'gt', ';', ':', '&', 'lt', ';', '#', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['otherwise', 'had', 'part', 'time', 'job', 'na-tuition', '..']\n",
      "AFter tokenizer:  ['i', 'know', 'she', 'called', 'me']\n",
      "AFter tokenizer:  ['me', 'also', 'da', ',', 'i', 'feel', 'yesterday', 'night', 'wait', 'til', '2day', 'night', 'dear', '.']\n",
      "AFter tokenizer:  ['thanks', 'for', 'understanding', '.', 'i', \"'ve\", 'been', 'trying', 'to', 'tell', 'sura', 'that', '.']\n",
      "AFter tokenizer:  ['win', 'a', 'year', 'supply', 'of', 'cds', '4', 'a', 'store', 'of', 'ur', 'choice', 'worth', '£500', '&', 'enter', 'our', '£100', 'weekly', 'draw', 'txt', 'music', 'to', '87066', 'ts', '&', 'cs', 'www.ldew.com.subs16+1win150ppmx3']\n",
      "AFter tokenizer:  ['the', 'whole', 'car', 'appreciated', 'the', 'last', 'two', '!', 'dad', 'and', 'are', 'having', 'a', 'map', 'reading', 'semi', 'argument', 'but', 'apart', 'from', 'that', 'things', 'are', 'going', 'ok.', 'p', '.']\n",
      "AFter tokenizer:  ['as', 'a', 'sim', 'subscriber', ',', 'you', 'are', 'selected', 'to', 'receive', 'a', 'bonus', '!', 'get', 'it', 'delivered', 'to', 'your', 'door', ',', 'txt', 'the', 'word', 'ok', 'to', 'no', ':', '88600', 'to', 'claim', '.', '150p/msg', ',', 'exp', '.', '30apr']\n",
      "AFter tokenizer:  ['i', 'need', 'you', 'to', 'be', 'in', 'my', 'strong', 'arms', '...']\n",
      "AFter tokenizer:  ['also', 'maaaan', 'are', 'you', 'missing', 'out']\n",
      "AFter tokenizer:  ['his', 'bday', 'real', 'is', 'in', 'april', '.']\n",
      "AFter tokenizer:  ['guessin', 'you', 'ai', \"n't\", 'gon', 'na', 'be', 'here', 'before', '9', '?']\n",
      "AFter tokenizer:  ['ok', 'then', 'i', 'will', 'come', 'to', 'ur', 'home', 'after', 'half', 'an', 'hour']\n",
      "AFter tokenizer:  ['yo', ',', 'the', 'game', 'almost', 'over', '?', 'want', 'to', 'go', 'to', 'walmart', 'soon']\n",
      "AFter tokenizer:  ['yeah', ',', 'probably', 'but', 'not', 'sure', '.', 'ilol', 'let', 'u', 'know', ',', 'but', 'personally', 'i', 'wuldnt', 'bother', ',', 'then', 'again', 'if', 'ur', 'goin', 'to', 'then', 'i', 'mite', 'as', 'well', '!', '!']\n",
      "AFter tokenizer:  ['i', \"'ll\", 'text', 'now', '!', 'all', 'creepy', 'like', 'so', 'he', 'wo', \"n't\", 'think', 'that', 'we', 'forgot']\n",
      "AFter tokenizer:  ['that', 'would', 'be', 'good', '…', 'i', \"'ll\", 'phone', 'you', 'tomo', 'lunchtime', ',', 'shall', 'i', ',', 'to', 'organise', 'something', '?']\n",
      "AFter tokenizer:  ['you', 'have', '1', 'new', 'voicemail', '.', 'please', 'call', '08719181513', '.']\n",
      "AFter tokenizer:  ['damn', ',', 'can', 'you', 'make', 'it', 'tonight', 'or', 'do', 'you', 'want', 'to', 'just', 'wait', 'til', 'tomorrow']\n",
      "AFter tokenizer:  ['k', '..', 'k', '..', 'i', \"'m\", 'also', 'fine', ':', ')', 'when', 'will', 'you', 'complete', 'the', 'course', '?']\n",
      "AFter tokenizer:  ['true', '.', 'it', 'is', 'passable', '.', 'and', 'if', 'you', 'get', 'a', 'high', 'score', 'and', 'apply', 'for', 'phd', ',', 'you', 'get', '5years', 'of', 'salary', '.', 'so', 'it', 'makes', 'life', 'easier', '.']\n",
      "AFter tokenizer:  ['no', '.', '1', 'nokia', 'tone', '4', 'ur', 'mob', 'every', 'week', '!', 'just', 'txt', 'nok', 'to', '87021', '.', '1st', 'tone', 'free', '!', 'so', 'get', 'txtin', 'now', 'and', 'tell', 'ur', 'friends', '.', '150p/tone', '.', '16', 'reply', 'hl', '4info']\n",
      "AFter tokenizer:  ['prakesh', 'is', 'there', 'know', '.']\n",
      "AFter tokenizer:  ['teach', 'me', 'apps', 'da', '.', 'when', 'you', 'come', 'to', 'college', '.']\n",
      "AFter tokenizer:  ['rofl', 'betta', 'invest', 'in', 'some', 'anti', 'aging', 'products']\n",
      "AFter tokenizer:  ['sir', ',', 'you', 'will', 'receive', 'the', 'account', 'no', 'another', '1hr', 'time', '.', 'sorry', 'for', 'the', 'delay', '.']\n",
      "AFter tokenizer:  ['reply', 'with', 'your', 'name', 'and', 'address', 'and', 'you', 'will', 'receive', 'by', 'post', 'a', 'weeks', 'completely', 'free', 'accommodation', 'at', 'various', 'global', 'locations', 'www.phb1.com', 'ph:08700435505150p']\n",
      "AFter tokenizer:  ['so', 'ü', \"'ll\", 'be', 'submitting', 'da', 'project', 'tmr', 'rite', '?']\n",
      "AFter tokenizer:  ['free', 'entry', 'into', 'our', '£250', 'weekly', 'comp', 'just', 'send', 'the', 'word', 'enter', 'to', '84128', 'now', '.', '18', 't', '&', 'c', 'www.textcomp.com', 'cust', 'care', '08712405020', '.']\n",
      "AFter tokenizer:  ['jus', 'ans', 'me', 'lar', '.', 'u', \"'ll\", 'noe', 'later', '.']\n",
      "AFter tokenizer:  ['i', 'want', 'to', 'send', 'something', 'that', 'can', 'sell', 'fast', '.', '&', 'lt', ';', '#', '&', 'gt', ';', 'k', 'is', 'not', 'easy', 'money', '.']\n",
      "AFter tokenizer:  ['have', 'got', '*', 'few', 'things', 'to', 'do', '.', 'may', 'be', 'in', '*', 'pub', 'later', '.']\n",
      "AFter tokenizer:  ['1', \"'s\", 'finish', 'meeting', 'call', 'me', '.']\n",
      "AFter tokenizer:  ['lol', 'ok.', 'i', \"'ll\", 'snatch', 'her', 'purse', 'too', '.']\n",
      "AFter tokenizer:  ['hello-/', '@', 'drivby-:0quit', 'edrunk', 'sorry', 'iff', 'pthis', 'makes', 'no', 'senrd-dnot', 'no', 'how', '^', 'dancce', '2', 'drum', 'n', 'basq', '!', 'ihave', 'fun', '2nhite', 'x', 'ros', 'xxxxxxx']\n",
      "AFter tokenizer:  ['how', 'much', 'are', 'we', 'getting', '?']\n",
      "AFter tokenizer:  ['is', 'ur', 'paper', 'in', 'e', 'morn', 'or', 'aft', 'tmr', '?']\n",
      "AFter tokenizer:  ['dear', 'relieved', 'of', 'westonzoyland', ',', 'all', 'going', 'to', 'plan', 'this', 'end', 'too', '!']\n",
      "AFter tokenizer:  ['hope', 'you', 'are', 'having', 'a', 'great', 'new', 'semester', '.', 'do', 'wish', 'you', 'the', 'very', 'best', '.', 'you', 'are', 'made', 'for', 'greatness', '.']\n",
      "AFter tokenizer:  ['oh', 'yes', 'i', 'can', 'speak', 'txt', '2', 'u', 'no', '!', 'hmm', '.', 'did', 'u', 'get', 'email', '?']\n",
      "AFter tokenizer:  ['i', 'want', 'to', 'show', 'you', 'the', 'world', ',', 'princess', ':', ')', 'how', 'about', 'europe', '?']\n",
      "AFter tokenizer:  ['nobody', 'can', 'decide', 'where', 'to', 'eat', 'and', 'dad', 'wants', 'chinese']\n",
      "AFter tokenizer:  ['no', 'shoot', 'me', '.', 'i', \"'m\", 'in', 'the', 'docs', 'waiting', 'room', '.', ':', '/']\n",
      "AFter tokenizer:  ['now', '?', 'i', \"'m\", 'going', 'out', '4', 'dinner', 'soon', '..']\n",
      "AFter tokenizer:  ['hello', 'which', 'the', 'site', 'to', 'download', 'songs', 'its', 'urgent', 'pls']\n",
      "AFter tokenizer:  ['i', 'do', 'know', 'what', 'u', 'mean', ',', 'is', 'the', 'king', 'of', 'not', 'havin', 'credit', '!', 'i', \"'m\", 'goin2bed', 'now', '.', 'night', 'night', 'sweet', '!', 'only1more', 'sleep', '!']\n",
      "AFter tokenizer:  ['horrible', 'gal', '.', 'me', 'in', 'sch', 'doing', 'some', 'stuff', '.', 'how', 'come', 'u', 'got', 'mc', '?']\n",
      "AFter tokenizer:  ['hi', 'hun', '!', 'im', 'not', 'comin', '2nite-tell', 'every1', 'im', 'sorry', '4', 'me', ',', 'hope', 'u', 'ava', 'goodtime', '!', 'oli', 'rang', 'melnite', 'ifink', 'it', 'mite', 'b', 'sorted', ',', 'but', 'il', 'explain', 'everythin', 'on', 'mon.l8rs.x']\n",
      "AFter tokenizer:  ['please', 'call', '08712402779', 'immediately', 'as', 'there', 'is', 'an', 'urgent', 'message', 'waiting', 'for', 'you']\n",
      "AFter tokenizer:  ['yeah', 'like', 'if', 'it', 'goes', 'like', 'it', 'did', 'with', 'my', 'friends', 'imma', 'flip', 'my', 'shit', 'in', 'like', 'half', 'an', 'hour']\n",
      "AFter tokenizer:  ['mum', 'say', 'we', 'wan', 'to', 'go', 'then', 'go', '...', 'then', 'she', 'can', 'shun', 'bian', 'watch', 'da', 'glass', 'exhibition', '...']\n",
      "AFter tokenizer:  ['what', 'your', 'plan', 'for', 'pongal', '?']\n",
      "AFter tokenizer:  ['just', 'wait', 'till', 'end', 'of', 'march', 'when', 'el', 'nino', 'gets', 'himself', '.', 'oh', '.']\n",
      "AFter tokenizer:  ['not', 'yet', 'chikku', '..', 'going', 'to', 'room', 'nw', ',', 'i', \"'m\", 'in', 'bus', '..']\n",
      "AFter tokenizer:  ['am', 'also', 'doing', 'in', 'cbe', 'only', '.', 'but', 'have', 'to', 'pay', '.']\n",
      "AFter tokenizer:  ['honey', 'boo', 'i', \"'m\", 'missing', 'u', '.']\n",
      "AFter tokenizer:  ['we', 'have', 'sent', 'jd', 'for', 'customer', 'service', 'cum', 'accounts', 'executive', 'to', 'ur', 'mail', 'id', ',', 'for', 'details', 'contact', 'us']\n",
      "AFter tokenizer:  ['yo', ',', 'i', \"'m\", 'at', 'my', 'parents', \"'\", 'gettin', 'cash', '.', 'good', 'news', ':', 'we', 'picked', 'up', 'a', 'downstem']\n",
      "AFter tokenizer:  ['thank', 'you', 'so', 'much', '.', 'when', 'we', 'skyped', 'wit', 'kz', 'and', 'sura', ',', 'we', 'didnt', 'get', 'the', 'pleasure', 'of', 'your', 'company', '.', 'hope', 'you', 'are', 'good', '.', 'we', \"'ve\", 'given', 'you', 'ultimatum', 'oh', '!', 'we', 'are', 'countin', 'down', 'to', 'aburo', '.', 'enjoy', '!']\n",
      "AFter tokenizer:  ['hungry', 'gay', 'guys', 'feeling', 'hungry', 'and', 'up', '4', 'it', ',', 'now', '.', 'call', '08718730555', 'just', '10p/min', '.', 'to', 'stop', 'texts', 'call', '08712460324', '(', '10p/min', ')']\n",
      "AFter tokenizer:  ['ok.', 'no', 'wahala', '.', 'just', 'remember', 'that', 'a', 'friend', 'in', 'need', '...']\n",
      "AFter tokenizer:  ['i', 'will', 'see', 'in', 'half', 'an', 'hour']\n",
      "AFter tokenizer:  ['im', 'in', 'inperialmusic', 'listening2the', 'weirdest', 'track', 'ever', 'by\\x94leafcutter', 'john\\x94-sounds', 'like', 'insects', 'being', 'molested', '&', 'someone', 'plumbing', ',', 'remixed', 'by', 'evil', 'men', 'on', 'acid', '!']\n",
      "AFter tokenizer:  ['hey', 'sorry', 'i', 'didntgive', 'ya', 'a', 'a', 'bellearlier', 'hunny', ',', 'just', 'been', 'in', 'bedbut', 'mite', 'go', '2', 'thepub', 'l8tr', 'if', 'uwana', 'mt', 'up', '?', 'loads', 'a', 'luv', 'jenxxx', '.']\n",
      "AFter tokenizer:  ['seriously', '.', 'tell', 'her', 'those', 'exact', 'words', 'right', 'now', '.']\n",
      "AFter tokenizer:  ['can', 'u', 'get', '2', 'phone', 'now', '?', 'i', 'wan', 'na', 'chat', '2', 'set', 'up', 'meet', 'call', 'me', 'now', 'on', '09096102316', 'u', 'can', 'cum', 'here', '2moro', 'luv', 'jane', 'xx', 'calls£1/minmoremobsemspobox45po139wa']\n",
      "AFter tokenizer:  ['tee', 'hee', '.', 'off', 'to', 'lecture', ',', 'cheery', 'bye', 'bye', '.']\n",
      "AFter tokenizer:  ['sorry', 'chikku', ',', 'my', 'cell', 'got', 'some', 'problem', 'thts', 'y', 'i', 'was', 'nt', 'able', 'to', 'reply', 'u', 'or', 'msg', 'u', '..']\n",
      "AFter tokenizer:  ['if', 'you', 'still', 'havent', 'collected', 'the', 'dough', 'pls', 'let', 'me', 'know', 'so', 'i', 'can', 'go', 'to', 'the', 'place', 'i', 'sent', 'it', 'to', 'get', 'the', 'control', 'number']\n",
      "AFter tokenizer:  ['ok', '...']\n",
      "AFter tokenizer:  ['network', 'operator', '.', 'the', 'service', 'is', 'free', '.', 'for', 't', '&', 'c', \"'s\", 'visit', '80488.biz']\n",
      "AFter tokenizer:  ['let', 'me', 'know', 'how', 'to', 'contact', 'you', '.', 'i', \"'ve\", 'you', 'settled', 'in', 'a', 'room', '.', 'lets', 'know', 'you', 'are', 'ok', '.']\n",
      "AFter tokenizer:  ['wot', 'u', 'up', '2', 'u', 'weirdo', '?']\n",
      "AFter tokenizer:  ['can', 'do', 'lor', '...']\n",
      "AFter tokenizer:  ['dont', 'put', 'your', 'phone', 'on', 'silent', 'mode', 'ok']\n",
      "AFter tokenizer:  ['can', 'i', 'meet', 'ü', 'at', '5', '..', 'as', '4', 'where', 'depends', 'on', 'where', 'ü', 'wan', '2', 'in', 'lor', '..']\n",
      "AFter tokenizer:  ['waiting', '4', 'my', 'tv', 'show', '2', 'start', 'lor', '...', 'u', 'leh', 'still', 'busy', 'doing', 'ur', 'report', '?']\n",
      "AFter tokenizer:  ['oh', 'ho', '.', 'is', 'this', 'the', 'first', 'time', 'u', 'use', 'these', 'type', 'of', 'words']\n",
      "AFter tokenizer:  ['am', 'i', 'the', 'only', 'one', 'who', 'does', \"n't\", 'stalk', 'profiles', '?']\n",
      "AFter tokenizer:  ['ever', 'green', 'quote', 'ever', 'told', 'by', 'jerry', 'in', 'cartoon', '``', 'a', 'person', 'who', 'irritates', 'u', 'always', 'is', 'the', 'one', 'who', 'loves', 'u', 'vry', 'much', 'but', 'fails', 'to', 'express', 'it', '...', '!', '..', '!', '!', ':', '-', ')', ':', '-', ')', 'gud', 'nyt']\n",
      "AFter tokenizer:  ['yes', 'i', 'thought', 'so', '.', 'thanks', '.']\n",
      "AFter tokenizer:  ['but', 'if', 'she.s', 'drinkin', 'i', \"'m\", 'ok', '.']\n",
      "AFter tokenizer:  ['just', 'wondering', ',', 'the', 'others', 'just', 'took', 'off']\n",
      "AFter tokenizer:  ['night', 'has', 'ended', 'for', 'another', 'day', ',', 'morning', 'has', 'come', 'in', 'a', 'special', 'way', '.', 'may', 'you', 'smile', 'like', 'the', 'sunny', 'rays', 'and', 'leaves', 'your', 'worries', 'at', 'the', 'blue', 'blue', 'bay', '.', 'gud', 'mrng']\n",
      "AFter tokenizer:  ['what', 'do', 'you', 'do', ',', 'my', 'dog', '?', 'must', 'i', 'always', 'wait', 'till', 'the', 'end', 'of', 'your', 'day', 'to', 'have', 'word', 'from', 'you', '?', 'did', 'you', 'run', 'out', 'of', 'time', 'on', 'your', 'cell', 'already', '?']\n",
      "AFter tokenizer:  ['happy', 'new', 'year', 'to', 'u', 'too', '!']\n",
      "AFter tokenizer:  ['hey', '...', 'great', 'deal', '...', 'farm', 'tour', '9am', 'to', '5pm', '$', '95/pax', ',', '$', '50', 'deposit', 'by', '16', 'may']\n",
      "AFter tokenizer:  ['eat', 'jap', 'done', 'oso', 'aft', 'ur', 'lect', 'wat', '...', 'ü', 'got', 'lect', 'at', '12', 'rite', '...']\n",
      "AFter tokenizer:  ['hey', 'babe', '!', 'i', 'saw', 'you', 'came', 'online', 'for', 'a', 'second', 'and', 'then', 'you', 'disappeared', ',', 'what', 'happened', '?']\n",
      "AFter tokenizer:  ['da', 'my', 'birthdate', 'in', 'certificate', 'is', 'in', 'april', 'but', 'real', 'date', 'is', 'today', '.', 'but', 'dont', 'publish', 'it', '.', 'i', 'shall', 'give', 'you', 'a', 'special', 'treat', 'if', 'you', 'keep', 'the', 'secret', '.', 'any', 'way', 'thanks', 'for', 'the', 'wishes']\n",
      "AFter tokenizer:  ['happy', 'birthday', '...', 'may', 'all', 'ur', 'dreams', 'come', 'true', '...']\n",
      "AFter tokenizer:  ['aiyah', 'u', 'did', 'ok', 'already', 'lar', '.', 'e', 'nydc', 'at', 'wheellock', '?']\n",
      "AFter tokenizer:  ['tell', 'her', 'i', 'said', 'eat', 'shit', '.']\n",
      "AFter tokenizer:  ['sure', '!', 'i', 'am', 'driving', 'but', 'will', 'reach', 'my', 'destination', 'soon', '.']\n",
      "AFter tokenizer:  ['k', 'so', 'am', 'i', ',', 'how', 'much', 'for', 'an', '8th', '?', 'fifty', '?']\n",
      "AFter tokenizer:  ['your', 'daily', 'text', 'from', 'me', '–', 'a', 'favour', 'this', 'time']\n",
      "AFter tokenizer:  ['great', 'to', 'hear', 'you', 'are', 'settling', 'well', '.', 'so', 'what', \"'s\", 'happenin', 'wit', 'ola', '?']\n",
      "AFter tokenizer:  ['those', 'cocksuckers', '.', 'if', 'it', 'makes', 'you', 'feel', 'better', 'ipads', 'are', 'worthless', 'garbage', 'novelty', 'items', 'and', 'you', 'should', 'feel', 'bad', 'for', 'even', 'wanting', 'one']\n",
      "AFter tokenizer:  ['i', 'tot', 'u', 'reach', 'liao', '.', 'he', 'said', 't-shirt', '.']\n",
      "AFter tokenizer:  ['fran', 'i', 'decided', '2', 'go', 'n', 'e', 'way', 'im', 'completely', 'broke', 'an', 'knackered', 'i', 'got', 'up', 'bout', '3', 'c', 'u', '2mrw', 'love', 'janx', 'p.s', 'this', 'is', 'my', 'dads', 'fone', ',', '-no', 'credit']\n",
      "AFter tokenizer:  ['your', 'right', '!', 'i', \"'ll\", 'make', 'the', 'appointment', 'right', 'now', '.']\n",
      "AFter tokenizer:  ['designation', 'is', 'software', 'developer', 'and', 'may', 'be', 'she', 'get', 'chennai', ':', ')']\n",
      "AFter tokenizer:  ['enjoy', 'the', 'jamster', 'videosound', 'gold', 'club', 'with', 'your', 'credits', 'for', '2', 'new', 'videosounds+2', 'logos+musicnews', '!', 'get', 'more', 'fun', 'from', 'jamster.co.uk', '!', '16+only', 'help', '?', 'call', ':', '09701213186']\n",
      "AFter tokenizer:  ['get', '3', 'lions', 'england', 'tone', ',', 'reply', 'lionm', '4', 'mono', 'or', 'lionp', '4', 'poly', '.', '4', 'more', 'go', '2', 'www.ringtones.co.uk', ',', 'the', 'original', 'n', 'best', '.', 'tones', '3gbp', 'network', 'operator', 'rates', 'apply']\n",
      "AFter tokenizer:  ['i', 'jokin', 'oni', 'lar', '..', 'ü', 'busy', 'then', 'i', 'wun', 'disturb', 'ü', '.']\n",
      "AFter tokenizer:  ['ok', ',', 'be', 'careful', '!', 'do', \"n't\", 'text', 'and', 'drive', '!']\n",
      "AFter tokenizer:  ['i.ll', 'always', 'be', 'there', ',', 'even', 'if', 'its', 'just', 'in', 'spirit', '.', 'i.ll', 'get', 'a', 'bb', 'soon', '.', 'just', 'trying', 'to', 'be', 'sure', 'i', 'need', 'it', '.']\n",
      "AFter tokenizer:  ['u', 'r', 'too', 'much', 'close', 'to', 'my', 'heart', '.', 'if', 'u', 'go', 'away', 'i', 'will', 'be', 'shattered', '.', 'plz', 'stay', 'with', 'me', '.']\n",
      "AFter tokenizer:  ['i', 'love', 'u', '2', 'babe', '!', 'r', 'u', 'sure', 'everything', 'is', 'alrite', '.', 'is', 'he', 'being', 'an', 'idiot', '?', 'txt', 'bak', 'girlie']\n",
      "AFter tokenizer:  ['how', 'abt', 'making', 'some', 'of', 'the', 'pics', 'bigger', '?']\n",
      "AFter tokenizer:  ['got', 'but', 'got', '2', 'colours', 'lor', '.', 'one', 'colour', 'is', 'quite', 'light', 'n', 'e', 'other', 'is', 'darker', 'lor', '.', 'actually', 'i', \"'m\", 'done', 'she', \"'s\", 'styling', 'my', 'hair', 'now', '.']\n",
      "AFter tokenizer:  ['whenevr', 'ur', 'sad', ',', 'whenevr', 'ur', 'gray', ',', 'remembr', 'im', 'here', '2', 'listn', '2', 'watevr', 'u', 'wan', 'na', 'say', ',', 'jus', 'walk', 'wid', 'me', 'a', 'little', 'while', ',', '&', 'amp', ';', 'i', 'promise', 'i', \"'ll\", 'bring', 'back', 'ur', 'smile', '.', ':', '-', ')']\n",
      "AFter tokenizer:  ['why', 'nothing', '.', 'ok', 'anyway', 'give', 'me', 'treat']\n",
      "AFter tokenizer:  ['win', 'the', 'newest', '“', 'harry', 'potter', 'and', 'the', 'order', 'of', 'the', 'phoenix', '(', 'book', '5', ')', 'reply', 'harry', ',', 'answer', '5', 'questions', '-', 'chance', 'to', 'be', 'the', 'first', 'among', 'readers', '!']\n",
      "AFter tokenizer:  ['correct', '.', 'so', 'how', 'was', 'work', 'today']\n",
      "AFter tokenizer:  ['just', 'sent', 'again', '.', 'do', 'you', 'scream', 'and', 'moan', 'in', 'bed', ',', 'princess', '?']\n",
      "AFter tokenizer:  ['i', 'wake', 'up', 'long', 'ago', 'already', '...', 'dunno', ',', 'what', 'other', 'thing', '?']\n",
      "AFter tokenizer:  ['oh', 'just', 'getting', 'even', 'with', 'u', '....', 'u', '?']\n",
      "AFter tokenizer:  ['i', 'thk', '50', 'shd', 'be', 'ok', 'he', 'said', 'plus', 'minus', '10', '..', 'did', 'ü', 'leave', 'a', 'line', 'in', 'between', 'paragraphs', '?']\n",
      "AFter tokenizer:  ['can', 'you', 'call', 'me', 'plz', '.', 'your', 'number', 'shows', 'out', 'of', 'coveragd', 'area', '.', 'i', 'have', 'urgnt', 'call', 'in', 'vasai', '&', 'amp', ';', 'have', 'to', 'reach', 'before', '4', \"'\", 'o', 'clock', 'so', 'call', 'me', 'plz']\n",
      "AFter tokenizer:  ['yeah', 'jay', \"'s\", 'sort', 'of', 'a', 'fucking', 'retard']\n",
      "AFter tokenizer:  ['sorry', ',', 'was', 'in', 'the', 'bathroom', ',', 'sup']\n",
      "AFter tokenizer:  ['ur', 'balance', 'is', 'now', '£500', '.', 'ur', 'next', 'question', 'is', ':', 'who', 'sang', \"'uptown\", 'girl', \"'\", 'in', 'the', '80', \"'s\", '?', '2', 'answer', 'txt', 'ur', 'answer', 'to', '83600.', 'good', 'luck', '!']\n",
      "AFter tokenizer:  ['my', 'exam', 'is', 'for', 'february', '4.', 'wish', 'you', 'a', 'great', 'day', '.']\n",
      "AFter tokenizer:  ['i', 'dont', 'know', 'what', 'to', 'do', 'to', 'come', 'out', 'of', 'this', 'so', 'only', 'am', 'ask', 'questions', 'like', 'this', 'dont', 'mistake', 'me', '.']\n",
      "AFter tokenizer:  ['aight', 'no', 'rush', ',', 'i', \"'ll\", 'ask', 'jay']\n",
      "AFter tokenizer:  ['good', 'morning', 'plz', 'call', 'me', 'sir']\n",
      "AFter tokenizer:  ['it', \"'s\", 'ok', 'lar', '.', 'u', 'sleep', 'early', 'too', '...', 'nite', '...']\n",
      "AFter tokenizer:  ['oh', '...', 'icic', '...', 'k', 'lor', ',', 'den', 'meet', 'other', 'day', '...']\n",
      "AFter tokenizer:  ['oh', '!', 'a', 'half', 'hour', 'is', 'much', 'longer', 'in', 'syria', 'than', 'canada', ',', 'eh', '?', 'wow', 'you', 'must', 'get', 'so', 'much', 'more', 'work', 'done', 'in', 'a', 'day', 'than', 'us', 'with', 'all', 'that', 'extra', 'time', '!', '*', 'grins', '*']\n",
      "AFter tokenizer:  ['sometimes', 'we', 'put', 'walls', 'around', 'our', 'hearts', ',', 'not', 'just', 'to', 'be', 'safe', 'from', 'getting', 'hurt', '..', 'but', 'to', 'find', 'out', 'who', 'cares', 'enough', 'to', 'break', 'the', 'walls', '&', 'amp', ';', 'get', 'closer', '..', 'goodnoon', ':', ')']\n",
      "AFter tokenizer:  ['sweet', ',', 'we', 'may', 'or', 'may', 'not', 'go', 'to', '4u', 'to', 'meet', 'carlos', 'so', 'gauge', 'patty', \"'s\", 'interest', 'in', 'that']\n",
      "AFter tokenizer:  ['then', 'she', 'buying', 'today', '?', 'ü', 'no', 'need', 'to', 'c', 'meh', '...']\n",
      "AFter tokenizer:  ['aight', 'sorry', 'i', 'take', 'ten', 'years', 'to', 'shower', '.', 'what', \"'s\", 'the', 'plan', '?']\n",
      "AFter tokenizer:  ['every', 'monday', '..', 'nxt', 'week', 'vl', 'be', 'completing', '..']\n",
      "AFter tokenizer:  ['might', 'ax', 'well', 'im', 'there', '.']\n",
      "AFter tokenizer:  ['just', 'chill', 'for', 'another', '6hrs', '.', 'if', 'you', 'could', 'sleep', 'the', 'pain', 'is', 'not', 'a', 'surgical', 'emergency', 'so', 'see', 'how', 'it', 'unfolds', '.', 'okay']\n",
      "AFter tokenizer:  ['yeah', 'i', \"'ll\", 'try', 'to', 'scrounge', 'something', 'up']\n",
      "AFter tokenizer:  ['crazy', 'ar', 'he', \"'s\", 'married', '.', 'ü', 'like', 'gd', 'looking', 'guys', 'not', 'me', '.', 'my', 'frens', 'like', 'say', 'he', \"'s\", 'korean', 'leona', \"'s\", 'fave', 'but', 'i', 'dun', 'thk', 'he', 'is', '.', 'aft', 'some', 'thinking', 'mayb', 'most', 'prob', 'i', \"'ll\", 'go', '.']\n",
      "AFter tokenizer:  ['were', 'somewhere', 'on', 'fredericksburg']\n",
      "AFter tokenizer:  ['que', 'pases', 'un', 'buen', 'tiempo', 'or', 'something', 'like', 'that']\n",
      "AFter tokenizer:  ['is', 'it', 'ok', 'if', 'i', 'stay', 'the', 'night', 'here', '?', 'xavier', 'has', 'a', 'sleeping', 'bag', 'and', 'i', \"'m\", 'getting', 'tired']\n",
      "AFter tokenizer:  ['she', 'doesnt', 'need', 'any', 'test', '.']\n",
      "AFter tokenizer:  ['nothing', 'much', ',', 'chillin', 'at', 'home', '.', 'any', 'super', 'bowl', 'plan', '?']\n",
      "AFter tokenizer:  ['free2day', 'sexy', 'st', 'george', \"'s\", 'day', 'pic', 'of', 'jordan', '!', 'txt', 'pic', 'to', '89080', 'dont', 'miss', 'out', ',', 'then', 'every', 'wk', 'a', 'saucy', 'celeb', '!', '4', 'more', 'pics', 'c', 'pocketbabe.co.uk', '0870241182716', '£3/wk']\n",
      "AFter tokenizer:  ['bugis', 'oso', 'near', 'wat', '...']\n",
      "AFter tokenizer:  ['yo', 'theres', 'no', 'class', 'tmrw', 'right', '?']\n",
      "AFter tokenizer:  ['let', 'ur', 'heart', 'be', 'ur', 'compass', 'ur', 'mind', 'ur', 'map', 'ur', 'soul', 'ur', 'guide', 'and', 'u', 'will', 'never', 'loose', 'in', 'world', '....', 'gnun', '-', 'sent', 'via', 'way2sms.com']\n",
      "AFter tokenizer:  ['goodnight', ',', 'sleep', 'well', 'da', 'please', 'take', 'care', 'pa.', 'please', '.']\n",
      "AFter tokenizer:  ['baaaaabe', '!', 'i', 'misss', 'youuuuu', '!', 'where', 'are', 'you', '?', 'i', 'have', 'to', 'go', 'and', 'teach', 'my', 'class', 'at', '5', '...']\n",
      "AFter tokenizer:  ['u', 'ned', 'to', 'convince', 'him', 'tht', 'its', 'not', 'possible', 'witot', 'hurting', 'his', 'feeling', 'its', 'the', 'main']\n",
      "AFter tokenizer:  ['good', 'afternoon', 'loverboy', '!', 'how', 'goes', 'you', 'day', '?', 'any', 'luck', 'come', 'your', 'way', '?', 'i', 'think', 'of', 'you', ',', 'sweetie', 'and', 'send', 'my', 'love', 'across', 'the', 'sea', 'to', 'make', 'you', 'smile', 'and', 'happy']\n",
      "AFter tokenizer:  ['if', 'i', 'start', 'sending', 'blackberry', 'torch', 'to', 'nigeria', 'will', 'you', 'find', 'buyer', 'for', 'me', '?', 'like', '4a', 'month', '.', 'and', 'tell', 'dad', 'not', 'to', 'buy', 'bb', 'from', 'anyone', 'oh', '.']\n",
      "AFter tokenizer:  ['&', 'lt', ';', '#', '&', 'gt', ';', '%', 'of', 'pple', 'marry', 'with', 'their', 'lovers', '...', 'becz', 'they', 'hav', 'gud', 'undrstndng', 'dat', 'avoids', 'problems', '.', 'i', 'sent', 'dis', '2', 'u', ',', 'u', 'wil', 'get', 'gud', 'news', 'on', 'friday', 'by', 'd', 'person', 'you', 'like', '.', 'and', 'tomorrow', 'will', 'be', 'the', 'best', 'day', 'of', 'your', 'life', '.', 'dont', 'break', 'this', 'chain', '.', 'if', 'you', 'break', 'you', 'will', 'suffer', '.', 'send', 'this', 'to', '&', 'lt', ';', '#', '&', 'gt', ';', 'frnds', 'in', '&', 'lt', ';', '#', '&', 'gt', ';', 'mins', 'whn', 'u', 'read', '...']\n",
      "AFter tokenizer:  ['yo', 'dude', 'guess', 'who', 'just', 'got', 'arrested', 'the', 'other', 'day']\n",
      "AFter tokenizer:  ['shuhui', 'say', 'change', '2', 'suntec', 'steamboat', '?', 'u', 'noe', 'where', '?', 'where', 'r', 'u', 'now', '?']\n",
      "AFter tokenizer:  ['what', 'does', 'the', 'dance', 'river', 'do', '?']\n",
      "AFter tokenizer:  ['yetunde', ',', 'i', \"'m\", 'sorry', 'but', 'moji', 'and', 'i', 'seem', 'too', 'busy', 'to', 'be', 'able', 'to', 'go', 'shopping', '.', 'can', 'you', 'just', 'please', 'find', 'some', 'other', 'way', 'to', 'get', 'what', 'you', 'wanted', 'us', 'to', 'get', '.', 'please', 'forgive', 'me', '.', 'you', 'can', 'reply', 'free', 'via', 'yahoo', 'messenger', '.']\n",
      "AFter tokenizer:  ['hey', 'i', 'will', 'be', 'really', 'pretty', 'late', '...', 'you', 'want', 'to', 'go', 'for', 'the', 'lesson', 'first', '?', 'i', 'will', 'join', 'you', '.', 'i', \"'m\", 'only', 'reaching', 'tp', 'mrt']\n",
      "AFter tokenizer:  ['hot', 'live', 'fantasies', 'call', 'now', '08707509020', 'just', '20p', 'per', 'min', 'ntt', 'ltd', ',', 'po', 'box', '1327', 'croydon', 'cr9', '5wb', '0870', '..', 'k']\n",
      "AFter tokenizer:  ['bbq', 'this', 'sat', 'at', 'mine', 'from', '6ish', '.', 'ur', 'welcome', '2', 'come']\n",
      "AFter tokenizer:  ['i', 'do', \"n't\", 'know', ',', 'same', 'thing', 'that', \"'s\", 'wrong', 'everyso', 'often', ',', 'he', 'panicks', 'starts', 'goin', 'on', 'bout', 'not', 'bein', 'good', 'enough', '…']\n",
      "AFter tokenizer:  ['alright', '.', 'i', \"'m\", 'out', '--', 'have', 'a', 'good', 'night', '!']\n",
      "AFter tokenizer:  ['did', 'you', 'try', 'making', 'another', 'butt', '.']\n",
      "AFter tokenizer:  ['hope', 'you', 'are', 'feeling', 'great', '.', 'pls', 'fill', 'me', 'in', '.', 'abiola']\n",
      "AFter tokenizer:  ['i', 'though', 'we', 'shd', 'go', 'out', 'n', 'have', 'some', 'fun', 'so', 'bar', 'in', 'town', 'or', 'something', '–', 'sound', 'ok', '?']\n",
      "AFter tokenizer:  ['1', ')', 'go', 'to', 'write', 'msg', '2', ')', 'put', 'on', 'dictionary', 'mode', '3', ')', 'cover', 'the', 'screen', 'with', 'hand', ',', '4', ')', 'press', '&', 'lt', ';', '#', '&', 'gt', ';', '.', '5', ')', 'gently', 'remove', 'ur', 'hand', '..', 'its', 'interesting', '..', ':', ')']\n",
      "AFter tokenizer:  ['bears', 'pic', 'nick', ',', 'and', 'tom', ',', 'pete', 'and', '...', 'dick', '.', 'in', 'fact', ',', 'all', 'types', 'try', 'gay', 'chat', 'with', 'photo', 'upload', 'call', '08718730666', '(', '10p/min', ')', '.', '2', 'stop', 'texts', 'call', '08712460324']\n",
      "AFter tokenizer:  ['500', 'new', 'mobiles', 'from', '2004', ',', 'must', 'go', '!', 'txt', ':', 'nokia', 'to', 'no', ':', '89545', '&', 'collect', 'yours', 'today', '!', 'from', 'only', '£1', 'www.4-tc.biz', '2optout', '087187262701.50gbp/mtmsg18', 'txtauction']\n",
      "AFter tokenizer:  ['we', \"'re\", 'finally', 'ready', 'fyi']\n",
      "AFter tokenizer:  ['auntie', 'huai', 'juan', 'never', 'pick', 'up', 'her', 'phone']\n",
      "AFter tokenizer:  ['double', 'mins', '&', 'double', 'txt', '&', '1/2', 'price', 'linerental', 'on', 'latest', 'orange', 'bluetooth', 'mobiles', '.', 'call', 'mobileupd8', 'for', 'the', 'very', 'latest', 'offers', '.', '08000839402', 'or', 'call2optout/lf56']\n",
      "AFter tokenizer:  ['ya', 'tel', ',', 'wats', 'ur', 'problem', '..']\n",
      "AFter tokenizer:  ['i', 'dnt', 'wnt', 'to', 'tlk', 'wid', 'u']\n",
      "AFter tokenizer:  ['we', 'spend', 'our', 'days', 'waiting', 'for', 'the', 'ideal', 'path', 'to', 'appear', 'in', 'front', 'of', 'us', '..', 'but', 'what', 'we', 'forget', 'is', '..', '``', 'paths', 'are', 'made', 'by', 'walking', '..', 'not', 'by', 'waiting', '..', \"''\", 'goodnight', '!']\n",
      "AFter tokenizer:  ['its', 'ok', 'my', 'arm', 'is', 'feeling', 'weak', 'cuz', 'i', 'got', 'a', 'shot', 'so', 'we', 'can', 'go', 'another', 'time']\n",
      "AFter tokenizer:  ['please', 'reserve', 'ticket', 'on', 'saturday', 'eve', 'from', 'chennai', 'to', 'thirunelvali', 'and', 'again', 'from', 'tirunelvali', 'to', 'chennai', 'on', 'sunday', 'eve', '...', 'i', 'already', 'see', 'in', 'net', '..', 'no', 'ticket', 'available', '..', 'i', 'want', 'to', 'book', 'ticket', 'through', 'tackle', '..']\n",
      "AFter tokenizer:  ['storming', 'msg', ':', 'wen', 'u', 'lift', 'd', 'phne', ',', 'u', 'say', '``', 'hello', \"''\", 'do', 'u', 'knw', 'wt', 'is', 'd', 'real', 'meaning', 'of', 'hello', '?', '?', '.', '.', '.', 'it', \"'s\", 'd', 'name', 'of', 'a', 'girl', '..', '!', '.', '.', '.', 'yes', '..', 'and', 'u', 'knw', 'who', 'is', 'dat', 'girl', '?', '?', '``', 'margaret', 'hello', \"''\", 'she', 'is', 'd', 'girlfrnd', 'f', 'grahmbell', 'who', 'invnted', 'telphone', '...', '.', '.', '.', '.', 'moral', ':', 'one', 'can', '4get', 'd', 'name', 'of', 'a', 'person', ',', 'bt', 'not', 'his', 'girlfrnd', '...', 'g', 'o', 'o', 'd', 'n', 'i', 'g', 'h', 't', '.', '.', '.', '@']\n",
      "AFter tokenizer:  ['that', \"'s\", 'ok.', 'i', 'popped', 'in', 'to', 'ask', 'bout', 'something', 'and', 'she', 'said', 'you', \"'d\", 'been', 'in', '.', 'are', 'you', 'around', 'tonght', 'wen', 'this', 'girl', 'comes', '?']\n",
      "AFter tokenizer:  ['all', 'e', 'best', '4', 'ur', 'exam', 'later', '.']\n",
      "AFter tokenizer:  ['hope', 'ur', 'head', 'does', \"n't\", 'hurt', '2', 'much', '!', 'am', 'ploughing', 'my', 'way', 'through', 'a', 'pile', 'of', 'ironing', '!', 'staying', 'in', 'with', 'a', 'chinky', 'tonight', 'come', 'round', 'if', 'you', 'like', '.']\n",
      "AFter tokenizer:  ['oh', 'k.i', 'think', 'most', 'of', 'wi', 'and', 'nz', 'players', 'unsold', '.']\n",
      "AFter tokenizer:  ['haha', '...', 'where', 'got', 'so', 'fast', 'lose', 'weight', ',', 'thk', 'muz', 'go', '4', 'a', 'month', 'den', 'got', 'effect', '...', 'gee', ',', 'later', 'we', 'go', 'aust', 'put', 'bk', 'e', 'weight', '.']\n",
      "AFter tokenizer:  ['i', 'wonder', 'how', 'you', 'got', 'online', ',', 'my', 'love', '?', 'had', 'you', 'gone', 'to', 'the', 'net', 'cafe', '?', 'did', 'you', 'get', 'your', 'phone', 'recharged', '?', 'were', 'you', 'on', 'a', 'friends', 'net', '?', 'i', 'think', 'of', 'you', ',', 'boytoy']\n",
      "AFter tokenizer:  ['haha', 'just', 'kidding', ',', 'papa', 'needs', 'drugs']\n",
      "AFter tokenizer:  ['thk', 'shld', 'b', 'can', '...', 'ya', ',', 'i', 'wana', 'go', '4', 'lessons', '...', 'haha', ',', 'can', 'go', 'for', 'one', 'whole', 'stretch', '...']\n",
      "AFter tokenizer:  ['oh', 'ok', '..']\n",
      "AFter tokenizer:  ['r', 'we', 'still', 'meeting', '4', 'dinner', 'tonight', '?']\n",
      "AFter tokenizer:  ['thats', 'cool', '!', 'i', 'am', 'a', 'gentleman', 'and', 'will', 'treat', 'you', 'with', 'dignity', 'and', 'respect', '.']\n",
      "AFter tokenizer:  ['shall', 'i', 'start', 'from', 'hear', '.']\n",
      "AFter tokenizer:  ['then', 'we', 'wait', '4', 'u', 'lor', '...', 'no', 'need', '2', 'feel', 'bad', 'lar', '...']\n",
      "AFter tokenizer:  ['no', 'did', 'you', 'check', '?', 'i', 'got', 'his', 'detailed', 'message', 'now']\n",
      "AFter tokenizer:  ['you', 'have', 'registered', 'sinco', 'as', 'payee', '.', 'log', 'in', 'at', 'icicibank.com', 'and', 'enter', 'urn', '&', 'lt', ';', '#', '&', 'gt', ';', 'to', 'confirm', '.', 'beware', 'of', 'frauds', '.', 'do', 'not', 'share', 'or', 'disclose', 'urn', 'to', 'anyone', '.']\n",
      "AFter tokenizer:  ['no', ',', 'i', 'decided', 'that', 'only', 'people', 'who', 'care', 'about', 'stuff', 'vote', 'and', 'caring', 'about', 'stuff', 'is', 'for', 'losers']\n",
      "AFter tokenizer:  ['kaiez', '...', 'enjoy', 'ur', 'tuition', '...', 'gee', '...', 'thk', 'e', 'second', 'option', 'sounds', 'beta', '...', 'i', \"'ll\", 'go', 'yan', 'jiu', 'den', 'msg', 'u', '...']\n",
      "AFter tokenizer:  ['cool', '.', 'we', 'will', 'have', 'fun', 'practicing', 'making', 'babies', '!']\n",
      "AFter tokenizer:  ['actually', 'getting', 'ready', 'to', 'leave', 'the', 'house', '.']\n",
      "AFter tokenizer:  ['k', '..', 'k', '..', 'any', 'special', 'today', '?']\n",
      "AFter tokenizer:  ['urgent', ',', 'important', 'information', 'for', 'o2', 'user', '.', 'today', 'is', 'your', 'lucky', 'day', '!', '2', 'find', 'out', 'why', 'log', 'onto', 'http', ':', '//www.urawinner.com', 'there', 'is', 'a', 'fantastic', 'surprise', 'awaiting', 'for', 'you']\n",
      "AFter tokenizer:  ['then', 'we', 'got', 'ta', 'do', 'it', 'after', 'that']\n",
      "AFter tokenizer:  ['i', \"'ve\", 'got', 'ten', 'bucks', ',', 'jay', 'is', 'being', 'noncomittal']\n",
      "AFter tokenizer:  ['where', 'at', 'were', 'hungry', 'too']\n",
      "AFter tokenizer:  ['pls', 'speak', 'to', 'that', 'customer', 'machan', '.']\n",
      "AFter tokenizer:  ['somewhere', 'out', 'there', 'beneath', 'the', 'pale', 'moon', 'light', 'someone', 'think', 'in', 'of', 'u', 'some', 'where', 'out', 'there', 'where', 'dreams', 'come', 'true', '...', 'goodnite', '&', 'amp', ';', 'sweet', 'dreams']\n",
      "AFter tokenizer:  ['dear', 'u', \"'ve\", 'been', 'invited', 'to', 'xchat', '.', 'this', 'is', 'our', 'final', 'attempt', 'to', 'contact', 'u', '!', 'txt', 'chat', 'to', '86688', '150p/msgrcvdhg/suite342/2lands/row/w1j6hl', 'ldn', '18', 'yrs']\n",
      "AFter tokenizer:  ['so', 'wats', 'ur', 'opinion', 'abt', 'him', 'and', 'how', 'abt', 'is', 'character', '?']\n",
      "AFter tokenizer:  ['jay', 'is', 'snickering', 'and', 'tells', 'me', 'that', 'x', 'is', 'totally', 'fucking', 'up', 'the', 'chords', 'as', 'we', 'speak']\n",
      "AFter tokenizer:  ['no', '..', 'few', 'hours', 'before.went', 'to', 'hair', 'cut', '.']\n",
      "AFter tokenizer:  ['no', 'wonder', '...', 'cos', 'i', 'dun', 'rem', 'seeing', 'a', 'silver', 'car', '...', 'but', 'i', 'thk', 'i', 'saw', 'a', 'black', 'one', '...']\n",
      "AFter tokenizer:  ['lmao', '.', 'take', 'a', 'pic', 'and', 'send', 'it', 'to', 'me', '.']\n",
      "AFter tokenizer:  ['speak', 'only', 'when', 'you', 'feel', 'your', 'words', 'are', 'better', 'than', 'the', 'silence', '...', 'gud', 'mrng', ':', '-', ')']\n",
      "AFter tokenizer:  ['no', '.', 'she', \"'s\", 'currently', 'in', 'scotland', 'for', 'that', '.']\n",
      "AFter tokenizer:  ['do', 'you', 'work', 'all', 'this', 'week', '?']\n",
      "AFter tokenizer:  ['congratulations', 'ur', 'awarded', 'either', '£500', 'of', 'cd', 'gift', 'vouchers', '&', 'free', 'entry', '2', 'our', '£100', 'weekly', 'draw', 'txt', 'music', 'to', '87066', 'tncs', 'www.ldew.com', '1', 'win150ppmx3age16']\n",
      "AFter tokenizer:  ['lol', 'great', 'now', 'im', 'getting', 'hungry', '.']\n",
      "AFter tokenizer:  ['yes', '..', 'now', 'only', 'saw', 'your', 'message', '..']\n",
      "AFter tokenizer:  ['i', \"'ll\", 'be', 'at', 'mu', 'in', 'like', '&', 'lt', ';', '#', '&', 'gt', ';', 'seconds']\n",
      "AFter tokenizer:  ['thing', 'r', 'good', 'thanx', 'got', 'exams', 'in', 'march', 'ive', 'done', 'no', 'revision', '?', 'is', 'fran', 'still', 'with', 'boyf', '?', 'ive', 'got', 'ta', 'interviw', '4', 'exeter', 'bit', 'worried', '!', 'x']\n",
      "AFter tokenizer:  ['tell', 'you', 'what', ',', 'if', 'you', 'make', 'a', 'little', 'spreadsheet', 'and', 'track', 'whose', 'idea', 'it', 'was', 'to', 'smoke', 'to', 'determine', 'who', '``', 'smokes', 'too', 'much', \"''\", 'for', 'the', 'entire', 'month', 'of', 'february', ',', 'i', \"'ll\", 'come', 'up']\n",
      "AFter tokenizer:  ['for', 'sale', '-', 'arsenal', 'dartboard', '.', 'good', 'condition', 'but', 'no', 'doubles', 'or', 'trebles', '!']\n",
      "AFter tokenizer:  ['do', \"n't\", 'look', 'back', 'at', 'the', 'building', 'because', 'you', 'have', 'no', 'coat', 'and', 'i', 'do', \"n't\", 'want', 'you', 'to', 'get', 'more', 'sick', '.', 'just', 'hurry', 'home', 'and', 'wear', 'a', 'coat', 'to', 'the', 'gym', '!', '!', '!']\n",
      "AFter tokenizer:  ['my', 'painful', 'personal', 'thought-', '``', 'i', 'always', 'try', 'to', 'keep', 'everybody', 'happy', 'all', 'the', 'time', '.', 'but', 'nobody', 'recognises', 'me', 'when', 'i', 'am', 'alone', \"''\"]\n",
      "AFter tokenizer:  ['thanks', 'for', 've', 'lovely', 'wisheds', '.', 'you', 'rock']\n",
      "AFter tokenizer:  ['you', 'intrepid', 'duo', 'you', '!', 'have', 'a', 'great', 'time', 'and', 'see', 'you', 'both', 'soon', '.']\n",
      "AFter tokenizer:  ['i', 'asked', 'sen', 'to', 'come', 'chennai', 'and', 'search', 'for', 'job', '.']\n",
      "AFter tokenizer:  ['dad', 'went', 'out', 'oredi', '...']\n",
      "AFter tokenizer:  ['i', 'jus', 'hope', 'its', 'true', 'that', 'missin', 'me', 'cos', 'i', \"'m\", 'really', 'missin', 'him', '!', 'you', 'have', \"n't\", 'done', 'anything', 'to', 'feel', 'guilty', 'about', ',', 'yet', '.']\n",
      "AFter tokenizer:  ['wat', 'so', 'late', 'still', 'early', 'mah', '.', 'or', 'we', 'juz', 'go', '4', 'dinner', 'lor', '.', 'aiya', 'i', 'dunno', '...']\n",
      "AFter tokenizer:  ['arms', 'fine', ',', 'how', \"'s\", 'cardiff', 'and', 'uni', '?']\n",
      "AFter tokenizer:  ['in', 'fact', 'when', 'do', 'you', 'leave', '?', 'i', 'think', 'addie', 'goes', 'back', 'to', 'school', 'tues', 'or', 'wed']\n",
      "AFter tokenizer:  ['cool', 'breeze', '...', 'bright', 'sun', '...', 'fresh', 'flower', '...', 'twittering', 'birds', '...', 'all', 'these', 'waiting', 'to', 'wish', 'u', ':', '``', 'goodmorning', '&', 'amp', ';', 'have', 'a', 'nice', 'day', \"''\", ':', ')']\n",
      "AFter tokenizer:  ['ya', ':', ')', 'going', 'for', 'restaurant', '..']\n",
      "AFter tokenizer:  ['its', 'ok.', ',', 'i', 'just', 'askd', 'did', 'u', 'knw', 'tht', 'no', '?']\n",
      "AFter tokenizer:  ['free', '1st', 'week', 'entry', '2', 'textpod', '4', 'a', 'chance', '2', 'win', '40gb', 'ipod', 'or', '£250', 'cash', 'every', 'wk', '.', 'txt', 'pod', 'to', '84128', 'ts', '&', 'cs', 'www.textpod.net', 'custcare', '08712405020', '.']\n",
      "AFter tokenizer:  ['those', 'ducking', 'chinchillas']\n",
      "AFter tokenizer:  ['i', 'am', 'in', 'a', 'marriage', 'function']\n",
      "AFter tokenizer:  ['looks', 'like', 'u', 'wil', 'b', 'getting', 'a', 'headstart', 'im', 'leaving', 'here', 'bout', '2.30ish', 'but', 'if', 'u', 'r', 'desperate', 'for', 'my', 'company', 'i', 'could', 'head', 'in', 'earlier-we', 'were', 'goin', 'to', 'meet', 'in', 'rummer', '.']\n",
      "AFter tokenizer:  ['don', '‘', 't', 'give', 'a', 'flying', 'monkeys', 'wot', 'they', 'think', 'and', 'i', 'certainly', 'don', '‘', 't', 'mind', '.', 'any', 'friend', 'of', 'mine', 'and', 'all', 'that', '!']\n",
      "AFter tokenizer:  ['as', 'a', 'registered', 'optin', 'subscriber', 'ur', 'draw', '4', '£100', 'gift', 'voucher', 'will', 'be', 'entered', 'on', 'receipt', 'of', 'a', 'correct', 'ans', 'to', '80062', 'whats', 'no1', 'in', 'the', 'bbc', 'charts']\n",
      "AFter tokenizer:  ['say', 'thanks2', '.']\n",
      "AFter tokenizer:  ['msg', 'me', 'when', 'rajini', 'comes', '.']\n",
      "AFter tokenizer:  ['ya', '!', 'when', 'are', 'ü', 'taking', 'ure', 'practical', 'lessons', '?', 'i', 'start', 'in', 'june', '..']\n",
      "AFter tokenizer:  ['that', \"'s\", 'good', ',', 'because', 'i', 'need', 'drugs']\n",
      "AFter tokenizer:  ['stupid.its', 'not', 'possible']\n",
      "AFter tokenizer:  ['can', 'ü', 'all', 'decide', 'faster', 'cos', 'my', 'sis', 'going', 'home', 'liao', '..']\n",
      "AFter tokenizer:  ['summers', 'finally', 'here', '!', 'fancy', 'a', 'chat', 'or', 'flirt', 'with', 'sexy', 'singles', 'in', 'yr', 'area', '?', 'to', 'get', 'matched', 'up', 'just', 'reply', 'summer', 'now', '.', 'free', '2', 'join', '.', 'optout', 'txt', 'stop', 'help08714742804']\n",
      "AFter tokenizer:  ['u', 'sleeping', 'now', '..', 'or', 'you', 'going', 'to', 'take', '?', 'haha', '..', 'i', 'got', 'spys', 'wat', '..', 'me', 'online', 'checking', 'n', 'replying', 'mails', 'lor', '..']\n",
      "AFter tokenizer:  ['claire', 'here', 'am', 'havin', 'borin', 'time', '&', 'am', 'now', 'alone', 'u', 'wan', 'na', 'cum', 'over', '2nite', '?', 'chat', 'now', '09099725823', 'hope', '2', 'c', 'u', 'luv', 'claire', 'xx', 'calls£1/minmoremobsemspobox45po139wa']\n",
      "AFter tokenizer:  ['bought', 'one', 'ringtone', 'and', 'now', 'getting', 'texts', 'costing', '3', 'pound', 'offering', 'more', 'tones', 'etc']\n",
      "AFter tokenizer:  ['yalru', 'lyfu', 'astne', 'chikku', '..', 'bt', 'innu', 'mundhe', 'lyf', 'ali', 'halla', 'ke', 'bilo', '(', 'marriage', ')', 'program', 'edhae', ',', 'so', 'lyf', 'is', 'nt', 'yet', 'ovr', 'chikku', '..', 'ali', 'vargu', 'lyfu', 'meow', 'meow', ':', '-d']\n",
      "AFter tokenizer:  ['kinda', '.', 'first', 'one', 'gets', 'in', 'at', 'twelve', '!', 'aah', '.', 'speak', 'tomo']\n",
      "AFter tokenizer:  ['09066362231', 'urgent', '!', 'your', 'mobile', 'no', '07xxxxxxxxx', 'won', 'a', '£2,000', 'bonus', 'caller', 'prize', 'on', '02/06/03', '!', 'this', 'is', 'the', '2nd', 'attempt', 'to', 'reach', 'you', '!', 'call', '09066362231', 'asap', '!']\n",
      "AFter tokenizer:  ['ok', 'good', 'then', 'i', 'later', 'come', 'find', 'ü', '...', 'c', 'lucky', 'i', 'told', 'ü', 'to', 'go', 'earlier', '...', 'later', 'pple', 'take', 'finish', 'ü', 'no', 'more', 'again', '...']\n",
      "AFter tokenizer:  ['wat', 'makes', 'u', 'thk', 'i', \"'ll\", 'fall', 'down', '.', 'but', 'actually', 'i', 'thk', 'i', \"'m\", 'quite', 'prone', '2', 'falls', '.', 'lucky', 'my', 'dad', 'at', 'home', 'i', 'ask', 'him', 'come', 'n', 'fetch', 'me', 'already', '.']\n",
      "AFter tokenizer:  ['you', '07801543489', 'are', 'guaranteed', 'the', 'latests', 'nokia', 'phone', ',', 'a', '40gb', 'ipod', 'mp3', 'player', 'or', 'a', '£500', 'prize', '!', 'txt', 'word', ':', 'collect', 'to', 'no:83355', '!', 'tc-llc', 'ny-usa', '150p/mt', 'msgrcvd18+']\n",
      "AFter tokenizer:  ['i', 'wont', 'touch', 'you', 'with', 'out', 'your', 'permission', '.']\n",
      "AFter tokenizer:  ['hi', 'its', 'lucy', 'hubby', 'at', 'meetins', 'all', 'day', 'fri', '&', 'i', 'will', 'b', 'alone', 'at', 'hotel', 'u', 'fancy', 'cumin', 'over', '?', 'pls', 'leave', 'msg', '2day', '09099726395', 'lucy', 'x', 'calls£1/minmobsmorelkpobox177hp51fl']\n",
      "AFter tokenizer:  ['7', 'wonders', 'in', 'my', 'world', '7th', 'you', '6th', 'ur', 'style', '5th', 'ur', 'smile', '4th', 'ur', 'personality', '3rd', 'ur', 'nature', '2nd', 'ur', 'sms', 'and', '1st', '``', 'ur', 'lovely', 'friendship', \"''\", '...', 'good', 'morning', 'dear']\n",
      "AFter tokenizer:  ['take', 'some', 'small', 'dose', 'tablet', 'for', 'fever']\n",
      "AFter tokenizer:  ['oh', '.', 'u', 'must', 'have', 'taken', 'your', 'real', 'valentine', 'out', 'shopping', 'first', '.']\n",
      "AFter tokenizer:  ['just', 'sent', 'you', 'an', 'email', '–', 'to', 'an', 'address', 'with', 'incomm', 'in', 'it', ',', 'is', 'that', 'right', '?']\n",
      "AFter tokenizer:  ['will', 'do', ',', 'you', 'gon', 'na', 'be', 'at', 'blake', \"'s\", 'all', 'night', '?', 'i', 'might', 'be', 'able', 'to', 'get', 'out', 'of', 'here', 'a', 'little', 'early']\n",
      "AFter tokenizer:  ['friendship', 'is', 'not', 'a', 'game', 'to', 'play', ',', 'it', 'is', 'not', 'a', 'word', 'to', 'say', ',', 'it', \"doesn\\\\'t\", 'start', 'on', 'march', 'and', 'ends', 'on', 'may', ',', 'it', 'is', 'tomorrow', ',', 'yesterday', ',', 'today', 'and', 'e']\n",
      "AFter tokenizer:  ['nice', '.', 'wait', '...', 'should', 'you', 'be', 'texting', 'right', 'now', '?', 'i', \"'m\", 'not', 'gon', 'na', 'pay', 'your', 'ticket', ',', 'ya', 'know', '!']\n",
      "AFter tokenizer:  ['i', \"'m\", 'watching', 'lotr', 'w', 'my', 'sis', 'dis', 'aft', '.', 'so', 'u', 'wan', '2', 'meet', 'me', '4', 'dinner', 'at', 'nite', 'a', 'not', '?']\n",
      "AFter tokenizer:  ['why', 'you', 'keeping', 'me', 'away', 'like', 'this']\n",
      "AFter tokenizer:  ['i', 'think', 'its', 'far', 'more', 'than', 'that', 'but', 'find', 'out', '.', 'check', 'google', 'maps', 'for', 'a', 'place', 'from', 'your', 'dorm', '.']\n",
      "AFter tokenizer:  ['my', 'trip', 'was', 'ok', 'but', 'quite', 'tiring', 'lor', '.', 'uni', 'starts', 'today', 'but', 'it', \"'s\", 'ok', '4', 'me', 'cos', 'i', \"'m\", 'not', 'taking', 'any', 'modules', 'but', 'jus', 'concentrating', 'on', 'my', 'final', 'yr', 'project', '.']\n",
      "AFter tokenizer:  ['have', 'you', 'always', 'been', 'saying', 'welp', '?']\n",
      "AFter tokenizer:  ['i', \"'m\", 'a', 'guy', ',', 'browsin', 'is', 'compulsory']\n",
      "AFter tokenizer:  ['purity', 'of', 'friendship', 'between', 'two', 'is', 'not', 'about', 'smiling', 'after', 'reading', 'the', 'forwarded', 'message', '..', 'its', 'about', 'smiling', 'just', 'by', 'seeing', 'the', 'name', '.', 'gud', 'evng', 'musthu']\n",
      "AFter tokenizer:  ['(', 'i', 'should', 'add', 'that', 'i', 'do', \"n't\", 'really', 'care', 'and', 'if', 'you', 'ca', \"n't\", 'i', 'can', 'at', 'least', 'get', 'this', 'dude', 'to', 'fuck', 'off', 'but', 'hey', ',', 'your', 'money', 'if', 'you', 'want', 'it', ')']\n",
      "AFter tokenizer:  ['hello', 'lover', '!', 'how', 'goes', 'that', 'new', 'job', '?', 'are', 'you', 'there', 'now', '?', 'are', 'you', 'happy', '?', 'do', 'you', 'think', 'of', 'me', '?', 'i', 'wake', ',', 'my', 'slave', 'and', 'send', 'you', 'a', 'teasing', 'kiss', 'from', 'across', 'the', 'sea']\n",
      "AFter tokenizer:  ['i', 'told', 'your', 'number', 'to', 'gautham', '..']\n",
      "AFter tokenizer:  ['tell', 'them', 'no', 'need', 'to', 'investigate', 'about', 'me', 'anywhere', '.']\n",
      "AFter tokenizer:  ['ok', 'i', 'juz', 'receive', '..']\n",
      "AFter tokenizer:  ['cant', 'believe', 'i', 'said', 'so', 'many', 'things', 'to', 'you', 'this', 'morning', 'when', 'all', 'i', 'really', 'wanted', 'to', 'say', 'was', 'good', 'morning', ',', 'i', 'love', 'you', '!', 'have', 'a', 'beautiful', 'morning', '.', 'see', 'you', 'in', 'the', 'library', 'later', '.']\n",
      "AFter tokenizer:  ['your', 'account', 'has', 'been', 'credited', 'with', '500', 'free', 'text', 'messages', '.', 'to', 'activate', ',', 'just', 'txt', 'the', 'word', ':', 'credit', 'to', 'no', ':', '80488', 't', '&', 'cs', 'www.80488.biz']\n",
      "AFter tokenizer:  ['in', 'the', 'end', 'she', 'might', 'still', 'vomit', 'but', 'its', 'okay', '.', 'not', 'everything', 'will', 'come', 'out', '.']\n",
      "AFter tokenizer:  ['how', 'are', 'you', 'with', 'money', '...', 'as', 'in', 'to', 'you', '...', 'money', 'aint', 'a', 'thing', '....', 'how', 'are', 'you', 'sha', '!']\n",
      "AFter tokenizer:  ['it', 'has', 'everything', 'to', 'do', 'with', 'the', 'weather', '.', 'keep', 'extra', 'warm', '.', 'its', 'a', 'cold', 'but', 'nothing', 'serious', '.', 'pls', 'lots', 'of', 'vitamin', 'c']\n",
      "AFter tokenizer:  ['hey', 'gals', '..', 'anyone', 'of', 'u', 'going', 'down', 'to', 'e', 'driving', 'centre', 'tmr', '?']\n",
      "AFter tokenizer:  ['i', \"'m\", 'always', 'on', 'yahoo', 'messenger', 'now', '.', 'just', 'send', 'the', 'message', 'to', 'me', 'and', 'i.ll', 'get', 'it', 'you', 'may', 'have', 'to', 'send', 'it', 'in', 'the', 'mobile', 'mode', 'sha', 'but', 'i.ll', 'get', 'it', '.', 'and', 'will', 'reply', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'putting', 'it', 'on', 'now', '.', 'it', 'should', 'be', 'ready', 'for', '&', 'lt', ';', 'time', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['time', 'n', 'smile', 'r', 'the', 'two', 'crucial', 'things', 'in', 'our', 'life', '.', 'sometimes', 'time', 'makes', 'us', 'to', 'forget', 'smile', ',', 'and', 'sometimes', 'someone', \"'s\", 'smile', 'makes', 'us', 'to', 'forget', 'time', 'gud', 'noon']\n",
      "AFter tokenizer:  ['sms', '.', 'ac', 'jsco', ':', 'energy', 'is', 'high', ',', 'but', 'u', 'may', 'not', 'know', 'where', '2channel', 'it', '.', '2day', 'ur', 'leadership', 'skills', 'r', 'strong', '.', 'psychic', '?', 'reply', 'ans', 'w/question', '.', 'end', '?', 'reply', 'end', 'jsco']\n",
      "AFter tokenizer:  ['host-based', 'idps', 'for', 'linux', 'systems', '.']\n",
      "AFter tokenizer:  ['hot', 'live', 'fantasies', 'call', 'now', '08707509020', 'just', '20p', 'per', 'min', 'ntt', 'ltd', ',', 'po', 'box', '1327', 'croydon', 'cr9', '5wb', '0870', 'is', 'a', 'national', 'rate', 'call']\n",
      "AFter tokenizer:  ['don', 'no', 'da', ':', ')', 'whats', 'you', 'plan', '?']\n",
      "AFter tokenizer:  ['ill', 'be', 'there', 'on', '&', 'lt', ';', '#', '&', 'gt', ';', 'ok', '.']\n",
      "AFter tokenizer:  ['oh', 'my', 'god', '.', 'i', \"'m\", 'almost', 'home']\n",
      "AFter tokenizer:  ['total', 'video', 'converter', 'free', 'download', 'type', 'this', 'in', 'google', 'search', ':', ')']\n",
      "AFter tokenizer:  ['thanks', 'for', 'the', 'vote', '.', 'now', 'sing', 'along', 'with', 'the', 'stars', 'with', 'karaoke', 'on', 'your', 'mobile', '.', 'for', 'a', 'free', 'link', 'just', 'reply', 'with', 'sing', 'now', '.']\n",
      "AFter tokenizer:  ['sounds', 'like', 'something', 'that', 'someone', 'testing', 'me', 'would', 'sayy']\n",
      "AFter tokenizer:  ['when', 'u', 'love', 'someone', 'dont', 'make', 'them', 'to', 'love', 'u', 'as', 'much', 'as', 'u', 'do', '.', 'but', 'love', 'them', 'so', 'much', 'that', 'they', 'dont', 'want', 'to', 'be', 'loved', 'by', 'anyone', 'except', 'you', '...', 'gud', 'nit', '.']\n",
      "AFter tokenizer:  ['pete', ',', 'is', 'this', 'your', 'phone', 'still', '?', 'its', 'jenny', 'from', 'college', 'and', 'leanne.what', 'are', 'you', 'up', 'to', 'now', '?', ':', ')']\n",
      "AFter tokenizer:  ['oops', 'sorry', '.', 'just', 'to', 'check', 'that', 'you', 'do', \"n't\", 'mind', 'picking', 'me', 'up', 'tomo', 'at', 'half', 'eight', 'from', 'station', '.', 'would', 'that', 'be', 'ok', '?']\n",
      "AFter tokenizer:  ['hey', 'sweet', ',', 'i', 'was', 'wondering', 'when', 'you', 'had', 'a', 'moment', 'if', 'you', 'might', 'come', 'to', 'me', '?', 'i', 'want', 'to', 'send', 'a', 'file', 'to', 'someone', 'but', 'it', 'wo', \"n't\", 'go', 'over', 'yahoo', 'for', 'them', 'because', 'their', 'connection', 'sucks', ',', 'remember', 'when', 'you', 'set', 'up', 'that', 'page', 'for', 'me', 'to', 'go', 'to', 'and', 'download', 'the', 'format', 'disc', '?', 'could', 'you', 'tell', 'me', 'how', 'to', 'do', 'that', '?', 'or', 'do', 'you', 'know', 'some', 'other', 'way', 'to', 'download', 'big', 'files', '?', 'because', 'they', 'can', 'download', 'stuff', 'directly', 'from', 'the', 'internet', '.', 'any', 'help', 'would', 'be', 'great', ',', 'my', 'prey', '...', '*', 'teasing', 'kiss', '*']\n",
      "AFter tokenizer:  ['hows', 'the', 'champ', 'just', 'leaving', 'glasgow', '!']\n",
      "AFter tokenizer:  ['k', ':', ')', 'all', 'the', 'best', ':', ')', 'congrats', '...']\n",
      "AFter tokenizer:  ['i', 'wonder', 'if', 'you', \"'ll\", 'get', 'this', 'text', '?']\n",
      "AFter tokenizer:  ['i', 'need', 'to', 'come', 'home', 'and', 'give', 'you', 'some', 'good', 'lovin', '...']\n",
      "AFter tokenizer:  ['our', 'brand', 'new', 'mobile', 'music', 'service', 'is', 'now', 'live', '.', 'the', 'free', 'music', 'player', 'will', 'arrive', 'shortly', '.', 'just', 'install', 'on', 'your', 'phone', 'to', 'browse', 'content', 'from', 'the', 'top', 'artists', '.']\n",
      "AFter tokenizer:  ['shall', 'i', 'ask', 'one', 'thing', 'if', 'you', 'dont', 'mistake', 'me', '.']\n",
      "AFter tokenizer:  ['check', 'wid', 'corect', 'speling', 'i.e', '.', 'sarcasm']\n",
      "AFter tokenizer:  ['urgent', '!', 'your', 'mobile', 'no', 'was', 'awarded', 'a', '£2,000', 'bonus', 'caller', 'prize', 'on', '1/08/03', '!', 'this', 'is', 'our', '2nd', 'attempt', 'to', 'contact', 'you', '!', 'call', '0871-4719-523', 'box95qu', 'bt', 'national', 'rate']\n",
      "AFter tokenizer:  ['are', 'you', 'angry', 'with', 'me', '.', 'what', 'happen', 'dear']\n",
      "AFter tokenizer:  ['i', 'thk', 'u', 'dun', 'haf', '2', 'hint', 'in', 'e', 'forum', 'already', 'lor', '...', 'cos', 'i', 'told', 'ron', 'n', 'darren', 'is', 'going', '2', 'tell', 'shuhui', '.']\n",
      "AFter tokenizer:  ['yup', 'ok', 'thanx', '...']\n",
      "AFter tokenizer:  ['hi', ':', ')', 'cts', 'employee', 'how', 'are', 'you', '?']\n",
      "AFter tokenizer:  ['pls', 'pls', 'find', 'out', 'from', 'aunt', 'nike', '.']\n",
      "AFter tokenizer:  ['wow', '...', 'i', 'love', 'you', 'sooo', 'much', ',', 'you', 'know', '?', 'i', 'can', 'barely', 'stand', 'it', '!', 'i', 'wonder', 'how', 'your', 'day', 'goes', 'and', 'if', 'you', 'are', 'well', ',', 'my', 'love', '...', 'i', 'think', 'of', 'you', 'and', 'miss', 'you']\n",
      "AFter tokenizer:  ['no', 'screaming', 'means', 'shouting', '..']\n",
      "AFter tokenizer:  ['hey', 'what', 'happen', 'de', '.', 'are', 'you', 'alright', '.']\n",
      "AFter tokenizer:  ['should', 'i', 'have', 'picked', 'up', 'a', 'receipt', 'or', 'something', 'earlier']\n",
      "AFter tokenizer:  ['i', 'think', 'chennai', 'well', 'settled', '?']\n",
      "AFter tokenizer:  ['oh', 'dang', '!', 'i', 'did', \"n't\", 'mean', 'o', 'send', 'that', 'to', 'you', '!', 'lol', '!']\n",
      "AFter tokenizer:  ['unfortunately', 'i', \"'ve\", 'just', 'found', 'out', 'that', 'we', 'have', 'to', 'pick', 'my', 'sister', 'up', 'from', 'the', 'airport', 'that', 'evening', 'so', 'do', \"n't\", 'think', 'i', \"'ll\", 'be', 'going', 'out', 'at', 'all', '.', 'we', 'should', 'try', 'to', 'go', 'out', 'one', 'of', 'th']\n",
      "AFter tokenizer:  ['horrible', 'bf', '...', 'i', 'now', 'v', 'hungry', '...']\n",
      "AFter tokenizer:  ['remember', 'on', 'that', 'day', '..']\n",
      "AFter tokenizer:  ['you', 'have', 'won', 'a', 'nokia', '7250i', '.', 'this', 'is', 'what', 'you', 'get', 'when', 'you', 'win', 'our', 'free', 'auction', '.', 'to', 'take', 'part', 'send', 'nokia', 'to', '86021', 'now', '.', 'hg/suite342/2lands', 'row/w1jhl', '16+']\n",
      "AFter tokenizer:  ['how', \"'s\", 'it', 'feel', '?', 'mr.', 'your', 'not', 'my', 'real', 'valentine', 'just', 'my', 'yo', 'valentine', 'even', 'tho', 'u', 'hardly', 'play', '!', '!']\n",
      "AFter tokenizer:  ['all', 'sounds', 'good', '.', 'fingers', '.', 'makes', 'it', 'difficult', 'to', 'type']\n",
      "AFter tokenizer:  ['midnight', 'at', 'the', 'earliest']\n",
      "AFter tokenizer:  ['you', \"'re\", 'not', 'sure', 'that', 'i', \"'m\", 'not', 'trying', 'to', 'make', 'xavier', 'smoke', 'because', 'i', 'do', \"n't\", 'want', 'to', 'smoke', 'after', 'being', 'told', 'i', 'smoke', 'too', 'much', '?']\n",
      "AFter tokenizer:  ['k', 'come', 'to', 'nordstrom', 'when', 'you', \"'re\", 'done']\n",
      "AFter tokenizer:  ['do', 'u', 'konw', 'waht', 'is', 'rael', 'friendship', 'im', 'gving', 'yuo', 'an', 'exmpel', ':', 'jsut', 'ese', 'tihs', 'msg', '..', 'evrey', 'splleing', 'of', 'tihs', 'msg', 'is', 'wrnog', '..', 'bt', 'sitll', 'yuo', 'can', 'raed', 'it', 'wihtuot', 'ayn', 'mitsake', '..', 'goodnight', '&', 'amp', ';', 'have', 'a', 'nice', 'sleep', '..', 'sweet', 'dreams', '..']\n",
      "AFter tokenizer:  ['now', 'press', 'conference', 'da', ':', ')']\n",
      "AFter tokenizer:  ['hello', 'from', 'orange', '.', 'for', '1', 'month', \"'s\", 'free', 'access', 'to', 'games', ',', 'news', 'and', 'sport', ',', 'plus', '10', 'free', 'texts', 'and', '20', 'photo', 'messages', ',', 'reply', 'yes', '.', 'terms', 'apply', ':', 'www.orange.co.uk/ow']\n",
      "AFter tokenizer:  ['after', 'completed', 'degree', '.', 'there', 'is', 'no', 'use', 'in', 'joining', 'finance', '.']\n",
      "AFter tokenizer:  ['good', 'afternoon', ',', 'my', 'love', '!', 'any', 'job', 'prospects', '?', 'are', 'you', 'missing', 'me', '?', 'what', 'do', 'you', 'do', '?', 'are', 'you', 'being', 'lazy', 'and', 'bleak', ',', 'hmmm', '?', 'or', 'happy', 'and', 'filled', 'with', 'my', 'love', '?']\n",
      "AFter tokenizer:  ['shant', 'disturb', 'u', 'anymore', '...', 'jia', 'you', '...']\n",
      "AFter tokenizer:  ['bishan', 'lar', 'nearer', '...', 'no', 'need', 'buy', 'so', 'early', 'cos', 'if', 'buy', 'now', 'i', 'got', 'ta', 'park', 'my', 'car', '...']\n",
      "AFter tokenizer:  ['me', ',', 'i', 'dont', 'know', 'again', 'oh']\n",
      "AFter tokenizer:  ['dude', 'sux', 'for', 'snake', '.', 'he', 'got', 'old', 'and', 'raiden', 'got', 'buff']\n",
      "AFter tokenizer:  ['he', 'says', 'hi', 'and', 'to', 'get', 'your', 'ass', 'back', 'to', 'south', 'tampa', '(', 'preferably', 'at', 'a', 'kegger', ')']\n",
      "AFter tokenizer:  ['in', 'e', 'msg', 'jus', 'now', '.', 'u', 'said', 'thanks', 'for', 'gift', '.']\n",
      "AFter tokenizer:  ['u', 'too', '...']\n",
      "AFter tokenizer:  ['ok', 'how', 'you', 'dear', '.', 'did', 'you', 'call', 'chechi']\n",
      "AFter tokenizer:  ['yeah', 'we', 'do', 'totes', '.', 'when', 'u', 'wan', 'na', '?']\n",
      "AFter tokenizer:  ['ok', 'i', 'found', 'dis', 'pierre', 'cardin', 'one', 'which', 'looks', 'normal', 'costs', '20', 'its', 'on', 'sale', '.']\n",
      "AFter tokenizer:  ['good', 'sleep', 'is', 'about', 'rhythm', '.', 'the', 'person', 'has', 'to', 'establish', 'a', 'rhythm', 'that', 'the', 'body', 'will', 'learn', 'and', 'use', '.', 'if', 'you', 'want', 'to', 'know', 'more', ':', '-', ')']\n",
      "AFter tokenizer:  ['wat', 'r', 'u', 'doing', '?']\n",
      "AFter tokenizer:  ['message', 'from', '.', 'i', 'am', 'at', 'truro', 'hospital', 'on', 'ext', '.', 'you', 'can', 'phone', 'me', 'here', '.', 'as', 'i', 'have', 'a', 'phone', 'by', 'my', 'side']\n",
      "AFter tokenizer:  ['single', 'line', 'with', 'a', 'big', 'meaning', ':', ':', ':', ':', ':', '``', 'miss', 'anything', '4', 'ur', '``', 'best', 'life', \"''\", 'but', ',', 'do', \"n't\", 'miss', 'ur', 'best', 'life', 'for', 'anything', '...', 'gud', 'nyt', '...']\n",
      "AFter tokenizer:  ['just', 'got', 'some', 'gas', 'money', ',', 'any', 'chance', 'you', 'and', 'the', 'gang', 'want', 'to', 'go', 'on', 'a', 'grand', 'nature', 'adventure', '?']\n",
      "AFter tokenizer:  ['dnt', 'worry', '...', 'use', 'ice', 'pieces', 'in', 'a', 'cloth', 'pack.also', 'take', '2', 'tablets', '.']\n",
      "AFter tokenizer:  ['dude', 'just', 'saw', 'a', 'parked', 'car', 'with', 'its', 'sunroof', 'popped', 'up', '.', 'sux']\n",
      "AFter tokenizer:  ['get', 'ready', 'to', 'put', 'on', 'your', 'excellent', 'sub', 'face', ':', ')']\n",
      "AFter tokenizer:  ['tmrw', '.', 'im', 'finishing', '9', 'doors']\n",
      "AFter tokenizer:  ['the', '&', 'lt', ';', '#', '&', 'gt', ';', 'g', 'that', 'i', 'saw', 'a', 'few', 'days', 'ago', ',', 'the', 'guy', 'wants', 'sell', 'wifi', 'only', 'for', '&', 'lt', ';', '#', '&', 'gt', ';', 'and', 'with', '3g', 'for', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'that', \"'s\", 'why', 'i', 'blanked', 'him', '.']\n",
      "AFter tokenizer:  ['i', 'am', 'late', '.', 'i', 'will', 'be', 'there', 'at']\n",
      "AFter tokenizer:  ['whatever', ',', 'im', 'pretty', 'pissed', 'off', '.']\n",
      "AFter tokenizer:  ['i', 'dont', 'have', 'that', 'much', 'image', 'in', 'class', '.']\n",
      "AFter tokenizer:  ['no', ':', '-', ')', 'i', 'got', 'rumour', 'that', 'you', 'going', 'to', 'buy', 'apartment', 'in', 'chennai', ':', '-', ')']\n",
      "AFter tokenizer:  ['near', 'kalainar', 'tv', 'office.thenampet']\n",
      "AFter tokenizer:  ['ur', 'cash-balance', 'is', 'currently', '500', 'pounds', '-', 'to', 'maximize', 'ur', 'cash-in', 'now', 'send', 'go', 'to', '86688', 'only', '150p/msg', '.', 'cc', '08718720201', 'hg/suite342/2lands', 'row/w1j6hl']\n",
      "AFter tokenizer:  ['sms', 'auction', '-', 'a', 'brand', 'new', 'nokia', '7250', 'is', 'up', '4', 'auction', 'today', '!', 'auction', 'is', 'free', '2', 'join', '&', 'take', 'part', '!', 'txt', 'nokia', 'to', '86021', 'now', '!', 'hg/suite342/2lands', 'row/w1j6hl']\n",
      "AFter tokenizer:  ['my', 'sis', 'is', 'catching', 'e', 'show', 'in', 'e', 'afternoon', 'so', 'i', \"'m\", 'not', 'watching', 'w', 'her', '.', 'so', 'c', 'u', 'wan', '2', 'watch', 'today', 'or', 'tmr', 'lor', '.']\n",
      "AFter tokenizer:  ['sounds', 'gd', '...', 'haha', '...', 'can', '...', 'wah', ',', 'u', 'yan', 'jiu', 'so', 'fast', 'liao', '...']\n",
      "AFter tokenizer:  ['no', '.', 'to', 'be', 'nosy', 'i', 'guess', '.', 'idk', 'am', 'i', 'over', 'reacting', 'if', 'i', \"'m\", 'freaked', '?']\n",
      "AFter tokenizer:  ['remember', 'all', 'those', 'whom', 'i', 'hurt', 'during', 'days', 'of', 'satanic', 'imposter', 'in', 'me.need', 'to', 'pay', 'a', 'price', ',', 'so', 'be', 'it.may', 'destiny', 'keep', 'me', 'going', 'and', 'as', 'u', 'said', 'pray', 'that', 'i', 'get', 'the', 'mind', 'to', 'get', 'over', 'the', 'same', '.']\n",
      "AFter tokenizer:  ['how', 'to', 'make', 'a', 'girl', 'happy', '?', 'it', \"'s\", 'not', 'at', 'all', 'difficult', 'to', 'make', 'girls', 'happy', '.', 'u', 'only', 'need', 'to', 'be', '...', '1.', 'a', 'friend', '2.', 'companion', '3.', 'lover', '4.', 'chef', '.', '.', '.', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'good', 'listener', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'organizer', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'good', 'boyfriend', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'very', 'clean', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'sympathetic', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'athletic', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'warm', '.', '.', '.', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'courageous', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'determined', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'true', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'dependable', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'intelligent', '.', '.', '.', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'psychologist', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'pest', 'exterminator', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'psychiatrist', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'healer', '.', '.', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'stylist', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'driver', '.', '.', 'aaniye', 'pudunga', 'venaam', '..']\n",
      "AFter tokenizer:  ['why', 'is', 'that', ',', 'princess', '?', 'i', 'bet', 'the', 'brothas', 'are', 'all', 'chasing', 'you', '!']\n",
      "AFter tokenizer:  ['i', 'shall', 'book', 'chez', 'jules', 'for', 'half', 'eight', ',', 'if', 'that', \"'s\", 'ok', 'with', 'you', '?']\n",
      "AFter tokenizer:  ['hhahhaahahah', 'rofl', 'wtf', 'nig', 'was', 'leonardo', 'in', 'your', 'room', 'or', 'something']\n",
      "AFter tokenizer:  ['yep', ',', 'at', 'derek', \"'s\", 'house', 'now', ',', 'see', 'you', 'sunday', '&', 'lt', ';', '3']\n",
      "AFter tokenizer:  ['it', \"'s\", 'cool', ',', 'let', 'me', 'know', 'before', 'it', 'kicks', 'off', 'around', '&', 'lt', ';', '#', '&', 'gt', ';', ',', 'i', \"'ll\", 'be', 'out', 'and', 'about', 'all', 'day']\n",
      "AFter tokenizer:  ['i', 'was', 'wondering', 'if', 'it', 'would', 'be', 'okay', 'for', 'you', 'to', 'call', 'uncle', 'john', 'and', 'let', 'him', 'know', 'that', 'things', 'are', 'not', 'the', 'same', 'in', 'nigeria', 'as', 'they', 'r', 'here', '.', 'that', '&', 'lt', ';', '#', '&', 'gt', ';', 'dollars', 'is', '2years', 'sent', 'and', 'that', 'you', 'know', 'its', 'a', 'strain', 'but', 'i', 'plan', 'to', 'pay', 'back', 'every', 'dime', 'he', 'gives', '.', 'every', 'dime', 'so', 'for', 'me', 'to', 'expect', 'anything', 'from', 'you', 'is', 'not', 'practical', '.', 'something', 'like', 'that', '.']\n",
      "AFter tokenizer:  ['there', 'are', 'no', 'other', 'charges', 'after', 'transfer', 'charges', 'and', 'you', 'can', 'withdraw', 'anyhow', 'you', 'like']\n",
      "AFter tokenizer:  ['dont', 'search', 'love', ',', 'let', 'love', 'find', 'u.', 'thats', 'why', 'its', 'called', 'falling', 'in', 'love', ',', 'bcoz', 'u', 'dont', 'force', 'yourself', ',', 'u', 'just', 'fall', 'and', 'u', 'know', 'there', 'is', 'smeone', 'to', 'hold', 'u', '...', 'bslvyl']\n",
      "AFter tokenizer:  ['at', '4.', 'let', \"'s\", 'go', 'to', 'bill', 'millers']\n",
      "AFter tokenizer:  ['i', 'love', 'you', '.', 'you', 'set', 'my', 'soul', 'on', 'fire', '.', 'it', 'is', 'not', 'just', 'a', 'spark', '.', 'but', 'it', 'is', 'a', 'flame', '.', 'a', 'big', 'rawring', 'flame', '.', 'xoxo']\n",
      "AFter tokenizer:  ['somewhr', 'someone', 'is', 'surely', 'made', '4', 'u.', 'and', 'god', 'has', 'decided', 'a', 'perfect', 'time', 'to', 'make', 'u', 'meet', 'dat', 'person', '.', '.', '.', '.', 'till', 'den', ',', '.', '.', '.', '.', '.', 'enjoy', 'ur', 'crushes', '..', '!', '!', '!', ';', '-', ')']\n",
      "AFter tokenizer:  ['that', \"'s\", 'my', 'honeymoon', 'outfit', '.', ':', ')']\n",
      "AFter tokenizer:  ['will', 'it', 'help', 'if', 'we', 'propose', 'going', 'back', 'again', 'tomorrow']\n",
      "AFter tokenizer:  ['private', '!', 'your', '2003', 'account', 'statement', 'for', 'shows', '800', 'un-redeemed', 's.', 'i.', 'm.', 'points', '.', 'call', '08719899230', 'identifier', 'code', ':', '41685', 'expires', '07/11/04']\n",
      "AFter tokenizer:  ['never', 'blame', 'a', 'day', 'in', 'ur', 'life', '.', 'good', 'days', 'give', 'u', 'happiness', '.', 'bad', 'days', 'give', 'u', 'experience', '.', 'both', 'are', 'essential', 'in', 'life', '!', 'all', 'are', 'gods', 'blessings', '!', 'good', 'morning', '.', ':']\n",
      "AFter tokenizer:  ['pls', 'confirm', 'the', 'time', 'to', 'collect', 'the', 'cheque', '.']\n",
      "AFter tokenizer:  ['as', 'a', 'registered', 'subscriber', 'yr', 'draw', '4', 'a', '£100', 'gift', 'voucher', 'will', 'b', 'entered', 'on', 'receipt', 'of', 'a', 'correct', 'ans', '.', 'when', 'are', 'the', 'next', 'olympics', '.', 'txt', 'ans', 'to', '80062']\n",
      "AFter tokenizer:  ['urgent', '!', 'your', 'mobile', 'number', 'has', 'been', 'awarded', 'with', 'a', '£2000', 'prize', 'guaranteed', '.', 'call', '09061790121', 'from', 'land', 'line', '.', 'claim', '3030.', 'valid', '12hrs', 'only', '150ppm']\n",
      "AFter tokenizer:  ['daddy', 'will', 'take', 'good', 'care', 'of', 'you', ':', ')']\n",
      "AFter tokenizer:  ['yeah', 'probably', ',', 'i', 'still', 'got', 'ta', 'check', 'out', 'with', 'leo']\n",
      "AFter tokenizer:  ['k.then', 'any', 'other', 'special', '?']\n",
      "AFter tokenizer:  ['carlos', 'is', 'taking', 'his', 'sweet', 'time', 'as', 'usual', 'so', 'let', 'me', 'know', 'when', 'you', 'and', 'patty', 'are', 'done/want', 'to', 'smoke', 'and', 'i', \"'ll\", 'tell', 'him', 'to', 'haul', 'ass']\n",
      "AFter tokenizer:  ['ok', 'pa.', 'nothing', 'problem', ':', '-', ')']\n",
      "AFter tokenizer:  ['have', 'you', 'heard', 'about', 'that', 'job', '?', 'i', \"'m\", 'going', 'to', 'that', 'wildlife', 'talk', 'again', 'tonight', 'if', 'u', 'want2come', '.', 'its', 'that2worzels', 'and', 'a', 'wizzle', 'or', 'whatever', 'it', 'is', '?', '!']\n",
      "AFter tokenizer:  ['god', 'picked', 'up', 'a', 'flower', 'and', 'dippeditinadew', ',', 'lovingly', 'touched', 'itwhichturnedinto', 'u', ',', 'and', 'the', 'he', 'gifted', 'tomeandsaid', ',', 'this', 'friend', 'is', '4u']\n",
      "AFter tokenizer:  ['when', 'you', 'came', 'to', 'hostel', '.']\n",
      "AFter tokenizer:  ['ok', 'no', 'prob', '...', 'i', \"'ll\", 'come', 'after', 'lunch', 'then', '...']\n",
      "AFter tokenizer:  ['jus', 'telling', 'u', 'dat', 'i', \"'ll\", 'b', 'leaving', '4', 'shanghai', 'on', '21st', 'instead', 'so', 'we', \"'ll\", 'haf', 'more', 'time', '2', 'meet', 'up', 'cya', '...']\n",
      "AFter tokenizer:  ['are', 'your', 'freezing', '?', 'are', 'you', 'home', 'yet', '?', 'will', 'you', 'remember', 'to', 'kiss', 'your', 'mom', 'in', 'the', 'morning', '?', 'do', 'you', 'love', 'me', '?', 'do', 'you', 'think', 'of', 'me', '?', 'are', 'you', 'missing', 'me', 'yet', '?']\n",
      "AFter tokenizer:  ['you', 'all', 'ready', 'for', '*', 'big', 'day', 'tomorrow', '?']\n",
      "AFter tokenizer:  ['i', \"'ll\", 'probably', 'be', 'around', 'mu', 'a', 'lot']\n",
      "AFter tokenizer:  ['645']\n",
      "AFter tokenizer:  ['rt-king', 'pro', 'video', 'club', '>', '>', 'need', 'help', '?', 'info', '@', 'ringtoneking.co.uk', 'or', 'call', '08701237397', 'you', 'must', 'be', '16+', 'club', 'credits', 'redeemable', 'at', 'www.ringtoneking.co.uk', '!', 'enjoy', '!']\n",
      "AFter tokenizer:  ['thnx', 'dude', '.', 'u', 'guys', 'out', '2nite', '?']\n",
      "AFter tokenizer:  ['me', 'sef', 'dey', 'laugh', 'you', '.', 'meanwhile', 'how', \"'s\", 'my', 'darling', 'anjie', '!']\n",
      "AFter tokenizer:  ['mm', 'i', 'had', 'my', 'food', 'da', 'from', 'out']\n",
      "AFter tokenizer:  ['k', ',', 'makes', 'sense', ',', 'btw', 'carlos', 'is', 'being', 'difficult', 'so', 'you', 'guys', 'are', 'gon', 'na', 'smoke', 'while', 'i', 'go', 'pick', 'up', 'the', 'second', 'batch', 'and', 'get', 'gas']\n",
      "AFter tokenizer:  ['did', 'u', 'download', 'the', 'fring', 'app', '?']\n",
      "AFter tokenizer:  ['the', '2', 'oz', 'guy', 'is', 'being', 'kinda', 'flaky', 'but', 'one', 'friend', 'is', 'interested', 'in', 'picking', 'up', '$', '&', 'lt', ';', '#', '&', 'gt', ';', 'worth', 'tonight', 'if', 'possible']\n",
      "AFter tokenizer:  ['friends', 'that', 'u', 'can', 'stay', 'on', 'fb', 'chat', 'with']\n",
      "AFter tokenizer:  ['fuck', 'babe', ',', 'i', 'miss', 'you', 'sooooo', 'much', '!', '!', 'i', 'wish', 'you', 'were', 'here', 'to', 'sleep', 'with', 'me', '...', 'my', 'bed', 'is', 'so', 'lonely', '...', 'i', 'go', 'now', ',', 'to', 'sleep', '...', 'to', 'dream', 'of', 'you', ',', 'my', 'love', '...']\n",
      "AFter tokenizer:  ['living', 'is', 'very', 'simple', '..', 'loving', 'is', 'also', 'simple', '..', 'laughing', 'is', 'too', 'simple', '..', 'winning', 'is', 'tooo', 'simple', '..', 'but', ',', 'being', \"'simple\", \"'\", 'is', 'very', 'difficult', '..', 'gud', 'nte', '.', ':', '-']\n",
      "AFter tokenizer:  ['u', 'have', 'a', 'secret', 'admirer', 'who', 'is', 'looking', '2', 'make', 'contact', 'with', 'u-find', 'out', 'who', 'they', 'r', '*', 'reveal', 'who', 'thinks', 'ur', 'so', 'special-call', 'on', '09058094599']\n",
      "AFter tokenizer:  ['ah', ',', 'well', 'that', 'confuses', 'things', ',', 'doesn', '‘', 't', 'it', '?']\n",
      "AFter tokenizer:  ['500', 'free', 'text', 'msgs', '.', 'just', 'text', 'ok', 'to', '80488', 'and', 'we', \"'ll\", 'credit', 'your', 'account']\n",
      "AFter tokenizer:  ['hi', 'dear', 'call', 'me', 'its', 'urgnt', '.', 'i', 'do', \"n't\", 'know', 'whats', 'your', 'problem', '.', 'you', 'do', \"n't\", 'want', 'to', 'work', 'or', 'if', 'you', 'have', 'any', 'other', 'problem', 'at', 'least', 'tell', 'me', '.', 'wating', 'for', 'your', 'reply', '.']\n",
      "AFter tokenizer:  ['dear', 'how', 'you', '.', 'are', 'you', 'ok', '?']\n",
      "AFter tokenizer:  ['you', 'have', 'been', 'selected', 'to', 'stay', 'in', '1', 'of', '250', 'top', 'british', 'hotels', '-', 'for', 'nothing', '!', 'holiday', 'worth', '£350', '!', 'to', 'claim', ',', 'call', 'london', '02072069400.', 'bx', '526', ',', 'sw73ss']\n",
      "AFter tokenizer:  ['yes', 'princess', '!', 'i', 'want', 'to', 'make', 'you', 'happy', '...']\n",
      "AFter tokenizer:  ['sounds', 'like', 'you', 'have', 'many', 'talents', '!', 'would', 'you', 'like', 'to', 'go', 'on', 'a', 'dinner', 'date', 'next', 'week', '?']\n",
      "AFter tokenizer:  ['i', 'am', 'going', 'to', 'film', '2day', 'da', '.', 'at', '6pm', '.', 'sorry', 'da', '.']\n",
      "AFter tokenizer:  ['we', 'not', 'watching', 'movie', 'already', '.', 'xy', 'wants', '2', 'shop', 'so', 'i', \"'m\", 'shopping', 'w', 'her', 'now', '.']\n",
      "AFter tokenizer:  ['hello', 'my', 'little', 'party', 'animal', '!', 'i', 'just', 'thought', 'i', \"'d\", 'buzz', 'you', 'as', 'you', 'were', 'with', 'your', 'friends', '...', '*', 'grins', '*', '...', 'reminding', 'you', 'were', 'loved', 'and', 'send', 'a', 'naughty', 'adoring', 'kiss']\n",
      "AFter tokenizer:  ['yesterday', 'its', 'with', 'me', 'only', '.', 'now', 'am', 'going', 'home', '.']\n",
      "AFter tokenizer:  ['eerie', 'nokia', 'tones', '4u', ',', 'rply', 'tone', 'title', 'to', '8007', 'eg', 'tone', 'dracula', 'to', '8007', 'titles', ':', 'ghost', ',', 'addamsfa', ',', 'munsters', ',', 'exorcist', ',', 'twilight', 'www.getzed.co.uk', 'pobox36504w45wq', '150p']\n",
      "AFter tokenizer:  ['you', 'have', 'come', 'into', 'my', 'life', 'and', 'brought', 'the', 'sun', '..', 'shiny', 'down', 'on', 'me', ',', 'warming', 'my', 'heart', '.', 'putting', 'a', 'constant', 'smile', 'on', 'my', 'face', '...', 'making', 'me', 'feel', 'loved', 'and', 'cared', 'for']\n",
      "AFter tokenizer:  ['no', 'shit', ',', 'but', 'i', 'was', \"n't\", 'that', 'surprised', ',', 'so', 'i', 'went', 'and', 'spent', 'the', 'evening', 'with', 'that', 'french', 'guy', 'i', 'met', 'in', 'town', 'here', 'and', 'we', 'fooled', 'around', 'a', 'bit', 'but', 'i', 'did', \"n't\", 'let', 'him', 'fuck', 'me']\n",
      "AFter tokenizer:  ['0a', '$', 'networks', 'allow', 'companies', 'to', 'bill', 'for', 'sms', ',', 'so', 'they', 'are', 'responsible', 'for', 'their', '``', 'suppliers', \"''\", ',', 'just', 'as', 'a', 'shop', 'has', 'to', 'give', 'a', 'guarantee', 'on', 'what', 'they', 'sell', '.', 'b.', 'g', '.']\n",
      "AFter tokenizer:  ['great', 'comedy', '..', 'cant', 'stop', 'laughing', 'da', ':', ')']\n",
      "AFter tokenizer:  ['freemsg', ':', 'feelin', 'kinda', 'lnly', 'hope', 'u', 'like', '2', 'keep', 'me', 'company', '!', 'jst', 'got', 'a', 'cam', 'moby', 'wan', 'na', 'c', 'my', 'pic', '?', 'txt', 'or', 'reply', 'date', 'to', '82242', 'msg150p', '2rcv', 'hlp', '08712317606', 'stop', 'to', '82242']\n",
      "AFter tokenizer:  ['alright', ',', 'we', \"'re\", 'all', 'set', 'here', ',', 'text', 'the', 'man']\n",
      "AFter tokenizer:  ['hi', ',', 'where', 'are', 'you', '?', 'we', \"'re\", 'at', 'and', 'they', \"'re\", 'not', 'keen', 'to', 'go', 'out', 'i', 'kind', 'of', 'am', 'but', 'feel', 'i', 'should', \"n't\", 'so', 'can', 'we', 'go', 'out', 'tomo', ',', 'do', \"n't\", 'mind', 'do', 'you', '?']\n",
      "AFter tokenizer:  ['sleeping', 'nt', 'feeling', 'well']\n",
      "AFter tokenizer:  ['u', 'will', 'switch', 'your', 'fone', 'on', 'dammit', '!', '!']\n",
      "AFter tokenizer:  ['india', 'have', 'to', 'take', 'lead', ':', ')']\n",
      "AFter tokenizer:  ['i.ll', 'post', 'her', 'out', 'l8r', '.', 'in', 'class']\n",
      "AFter tokenizer:  ['thts', 'wat', 'wright', 'brother', 'did', 'to', 'fly', '..']\n",
      "AFter tokenizer:  ['evening', '*', 'v', 'good', 'if', 'somewhat', 'event', 'laden', '.', 'will', 'fill', 'you', 'in', ',', 'do', \"n't\", 'you', 'worry', '…', 'head', '*', 'ok', 'but', 'throat', '*', 'wrecked', '.', 'see', 'you', 'at', 'six', 'then', '!']\n",
      "AFter tokenizer:  ['if', 'u', 'laugh', 'really', 'loud', '..', 'if', 'u', 'talk', 'spontaneously', '..', 'if', 'u', 'dont', 'care', 'what', 'others', 'feel', '..', 'u', 'are', 'probably', 'with', 'your', 'dear', '&', 'amp', ';', 'best', 'friends', '..', 'goodevening', 'dear', '..', ':', ')']\n",
      "AFter tokenizer:  ['its', 'a', 'laptop', 'take', 'it', 'with', 'you', '.']\n",
      "AFter tokenizer:  ['i', 'dont', 'have', 'any', 'of', 'your', 'file', 'in', 'my', 'bag', '..', 'i', 'was', 'in', 'work', 'when', 'you', 'called', 'me.i', \"'ll\", 'tell', 'you', 'if', 'i', 'find', 'anything', 'in', 'my', 'room', '.']\n",
      "AFter tokenizer:  ['i', 'wan', 'but', 'too', 'early', 'lei', '...', 'me', 'outside', 'now', 'wun', 'b', 'home', 'so', 'early', '...', 'neva', 'mind', 'then', '...']\n",
      "AFter tokenizer:  ['for', 'ur', 'chance', 'to', 'win', 'a', '£250', 'cash', 'every', 'wk', 'txt', ':', 'action', 'to', '80608.', 't', \"'s\", '&', 'c', \"'s\", 'www.movietrivia.tv', 'custcare', '08712405022', ',', '1x150p/wk']\n",
      "AFter tokenizer:  ['i', 'was', 'at', 'bugis', 'juz', 'now', 'wat', '...', 'but', 'now', 'i', \"'m\", 'walking', 'home', 'oredi', '...', 'ü', 'so', 'late', 'then', 'reply', '...', 'i', 'oso', 'saw', 'a', 'top', 'dat', 'i', 'like', 'but', 'din', 'buy', '...', 'where', 'r', 'ü', 'now', '?']\n",
      "AFter tokenizer:  ['at', '7', 'we', 'will', 'go', 'ok', 'na', '.']\n",
      "AFter tokenizer:  ['yes', 'i', 'posted', 'a', 'couple', 'of', 'pics', 'on', 'fb', '.', 'there', \"'s\", 'still', 'snow', 'outside', 'too', '.', 'i', \"'m\", 'just', 'waking', 'up', ':', ')']\n",
      "AFter tokenizer:  ['s', ':', '-', ')', 'if', 'we', 'have', 'one', 'good', 'partnership', 'going', 'we', 'will', 'take', 'lead', ':', ')']\n",
      "AFter tokenizer:  ['rgent', '!', 'this', 'is', 'the', '2nd', 'attempt', 'to', 'contact', 'u', '!', 'u', 'have', 'won', '£1250', 'call', '09071512433', 'b4', '050703', 't', '&', 'csbcm4235wc1n3xx', '.', 'callcost', '150ppm', 'mobilesvary', '.', 'max£7', '.', '50']\n",
      "AFter tokenizer:  ['yeah', ',', 'where', \"'s\", 'your', 'class', 'at', '?']\n",
      "AFter tokenizer:  ['no', 'just', 'send', 'to', 'you', '.', 'bec', 'you', 'in', 'temple', 'na', '.']\n",
      "AFter tokenizer:  ['you', 'are', \"n't\", 'coming', 'home', 'between', 'class', ',', 'right', '?', 'i', 'need', 'to', 'work', 'out', 'and', 'shower', '!']\n",
      "AFter tokenizer:  ['hi', 'if', 'ur', 'lookin', '4', 'saucy', 'daytime', 'fun', 'wiv', 'busty', 'married', 'woman', 'am', 'free', 'all', 'next', 'week', 'chat', 'now', '2', 'sort', 'time', '09099726429', 'janinexx', 'calls£1/minmobsmorelkpobox177hp51fl']\n",
      "AFter tokenizer:  ['s', 'but', 'mostly', 'not', 'like', 'that', '.']\n",
      "AFter tokenizer:  ['ü', 'v', 'ma', 'fan', '...']\n",
      "AFter tokenizer:  ['dunno', 'cos', 'i', 'was', 'v', 'late', 'n', 'when', 'i', 'reach', 'they', 'inside', 'already', '...', 'but', 'we', 'ate', 'spageddies', 'lor', '...', 'it', \"'s\", 'e', 'gals', 'who', 'r', 'laughing', 'at', 'me', 'lor', '...']\n",
      "AFter tokenizer:  ['guess', 'who', 'spent', 'all', 'last', 'night', 'phasing', 'in', 'and', 'out', 'of', 'the', 'fourth', 'dimension']\n",
      "AFter tokenizer:  ['so', 'now', 'my', 'dad', 'is', 'gon', 'na', 'call', 'after', 'he', 'gets', 'out', 'of', 'work', 'and', 'ask', 'all', 'these', 'crazy', 'questions', '.']\n",
      "AFter tokenizer:  ['yes', '..', 'but', 'they', 'said', 'its', 'it.', ',']\n",
      "AFter tokenizer:  ['very', 'hurting', 'n', 'meaningful', 'lines', 'ever', ':', '``', 'i', 'compromised', 'everything', 'for', 'my', 'love', ',', 'but', 'at', 'd', 'end', 'my', 'love', 'compromised', 'me', 'for', 'everything', ':', '-', '(', '``', '..', 'gud', 'mornin', ':', '-', ')']\n",
      "AFter tokenizer:  ['lmao', '!', 'nice', '1']\n",
      "AFter tokenizer:  ['glad', 'to', 'see', 'your', 'reply', '.']\n",
      "AFter tokenizer:  ['urgent', '!', 'we', 'are', 'trying', 'to', 'contact', 'u.', 'todays', 'draw', 'shows', 'that', 'you', 'have', 'won', 'a', '£800', 'prize', 'guaranteed', '.', 'call', '09050001295', 'from', 'land', 'line', '.', 'claim', 'a21', '.', 'valid', '12hrs', 'only']\n",
      "AFter tokenizer:  ['monthly', 'password', 'for', 'wap', '.', 'mobsi.com', 'is', '391784.', 'use', 'your', 'wap', 'phone', 'not', 'pc', '.']\n",
      "AFter tokenizer:  ['nah', 'dub', 'but', 'je', 'still', 'buff']\n",
      "AFter tokenizer:  ['painful', 'words-', '``', 'i', 'thought', 'being', 'happy', 'was', 'the', 'most', 'toughest', 'thing', 'on', 'earth', '...', 'but', ',', 'the', 'toughest', 'is', 'acting', 'happy', 'with', 'all', 'unspoken', 'pain', 'inside', '..', \"''\"]\n",
      "AFter tokenizer:  ['yeah', ',', 'that', \"'s\", 'fine', '!', 'it', \"'s\", '£6', 'to', 'get', 'in', ',', 'is', 'that', 'ok', '?']\n",
      "AFter tokenizer:  ['lol', 'where', 'do', 'u', 'come', 'up', 'with', 'these', 'ideas', '?']\n",
      "AFter tokenizer:  ['so', 'many', 'people', 'seems', 'to', 'be', 'special', 'at', 'first', 'sight', ',', 'but', 'only', 'very', 'few', 'will', 'remain', 'special', 'to', 'you', 'till', 'your', 'last', 'sight', '..', 'maintain', 'them', 'till', 'life', 'ends', '..', 'sh', '!', 'jas']\n",
      "AFter tokenizer:  ['okay', '...', 'we', 'wait', 'ah']\n",
      "AFter tokenizer:  ['y', 'lei', '?']\n",
      "AFter tokenizer:  ['hi', 'babe', 'u', 'r', 'most', 'likely', 'to', 'be', 'in', 'bed', 'but', 'im', 'so', 'sorry', 'about', 'tonight', '!', 'i', 'really', 'wan', 'na', 'see', 'u', 'tomorrow', 'so', 'call', 'me', 'at', '9.', 'love', 'me', 'xxx']\n",
      "AFter tokenizer:  ['already', 'am', 'squatting', 'is', 'the', 'new', 'way', 'of', 'walking']\n",
      "AFter tokenizer:  ['do', 'you', 'want', 'bold', '2', 'or', 'bb', 'torch']\n",
      "AFter tokenizer:  ['cramps', 'stopped', '.', 'going', 'back', 'to', 'sleep']\n",
      "AFter tokenizer:  ['todays', 'vodafone', 'numbers', 'ending', 'with', '0089', '(', 'my', 'last', 'four', 'digits', ')', 'are', 'selected', 'to', 'received', 'a', '£350', 'award', '.', 'if', 'your', 'number', 'matches', 'please', 'call', '09063442151', 'to', 'claim', 'your', '£350', 'award']\n",
      "AFter tokenizer:  ['free', 'top', 'ringtone', '-sub', 'to', 'weekly', 'ringtone-get', '1st', 'week', 'free-send', 'subpoly', 'to', '81618-', '?', '3', 'per', 'week-stop', 'sms-08718727870']\n",
      "AFter tokenizer:  ['nan', 'sonathaya', 'soladha', '.', 'why', 'boss', '?']\n",
      "AFter tokenizer:  ['bring', 'tat', 'cd', 'don', 'forget']\n",
      "AFter tokenizer:  ['i', 'do', \"n't\", 'know', 'but', 'i', \"'m\", 'raping', 'dudes', 'at', 'poker']\n",
      "AFter tokenizer:  ['weightloss', '!', 'no', 'more', 'girl', 'friends', '.', 'make', 'loads', 'of', 'money', 'on', 'ebay', 'or', 'something', '.', 'and', 'give', 'thanks', 'to', 'god', '.']\n",
      "AFter tokenizer:  ['was', 'gr8', 'to', 'see', 'that', 'message', '.', 'so', 'when', 'r', 'u', 'leaving', '?', 'congrats', 'dear', '.', 'what', 'school', 'and', 'wat', 'r', 'ur', 'plans', '.']\n",
      "AFter tokenizer:  ['ü', 'eatin', 'later', 'but', 'i', \"'m\", 'eatin', 'wif', 'my', 'frens', 'now', 'lei', '...', 'ü', 'going', 'home', 'first', '?']\n",
      "AFter tokenizer:  ['finish', 'already', '...', 'yar', 'they', 'keep', 'saying', 'i', 'mushy', '...', 'i', 'so', 'embarrassed', 'ok', '...']\n",
      "AFter tokenizer:  ['sorry', 'man', ',', 'my', 'stash', 'ran', 'dry', 'last', 'night', 'and', 'i', 'ca', \"n't\", 'pick', 'up', 'more', 'until', 'sunday']\n",
      "AFter tokenizer:  ['hai', 'priya', 'are', 'you', 'right', '.', 'what', 'doctor', 'said', 'pa.', 'where', 'are', 'you', '.']\n",
      "AFter tokenizer:  ['free', 'msg', '.', 'sorry', ',', 'a', 'service', 'you', 'ordered', 'from', '81303', 'could', 'not', 'be', 'delivered', 'as', 'you', 'do', 'not', 'have', 'sufficient', 'credit', '.', 'please', 'top', 'up', 'to', 'receive', 'the', 'service', '.']\n",
      "AFter tokenizer:  ['please', 'ask', 'mummy', 'to', 'call', 'father']\n",
      "AFter tokenizer:  ['can', 'come', 'my', 'room', 'but', 'can', 'not', 'come', 'my', 'house', 'cos', 'my', 'house', 'still', 'messy', '...', 'haha', '...']\n",
      "AFter tokenizer:  ['i', 'have', 'lost', '10', 'kilos', 'as', 'of', 'today', '!']\n",
      "AFter tokenizer:  ['just', 'taste', 'fish', 'curry', ':', '-p']\n",
      "AFter tokenizer:  ['what', 'can', 'i', 'do', '?', 'might', 'accidant', 'tookplace', 'between', 'somewhere', 'ghodbandar', 'rd', '.', 'traffic', 'moves', 'slovely', '.', 'so', 'plz', 'slip', '&', 'amp', ';', 'do', \"n't\", 'worry', '.']\n",
      "AFter tokenizer:  ['yun', 'ah.now', 'ü', 'wkg', 'where', '?', 'btw', 'if', 'ü', 'go', 'nus', 'sc', '.', 'ü', 'wana', 'specialise', 'in', 'wad', '?']\n",
      "AFter tokenizer:  ['yes', '!', 'i', 'am', 'a', 'one', 'woman', 'man', '!', 'please', 'tell', 'me', 'your', 'likes', 'and', 'dislikes', 'in', 'bed', '...']\n",
      "AFter tokenizer:  ['was', 'doing', 'my', 'test', 'earlier', '.', 'i', 'appreciate', 'you', '.', 'will', 'call', 'you', 'tomorrow', '.']\n",
      "AFter tokenizer:  ['how', \"'s\", 'my', 'loverboy', 'doing', '?', 'what', 'does', 'he', 'do', 'that', 'keeps', 'him', 'from', 'coming', 'to', 'his', 'queen', ',', 'hmmm', '?', 'does', \"n't\", 'he', 'ache', 'to', 'speak', 'to', 'me', '?', 'miss', 'me', 'desparately', '?']\n",
      "AFter tokenizer:  ['u', 'meet', 'other', 'fren', 'dun', 'wan', 'meet', 'me', 'ah', '...', 'muz', 'b', 'a', 'guy', 'rite', '...']\n",
      "AFter tokenizer:  ['(', 'no', 'promises', 'on', 'when', 'though', ',', 'have', \"n't\", 'even', 'gotten', 'dinner', 'yet', ')']\n",
      "AFter tokenizer:  ['i', 'got', 'your', 'back', '!', 'do', 'you', 'have', 'any', 'dislikes', 'in', 'bed', '?']\n",
      "AFter tokenizer:  ['o', 'turns', 'out', 'i', 'had', 'stereo', 'love', 'on', 'mi', 'phone', 'under', 'the', 'unknown', 'album', '.']\n",
      "AFter tokenizer:  ['hard', 'live', '121', 'chat', 'just', '60p/min', '.', 'choose', 'your', 'girl', 'and', 'connect', 'live', '.', 'call', '09094646899', 'now', '!', 'cheap', 'chat', 'uk', \"'s\", 'biggest', 'live', 'service', '.', 'vu', 'bcm1896wc1n3xx']\n",
      "AFter tokenizer:  ['yeah', 'i', 'do', \"n't\", 'see', 'why', 'not']\n",
      "AFter tokenizer:  ['asking', 'do', 'u', 'knw', 'them', 'or', 'nt', '?', 'may', 'be', 'ur', 'frnds', 'or', 'classmates', '?']\n",
      "AFter tokenizer:  ['sorry', 'about', 'earlier', '.', 'putting', 'out', 'fires.are', 'you', 'around', 'to', 'talk', 'after', '9', '?', 'or', 'do', 'you', 'actually', 'have', 'a', 'life', ',', 'lol', '!']\n",
      "AFter tokenizer:  ['wow', '!', 'the', 'boys', 'r', 'back', '.', 'take', 'that', '2007', 'uk', 'tour', '.', 'win', 'vip', 'tickets', '&', 'pre-book', 'with', 'vip', 'club', '.', 'txt', 'club', 'to', '81303.', 'trackmarque', 'ltd', 'info', '@', 'vipclub4u', '.']\n",
      "AFter tokenizer:  ['as', 'in', 'missionary', 'hook', 'up', ',', 'doggy', 'hook', 'up', ',', 'standing', '...', '|']\n",
      "AFter tokenizer:  ['then', 'u', 'better', 'go', 'sleep', '..', 'dun', 'disturb', 'u', 'liao', '..', 'u', 'wake', 'up', 'then', 'msg', 'me', 'lor', '..']\n",
      "AFter tokenizer:  ['am', 'watching', 'house', '–', 'very', 'entertaining', '–', 'am', 'getting', 'the', 'whole', 'hugh', 'laurie', 'thing', '–', 'even', 'with', 'the', 'stick', '–', 'indeed', 'especially', 'with', 'the', 'stick', '.']\n",
      "AFter tokenizer:  ['thought', 'praps', 'you', 'meant', 'another', 'one', '.', 'goodo', '!', 'i', \"'ll\", 'look', 'tomorrow']\n",
      "AFter tokenizer:  ['hi', 'jon', ',', 'pete', 'here', ',', 'ive', 'bin', '2', 'spain', 'recently', '&', 'hav', 'sum', 'dinero', 'left', ',', 'bill', 'said', 'u', 'or', 'ur', '\\x91rents', 'mayb', 'interested', 'in', 'it', ',', 'i', 'hav', '12,000pes', ',', 'so', 'around', '£48', ',', 'tb', ',', 'james', '.']\n",
      "AFter tokenizer:  ['there', 'bold', '2', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'is', 'that', 'yours']\n",
      "AFter tokenizer:  ['you', 'know', 'there', 'is', '.', 'i', 'shall', 'speak', 'to', 'you', 'in', '&', 'lt', ';', '#', '&', 'gt', ';', 'minutes', 'then']\n",
      "AFter tokenizer:  ['alrite', 'hunny', '!', 'wot', 'u', 'up', '2', '2nite', '?', 'didnt', 'end', 'up', 'goin', 'down', 'town', 'jus', 'da', 'pub', 'instead', '!', 'jus', 'chillin', 'at', 'da', 'mo', 'in', 'me', 'bedroom', '!', 'love', 'jen', 'xxx', '.']\n",
      "AFter tokenizer:  ['i', 'went', 'to', 'project', 'centre']\n",
      "AFter tokenizer:  ['as', 'per', 'your', 'request', \"'maangalyam\", '(', 'alaipayuthe', ')', \"'\", 'has', 'been', 'set', 'as', 'your', 'callertune', 'for', 'all', 'callers', '.', 'press', '*', '9', 'to', 'copy', 'your', 'friends', 'callertune']\n",
      "AFter tokenizer:  ['lol', 'yeah', 'at', 'this', 'point', 'i', 'guess', 'not']\n",
      "AFter tokenizer:  ['doing', 'project', 'w', 'frens', 'lor', '.']\n",
      "AFter tokenizer:  ['lol', '.', 'well', 'quality', 'aint', 'bad', 'at', 'all', 'so', 'i', 'aint', 'complaining']\n",
      "AFter tokenizer:  ['k', ',', 'can', 'that', 'happen', 'tonight', '?']\n",
      "AFter tokenizer:  ['hi', ',', 'this', 'is', 'mandy', 'sullivan', 'calling', 'from', 'hotmix', 'fm', '...', 'you', 'are', 'chosen', 'to', 'receive', '£5000.00', 'in', 'our', 'easter', 'prize', 'draw', '.....', 'please', 'telephone', '09041940223', 'to', 'claim', 'before', '29/03/05', 'or', 'your', 'prize', 'will', 'be', 'transferred', 'to', 'someone', 'else', '....']\n",
      "AFter tokenizer:  ['i', 'think', 'we', \"'re\", 'going', 'to', 'finn', \"'s\", 'now', ',', 'come']\n",
      "AFter tokenizer:  ['why', 'tired', 'what', 'special', 'there', 'you', 'had']\n",
      "AFter tokenizer:  ['i', 'will', 'come', 'tomorrow', 'di']\n",
      "AFter tokenizer:  ['k', 'go', 'and', 'sleep', 'well', '.', 'take', 'rest', ':', '-', ')', '.']\n",
      "AFter tokenizer:  ['u', 'guys', 'never', 'invite', 'me', 'anywhere', ':', '(']\n",
      "AFter tokenizer:  ['ur', 'going', '2', 'bahamas', '!', 'callfreefone', '08081560665', 'and', 'speak', 'to', 'a', 'live', 'operator', 'to', 'claim', 'either', 'bahamas', 'cruise', 'of£2000', 'cash', '18+only', '.', 'to', 'opt', 'out', 'txt', 'x', 'to', '07786200117']\n",
      "AFter tokenizer:  ['i', 'can', 'do', 'that', '!', 'i', 'want', 'to', 'please', 'you', 'both', 'inside', 'and', 'outside', 'the', 'bedroom', '...']\n",
      "AFter tokenizer:  ['ey', '!', 'calm', 'downon', 'theacusations', '..', 'itxt', 'u', 'cos', 'iwana', 'know', 'wotu', 'r', 'doin', 'at', 'thew/end', '...', 'haventcn', 'u', 'in', 'ages', '..', 'ring', 'me', 'if', 'ur', 'up4', 'nething', 'sat.love', 'j', 'xxx', '.']\n",
      "AFter tokenizer:  ['i', 'love', 'to', 'wine', 'and', 'dine', 'my', 'lady', '!']\n",
      "AFter tokenizer:  ['someone', 'has', 'conacted', 'our', 'dating', 'service', 'and', 'entered', 'your', 'phone', 'because', 'they', 'fancy', 'you', '!', 'to', 'find', 'out', 'who', 'it', 'is', 'call', 'from', 'landline', '09111030116.', 'pobox12n146tf15']\n",
      "AFter tokenizer:  ['i\\x92m', 'cool', 'ta', 'luv', 'but', 'v.tired', '2', 'cause', 'i', 'have', 'been', 'doin', 'loads', 'of', 'planning', 'all', 'wk', ',', 'we', 'have', 'got', 'our', 'social', 'services', 'inspection', 'at', 'the', 'nursery', '!', 'take', 'care', '&', 'spk', 'sn', 'x', '.']\n",
      "AFter tokenizer:  ['i', 'don', 'know', 'account', 'details', '..', 'i', 'will', 'ask', 'my', 'mom', 'and', 'send', 'you.my', 'mom', 'is', 'out', 'of', 'reach', 'now', '.']\n",
      "AFter tokenizer:  ['i', 'think', 'u', 'have', 'the', 'wrong', 'number', '.']\n",
      "AFter tokenizer:  ['feel', 'yourself', 'that', 'you', 'are', 'always', 'happy', '..', 'slowly', 'it', 'becomes', 'your', 'habit', '&', 'amp', ';', 'finally', 'it', 'becomes', 'part', 'of', 'your', 'life', '..', 'follow', 'it', '..', 'happy', 'morning', '&', 'amp', ';', 'have', 'a', 'happy', 'day', ':', ')']\n",
      "AFter tokenizer:  ['do', 'not', 'b', 'late', 'love', 'mum']\n",
      "AFter tokenizer:  ['got', 'it', '..', 'mail', 'panren', 'paru', '..']\n",
      "AFter tokenizer:  ['*', 'was', 'thinking', 'about', 'chuckin', 'ur', 'red', 'green', 'n', 'black', 'trainners', '2', 'save', 'carryin', 'them', 'bac', 'on', 'train']\n",
      "AFter tokenizer:  ['give', 'one', 'miss', 'from', 'that', 'number', 'please']\n",
      "AFter tokenizer:  ['jus', 'came', 'back', 'fr', 'lunch', 'wif', 'my', 'sis', 'only', '.', 'u', 'leh', '?']\n",
      "AFter tokenizer:  ['how', 'is', 'your', 'schedule', 'next', 'week', '?', 'i', 'am', 'out', 'of', 'town', 'this', 'weekend', '.']\n",
      "AFter tokenizer:  ['really', 'good', ':', ')', 'dhanush', 'rocks', 'once', 'again', ':', ')']\n",
      "AFter tokenizer:  ['lmao', 'ok', 'i', 'wont', 'be', 'needing', 'u', 'to', 'do', 'my', 'hair', 'anymore', '.']\n",
      "AFter tokenizer:  ['miss', 'ya', ',', 'need', 'ya', ',', 'want', 'ya', ',', 'love', 'ya', '.']\n",
      "AFter tokenizer:  ['sorry', 'i', \"'m\", 'not', 'free', '...']\n",
      "AFter tokenizer:  ['do', 'u', 'ever', 'get', 'a', 'song', 'stuck', 'in', 'your', 'head', 'for', 'no', 'reason', 'and', 'it', 'wo', \"n't\", 'go', 'away', 'til', 'u', 'listen', 'to', 'it', 'like', '5', 'times', '?']\n",
      "AFter tokenizer:  ['nt', 'yet', 'chikku', '..', 'simple', 'habba', '..', 'hw', 'abt', 'u', '?']\n",
      "AFter tokenizer:  ['got', 'ur', 'mail', 'dileep.thank', 'you', 'so', 'muchand', 'look', 'forward', 'to', 'lots', 'of', 'support', '...', 'very', 'less', 'contacts', 'here', ',', 'remember', 'one', 'venugopal', 'you', 'mentioned.tomorrow', 'if', 'not', 'late', ',', 'i', 'shall', 'try', 'to', 'come', 'up', 'till', 'there.goodnight', 'dear', '.']\n",
      "AFter tokenizer:  ['sometimes', 'heart', 'remembrs', 'someone', 'very', 'much', '...', 'forgets', 'someone', 'soon', '...', 'bcoz', 'heart', 'will', 'not', 'like', 'everyone', '.', 'but', 'liked', 'ones', 'will', 'be', 'remembered', 'everytime', '...', 'bslvyl']\n",
      "AFter tokenizer:  ['joy', \"'s\", 'father', 'is', 'john', '.', 'then', 'john', 'is', 'the', 'name', 'of', 'joy', \"'s\", 'father', '.', 'mandan']\n",
      "AFter tokenizer:  ['hi', '07734396839', 'ibh', 'customer', 'loyalty', 'offer', ':', 'the', 'new', 'nokia6600', 'mobile', 'from', 'only', '£10', 'at', 'txtauction', '!', 'txt', 'word', ':', 'start', 'to', 'no:81151', '&', 'get', 'yours', 'now', '!', '4t', '&']\n",
      "AFter tokenizer:  ['hi', 'this', 'is', 'yijue', '...', 'it', \"'s\", 'regarding', 'the', '3230', 'textbook', 'it', \"'s\", 'intro', 'to', 'algorithms', 'second', 'edition', '...', 'i', \"'m\", 'selling', 'it', 'for', '$', '50', '...']\n",
      "AFter tokenizer:  ['sms', 'auction', 'you', 'have', 'won', 'a', 'nokia', '7250i', '.', 'this', 'is', 'what', 'you', 'get', 'when', 'you', 'win', 'our', 'free', 'auction', '.', 'to', 'take', 'part', 'send', 'nokia', 'to', '86021', 'now', '.', 'hg/suite342/2lands', 'row/w1jhl', '16+']\n",
      "AFter tokenizer:  ['k', ',', 'want', 'us', 'to', 'come', 'by', 'now', '?']\n",
      "AFter tokenizer:  ['how', '.', 'its', 'a', 'little', 'difficult', 'but', 'its', 'a', 'simple', 'way', 'to', 'enter', 'this', 'place']\n",
      "AFter tokenizer:  ['ha', '...', 'both', 'of', 'us', 'doing', 'e', 'same', 'thing', '.', 'but', 'i', 'got', 'tv', '2', 'watch', '.', 'u', 'can', 'thk', 'of', 'where', '2', 'go', 'tonight', 'or', 'u', 'already', 'haf', 'smth', 'in', 'mind', '...']\n",
      "AFter tokenizer:  ['dont', 'show', 'yourself', '.', 'how', 'far', '.', 'put', 'new', 'pictures', 'up', 'on', 'facebook', '.']\n",
      "AFter tokenizer:  ['watching', 'tv', 'now', '.', 'i', 'got', 'new', 'job', ':', ')']\n",
      "AFter tokenizer:  ['good', 'afternoon', 'sexy', 'buns', '!', 'how', 'goes', 'the', 'job', 'search', '?', 'i', 'wake', 'and', 'you', 'are', 'my', 'first', 'thought', 'as', 'always', ',', 'my', 'love', '.', 'i', 'wish', 'your', 'fine', 'and', 'happy', 'and', 'know', 'i', 'adore', 'you', '!']\n",
      "AFter tokenizer:  ['i', \"'m\", 'not', 'coming', 'over', ',', 'do', 'whatever', 'you', 'want']\n",
      "AFter tokenizer:  ['its', 'ok', 'chikku', ',', 'and', 'its', 'my', '1', 'of', 'favourite', 'song', '..', ':', '-', ')']\n",
      "AFter tokenizer:  ['did', 'u', 'see', 'what', 'i', 'posted', 'on', 'your', 'facebook', '?']\n",
      "AFter tokenizer:  ['call', 'freephone', '0800', '542', '0578', 'now', '!']\n",
      "AFter tokenizer:  ['buy', 'space', 'invaders', '4', 'a', 'chance', '2', 'win', 'orig', 'arcade', 'game', 'console', '.', 'press', '0', 'for', 'games', 'arcade', '(', 'std', 'wap', 'charge', ')', 'see', 'o2.co.uk/games', '4', 'terms', '+', 'settings', '.', 'no', 'purchase']\n",
      "AFter tokenizer:  ['big', 'brother', 'alert', '!', 'the', 'computer', 'has', 'selected', 'u', 'for', '10k', 'cash', 'or', '#', '150', 'voucher', '.', 'call', '09064018838.', 'ntt', 'po', 'box', 'cro1327', '18+', 'bt', 'landline', 'cost', '150ppm', 'mobiles', 'vary']\n",
      "AFter tokenizer:  [';', '-', '(', 'oh', 'well', ',', 'c', 'u', 'later']\n",
      "AFter tokenizer:  ['my', 'uncles', 'in', 'atlanta', '.', 'wish', 'you', 'guys', 'a', 'great', 'semester', '.']\n",
      "AFter tokenizer:  ['no', 'dear', 'i', 'do', 'have', 'free', 'messages', 'without', 'any', 'recharge', '.', 'hi', 'hi', 'hi']\n",
      "AFter tokenizer:  ['i', 'dun', 'believe', 'u.', 'i', 'thk', 'u', 'told', 'him', '.']\n",
      "AFter tokenizer:  ['do', 'you', 'know', 'why', 'god', 'created', 'gap', 'between', 'your', 'fingers', '..', '?', 'so', 'that', ',', 'one', 'who', 'is', 'made', 'for', 'you', 'comes', '&', 'amp', ';', 'fills', 'those', 'gaps', 'by', 'holding', 'your', 'hand', 'with', 'love', '..', '!']\n",
      "AFter tokenizer:  ['yes', ':', ')', 'sura', 'in', 'sun', 'tv', '.', ':', ')', 'lol', '.']\n",
      "AFter tokenizer:  ['arun', 'can', 'u', 'transfr', 'me', 'd', 'amt']\n",
      "AFter tokenizer:  ['takin', 'a', 'shower', 'now', 'but', 'yeah', 'i', \"'ll\", 'leave', 'when', 'i', \"'m\", 'done']\n",
      "AFter tokenizer:  ['am', 'not', 'working', 'but', 'am', 'up', 'to', 'eyes', 'in', 'philosophy', 'so', 'will', 'text', 'u', 'later', 'when', 'a', 'bit', 'more', 'free', 'for', 'chat', '...']\n",
      "AFter tokenizer:  ['u', 'haven\\x92t', 'lost', 'me', 'ill', 'always', 'b', 'here', '4u.i', 'didn\\x92t', 'intend', '2', 'hurt', 'u', 'but', 'i', 'never', 'knew', 'how', 'u', 'felt', 'about', 'me', 'when', 'iwas+marine', '&', 'that\\x92s', 'what', 'itried2tell', 'urmom.i', 'careabout', 'u']\n",
      "AFter tokenizer:  ['win', ':', 'we', 'have', 'a', 'winner', '!', 'mr.', 't.', 'foley', 'won', 'an', 'ipod', '!', 'more', 'exciting', 'prizes', 'soon', ',', 'so', 'keep', 'an', 'eye', 'on', 'ur', 'mobile', 'or', 'visit', 'www.win-82050.co.uk']\n",
      "AFter tokenizer:  ['you', 'bad', 'girl', '.', 'i', 'can', 'still', 'remember', 'them']\n",
      "AFter tokenizer:  ['how', 'much', 'i', 'gave', 'to', 'you', '.', 'morning', '.']\n",
      "AFter tokenizer:  ['i', 'hope', 'your', 'alright', 'babe', '?', 'i', 'worry', 'that', 'you', 'might', 'have', 'felt', 'a', 'bit', 'desparate', 'when', 'you', 'learned', 'the', 'job', 'was', 'a', 'fake', '?', 'i', 'am', 'here', 'waiting', 'when', 'you', 'come', 'back', ',', 'my', 'love']\n",
      "AFter tokenizer:  ['hey', ',', 'can', 'you', 'tell', 'me', 'blake', \"'s\", 'address', '?', 'carlos', 'wanted', 'me', 'to', 'meet', 'him', 'there', 'but', 'i', 'got', 'lost', 'and', 'he', \"'s\", 'not', 'answering', 'his', 'phone']\n",
      "AFter tokenizer:  ['can', 'i', 'get', 'your', 'opinion', 'on', 'something', 'first', '?']\n",
      "AFter tokenizer:  ['that', 'one', 'week', 'leave', 'i', 'put', 'know', 'that', 'time', '.', 'why', '.']\n",
      "AFter tokenizer:  ['if', 'we', 'hit', 'it', 'off', ',', 'you', 'can', 'move', 'in', 'with', 'me', ':', ')']\n",
      "AFter tokenizer:  ['excellent', '.', 'i', 'spent', '&', 'lt', ';', '#', '&', 'gt', ';', 'years', 'in', 'the', 'air', 'force', '.', 'iraq', 'and', 'afghanistan', '.', 'i', 'am', 'stable', 'and', 'honest', '.', 'do', 'you', 'like', 'traveling', '?']\n",
      "AFter tokenizer:  ['i', 'wan', 'na', 'watch', 'that', 'movie']\n",
      "AFter tokenizer:  ['ok', 'lor', 'thanx', '...', 'ü', 'in', 'school', '?']\n",
      "AFter tokenizer:  ['i', \"'m\", 'in', 'class', '.', 'did', 'you', 'get', 'my', 'text', '.']\n",
      "AFter tokenizer:  ['the', 'bus', 'leaves', 'at', '&', 'lt', ';', '#', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['god', 'bless.get', 'good', 'sleep', 'my', 'dear', '...', 'i', 'will', 'pray', '!']\n",
      "AFter tokenizer:  ['todays', 'voda', 'numbers', 'ending', '1225', 'are', 'selected', 'to', 'receive', 'a', '£50award', '.', 'if', 'you', 'have', 'a', 'match', 'please', 'call', '08712300220', 'quoting', 'claim', 'code', '3100', 'standard', 'rates', 'app']\n",
      "AFter tokenizer:  ['do', 'have', 'a', 'nice', 'day', 'today', '.', 'i', 'love', 'you', 'so', 'dearly', '.']\n",
      "AFter tokenizer:  ['aiyo', 'a', 'bit', 'pai', 'seh', 'ü', 'noe', '...', 'scared', 'he', 'dun', 'rem', 'who', 'i', 'am', 'then', 'die', '...', 'hee', '...', 'but', 'he', 'become', 'better', 'lookin', 'oredi', 'leh', '...']\n",
      "AFter tokenizer:  ['aight', ',', 'i', \"'ll\", 'ask', 'a', 'few', 'of', 'my', 'roommates']\n",
      "AFter tokenizer:  ['now', ',', 'whats', 'your', 'house', '#', 'again', '?', 'and', 'do', 'you', 'have', 'any', 'beer', 'there', '?']\n",
      "AFter tokenizer:  ['do', 'ü', 'all', 'wan', '2', 'meet', 'up', 'n', 'combine', 'all', 'the', 'parts', '?', 'how', \"'s\", 'da', 'rest', 'of', 'da', 'project', 'going', '?']\n",
      "AFter tokenizer:  ['getting', 'tickets', '4', 'walsall', 'tue', '6', 'th', 'march', '.', 'my', 'mate', 'is', 'getting', 'me', 'them', 'on', 'sat', '.', 'ill', 'pay', 'my', 'treat', '.', 'want', '2', 'go', '.', 'txt', 'bak', '.terry']\n",
      "AFter tokenizer:  ['yes', 'we', 'are', 'chatting', 'too', '.']\n",
      "AFter tokenizer:  ['hi', 'its', 'jess', 'i', 'dont', 'know', 'if', 'you', 'are', 'at', 'work', 'but', 'call', 'me', 'when', 'u', 'can', 'im', 'at', 'home', 'all', 'eve', '.', 'xxx']\n",
      "AFter tokenizer:  ['sian', '...', 'aft', 'meeting', 'supervisor', 'got', 'work', '2', 'do', 'liao', '...', 'u', 'working', 'now', '?']\n",
      "AFter tokenizer:  ['are', 'you', 'going', 'to', 'write', 'ccna', 'exam', 'this', 'week', '?', '?']\n",
      "AFter tokenizer:  ['well', 'i', 'will', 'watch', 'shrek', 'in', '3d', '!', '!', 'b', ')']\n",
      "AFter tokenizer:  ['am', 'i', 'that', 'much', 'dirty', 'fellow', '?']\n",
      "AFter tokenizer:  ['dunno', 'dat', \"'s\", 'wat', 'he', 'told', 'me', '.', 'ok', 'lor', '...']\n",
      "AFter tokenizer:  ['i', \"'ll\", 'probably', 'be', 'by', 'tomorrow', '(', 'or', 'even', 'later', 'tonight', 'if', 'something', \"'s\", 'going', 'on', ')']\n",
      "AFter tokenizer:  ['i', 'could', \"n't\", 'say', 'no', 'as', 'he', 'is', 'a', 'dying', 'man', 'and', 'i', 'feel', 'sad', 'for', 'him', 'so', 'i', 'will', 'go', 'and', 'i', 'just', 'wanted', 'you', 'to', 'know', 'i', 'would', 'probably', 'be', 'gone', 'late', 'into', 'your', 'night']\n",
      "AFter tokenizer:  ['if', 'you', \"'re\", 'thinking', 'of', 'lifting', 'me', 'one', 'then', 'no', '.']\n",
      "AFter tokenizer:  ['same', 'as', 'u', '...', 'dun', 'wan', '...', 'y', 'u', 'dun', 'like', 'me', 'already', 'ah', '...', 'wat', 'u', 'doing', 'now', '?', 'still', 'eating', '?']\n",
      "AFter tokenizer:  ['sent', 'me', 'ur', 'email', 'id', 'soon']\n",
      "AFter tokenizer:  ['dude', '.', 'what', \"'s\", 'up', '.', 'how', 'teresa', '.', 'hope', 'you', 'have', 'been', 'okay', '.', 'when', 'i', 'didnt', 'hear', 'from', 'these', 'people', ',', 'i', 'called', 'them', 'and', 'they', 'had', 'received', 'the', 'package', 'since', 'dec', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'just', 'thot', \"you'ld\", 'like', 'to', 'know', '.', 'do', 'have', 'a', 'fantastic', 'year', 'and', 'all', 'the', 'best', 'with', 'your', 'reading', '.', 'plus', 'if', 'you', 'can', 'really', 'really', 'bam', 'first', 'aid', 'for', 'usmle', ',', 'then', 'your', 'work', 'is', 'done', '.']\n",
      "AFter tokenizer:  ['hey', 'gorgeous', 'man', '.', 'my', 'work', 'mobile', 'number', 'is', '.', 'have', 'a', 'good', 'one', 'babe', '.', 'squishy', 'mwahs', '.']\n",
      "AFter tokenizer:  ['hottest', 'pics', 'straight', 'to', 'your', 'phone', '!', '!', 'see', 'me', 'getting', 'wet', 'and', 'wanting', ',', 'just', 'for', 'you', 'xx', 'text', 'pics', 'to', '89555', 'now', '!', 'txt', 'costs', '150p', 'textoperator', 'g696ga', '18', 'xxx']\n",
      "AFter tokenizer:  ['that', \"'s\", 'the', 'way', 'you', 'should', 'stay', 'oh', '.']\n",
      "AFter tokenizer:  ['hello-', 'thanx', 'for', 'taking', 'that', 'call', '.', 'i', 'got', 'a', 'job', '!', 'starts', 'on', 'monday', '!']\n",
      "AFter tokenizer:  ['what', 'time', 'is', 'ur', 'flight', 'tmr', '?']\n",
      "AFter tokenizer:  ['when', 'should', 'i', 'come', 'over', '?']\n",
      "AFter tokenizer:  ['i', 'have', 'a', 'rather', 'prominent', 'bite', 'mark', 'on', 'my', 'right', 'cheek']\n",
      "AFter tokenizer:  ['*', 'will', 'be', 'september', 'by', 'then', '!']\n",
      "AFter tokenizer:  ['are', 'you', 'wet', 'right', 'now', '?']\n",
      "AFter tokenizer:  ['and', 'how', \"'s\", 'your', 'husband', '.']\n",
      "AFter tokenizer:  ['hack', 'chat', '.', 'get', 'backdoor', 'entry', 'into', '121', 'chat', 'rooms', 'at', 'a', 'fraction', 'of', 'the', 'cost', '.', 'reply', 'neo69', 'or', 'call', '09050280520', ',', 'to', 'subscribe', '25p', 'pm', '.', 'dps', ',', 'bcm', 'box', '8027', 'ldn', ',', 'wc1n3xx']\n",
      "AFter tokenizer:  ['are', 'we', 'doing', 'the', 'norm', 'tomorrow', '?', 'i', 'finish', 'just', 'a', '4.15', 'cos', 'of', 'st', 'tests', '.', 'need', 'to', 'sort', 'library', 'stuff', 'out', 'at', 'some', 'point', 'tomo', '-', 'got', 'letter', 'from', 'today', '-', 'access', 'til', 'end', 'march', 'so', 'i', 'better', 'get', 'move', 'on', '!']\n",
      "AFter tokenizer:  ['yeah', '.', 'i', 'got', 'a', 'list', 'with', 'only', 'u', 'and', 'joanna', 'if', 'i', \"'m\", 'feeling', 'really', 'anti', 'social']\n",
      "AFter tokenizer:  ['i', 'am', 'in', 'your', 'office', 'na', '.']\n",
      "AFter tokenizer:  ['are', 'you', 'comingdown', 'later', '?']\n",
      "AFter tokenizer:  ['super', 'da', ':', ')', 'good', 'replacement', 'for', 'murali']\n",
      "AFter tokenizer:  ['da', 'is', 'good', 'good', 'player.why', 'he', 'is', 'unsold', '.']\n",
      "AFter tokenizer:  ['hi', '.', '||', 'do', 'u', 'want', '|', 'to', 'join', 'me', 'with', 'sts', 'later', '?', '||', 'meeting', 'them', 'at', 'five', '.', '||', 'call', 'u', 'after', 'class', '.']\n",
      "AFter tokenizer:  ['its', 'on', 'in', 'engalnd', '!', 'but', 'telly', 'has', 'decided', 'it', 'wo', \"n't\", 'let', 'me', 'watch', 'it', 'and', 'mia', 'and', 'elliot', 'were', 'kissing', '!', 'damn', 'it', '!']\n",
      "AFter tokenizer:  ['free', 'nokia', 'or', 'motorola', 'with', 'upto', '12mths', '1/2price', 'linerental', ',', '500', 'free', 'x-net', 'mins', '&', '100txt/mth', 'free', \"b'tooth\", '*', '.', 'call', 'mobileupd8', 'on', '08001950382', 'or', 'call', '2optout/d3wv']\n",
      "AFter tokenizer:  ['i', 'dont', 'want', 'to', 'hear', 'philosophy', '.', 'just', 'say', 'what', 'happen']\n",
      "AFter tokenizer:  ['you', 'got', 'job', 'in', 'wipro', ':', ')', 'you', 'will', 'get', 'every', 'thing', 'in', 'life', 'in', '2', 'or', '3', 'years', '.']\n",
      "AFter tokenizer:  ['then', 'cant', 'get', 'da', 'laptop', '?', 'my', 'matric', 'card', 'wif', 'ü', 'lei', '...']\n",
      "AFter tokenizer:  ['dunno', 'da', 'next', 'show', 'aft', '6', 'is', '850.', 'toa', 'payoh', 'got', '650', '.']\n",
      "AFter tokenizer:  ['this', 'is', 'the', '2nd', 'time', 'we', 'have', 'tried', '2', 'contact', 'u.', 'u', 'have', 'won', 'the', '750', 'pound', 'prize', '.', '2', 'claim', 'is', 'easy', ',', 'call', '08718726970', 'now', '!', 'only', '10p', 'per', 'min', '.', 'bt-national-rate']\n",
      "AFter tokenizer:  ['i', 'just', 'made', 'some', 'payments', 'so', 'dont', 'have', 'that', 'much', '.', 'sorry', '.', 'would', 'you', 'want', 'it', 'fedex', 'or', 'the', 'other', 'way', '.']\n",
      "AFter tokenizer:  ['they', \"did't\", 'play', 'one', 'day', 'last', 'year', 'know', 'even', 'though', 'they', 'have', 'very', 'good', 'team', '..', 'like', 'india', '.']\n",
      "AFter tokenizer:  ['k.', ':', ')', 'you', 'are', 'the', 'only', 'girl', 'waiting', 'in', 'reception', 'ah', '?']\n",
      "AFter tokenizer:  ['say', 'this', 'slowly.', '?', 'god', ',', 'i', 'love', 'you', '&', 'amp', ';', 'i', 'need', 'you', ',', 'clean', 'my', 'heart', 'with', 'your', 'blood.send', 'this', 'to', 'ten', 'special', 'people', '&', 'amp', ';', 'u', 'c', 'miracle', 'tomorrow', ',', 'do', 'it', ',', 'pls', ',', 'pls', 'do', 'it', '...']\n",
      "AFter tokenizer:  ['i', 'hate', 'when', 'she', 'does', 'this', '.', 'she', 'turns', 'what', 'should', 'be', 'a', 'fun', 'shopping', 'trip', 'into', 'an', 'annoying', 'day', 'of', 'how', 'everything', 'would', 'look', 'in', 'her', 'house', '.']\n",
      "AFter tokenizer:  ['sir', ',', 'i', 'am', 'waiting', 'for', 'your', 'call', '.']\n",
      "AFter tokenizer:  ['what', \"'s\", 'up', '.', 'do', 'you', 'want', 'me', 'to', 'come', 'online', '?']\n",
      "AFter tokenizer:  ['it', 'could', 'work', ',', 'we', \"'ll\", 'reach', 'a', 'consensus', 'at', 'the', 'next', 'meeting']\n",
      "AFter tokenizer:  ['aiyah', 'then', 'i', 'wait', 'lor', '.', 'then', 'u', 'entertain', 'me', '.', 'hee', '...']\n",
      "AFter tokenizer:  ['the', 'last', 'thing', 'i', 'ever', 'wanted', 'to', 'do', 'was', 'hurt', 'you', '.', 'and', 'i', 'did', \"n't\", 'think', 'it', 'would', 'have', '.', 'you', \"'d\", 'laugh', ',', 'be', 'embarassed', ',', 'delete', 'the', 'tag', 'and', 'keep', 'going', '.', 'but', 'as', 'far', 'as', 'i', 'knew', ',', 'it', 'was', \"n't\", 'even', 'up', '.', 'the', 'fact', 'that', 'you', 'even', 'felt', 'like', 'i', 'would', 'do', 'it', 'to', 'hurt', 'you', 'shows', 'you', 'really', 'do', \"n't\", 'know', 'me', 'at', 'all', '.', 'it', 'was', 'messy', 'wednesday', ',', 'but', 'it', 'was', \"n't\", 'bad', '.', 'the', 'problem', 'i', 'have', 'with', 'it', 'is', 'you', 'have', 'the', 'time', 'to', 'clean', 'it', ',', 'but', 'you', 'choose', 'not', 'to', '.', 'you', 'skype', ',', 'you', 'take', 'pictures', ',', 'you', 'sleep', ',', 'you', 'want', 'to', 'go', 'out', '.', 'i', 'do', \"n't\", 'mind', 'a', 'few', 'things', 'here', 'and', 'there', ',', 'but', 'when', 'you', 'do', \"n't\", 'make', 'the', 'bed', ',', 'when', 'you', 'throw', 'laundry', 'on', 'top', 'of', 'it', ',', 'when', 'i', 'ca', \"n't\", 'have', 'a', 'friend', 'in', 'the', 'house', 'because', 'i', \"'m\", 'embarassed', 'that', 'there', \"'s\", 'underwear', 'and', 'bras', 'strewn', 'on', 'the', 'bed', ',', 'pillows', 'on', 'the', 'floor', ',', 'that', \"'s\", 'something', 'else', '.', 'you', 'used', 'to', 'be', 'good', 'about', 'at', 'least', 'making', 'the', 'bed', '.']\n",
      "AFter tokenizer:  ['i', \"'ll\", 'let', 'you', 'know', 'when', 'it', 'kicks', 'in']\n",
      "AFter tokenizer:  ['you', 'call', 'him', 'now', 'ok', 'i', 'said', 'call', 'him']\n",
      "AFter tokenizer:  ['call', 'to', 'the', 'number', 'which', 'is', 'available', 'in', 'appointment', '.', 'and', 'ask', 'to', 'connect', 'the', 'call', 'to', 'waheed', 'fathima', '.']\n",
      "AFter tokenizer:  ['or', 'ü', 'go', 'buy', 'wif', 'him', 'then', 'i', 'meet', 'ü', 'later', 'can', '?']\n",
      "AFter tokenizer:  ['mmmm', '...', 'fuck', '...', 'not', 'fair', '!', 'you', 'know', 'my', 'weaknesses', '!', '*', 'grins', '*', '*', 'pushes', 'you', 'to', 'your', 'knee', \"'s\", '*', '*', 'exposes', 'my', 'belly', 'and', 'pulls', 'your', 'head', 'to', 'it', '*', 'do', \"n't\", 'forget', '...', 'i', 'know', 'yours', 'too', '*', 'wicked', 'smile', '*']\n",
      "AFter tokenizer:  ['today', 'my', 'system', 'sh', 'get', 'ready.all', 'is', 'well', 'and', 'i', 'am', 'also', 'in', 'the', 'deep', 'well']\n",
      "AFter tokenizer:  ['mom', 'wants', 'to', 'know', 'where', 'you', 'at']\n",
      "AFter tokenizer:  ['aight', ',', 'i', \"'ll\", 'text', 'you', 'when', 'i', \"'m\", 'back']\n",
      "AFter tokenizer:  ['dont', 'know', 'supports', 'ass', 'and', 'srt', 'i', 'thnk', '.', 'i', 'think', 'ps3', 'can', 'play', 'through', 'usb', 'too']\n",
      "AFter tokenizer:  ['oh', 'ok', 'i', 'didnt', 'know', 'what', 'you', 'meant', '.', 'yep', 'i', 'am', 'baby', 'jontin']\n",
      "AFter tokenizer:  ['you', 'have', 'won', 'a', 'guaranteed', '£1000', 'cash', 'or', 'a', '£2000', 'prize.to', 'claim', 'yr', 'prize', 'call', 'our', 'customer', 'service', 'representative', 'on']\n",
      "AFter tokenizer:  ['would', 'you', 'like', 'to', 'see', 'my', 'xxx', 'pics', 'they', 'are', 'so', 'hot', 'they', 'were', 'nearly', 'banned', 'in', 'the', 'uk', '!']\n",
      "AFter tokenizer:  ['this', 'pen', 'thing', 'is', 'beyond', 'a', 'joke', '.', 'wont', 'a', 'biro', 'do', '?', 'do', \"n't\", 'do', 'a', 'masters', 'as', 'ca', \"n't\", 'do', 'this', 'ever', 'again', '!']\n",
      "AFter tokenizer:  ['i', 'am', 'at', 'a', 'party', 'with', 'alex', 'nichols']\n",
      "AFter tokenizer:  ['u', 'have', 'a', 'secret', 'admirer', 'who', 'is', 'looking', '2', 'make', 'contact', 'with', 'u-find', 'out', 'who', 'they', 'r', '*', 'reveal', 'who', 'thinks', 'ur', 'so', 'special-call', 'on', '09058094594']\n",
      "AFter tokenizer:  ['just', 'seeing', 'your', 'missed', 'call', 'my', 'dear', 'brother', '.', 'do', 'have', 'a', 'gr8', 'day', '.']\n",
      "AFter tokenizer:  ['ok', '..', 'ü', 'finishing', 'soon', '?']\n",
      "AFter tokenizer:  ['sorry', ',', 'i', 'ca', \"n't\", 'help', 'you', 'on', 'this', '.']\n",
      "AFter tokenizer:  ['come', 'to', 'me', ',', 'slave', '.', 'your', 'doing', 'it', 'again', '...', 'going', 'into', 'your', 'shell', 'and', 'unconsciously', 'avoiding', 'me', '...', 'you', 'are', 'making', 'me', 'unhappy', ':', '-', '(']\n",
      "AFter tokenizer:  ['i', 'love', 'your', 'ass', '!', 'do', 'you', 'enjoy', 'doggy', 'style', '?', ':', ')']\n",
      "AFter tokenizer:  ['i', 'think', 'asking', 'for', 'a', 'gym', 'is', 'the', 'excuse', 'for', 'lazy', 'people', '.', 'i', 'jog', '.']\n",
      "AFter tokenizer:  ['dear', '0776xxxxxxx', 'u', \"'ve\", 'been', 'invited', 'to', 'xchat', '.', 'this', 'is', 'our', 'final', 'attempt', 'to', 'contact', 'u', '!', 'txt', 'chat', 'to', '86688', '150p/msgrcvdhg/suite342/2lands/row/w1j6hl', 'ldn', '18yrs']\n",
      "AFter tokenizer:  ['urgent', '!', 'please', 'call', '09061743811', 'from', 'landline', '.', 'your', 'abta', 'complimentary', '4', '*', 'tenerife', 'holiday', 'or', '£5000', 'cash', 'await', 'collection', 'sae', 't', '&', 'cs', 'box', '326', 'cw25wx', '150ppm']\n",
      "AFter tokenizer:  ['no', '.', 'on', 'the', 'way', 'home', '.', 'so', 'if', 'not', 'for', 'the', 'long', 'dry', 'spell', 'the', 'season', 'would', 'have', 'been', 'over']\n",
      "AFter tokenizer:  ['i', 'got', 'ta', 'collect', 'da', 'car', 'at', '6', 'lei', '.']\n",
      "AFter tokenizer:  ['ok', 'but', 'knackered', '.', 'just', 'came', 'home', 'and', 'went', 'to', 'sleep', '!', 'not', 'good', 'at', 'this', 'full', 'time', 'work', 'lark', '.']\n",
      "AFter tokenizer:  ['probably', 'earlier', 'than', 'that', 'if', 'the', 'station', \"'s\", 'where', 'i', 'think', 'it', 'is']\n",
      "AFter tokenizer:  ['call', '09090900040', '&', 'listen', 'to', 'extreme', 'dirty', 'live', 'chat', 'going', 'on', 'in', 'the', 'office', 'right', 'now', 'total', 'privacy', 'no', 'one', 'knows', 'your', '[', 'sic', ']', 'listening', '60p', 'min', '24/7mp', '0870753331018+']\n",
      "AFter tokenizer:  ['freemsg', 'hey', 'u', ',', 'i', 'just', 'got', '1', 'of', 'these', 'video/pic', 'fones', ',', 'reply', 'wild', 'to', 'this', 'txt', '&', 'ill', 'send', 'u', 'my', 'pics', ',', 'hurry', 'up', 'im', 'so', 'bored', 'at', 'work', 'xxx', '(', '18', '150p/rcvd', 'stop2stop', ')']\n",
      "AFter tokenizer:  ['uh', ',', 'heads', 'up', 'we', 'do', \"n't\", 'have', 'that', 'much', 'left']\n",
      "AFter tokenizer:  ['i', 'tot', 'u', 'outside', 'cos', 'darren', 'say', 'u', 'come', 'shopping', '.', 'of', 'course', 'we', 'nice', 'wat', '.', 'we', 'jus', 'went', 'sim', 'lim', 'look', 'at', 'mp3', 'player', '.']\n",
      "AFter tokenizer:  ['aight', ',', 'sounds', 'good', '.', 'when', 'do', 'you', 'want', 'me', 'to', 'come', 'down', '?']\n",
      "AFter tokenizer:  ['wat', 'would', 'u', 'like', '4', 'ur', 'birthday', '?']\n",
      "AFter tokenizer:  ['i', 'love', 'working', 'from', 'home', ':', ')']\n",
      "AFter tokenizer:  ['and', 'miss', 'vday', 'the', 'parachute', 'and', 'double', 'coins', '?', '?', '?', 'u', 'must', 'not', 'know', 'me', 'very', 'well', '...']\n",
      "AFter tokenizer:  ['my', 'sister', 'got', 'placed', 'in', 'birla', 'soft', 'da', ':', '-', ')']\n",
      "AFter tokenizer:  ['free', 'entry', 'in', '2', 'a', 'weekly', 'comp', 'for', 'a', 'chance', 'to', 'win', 'an', 'ipod', '.', 'txt', 'pod', 'to', '80182', 'to', 'get', 'entry', '(', 'std', 'txt', 'rate', ')', 't', '&', 'c', \"'s\", 'apply', '08452810073', 'for', 'details', '18+']\n",
      "AFter tokenizer:  ['wah', '...', 'okie', 'okie', '...', 'muz', 'make', 'use', 'of', 'e', 'unlimited', '...', 'haha', '...']\n",
      "AFter tokenizer:  ['there', \"'re\", 'some', 'people', 'by', 'mu', ',', 'i', \"'m\", 'at', 'the', 'table', 'by', 'lambda']\n",
      "AFter tokenizer:  ['and', 'stop', 'being', 'an', 'old', 'man', '.', 'you', 'get', 'to', 'build', 'snowman', 'snow', 'angels', 'and', 'snowball', 'fights', '.']\n",
      "AFter tokenizer:  ['ello', 'babe', 'u', 'ok', '?']\n",
      "AFter tokenizer:  ['hello', 'beautiful', 'r', 'u', 'ok', '?', 'i', \"'ve\", 'kinda', 'ad', 'a', 'row', 'wiv', 'and', 'he', 'walked', 'out', 'the', 'pub', '?', '?', 'i', 'wanted', 'a', 'night', 'wiv', 'u', 'miss', 'u']\n",
      "AFter tokenizer:  ['then', 'u', 'going', 'ikea', 'str', 'aft', 'dat', '?']\n",
      "AFter tokenizer:  ['becoz', 'its', '&', 'lt', ';', '#', '&', 'gt', ';', 'jan', 'whn', 'al', 'the', 'post', 'ofice', 'is', 'in', 'holiday', 'so', 'she', 'cn', 'go', 'fr', 'the', 'post', 'ofice', '...', 'got', 'it', 'duffer']\n",
      "AFter tokenizer:  ['lol', 'grr', 'my', 'mom', 'is', 'taking', 'forever', 'with', 'my', 'prescription', '.', 'pharmacy', 'is', 'like', '2', 'minutes', 'away', '.', 'ugh', '.']\n",
      "AFter tokenizer:  ['for', 'real', 'tho', 'this', 'sucks', '.', 'i', 'ca', \"n't\", 'even', 'cook', 'my', 'whole', 'electricity', 'is', 'out', '.', 'and', 'i', \"'m\", 'hungry', '.']\n",
      "AFter tokenizer:  ['you', 'want', 'to', 'go', '?']\n",
      "AFter tokenizer:  ['new', 'textbuddy', 'chat', '2', 'horny', 'guys', 'in', 'ur', 'area', '4', 'just', '25p', 'free', '2', 'receive', 'search', 'postcode', 'or', 'at', 'gaytextbuddy.com', '.', 'txt', 'one', 'name', 'to', '89693', '.', '08715500022', 'rpl', 'stop', '2', 'cnl']\n",
      "AFter tokenizer:  ['its', 'not', 'that', 'time', 'of', 'the', 'month', 'nor', 'mid', 'of', 'the', 'time', '?']\n",
      "AFter tokenizer:  ['fffff', '.', 'can', 'you', 'text', 'kadeem', 'or', 'are', 'you', 'too', 'far', 'gone']\n",
      "AFter tokenizer:  ['we', 'not', 'leaving', 'yet', '.', 'ok', 'lor', 'then', 'we', 'go', 'elsewhere', 'n', 'eat', '.', 'u', 'thk', '...']\n",
      "AFter tokenizer:  ['is', 'fujitsu', 's', 'series', 'lifebook', 'good', '?']\n",
      "AFter tokenizer:  ['yar', 'i', 'wanted', '2', 'scold', 'u', 'yest', 'but', 'late', 'already', '...', 'i', 'where', 'got', 'zhong', 'se', 'qing', 'you', '?', 'if', 'u', 'ask', 'me', 'b4', 'he', 'ask', 'me', 'then', 'i', \"'ll\", 'go', 'out', 'w', 'u', 'all', 'lor', '.', 'n', 'u', 'still', 'can', 'act', 'so', 'real', '.']\n",
      "AFter tokenizer:  ['dont', 'know', 'you', 'bring', 'some', 'food']\n",
      "AFter tokenizer:  ['no', 'current', 'and', 'food', 'here', '.', 'i', 'am', 'alone', 'also']\n",
      "AFter tokenizer:  ['i', \"'ll\", 'be', 'in', 'sch', 'fr', '4-6', '...', 'i', 'dun', 'haf', 'da', 'book', 'in', 'sch', '...', 'it', \"'s\", 'at', 'home', '...']\n",
      "AFter tokenizer:  ['hello', '.', 'they', 'are', 'going', 'to', 'the', 'village', 'pub', 'at', '8', 'so', 'either', 'come', 'here', 'or', 'there', 'accordingly', '.', 'ok', '?']\n",
      "AFter tokenizer:  ['ok']\n",
      "AFter tokenizer:  ['we', 'don', 'call', 'like', '&', 'lt', ';', '#', '&', 'gt', ';', 'times', 'oh', '.', 'no', 'give', 'us', 'hypertension', 'oh', '.']\n",
      "AFter tokenizer:  ['dont', 'give', 'a', 'monkeys', 'wot', 'they', 'think', 'and', 'i', 'certainly', 'do', \"n't\", 'mind', '.', 'any', 'friend', 'of', 'mine', '&', 'all', 'that', '!', 'just', 'do', \"n't\", 'sleep', 'wiv', ',', 'that', 'wud', 'be', 'annoyin', '!']\n",
      "AFter tokenizer:  ['omg', 'it', 'could', 'snow', 'here', 'tonite', '!']\n",
      "AFter tokenizer:  ['call', 'from', '08702490080', '-', 'tells', 'u', '2', 'call', '09066358152', 'to', 'claim', '£5000', 'prize', '.', 'u', 'have', '2', 'enter', 'all', 'ur', 'mobile', '&', 'personal', 'details', '@', 'the', 'prompts', '.', 'careful', '!']\n",
      "AFter tokenizer:  ['free', '1st', 'week', 'entry', '2', 'textpod', '4', 'a', 'chance', '2', 'win', '40gb', 'ipod', 'or', '£250', 'cash', 'every', 'wk', '.', 'txt', 'vpod', 'to', '81303', 'ts', '&', 'cs', 'www.textpod.net', 'custcare', '08712405020', '.']\n",
      "AFter tokenizer:  ['carry', 'on', 'not', 'disturbing', 'both', 'of', 'you']\n",
      "AFter tokenizer:  ['what', 'pa', 'tell', 'me', '..', 'i', 'went', 'to', 'bath', ':', '-', ')']\n",
      "AFter tokenizer:  ['jus', 'finished', 'avatar', 'nigro']\n",
      "AFter tokenizer:  ['r', 'u', 'over', 'scratching', 'it', '?']\n",
      "AFter tokenizer:  ['hope', 'you', 'are', 'having', 'a', 'great', 'day', '.']\n",
      "AFter tokenizer:  ['did', 'either', 'of', 'you', 'have', 'any', 'idea', \"'s\", '?', 'do', 'you', 'know', 'of', 'anyplaces', 'doing', 'something', '?']\n",
      "AFter tokenizer:  ['my', 'planning', 'usually', 'stops', 'at', '``', 'find', 'hella', 'weed', ',', 'smoke', 'hella', 'weed', \"''\"]\n",
      "AFter tokenizer:  ['the', 'fact', 'that', 'you', \"'re\", 'cleaning', 'shows', 'you', 'know', 'why', 'i', \"'m\", 'upset', '.', 'your', 'priority', 'is', 'constantly', '``', 'what', 'i', 'want', 'to', 'do', ',', \"''\", 'not', '``', 'what', 'i', 'need', 'to', 'do', '.', \"''\"]\n",
      "AFter tokenizer:  ['excellent', '!', 'are', 'you', 'ready', 'to', 'moan', 'and', 'scream', 'in', 'ecstasy', '?']\n",
      "AFter tokenizer:  ['more', 'people', 'are', 'dogging', 'in', 'your', 'area', 'now', '.', 'call', '09090204448', 'and', 'join', 'like', 'minded', 'guys', '.', 'why', 'not', 'arrange', '1', 'yourself', '.', 'there', \"'s\", '1', 'this', 'evening', '.', 'a£1.50', 'minapn', 'ls278bb']\n",
      "AFter tokenizer:  ['dude', 'avatar', '3d', 'was', 'imp', '.', 'at', 'one', 'point', 'i', 'thought', 'there', 'were', 'actually', 'flies', 'in', 'the', 'room', 'and', 'almost', 'tried', 'hittng', 'one', 'as', 'a', 'reflex']\n",
      "AFter tokenizer:  ['well', 'done', '!', 'your', '4', '*', 'costa', 'del', 'sol', 'holiday', 'or', '£5000', 'await', 'collection', '.', 'call', '09050090044', 'now', 'toclaim', '.', 'sae', ',', 'tcs', ',', 'pobox334', ',', 'stockport', ',', 'sk38xh', ',', 'cost£1.50/pm', ',', 'max10mins']\n",
      "AFter tokenizer:  ['k', '...', 'k', ':', ')', 'why', 'cant', 'you', 'come', 'here', 'and', 'search', 'job', ':', ')']\n",
      "AFter tokenizer:  ['i', 'got', 'lousy', 'sleep', '.', 'i', 'kept', 'waking', 'up', 'every', '2', 'hours', 'to', 'see', 'if', 'my', 'cat', 'wanted', 'to', 'come', 'in', '.', 'i', 'worry', 'about', 'him', 'when', 'its', 'cold', ':', '(']\n",
      "AFter tokenizer:  ['yeah', ',', 'i', \"'ll\", 'leave', 'in', 'a', 'couple', 'minutes', '&', 'amp', ';', 'let', 'you', 'know', 'when', 'i', 'get', 'to', 'mu']\n",
      "AFter tokenizer:  ['can', 'ü', 'call', 'me', 'at', '10:10', 'to', 'make', 'sure', 'dat', 'i', \"'ve\", 'woken', 'up', '...']\n",
      "AFter tokenizer:  ['hey', 'we', 'can', 'go', 'jazz', 'power', 'yoga', 'hip', 'hop', 'kb', 'and', 'yogasana']\n",
      "AFter tokenizer:  ['the', 'battery', 'is', 'for', 'mr', 'adewale', 'my', 'uncle', '.', 'aka', 'egbon']\n",
      "AFter tokenizer:  ['wait', '2', 'min', '..', 'stand', 'at', 'bus', 'stop']\n",
      "AFter tokenizer:  ['oh', 'ic', '.', 'i', 'thought', 'you', 'meant', 'mary', 'jane', '.']\n",
      "AFter tokenizer:  ['haha', '...', 'really', 'oh', 'no', '...', 'how', '?', 'then', 'will', 'they', 'deduct', 'your', 'lesson', 'tmr', '?']\n",
      "AFter tokenizer:  ['nah', 'im', 'goin', '2', 'the', 'wrks', 'with', 'j', 'wot', 'bout', 'u', '?']\n",
      "AFter tokenizer:  ['then', 'just', 'eat', 'a', 'shit', 'and', 'wait', 'for', 'ur', 'monkey', 'face', 'bitch', '..........', 'u', 'asshole', '..................']\n",
      "AFter tokenizer:  ['good', 'night', '.', 'am', 'going', 'to', 'sleep', '.']\n",
      "AFter tokenizer:  ['aight', 'i', \"'ll\", 'grab', 'something', 'to', 'eat', 'too', ',', 'text', 'me', 'when', 'you', \"'re\", 'back', 'at', 'mu']\n",
      "AFter tokenizer:  ['take', 'something', 'for', 'pain', '.', 'if', 'it', 'moves', 'however', 'to', 'any', 'side', 'in', 'the', 'next', '6hrs', 'see', 'a', 'doctor', '.']\n",
      "AFter tokenizer:  ['lol', '...', 'oh', 'no', 'babe', ',', 'i', 'wont', 'be', 'sliding', 'into', 'your', 'place', 'after', 'midnight', ',', 'but', 'thanks', 'for', 'the', 'invite']\n",
      "AFter tokenizer:  ['howz', 'that', 'persons', 'story']\n",
      "AFter tokenizer:  ['guess', 'what', '!', 'somebody', 'you', 'know', 'secretly', 'fancies', 'you', '!', 'wan', 'na', 'find', 'out', 'who', 'it', 'is', '?', 'give', 'us', 'a', 'call', 'on', '09065394973', 'from', 'landline', 'datebox1282essexcm61xn', '150p/min', '18']\n",
      "AFter tokenizer:  ['lol', 'that', 'would', 'be', 'awesome', 'payback', '.']\n",
      "AFter tokenizer:  ['it', 'to', '80488.', 'your', '500', 'free', 'text', 'messages', 'are', 'valid', 'until', '31', 'december', '2005', '.']\n",
      "AFter tokenizer:  ['honeybee', 'said', ':', '*', 'i', \"'m\", 'd', 'sweetest', 'in', 'd', 'world', '*', 'god', 'laughed', '&', 'amp', ';', 'said', ':', '*', 'wait', ',', 'u', 'havnt', 'met', 'd', 'person', 'reading', 'this', 'msg', '*', 'moral', ':', 'even', 'god', 'can', 'crack', 'jokes', '!', 'gm+gn+ge+gn', ':', ')']\n",
      "AFter tokenizer:  ['thanks', '.', 'it', 'was', 'only', 'from', 'tescos', 'but', 'quite', 'nice', '.', 'all', 'gone', 'now', '.', 'speak', 'soon']\n",
      "AFter tokenizer:  ['what', \"'s\", 'a', 'feathery', 'bowa', '?', 'is', 'that', 'something', 'guys', 'have', 'that', 'i', 'do', \"n't\", 'know', 'about', '?']\n",
      "AFter tokenizer:  ['even', 'i', 'cant', 'close', 'my', 'eyes', 'you', 'are', 'in', 'me', 'our', 'vava', 'playing', 'umma', ':', '-d']\n",
      "AFter tokenizer:  ['2', 'laptop', '...', 'i', 'noe', 'infra', 'but', 'too', 'slow', 'lar', '...', 'i', 'wan', 'fast', 'one']\n",
      "AFter tokenizer:  ['you', 'have', 'won', 'a', 'guaranteed', '£200', 'award', 'or', 'even', '£1000', 'cashto', 'claim', 'ur', 'award', 'call', 'free', 'on', '08000407165', '(', '18+', ')', '2', 'stop', 'getstop', 'on', '88222', 'php']\n",
      "AFter tokenizer:  ['nvm', 'it', \"'s\", 'ok', '...']\n",
      "AFter tokenizer:  ['enjoy', 'ur', 'life', '.', '.', 'good', 'night']\n",
      "AFter tokenizer:  ['yes', 'but', 'can', 'we', 'meet', 'in', 'town', 'cos', 'will', 'go', 'to', 'gep', 'and', 'then', 'home', '.', 'you', 'could', 'text', 'at', 'bus', 'stop', '.', 'and', 'do', \"n't\", 'worry', 'we', \"'ll\", 'have', 'finished', 'by', 'march', '…', 'ish', '!']\n",
      "AFter tokenizer:  ['thats', 'cool', '.', 'where', 'should', 'i', 'cum', '?', 'on', 'you', 'or', 'in', 'you', '?', ':', ')']\n",
      "AFter tokenizer:  ['delhi', 'and', 'chennai', 'still', 'silent', '.']\n",
      "AFter tokenizer:  ['lol', 'alright', 'i', 'was', 'thinkin', 'that', 'too', 'haha']\n",
      "AFter tokenizer:  ['reply', 'to', 'win', '£100', 'weekly', '!', 'where', 'will', 'the', '2006', 'fifa', 'world', 'cup', 'be', 'held', '?', 'send', 'stop', 'to', '87239', 'to', 'end', 'service']\n",
      "AFter tokenizer:  ['no', 'i', \"'m\", 'in', 'the', 'same', 'boat', '.', 'still', 'here', 'at', 'my', 'moms', '.', 'check', 'me', 'out', 'on', 'yo', '.', 'i', \"'m\", 'half', 'naked', '.']\n",
      "AFter tokenizer:  ['shhhhh', 'nobody', 'is', 'supposed', 'to', 'know', '!']\n",
      "AFter tokenizer:  ['sorry', ',', 'i', \"'ll\", 'call', 'later', 'in', 'meeting', 'any', 'thing', 'related', 'to', 'trade', 'please', 'call', 'arul', '.', '&', 'lt', ';', '#', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['hey', 'i', 'will', 'be', 'late', '...', 'i', \"'m\", 'at', 'amk', '.', 'need', 'to', 'drink', 'tea', 'or', 'coffee']\n",
      "AFter tokenizer:  ['urgent', '!', 'please', 'call', '09061743810', 'from', 'landline', '.', 'your', 'abta', 'complimentary', '4', '*', 'tenerife', 'holiday', 'or', '#', '5000', 'cash', 'await', 'collection', 'sae', 't', '&', 'cs', 'box', '326', 'cw25wx', '150', 'ppm']\n",
      "AFter tokenizer:  ['the', 'length', 'is', 'e', 'same', 'but', 'e', 'top', 'shorter', 'n', 'i', 'got', 'a', 'fringe', 'now', '.', 'i', 'thk', 'i', \"'m\", 'not', 'going', 'liao', '.', 'too', 'lazy', '.', 'dun', 'wan', '2', 'distract', 'u', 'also', '.']\n",
      "AFter tokenizer:  ['s', '..', 'antha', 'num', 'corrct', 'dane']\n",
      "AFter tokenizer:  ['the', 'basket', \"'s\", 'gettin', 'full', 'so', 'i', 'might', 'be', 'by', 'tonight']\n",
      "AFter tokenizer:  ['hi', 'darlin', 'ive', 'just', 'got', 'back', 'and', 'i', 'had', 'a', 'really', 'nice', 'night', 'and', 'thanks', 'so', 'much', 'for', 'the', 'lift', 'see', 'u', 'tomorrow', 'xxx']\n",
      "AFter tokenizer:  ['no', 'other', 'valentines', 'huh', '?', 'the', 'proof', 'is', 'on', 'your', 'fb', 'page', '.', 'ugh', 'i', \"'m\", 'so', 'glad', 'i', 'really', 'did', \"n't\", 'watch', 'your', 'rupaul', 'show', 'you', 'tool', '!']\n",
      "AFter tokenizer:  ['free', 'tones', 'hope', 'you', 'enjoyed', 'your', 'new', 'content', '.', 'text', 'stop', 'to', '61610', 'to', 'unsubscribe', '.', 'help:08712400602450p', 'provided', 'by', 'tones2you.co.uk']\n",
      "AFter tokenizer:  ['eh', 'den', 'sat', 'u', 'book', 'e', 'kb', 'liao', 'huh', '...']\n",
      "AFter tokenizer:  ['have', 'you', 'been', 'practising', 'your', 'curtsey', '?']\n",
      "AFter tokenizer:  ['lol', 'boo', 'i', 'was', 'hoping', 'for', 'a', 'laugh']\n",
      "AFter tokenizer:  ['yeh', 'i', 'am', 'def', 'up4', 'something', 'sat', ',', 'just', 'got', 'payed2day', '&', 'i', 'havbeen', 'given', 'a£50', 'pay', 'rise', '4my', 'work', '&', 'havebeen', 'made', 'preschoolco-ordinator', '2i', 'am', 'feelingood', 'luv']\n",
      "AFter tokenizer:  ['well', ',', 'i', 'have', 'to', 'leave', 'for', 'my', 'class', 'babe', '...', 'you', 'never', 'came', 'back', 'to', 'me', '...', ':', '-', '(', '...', 'hope', 'you', 'have', 'a', 'nice', 'sleep', ',', 'my', 'love']\n",
      "AFter tokenizer:  ['lmao', 'where', \"'s\", 'your', 'fish', 'memory', 'when', 'i', 'need', 'it', '?']\n",
      "AFter tokenizer:  ['but', 'i', \"'ll\", 'b', 'going', '2', 'sch', 'on', 'mon', '.', 'my', 'sis', 'need', '2', 'take', 'smth', '.']\n",
      "AFter tokenizer:  ['idea', 'will', 'soon', 'get', 'converted', 'to', 'live', ':', ')']\n",
      "AFter tokenizer:  ['themob', '>', 'yo', 'yo', 'yo-here', 'comes', 'a', 'new', 'selection', 'of', 'hot', 'downloads', 'for', 'our', 'members', 'to', 'get', 'for', 'free', '!', 'just', 'click', '&', 'open', 'the', 'next', 'link', 'sent', 'to', 'ur', 'fone', '...']\n",
      "AFter tokenizer:  ['s', '....', 's', '...', 'india', 'going', 'to', 'draw', 'the', 'series', 'after', 'many', 'years', 'in', 'south', 'african', 'soil', '..']\n",
      "AFter tokenizer:  ['goodmorning', ',', 'today', 'i', 'am', 'late', 'for', '&', 'lt', ';', 'decimal', '&', 'gt', ';', 'min', '.']\n",
      "AFter tokenizer:  ['ca', \"n't\", 'take', 'any', 'major', 'roles', 'in', 'community', 'outreach', '.', 'you', 'rock', 'mel']\n",
      "AFter tokenizer:  ['shopping', 'lor', '.', 'them', 'raining', 'mah', 'hard', '2', 'leave', 'orchard', '.']\n",
      "AFter tokenizer:  ['hi', 'here', '.', 'have', 'birth', 'at', 'on', 'the', 'to', 'at', '8lb', '7oz', '.', 'mother', 'and', 'baby', 'doing', 'brilliantly', '.']\n",
      "AFter tokenizer:  ['see', 'the', 'forwarding', 'message', 'for', 'proof']\n",
      "AFter tokenizer:  ['i', 'ca', \"n't\", 'keep', 'going', 'through', 'this', '.', 'it', 'was', 'never', 'my', 'intention', 'to', 'run', 'you', 'out', ',', 'but', 'if', 'you', 'choose', 'to', 'do', 'that', 'rather', 'than', 'keep', 'the', 'room', 'clean', 'so', '*', 'i', '*', 'do', \"n't\", 'have', 'to', 'say', 'no', 'to', 'visitors', ',', 'then', 'maybe', 'that', \"'s\", 'the', 'best', 'choice', '.', 'yes', ',', 'i', 'wanted', 'you', 'to', 'be', 'embarassed', ',', 'so', 'maybe', 'you', \"'d\", 'feel', 'for', 'once', 'how', 'i', 'feel', 'when', 'i', 'have', 'a', 'friend', 'who', 'wants', 'to', 'drop', 'buy', 'and', 'i', 'have', 'to', 'say', 'no', ',', 'as', 'happened', 'this', 'morning', '.', 'i', \"'ve\", 'tried', 'everything', '.', 'i', 'do', \"n't\", 'know', 'what', 'else', 'to', 'do', '.']\n",
      "AFter tokenizer:  ['dunno', 'lei', '...', 'i', 'thk', 'mum', 'lazy', 'to', 'go', 'out', '...', 'i', 'neva', 'ask', 'her', 'yet', '...']\n",
      "AFter tokenizer:  ['do', 'whatever', 'you', 'want', '.', 'you', 'know', 'what', 'the', 'rules', 'are', '.', 'we', 'had', 'a', 'talk', 'earlier', 'this', 'week', 'about', 'what', 'had', 'to', 'start', 'happening', ',', 'you', 'showing', 'responsibility', '.', 'yet', ',', 'every', 'week', 'it', \"'s\", 'can', 'i', 'bend', 'the', 'rule', 'this', 'way', '?', 'what', 'about', 'that', 'way', '?', 'do', 'whatever', '.', 'i', \"'m\", 'tired', 'of', 'having', 'thia', 'same', 'argument', 'with', 'you', 'every', 'week', '.', 'and', 'a', '&', 'lt', ';', '#', '&', 'gt', ';', 'movie', 'doesnt', 'inlude', 'the', 'previews', '.', 'you', \"'re\", 'still', 'getting', 'in', 'after', '1', '.']\n",
      "AFter tokenizer:  ['beautiful', 'truth', 'against', 'gravity', '..', 'read', 'carefully', ':', '``', 'our', 'heart', 'feels', 'light', 'when', 'someone', 'is', 'in', 'it', '..', 'but', 'it', 'feels', 'very', 'heavy', 'when', 'someone', 'leaves', 'it', '..', \"''\", 'goodmorning']\n",
      "AFter tokenizer:  ['great', 'news', '!', 'call', 'freefone', '08006344447', 'to', 'claim', 'your', 'guaranteed', '£1000', 'cash', 'or', '£2000', 'gift', '.', 'speak', 'to', 'a', 'live', 'operator', 'now', '!']\n",
      "AFter tokenizer:  ['ambrith', '..', 'madurai', '..', 'met', 'u', 'in', 'arun', 'dha', 'marrge', '..', 'remembr', '?']\n",
      "AFter tokenizer:  ['just', 're', 'read', 'it', 'and', 'i', 'have', 'no', 'shame', 'but', 'tell', 'me', 'how', 'he', 'takes', 'it', 'and', 'if', 'he', 'runs', 'i', 'will', 'blame', 'u', '4', 'ever', '!', '!', 'not', 'really', '4', 'ever', 'just', 'a', 'long', 'time']\n",
      "AFter tokenizer:  ['princess', ',', 'is', 'your', 'kitty', 'shaved', 'or', 'natural', '?']\n",
      "AFter tokenizer:  ['better', 'than', 'bb', '.', 'if', 'he', 'wont', 'use', 'it', ',', 'his', 'wife', 'will', 'or', 'them', 'doctor']\n",
      "AFter tokenizer:  ['ya', 'it', 'came', 'a', 'while', 'ago']\n",
      "AFter tokenizer:  ['from', 'tomorrow', 'onwards', 'eve', '6', 'to', '3', 'work', '.']\n",
      "AFter tokenizer:  ['anything', 'lor', 'but', 'toa', 'payoh', 'got', 'place', '2', 'walk', 'meh', '...']\n",
      "AFter tokenizer:  ['i', 'do', \"n't\", 'have', 'anybody', \"'s\", 'number', ',', 'i', 'still', 'have', \"n't\", 'thought', 'up', 'a', 'tactful', 'way', 'to', 'ask', 'alex']\n",
      "AFter tokenizer:  ['u', 'can', 'win', '£100', 'of', 'music', 'gift', 'vouchers', 'every', 'week', 'starting', 'now', 'txt', 'the', 'word', 'draw', 'to', '87066', 'tscs', 'www.ldew.com', 'skillgame,1winaweek', ',', 'age16.150ppermesssubscription']\n",
      "AFter tokenizer:  ['is', 'there', 'any', 'movie', 'theatre', 'i', 'can', 'go', 'to', 'and', 'watch', 'unlimited', 'movies', 'and', 'just', 'pay', 'once', '?']\n",
      "AFter tokenizer:  ['u', 'having', 'lunch', 'alone', '?', 'i', 'now', 'so', 'bored', '...']\n",
      "AFter tokenizer:  ['yes', 'obviously', ',', 'but', 'you', 'are', 'the', 'eggs-pert', 'and', 'the', 'potato', 'head…', 'speak', 'soon', '!']\n",
      "AFter tokenizer:  ['nah', 'man', ',', 'my', 'car', 'is', 'meant', 'to', 'be', 'crammed', 'full', 'of', 'people']\n",
      "AFter tokenizer:  ['no', 'got', 'new', 'job', 'at', 'bar', 'in', 'airport', 'on', 'satsgettin', '4.47per', 'hour', 'but', 'means', 'no', 'lie', 'in', '!', 'keep', 'in', 'touch']\n",
      "AFter tokenizer:  ['kallis', 'is', 'ready', 'for', 'bat', 'in', '2nd', 'innings']\n",
      "AFter tokenizer:  ['thanx', 'but', 'my', 'birthday', 'is', 'over', 'already', '.']\n",
      "AFter tokenizer:  ['ugh', 'y', 'ca', \"n't\", 'u', 'just', 'apologize', ',', 'admit', 'u', 'were', 'wrong', 'and', 'ask', 'me', 'to', 'take', 'u', 'back', '?']\n",
      "AFter tokenizer:  ['i', 'noe', 'la', '...', 'u', 'wana', 'pei', 'bf', 'oso', 'rite', '...', 'k', 'lor', ',', 'other', 'days', 'den', '...']\n",
      "AFter tokenizer:  ['yes', ',', 'i', \"'m\", 'small', 'kid', '..', 'and', 'boost', 'is', 'the', 'secret', 'of', 'my', 'energy', '..']\n",
      "AFter tokenizer:  ['im', 'gon', 'na', 'miss', 'u', 'so', 'much']\n",
      "AFter tokenizer:  ['is', 'avatar', 'supposed', 'to', 'have', 'subtoitles']\n",
      "AFter tokenizer:  ['simply', 'sitting', 'and', 'watching', 'match', 'in', 'office', '..']\n",
      "AFter tokenizer:  ['you', 'can', 'jot', 'down', 'things', 'you', 'want', 'to', 'remember', 'later', '.']\n",
      "AFter tokenizer:  ['oh', 'sorry', 'please', 'its', 'over']\n",
      "AFter tokenizer:  ['hey', 'are', 'we', 'going', 'for', 'the', 'lo', 'lesson', 'or', 'gym', '?']\n",
      "AFter tokenizer:  ['dont', 'pack', 'what', 'you', 'can', 'buy', 'at', 'any', 'store.like', 'cereals', '.', 'if', 'you', 'must', 'pack', 'food', ',', 'pack', 'gari', 'or', 'something', '9ja', 'that', 'you', 'will', 'miss', '.']\n",
      "AFter tokenizer:  ['you', 'always', 'make', 'things', 'bigger', 'than', 'they', 'are']\n",
      "AFter tokenizer:  ['ü', 'dun', 'wan', 'to', 'watch', 'infernal', 'affair', '?']\n",
      "AFter tokenizer:  ['me', 'not', 'waking', 'up', 'until', '4', 'in', 'the', 'afternoon', ',', 'sup']\n",
      "AFter tokenizer:  ['i', 'can', 'send', 'you', 'a', 'pic', 'if', 'you', 'like', ':', ')']\n",
      "AFter tokenizer:  ['okay', '...', 'i', 'booked', 'all', 'already', '...', 'including', 'the', 'one', 'at', 'bugis', '.']\n",
      "AFter tokenizer:  ['aight', 'fuck', 'it', ',', 'i', \"'ll\", 'get', 'it', 'later']\n",
      "AFter tokenizer:  ['no', 'de', '.', 'but', 'call', 'me', 'after', 'some', 'time', '.', 'ill', 'tell', 'you', 'k']\n",
      "AFter tokenizer:  ['so', 'dont', 'use', 'hook', 'up', 'any', 'how']\n",
      "AFter tokenizer:  ['how', 'much', 'is', 'blackberry', 'bold2', 'in', 'nigeria', '.']\n",
      "AFter tokenizer:  ['hi', 'where', 'you', '.', 'you', 'in', 'home', 'or', 'calicut', '?']\n",
      "AFter tokenizer:  ['hey', 'darlin', '..', 'i', 'can', 'pick', 'u', 'up', 'at', 'college', 'if', 'u', 'tell', 'me', 'wen', '&', 'where', '2', 'mt', '..', 'love', 'pete', 'xx']\n",
      "AFter tokenizer:  ['call', '09094100151', 'to', 'use', 'ur', 'mins', '!', 'calls', 'cast', '10p/min', '(', 'mob', 'vary', ')', '.', 'service', 'provided', 'by', 'aom', ',', 'just', 'gbp5/month', '.', 'aom', 'box61', ',', 'm60', '1er', 'until', 'u', 'stop', '.', 'ages', '18+', 'only', '!']\n",
      "AFter tokenizer:  ['oh', '...', 'i', 'was', 'thkin', 'of', 'goin', 'yogasana', 'at', '10', 'den', 'no', 'nd', 'to', 'go', 'at', '3', 'den', 'can', 'rush', 'to', 'parco', '4', 'nb', '...', 'okie', 'lor', ',', 'u', 'call', 'me', 'when', 'ready', '...']\n",
      "AFter tokenizer:  ['y', 'so', 'late', 'but', 'i', 'need', 'to', 'go', 'n', 'get', 'da', 'laptop', '...']\n",
      "AFter tokenizer:  ['sir', ',', 'i', 'am', 'waiting', 'for', 'your', 'mail', '.']\n",
      "AFter tokenizer:  ['.please', 'charge', 'my', 'mobile', 'when', 'you', 'get', 'up', 'in', 'morning', '.']\n",
      "AFter tokenizer:  ['nothing', ',', 'i', 'got', 'msg', 'frm', 'tht', 'unknown', 'no', '..']\n",
      "AFter tokenizer:  ['ugh', 'fuck', 'it', 'i', \"'m\", 'resubbing', 'to', 'eve']\n",
      "AFter tokenizer:  ['he', 'did', \"n't\", 'see', 'his', 'shadow', '.', 'we', 'get', 'an', 'early', 'spring', 'yay']\n",
      "AFter tokenizer:  ['i', 'did', '.', 'one', 'slice', 'and', 'one', 'breadstick', '.', 'lol']\n",
      "AFter tokenizer:  ['hey', '!', 'i', 'want', 'you', '!', 'i', 'crave', 'you', '!', 'i', 'miss', 'you', '!', 'i', 'need', 'you', '!', 'i', 'love', 'you', ',', 'ahmad', 'saeed', 'al', 'hallaq', '...']\n",
      "AFter tokenizer:  ['is', 'there', 'any', 'training', 'tomorrow', '?']\n",
      "AFter tokenizer:  ['urgent', '!', 'your', 'mobile', 'no', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', 'won', 'a', '£2,000', 'bonus', 'caller', 'prize', 'on', '02/06/03', '!', 'this', 'is', 'the', '2nd', 'attempt', 'to', 'reach', 'you', '!', 'call', '09066362220', 'asap', '!', 'box97n7qp', ',', '150ppm']\n",
      "AFter tokenizer:  ['pass', 'dis', 'to', 'all', 'ur', 'contacts', 'n', 'see', 'wat', 'u', 'get', '!', 'red', ';', 'i', \"'m\", 'in', 'luv', 'wid', 'u.', 'blue', ';', 'u', 'put', 'a', 'smile', 'on', 'my', 'face', '.', 'purple', ';', 'u', 'r', 'realy', 'hot', '.', 'pink', ';', 'u', 'r', 'so', 'swt', '.', 'orange', ';', 'i', 'thnk', 'i', 'lyk', 'u.', 'green', ';', 'i', 'realy', 'wana', 'go', 'out', 'wid', 'u.', 'yelow', ';', 'i', 'wnt', 'u', 'bck', '.', 'black', ';', 'i', \"'m\", 'jealous', 'of', 'u.', 'brown', ';', 'i', 'miss', 'you', 'nw', 'plz', 'giv', 'me', 'one', 'color']\n",
      "AFter tokenizer:  ['cos', 'daddy', 'arranging', 'time', 'c', 'wat', 'time', 'fetch', 'ü', 'mah', '...']\n",
      "AFter tokenizer:  ['then', '.', 'you', 'are', 'eldest', 'know', '.']\n",
      "AFter tokenizer:  ['who', \"'s\", 'there', 'say', 'hi', 'to', 'our', 'drugdealer']\n",
      "AFter tokenizer:  ['its', 'hard', 'to', 'believe', 'things', 'like', 'this', '.', 'all', 'can', 'say', 'lie', 'but', 'think', 'twice', 'before', 'saying', 'anything', 'to', 'me', '.']\n",
      "AFter tokenizer:  ['sexy', 'singles', 'are', 'waiting', 'for', 'you', '!', 'text', 'your', 'age', 'followed', 'by', 'your', 'gender', 'as', 'wither', 'm', 'or', 'f', 'e.g.23f', '.', 'for', 'gay', 'men', 'text', 'your', 'age', 'followed', 'by', 'a', 'g.', 'e.g.23g', '.']\n",
      "AFter tokenizer:  ['good', 'night', 'my', 'dear', '..', 'sleepwell', '&', 'amp', ';', 'take', 'care']\n",
      "AFter tokenizer:  ['that', 'is', 'wondarfull', 'song']\n",
      "AFter tokenizer:  ['freemsg', ':', 'claim', 'ur', '250', 'sms', 'messages-text', 'ok', 'to', '84025', 'now', '!', 'use', 'web2mobile', '2', 'ur', 'mates', 'etc', '.', 'join', 'txt250.com', 'for', '1.50p/wk', '.', 't', '&', 'c', 'box139', ',', 'la32wu', '.', '16', '.', 'remove', 'txtx', 'or', 'stop']\n",
      "AFter tokenizer:  ['yar', 'lor', 'actually', 'we', 'quite', 'fast', '...', 'cos', 'da', 'ge', 'slow', 'wat', '...', 'haha', '...']\n",
      "AFter tokenizer:  ['must', 'come', 'later', '..', 'i', 'normally', 'bathe', 'him', 'in', 'da', 'afternoon', 'mah', '..']\n",
      "AFter tokenizer:  ['trust', 'me', '.', 'even', 'if', 'is', \"n't\", 'there', ',', 'its', 'there', '.']\n",
      "AFter tokenizer:  ['hey', 'hun-onbus', 'goin', '2', 'meet', 'him', '.', 'he', 'wants', '2go', 'out', '4a', 'meal', 'but', 'i', 'donyt', 'feel', 'like', 'it', 'cuz', 'have', '2', 'get', 'last', 'bus', 'home', '!', 'but', 'hes', 'sweet', 'latelyxxx']\n",
      "AFter tokenizer:  ['85233', 'free', '>', 'ringtone', '!', 'reply', 'real']\n",
      "AFter tokenizer:  ['i', 'can', 'take', 'you', 'at', 'like', 'noon']\n",
      "AFter tokenizer:  ['where', 'is', 'it', '.', 'is', 'there', 'any', 'opening', 'for', 'mca', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'aight', '.', 'wat', \"'s\", 'happening', 'on', 'your', 'side', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'done', 'oredi', '...']\n",
      "AFter tokenizer:  ['you', 'are', 'sweet', 'as', 'well', ',', 'princess', '.', 'please', 'tell', 'me', 'your', 'likes', 'and', 'dislikes', 'in', 'bed', '...']\n",
      "AFter tokenizer:  ['how', 'are', 'you', '.', 'wish', 'you', 'a', 'great', 'semester']\n",
      "AFter tokenizer:  ['moji', 'i', 'love', 'you', 'more', 'than', 'words', '.', 'have', 'a', 'rich', 'day']\n",
      "AFter tokenizer:  ['dude', 'how', 'do', 'you', 'like', 'the', 'buff', 'wind', '.']\n",
      "AFter tokenizer:  ['alright', 'babe', ',', 'justthought', 'i\\x92d', 'sayhey', '!', 'how', 'u', 'doin', '?', 'nearly', 'the', 'endof', 'me', 'wk', 'offdam', 'nevamind', '!', 'we', 'will', 'have', '2hook', 'up', 'sn', 'if', 'uwant', 'm8', '?', 'lovejen', 'x', '.']\n",
      "AFter tokenizer:  ['well', 'done', 'england', '!', 'get', 'the', 'official', 'poly', 'ringtone', 'or', 'colour', 'flag', 'on', 'yer', 'mobile', '!', 'text', 'tone', 'or', 'flag', 'to', '84199', 'now', '!', 'opt-out', 'txt', 'eng', 'stop', '.', 'box39822', 'w111wx', '£1.50']\n",
      "AFter tokenizer:  ['no', 'i', \"'m\", 'not', '.', 'i', 'ca', \"n't\", 'give', 'you', 'everything', 'you', 'want', 'and', 'need', '.', 'you', 'actually', 'could', 'do', 'better', 'for', 'yourself', 'on', 'yor', 'own', '--', 'you', \"'ve\", 'got', 'more', 'money', 'than', 'i', 'do', '.', 'i', 'ca', \"n't\", 'get', 'work', ',', 'i', 'ca', \"n't\", 'get', 'a', 'man', ',', 'i', 'ca', \"n't\", 'pay', 'the', 'rent', ',', 'i', 'ca', \"n't\", 'even', 'fill', 'my', 'fucking', 'gas', 'tank', '.', 'yes', ',', 'i', \"'m\", 'stressed', 'and', 'depressed', '.', 'i', 'did', \"n't\", 'even', 'call', 'home', 'for', 'thanksgiving', 'cuz', 'i', \"'ll\", 'have', 'to', 'tell', 'them', 'i', ',', 'm', 'up', 'to', 'nothing', '.']\n",
      "AFter tokenizer:  ['s', ':', '-', ')', 'kallis', 'wont', 'play', 'in', 'first', 'two', 'odi', ':', '-', ')']\n",
      "AFter tokenizer:  ['then', 'get', 'some', 'cash', 'together', 'and', 'i', \"'ll\", 'text', 'jason']\n",
      "AFter tokenizer:  ['oh', ',', 'my', 'love', ',', 'it', \"'s\", 'soooo', 'good', 'to', 'hear', 'from', 'you', '.', 'omg', 'i', 'missed', 'you', 'so', 'much', 'today', '.', 'i', \"'m\", 'sorry', 'your', 'having', 'problems', 'with', 'the', 'provider', 'but', 'thank', 'you', 'for', 'tming', 'me']\n",
      "AFter tokenizer:  ['final', 'chance', '!', 'claim', 'ur', '£150', 'worth', 'of', 'discount', 'vouchers', 'today', '!', 'text', 'yes', 'to', '85023', 'now', '!', 'savamob', ',', 'member', 'offers', 'mobile', '!', 't', 'cs', 'savamob', 'pobox84', ',', 'm263uz', '.', '£3.00', 'subs', '16']\n",
      "AFter tokenizer:  ['probably', ',', 'want', 'to', 'pick', 'up', 'more', '?']\n",
      "AFter tokenizer:  ['i', \"'m\", 'done', '...']\n",
      "AFter tokenizer:  ['are', 'you', 'the', 'cutest', 'girl', 'in', 'the', 'world', 'or', 'what']\n",
      "AFter tokenizer:  ['no', 'dice', ',', 'art', 'class', '6', 'thru', '9', ':', '(', 'thanks', 'though', '.', 'any', 'idea', 'what', 'time', 'i', 'should', 'come', 'tomorrow', '?']\n",
      "AFter tokenizer:  ['sms', 'services', '.', 'for', 'your', 'inclusive', 'text', 'credits', ',', 'pls', 'goto', 'www.comuk.net', 'login=', '*', '*', '*', '*', '*', 'unsubscribe', 'with', 'stop', '.', 'no', 'extra', 'charge', '.', 'help:08700469649.', 'po', 'box420', '.', 'ip4', '5we']\n",
      "AFter tokenizer:  ['oh', 'howda', 'gud', 'gud', '..', 'mathe', 'en', 'samachara', 'chikku', ':', '-', ')']\n",
      "AFter tokenizer:  ['i', 'thk', '530', 'lor', '.', 'but', 'dunno', 'can', 'get', 'tickets', 'a', 'not', '.', 'wat', 'u', 'doing', 'now', '?']\n",
      "AFter tokenizer:  ['audrie', 'lousy', 'autocorrect']\n",
      "AFter tokenizer:  ['its', 'a', 'site', 'to', 'simulate', 'the', 'test', '.', 'it', 'just', 'gives', 'you', 'very', 'tough', 'questions', 'to', 'test', 'your', 'readiness', '.']\n",
      "AFter tokenizer:  ['anyway', 'seriously', 'hit', 'me', 'up', 'when', 'you', \"'re\", 'back', 'because', 'otherwise', 'i', 'have', 'to', 'light', 'up', 'with', 'armand', 'and', 'he', 'always', 'has', 'shit', 'and/or', 'is', 'vomiting']\n",
      "AFter tokenizer:  ['i', 'fetch', 'yun', 'or', 'u', 'fetch', '?']\n",
      "AFter tokenizer:  ['thank', 'you', '.', 'i', 'like', 'you', 'as', 'well', '...']\n",
      "AFter tokenizer:  ['hmmm', '...', 'and', 'imagine', 'after', 'you', \"'ve\", 'come', 'home', 'from', 'that', 'having', 'to', 'rub', 'my', 'feet', ',', 'make', 'me', 'dinner', 'and', 'help', 'me', 'get', 'ready', 'for', 'my', 'date', '!', 'are', 'you', 'sure', 'your', 'ready', 'for', 'that', 'kind', 'of', 'life', '?']\n",
      "AFter tokenizer:  ['lara', 'said', 'she', 'can', 'loan', 'me', '&', 'lt', ';', '#', '&', 'gt', ';', '.']\n",
      "AFter tokenizer:  ['do', 'we', 'have', 'any', 'spare', 'power', 'supplies']\n",
      "AFter tokenizer:  ['yar', 'he', 'quite', 'clever', 'but', 'aft', 'many', 'guesses', 'lor', '.', 'he', 'got', 'ask', 'me', '2', 'bring', 'but', 'i', 'thk', 'darren', 'not', 'so', 'willing', '2', 'go', '.', 'aiya', 'they', 'thk', 'leona', 'still', 'not', 'attach', 'wat', '.']\n",
      "AFter tokenizer:  ['you', 'are', 'a', 'winner', 'you', 'have', 'been', 'specially', 'selected', 'to', 'receive', '£1000', 'cash', 'or', 'a', '£2000', 'award', '.', 'speak', 'to', 'a', 'live', 'operator', 'to', 'claim', 'call', '087123002209am-7pm', '.', 'cost', '10p']\n",
      "AFter tokenizer:  ['yeah', ',', 'do', \"n't\", 'go', 'to', 'bed', ',', 'i', \"'ll\", 'be', 'back', 'before', 'midnight']\n",
      "AFter tokenizer:  ['sunshine', 'hols', '.', 'to', 'claim', 'ur', 'med', 'holiday', 'send', 'a', 'stamped', 'self', 'address', 'envelope', 'to', 'drinks', 'on', 'us', 'uk', ',', 'po', 'box', '113', ',', 'bray', ',', 'wicklow', ',', 'eire', '.', 'quiz', 'starts', 'saturday', '!', 'unsub', 'stop']\n",
      "AFter tokenizer:  ['well', 'i', 'was', \"n't\", 'available', 'as', 'i', 'washob', 'nobbing', 'with', 'last', 'night', 'so', 'they', 'had', 'to', 'ask', 'nickey', 'platt', 'instead', 'of', 'me', '!', ';']\n",
      "AFter tokenizer:  ['it', \"'s\", 'that', 'time', 'of', 'the', 'week', 'again', ',', 'ryan']\n",
      "AFter tokenizer:  ['wish', 'u', 'many', 'many', 'returns', 'of', 'the', 'day', '..', 'happy', 'birthday', 'vikky', '..']\n",
      "AFter tokenizer:  ['u', 'can', 'win', '£100', 'of', 'music', 'gift', 'vouchers', 'every', 'week', 'starting', 'now', 'txt', 'the', 'word', 'draw', 'to', '87066', 'tscs', 'www.idew.com', 'skillgame', ',', '1winaweek', ',', 'age16', '.', '150ppermesssubscription']\n",
      "AFter tokenizer:  ['i', 'hope', 'you', 'know', 'i', \"'m\", 'still', 'mad', 'at', 'you', '.']\n",
      "AFter tokenizer:  ['argh', 'my', '3g', 'is', 'spotty', ',', 'anyway', 'the', 'only', 'thing', 'i', 'remember', 'from', 'the', 'research', 'we', 'did', 'was', 'that', 'province', 'and', 'sterling', 'were', 'the', 'only', 'problem-free', 'places', 'we', 'looked', 'at']\n",
      "AFter tokenizer:  ['in', 'xam', 'hall', 'boy', 'asked', 'girl', 'tell', 'me', 'the', 'starting', 'term', 'for', 'dis', 'answer', 'i', 'can', 'den', 'manage', 'on', 'my', 'own', 'after', 'lot', 'of', 'hesitation', 'n', 'lookin', 'around', 'silently', 'she', 'said', 'the', '!', 'intha', 'ponnungale', 'ipaditan', ';', ')']\n",
      "AFter tokenizer:  ['do', 'you', 'know', 'when', 'the', 'result', '.']\n",
      "AFter tokenizer:  ['sorry', 'im', 'getting', 'up', 'now', ',', 'feel', 'really', 'bad-', 'totally', 'rejected', 'that', 'kinda', 'me', 'thing', '.']\n",
      "AFter tokenizer:  ['you', 'do', 'got', 'a', 'shitload', 'of', 'diamonds', 'though']\n",
      "AFter tokenizer:  ['tessy', '..', 'pls', 'do', 'me', 'a', 'favor', '.', 'pls', 'convey', 'my', 'birthday', 'wishes', 'to', 'nimya', '..', 'pls', 'dnt', 'forget', 'it', '.', 'today', 'is', 'her', 'birthday', 'shijas']\n",
      "AFter tokenizer:  ['well', 'i', \"'m\", 'going', 'to', 'be', 'an', 'aunty', '!']\n",
      "AFter tokenizer:  ['mine', 'here', 'like', 'all', 'fr', 'china', 'then', 'so', 'noisy', '.']\n",
      "AFter tokenizer:  ['later', 'i', 'guess', '.', 'i', 'needa', 'do', 'mcat', 'study', 'too', '.']\n",
      "AFter tokenizer:  ['s', '...', 'from', 'the', 'training', 'manual', 'it', 'show', 'there', 'is', 'no', 'tech', 'process', ':', ')', 'its', 'all', 'about', 'password', 'reset', 'and', 'troubleshooting', ':', ')']\n",
      "AFter tokenizer:  ['your', 'b4u', 'voucher', 'w/c', '27/03', 'is', 'marsms', '.', 'log', 'onto', 'www.b4utele.com', 'for', 'discount', 'credit', '.', 'to', 'opt', 'out', 'reply', 'stop', '.', 'customer', 'care', 'call', '08717168528']\n",
      "AFter tokenizer:  ['spoke', 'with', 'uncle', 'john', 'today', '.', 'he', 'strongly', 'feels', 'that', 'you', 'need', 'to', 'sacrifice', 'to', 'keep', 'me', 'here', '.', 'he', \"'s\", 'going', 'to', 'call', 'you', '.', 'when', 'he', 'does', ',', 'i', 'beg', 'you', 'to', 'just', 'listen', '.', 'dont', 'make', 'any', 'promises', 'or', 'make', 'it', 'clear', 'things', 'are', 'not', 'easy', '.', 'and', 'i', 'need', 'you', 'to', 'please', 'let', 'us', 'work', 'things', 'out', '.', 'as', 'long', 'as', 'i', 'keep', 'expecting', 'help', ',', 'my', 'creativity', 'will', 'be', 'stifled', 'so', 'pls', 'just', 'keep', 'him', 'happy', ',', 'no', 'promises', 'on', 'your', 'part', '.']\n",
      "AFter tokenizer:  ['carlos', 'took', 'a', 'while', '(', 'again', ')', ',', 'we', 'leave', 'in', 'a', 'minute']\n",
      "AFter tokenizer:  ['well', 'done', 'and', '!', 'luv', 'ya', 'all']\n",
      "AFter tokenizer:  ['then', 'why', 'you', 'came', 'to', 'hostel', '.']\n",
      "AFter tokenizer:  ['k', 'still', 'are', 'you', 'loving', 'me', '.']\n",
      "AFter tokenizer:  ['but', 'i', 'juz', 'remembered', 'i', 'got', 'ta', 'bathe', 'my', 'dog', 'today', '..']\n",
      "AFter tokenizer:  ['after', 'the', 'drug', 'she', 'will', 'be', 'able', 'to', 'eat', '.']\n",
      "AFter tokenizer:  ['alright', 'took', 'the', 'morphine', '.', 'back', 'in', 'yo', '.']\n",
      "AFter tokenizer:  ['you', 'see', 'the', 'requirements', 'please']\n",
      "AFter tokenizer:  ['you', 'stayin', 'out', 'of', 'trouble', 'stranger', '!', '!', 'saw', 'dave', 'the', 'other', 'day', 'he\\x92s', 'sorted', 'now', '!', 'still', 'with', 'me', 'bloke', 'when', 'u', 'gona', 'get', 'a', 'girl', 'mr', '!', 'ur', 'mum', 'still', 'thinks', 'we', 'will', 'get', '2getha', '!']\n",
      "AFter tokenizer:  ['freemsg', ':', 'hey', '-', 'i', \"'m\", 'buffy', '.', '25', 'and', 'love', 'to', 'satisfy', 'men', '.', 'home', 'alone', 'feeling', 'randy', '.', 'reply', '2', 'c', 'my', 'pix', '!', 'qlynnbv', 'help08700621170150p', 'a', 'msg', 'send', 'stop', 'to', 'stop', 'txts']\n",
      "AFter tokenizer:  ['so', 'can', 'collect', 'ur', 'laptop', '?']\n",
      "AFter tokenizer:  ['ok.', 'can', 'be', 'later', 'showing', 'around', '8-8:30', 'if', 'you', 'want', '+', 'cld', 'have', 'drink', 'before', '.', 'wld', 'prefer', 'not', 'to', 'spend', 'money', 'on', 'nosh', 'if', 'you', 'do', \"n't\", 'mind', ',', 'as', 'doing', 'that', 'nxt', 'wk', '.']\n",
      "AFter tokenizer:  ['i', 'will', 'once', 'i', 'get', 'home']\n",
      "AFter tokenizer:  ['waaaat', '?', '?', 'lololo', 'ok', 'next', 'time', 'then', '!']\n",
      "AFter tokenizer:  ['the', 'table', \"'s\", 'occupied', ',', 'i', \"'m\", 'waiting', 'by', 'the', 'tree']\n",
      "AFter tokenizer:  ['i', 'surely', 'dont', 'forgot', 'to', 'come', ':', ')', 'i', 'will', 'always', 'be', 'in', 'touch', 'in', 'with', 'you', ':', '-', ')']\n",
      "AFter tokenizer:  ['hi', 'kindly', 'give', 'us', 'back', 'our', 'documents', 'which', 'we', 'submitted', 'for', 'loan', 'from', 'stapati']\n",
      "AFter tokenizer:  ['i', 'dont', 'have', 'i', 'shall', 'buy', 'one', 'dear']\n",
      "AFter tokenizer:  ['oh', 'god', 'i', 'am', 'happy', 'to', 'see', 'your', 'message', 'after', '3', 'days']\n",
      "AFter tokenizer:  ['what', 'year', '.', 'and', 'how', 'many', 'miles', '.']\n",
      "AFter tokenizer:  ['hey', 'cutie', '.', 'how', 'goes', 'it', '?', 'here', 'in', 'wales', 'its', 'kinda', 'ok.', 'there', 'is', 'like', 'hills', 'and', 'shit', 'but', 'i', 'still', 'avent', 'killed', 'myself', '.']\n",
      "AFter tokenizer:  ['sad', 'story', 'of', 'a', 'man', '-', 'last', 'week', 'was', 'my', \"b'day\", '.', 'my', 'wife', \"did'nt\", 'wish', 'me', '.', 'my', 'parents', 'forgot', 'n', 'so', 'did', 'my', 'kids', '.', 'i', 'went', 'to', 'work', '.', 'even', 'my', 'colleagues', 'did', 'not', 'wish', '.', 'as', 'i', 'entered', 'my', 'cabin', 'my', 'pa', 'said', ',', '``', 'happy', \"b'day\", 'boss', '!', '!', \"''\", '.', 'i', 'felt', 'special', '.', 'she', 'askd', 'me', '4', 'lunch', '.', 'after', 'lunch', 'she', 'invited', 'me', 'to', 'her', 'apartment', '.', 'we', 'went', 'there', '.', 'she', 'said', ',', \"''\", 'do', 'u', 'mind', 'if', 'i', 'go', 'into', 'the', 'bedroom', 'for', 'a', 'minute', '?', '``', \"''\", 'ok', \"''\", ',', 'i', 'sed', 'in', 'a', 'sexy', 'mood', '.', 'she', 'came', 'out', '5', 'minuts', 'latr', 'wid', 'a', 'cake', '...', 'n', 'my', 'wife', ',', 'my', 'parents', ',', 'my', 'kidz', ',', 'my', 'friends', 'n', 'my', 'colleagues', '.', 'all', 'screaming', '..', 'surprise', '!', '!', 'and', 'i', 'was', 'waiting', 'on', 'the', 'sofa', '..', '...', '.....', \"'\", 'naked', '...', '!']\n",
      "AFter tokenizer:  ['i', 'think', 'you', 'should', 'go', 'the', 'honesty', 'road', '.', 'call', 'the', 'bank', 'tomorrow', '.', 'its', 'the', 'tough', 'decisions', 'that', 'make', 'us', 'great', 'people', '.']\n",
      "AFter tokenizer:  ['free', 'for', '1st', 'week', '!', 'no1', 'nokia', 'tone', '4', 'ur', 'mob', 'every', 'week', 'just', 'txt', 'nokia', 'to', '87077', 'get', 'txting', 'and', 'tell', 'ur', 'mates', '.', 'zed', 'pobox', '36504', 'w45wq', 'norm150p/tone', '16+']\n",
      "AFter tokenizer:  ['no', '.', 'its', 'not', 'specialisation', '.', 'can', 'work', 'but', 'its', 'slave', 'labor', '.', 'will', 'look', 'for', 'it', 'this', 'month', 'sha', 'cos', 'no', 'shakara', '4', 'beggar', '.']\n",
      "AFter tokenizer:  ['is', 'she', 'replying', '.', 'has', 'boye', 'changed', 'his', 'phone', 'number']\n",
      "AFter tokenizer:  ['hi', 'my', 'darlin', 'im', 'on', 'my', 'way', 'to', 'london', 'and', 'we', 'have', 'just', 'been', 'smashed', 'into', 'by', 'another', 'driver', '!', 'and', 'have', 'a', 'big', 'dent', '!', 'im', 'really', 'missing', 'u', 'what', 'have', 'u', 'been', 'up', 'to', '?', 'xxx']\n",
      "AFter tokenizer:  ['nothing', 'really', ',', 'just', 'making', 'sure', 'everybody', \"'s\", 'up', 'to', 'speed']\n",
      "AFter tokenizer:  ['i', \"'m\", 'not', 'coming', 'home', '4', 'dinner', '.']\n",
      "AFter tokenizer:  ['thank', 'you', '.', 'and', 'by', 'the', 'way', ',', 'i', 'just', 'lost', '.']\n",
      "AFter tokenizer:  ['yes.he', 'have', 'good', 'crickiting', 'mind']\n",
      "AFter tokenizer:  ['thx', '.', 'all', 'will', 'be', 'well', 'in', 'a', 'few', 'months']\n",
      "AFter tokenizer:  ['can', 'i', 'please', 'come', 'up', 'now', 'imin', 'town.dontmatter', 'if', 'urgoin', 'outl8r', ',', 'just', 'reallyneed', '2docd.please', 'dontplease', 'dontignore', 'mycalls', ',', 'u', 'no', 'thecd', 'isv.important', 'tome', '4', '2moro']\n",
      "AFter tokenizer:  ['i', 'wont', '.', 'so', 'wat', \"'s\", 'wit', 'the', 'guys']\n",
      "AFter tokenizer:  ['yavnt', 'tried', 'yet', 'and', 'never', 'played', 'original', 'either']\n",
      "AFter tokenizer:  ['hiya', ',', 'had', 'a', 'good', 'day', '?', 'have', 'you', 'spoken', 'to', 'since', 'the', 'weekend', '?']\n",
      "AFter tokenizer:  ['see', '?', 'i', 'thought', 'it', 'all', 'through']\n",
      "AFter tokenizer:  ['get', 'ready', 'to', 'moan', 'and', 'scream', ':', ')']\n",
      "AFter tokenizer:  ['oh', 'k', ':', ')', 'why', 'you', 'got', 'job', 'then', 'whats', 'up', '?']\n",
      "AFter tokenizer:  ['i', 'don', ',', 't', 'think', 'so', '.', 'you', 'do', \"n't\", 'need', 'to', 'be', 'going', 'out', 'that', 'late', 'on', 'a', 'school', 'night', '.', 'especially', 'when', 'the', 'one', 'class', 'you', 'have', 'is', 'the', 'one', 'you', 'missed', 'last', 'wednesday', 'and', 'probably', 'failed', 'a', 'test', 'in', 'on', 'friday']\n",
      "AFter tokenizer:  ['and', 'popping', '&', 'lt', ';', '#', '&', 'gt', ';', 'ibuprofens', 'was', 'no', 'help', '.']\n",
      "AFter tokenizer:  ['babe', '!', 'how', 'goes', 'that', 'day', '?', 'what', 'are', 'you', 'doing', '?', 'where', 'are', 'you', '?', 'i', 'sip', 'my', 'cappuccino', 'and', 'think', 'of', 'you', ',', 'my', 'love', '...', 'i', 'send', 'a', 'kiss', 'to', 'you', 'from', 'across', 'the', 'sea']\n",
      "AFter tokenizer:  ['ok', '.']\n",
      "AFter tokenizer:  ['ps', 'u', 'no', 'ur', 'a', 'grown', 'up', 'now', 'right', '?']\n",
      "AFter tokenizer:  ['chinatown', 'got', 'porridge', ',', 'claypot', 'rice', ',', 'yam', 'cake', ',', 'fishhead', 'beehoon', '...', 'either', 'we', 'eat', 'cheap', 'den', 'go', 'cafe', 'n', 'tok', 'or', 'go', 'nydc', 'or', 'somethin', '...']\n",
      "AFter tokenizer:  ['i', 'know', 'a', 'few', 'people', 'i', 'can', 'hit', 'up', 'and', 'fuck', 'to', 'the', 'yes']\n",
      "AFter tokenizer:  ['purity', 'of', 'friendship', 'between', 'two', 'is', 'not', 'about', 'smiling', 'after', 'reading', 'the', 'forwarded', 'message', '..', 'its', 'about', 'smiling', 'just', 'by', 'seeing', 'the', 'name', '.', 'gud', 'evng']\n",
      "AFter tokenizer:  ['so', 'is', 'there', 'anything', 'specific', 'i', 'should', 'be', 'doing', 'with', 'regards', 'to', 'jaklin', 'or', 'what', 'because', 'idk', 'what', 'the', 'fuck']\n",
      "AFter tokenizer:  ['oh', 'god', '.', 'i', \"'m\", 'gon', 'na', 'google', 'nearby', 'cliffs', 'now', '.']\n",
      "AFter tokenizer:  ['free', 'camera', 'phones', 'with', 'linerental', 'from', '4.49/month', 'with', '750', 'cross', 'ntwk', 'mins', '.', '1/2', 'price', 'txt', 'bundle', 'deals', 'also', 'avble', '.', 'call', '08001950382', 'or', 'call2optout/j', 'mf']\n",
      "AFter tokenizer:  ['yup', 'i', 'shd', 'haf', 'ard', '10', 'pages', 'if', 'i', 'add', 'figures', '...', 'ü', 'all', 'got', 'how', 'many', 'pages', '?']\n",
      "AFter tokenizer:  ['ooh', ',', '4got', ',', 'i', \"'m\", 'gon', 'na', 'start', 'belly', 'dancing', 'in', 'moseley', 'weds', '6.30', 'if', 'u', 'want', '2', 'join', 'me', ',', 'they', 'have', 'a', 'cafe', 'too', '.']\n",
      "AFter tokenizer:  ['thankyou', 'so', 'much', 'for', 'the', 'call', '.', 'i', 'appreciate', 'your', 'care', '.']\n",
      "AFter tokenizer:  ['congrats', '!', 'treat', 'pending.i', 'am', 'not', 'on', 'mail', 'for', '2', 'days.will', 'mail', 'once', 'thru.respect', 'mother', 'at', 'home.check', 'mails', '.']\n",
      "AFter tokenizer:  ['i', 'called', 'but', 'no', 'one', 'pick', 'up', 'e', 'phone', '.', 'i', 'ask', 'both', 'of', 'them', 'already', 'they', 'said', 'ok', '.']\n",
      "AFter tokenizer:  ['hi', 'my', 'email', 'address', 'has', 'changed', 'now', 'it', 'is']\n",
      "AFter tokenizer:  ['v-aluable', '.', 'a-ffectionate', '.', 'l-oveable', '.', 'e-ternal', '.', 'n-oble', '.', 't-ruthful', '.', 'i-ntimate', '.', 'n-atural', '.', 'e-namous', '.', 'happy', '``', 'valentines', 'day', \"''\", 'in', 'advance']\n",
      "AFter tokenizer:  ['not', 'much', ',', 'just', 'some', 'textin', \"'\", '.', 'how', 'bout', 'you', '?']\n",
      "AFter tokenizer:  ['bring', 'it', 'if', 'you', 'got', 'it']\n",
      "AFter tokenizer:  ['i', \"'m\", 'in', 'a', 'movie', '.', 'call', 'me', '4', 'wat', '?']\n",
      "AFter tokenizer:  ['not', 'sure', 'i', 'have', 'the', 'stomach', 'for', 'it', '...']\n",
      "AFter tokenizer:  ['haha', '...', 'can', '...', 'but', 'i', \"'m\", 'having', 'dinner', 'with', 'my', 'cousin', '...']\n",
      "AFter tokenizer:  ['a', 'boy', 'was', 'late', '2', 'home', '.', 'his', 'father', ':', '``', 'power', 'of', 'frndship', \"''\"]\n",
      "AFter tokenizer:  ['(', 'and', 'my', 'man', 'carlos', 'is', 'definitely', 'coming', 'by', 'mu', 'tonight', ',', 'no', 'excuses', ')']\n",
      "AFter tokenizer:  ['soon', 'you', 'will', 'have', 'the', 'real', 'thing', 'princess', '!', 'do', 'i', 'make', 'you', 'wet', '?', ':', ')']\n",
      "AFter tokenizer:  ['raji', '..', 'pls', 'do', 'me', 'a', 'favour', '.', 'pls', 'convey', 'my', 'birthday', 'wishes', 'to', 'nimya', '.', 'pls', '.', 'today', 'is', 'her', 'birthday', '.']\n",
      "AFter tokenizer:  ['haha', ',', 'my', 'legs', 'and', 'neck', 'are', 'killing', 'me', 'and', 'my', 'amigos', 'are', 'hoping', 'to', 'end', 'the', 'night', 'with', 'a', 'burn', ',', 'think', 'i', 'could', 'swing', 'by', 'in', 'like', 'an', 'hour', '?']\n",
      "AFter tokenizer:  ['urgent', '!', 'your', 'mobile', 'no', '07xxxxxxxxx', 'won', 'a', '£2,000', 'bonus', 'caller', 'prize', 'on', '02/06/03', '!', 'this', 'is', 'the', '2nd', 'attempt', 'to', 'reach', 'you', '!', 'call', '09066362231', 'asap', '!', 'box97n7qp', ',', '150ppm']\n",
      "AFter tokenizer:  ['usually', 'the', 'body', 'takes', 'care', 'of', 'it', 'buy', 'making', 'sure', 'it', 'doesnt', 'progress', '.', 'can', 'we', 'pls', 'continue', 'this', 'talk', 'on', 'saturday', '.']\n",
      "AFter tokenizer:  ['urgent', '!', '!', 'your', '4', '*', 'costa', 'del', 'sol', 'holiday', 'or', '£5000', 'await', 'collection', '.', 'call', '09050090044', 'now', 'toclaim', '.', 'sae', ',', 'tc', 's', ',', 'pobox334', ',', 'stockport', ',', 'sk38xh', ',', 'cost£1.50/pm', ',', 'max10mins']\n",
      "AFter tokenizer:  ['hmm', 'well', ',', 'night', 'night']\n",
      "AFter tokenizer:  ['just', 'wanted', 'to', 'say', 'holy', 'shit', 'you', 'guys', 'were', \"n't\", 'kidding', 'about', 'this', 'bud']\n",
      "AFter tokenizer:  ['just', 'gettin', 'a', 'bit', 'arty', 'with', 'my', 'collages', 'at', 'the', 'mo', ',', 'well', 'tryin', '2', 'ne', 'way', '!', 'got', 'a', 'roast', 'in', 'a', 'min', 'lovely', 'i', 'shall', 'enjoy', 'that', '!']\n",
      "AFter tokenizer:  ['this', 'is', 'one', 'of', 'the', 'days', 'you', 'have', 'a', 'billion', 'classes', ',', 'right', '?']\n",
      "AFter tokenizer:  ['goodmorning', ',', 'today', 'i', 'am', 'late', 'for', '2hrs', '.', 'because', 'of', 'back', 'pain', '.']\n",
      "AFter tokenizer:  ['ok', 'then', 'i', \"'ll\", 'let', 'him', 'noe', 'later', 'n', 'ask', 'him', 'call', 'u', 'tmr', '...']\n",
      "AFter tokenizer:  ['ok', 'i', \"'m\", 'waliking', 'ard', 'now', '...', 'do', 'u', 'wan', 'me', '2', 'buy', 'anything', 'go', 'ur', 'house', '?']\n",
      "AFter tokenizer:  ['*', 'will', 'have', 'two', 'more', 'cartons', 'off', 'u', 'and', 'is', 'very', 'pleased', 'with', 'shelves']\n",
      "AFter tokenizer:  ['nice', 'talking', 'to', 'you', '!', 'please', 'dont', 'forget', 'my', 'pix', ':', ')', 'i', 'want', 'to', 'see', 'all', 'of', 'you', '...']\n",
      "AFter tokenizer:  ['you', 'have', 'won', 'a', 'guaranteed', '£1000', 'cash', 'or', 'a', '£2000', 'prize', '.', 'to', 'claim', 'yr', 'prize', 'call', 'our', 'customer', 'service', 'representative', 'on', '08714712379', 'between', '10am-7pm', 'cost', '10p']\n",
      "AFter tokenizer:  ['but', 'really', 'quite', 'funny', 'lor', 'wat', '...', 'then', 'u', 'shd', 'haf', 'run', 'shorter', 'distance', 'wat', '...']\n",
      "AFter tokenizer:  ['i', 'notice', 'you', 'like', 'looking', 'in', 'the', 'shit', 'mirror', 'youre', 'turning', 'into', 'a', 'right', 'freak']\n",
      "AFter tokenizer:  ['great', '.', 'i', 'was', 'getting', 'worried', 'about', 'you', '.', 'just', 'know', 'that', 'a', 'wonderful', 'and', 'caring', 'person', 'like', 'you', 'will', 'have', 'only', 'the', 'best', 'in', 'life', '.', 'know', 'that', 'u', 'r', 'wonderful', 'and', 'god', \"'s\", 'love', 'is', 'yours', '.']\n",
      "AFter tokenizer:  ['thanks', 'for', 'your', 'ringtone', 'order', ',', 'ref', 'number', 'k718', '.', 'your', 'mobile', 'will', 'be', 'charged', '£4.50', '.', 'should', 'your', 'tone', 'not', 'arrive', 'please', 'call', 'customer', 'services', 'on', '09065069120']\n",
      "AFter tokenizer:  ['i', 'prefer', 'my', 'free', 'days', '...', 'tues', ',', 'wed', ',', 'fri', 'oso', 'can', '...', 'ü', 'ask', 'those', 'workin', 'lor', '...']\n",
      "AFter tokenizer:  ['alrite', 'jod', 'hows', 'the', 'revision', 'goin', '?', 'keris', 'bin', 'doin', 'a', 'smidgin', '.', 'n', 'e', 'way', 'u', 'wan', 'na', 'cum', 'over', 'after', 'college', '?', 'xx']\n",
      "AFter tokenizer:  ['if', 'you', 'have', 'belive', 'me', '.', 'come', 'to', 'my', 'home', '.']\n",
      "AFter tokenizer:  ['oh', 'k.k', '..', 'where', 'did', 'you', 'take', 'test', '?']\n",
      "AFter tokenizer:  ['those', 'were', 'my', 'exact', 'intentions']\n",
      "AFter tokenizer:  ['haha', 'but', 'no', 'money', 'leh', '...', 'later', 'got', 'to', 'go', 'for', 'tuition', '...', 'haha', 'and', 'looking', 'for', 'empty', 'slots', 'for', 'driving', 'lessons']\n",
      "AFter tokenizer:  ['hey', '...', 'thk', 'we', 'juz', 'go', 'accordin', 'to', 'wat', 'we', 'discussed', 'yest', 'lor', ',', 'except', 'no', 'kb', 'on', 'sun', '...', 'cos', 'there', \"'s\", 'nt', 'much', 'lesson', 'to', 'go', 'if', 'we', 'attend', 'kb', 'on', 'sat', '...']\n",
      "AFter tokenizer:  ['k', ',', 'wen', 'ur', 'free', 'come', 'to', 'my', 'home', 'and', 'also', 'tel', 'vikky', 'i', 'hav', 'sent', 'mail', 'to', 'him', 'also', '..', 'better', 'come', 'evening', 'il', 'be', 'free', 'today', 'aftr', '6pm', '..', ':', '-', ')']\n",
      "AFter tokenizer:  ['nothing', 'just', 'getting', 'msgs', 'by', 'dis', 'name', 'wit', 'different', 'no', \"'s\", '..']\n",
      "AFter tokenizer:  ['what', \"'s\", 'your', 'room', 'number', 'again', '?', 'wan', 'na', 'make', 'sure', 'i', \"'m\", 'knocking', 'on', 'the', 'right', 'door']\n",
      "AFter tokenizer:  ['si.como', 'no', '?', '!', 'listened2the', 'plaid', 'album-quite', 'gd', '&', 'the', 'new', 'air1', 'which', 'is', 'hilarious-also', 'bought\\x94braindance\\x94a', 'comp.ofstuff', 'on', 'aphex\\x92s', ';', 'abel', ',', 'u', 'hav2hear', 'it', '!', 'c', 'u', 'sn', 'xxxx']\n",
      "AFter tokenizer:  ['pls', 'tell', 'nelson', 'that', 'the', 'bb', \"'s\", 'are', 'no', 'longer', 'comin', '.', 'the', 'money', 'i', 'was', 'expecting', 'aint', 'coming']\n",
      "AFter tokenizer:  ['give', 'her', 'something', 'to', 'drink', ',', 'if', 'she', 'takes', 'it', 'and', 'does', \"n't\", 'vomit', 'then', 'you', 'her', 'temp', 'might', 'drop', '.', 'if', 'she', 'unmits', 'however', 'let', 'me', 'know', '.']\n",
      "AFter tokenizer:  ['think', 'you', 'sent', 'the', 'text', 'to', 'the', 'home', 'phone', '.', 'that', 'cant', 'display', 'texts', '.', 'if', 'you', 'still', 'want', 'to', 'send', 'it', 'his', 'number', 'is']\n",
      "AFter tokenizer:  ['every', 'day', 'i', 'use', 'to', 'sleep', 'after', '&', 'lt', ';', '#', '&', 'gt', ';', 'so', 'only', '.']\n",
      "AFter tokenizer:  ['k', 'i', \"'ll\", 'call', 'you', 'when', 'i', \"'m\", 'close']\n",
      "AFter tokenizer:  ['u', 'buy', 'newspapers', 'already', '?']\n",
      "AFter tokenizer:  ['nope', 'wif', 'my', 'sis', 'lor', '...', 'aft', 'bathing', 'my', 'dog', 'then', 'i', 'can', 'bathe', '...', 'looks', 'like', 'it', \"'s\", 'going', '2', 'rain', 'soon', '.']\n",
      "AFter tokenizer:  ['boo', 'i', \"'m\", 'on', 'my', 'way', 'to', 'my', 'moms', '.', 'she', \"'s\", 'making', 'tortilla', 'soup', '.', 'yummmm']\n",
      "AFter tokenizer:  ['no', 'management', 'puzzeles', '.']\n",
      "AFter tokenizer:  ['how', 'did', 'you', 'find', 'out', 'in', 'a', 'way', 'that', 'did', \"n't\", 'include', 'all', 'of', 'these', 'details']\n",
      "AFter tokenizer:  ['hi', 'ya', 'babe', 'x', 'u', '4goten', 'bout', 'me', '?', \"'\", 'scammers', 'getting', 'smart', '..', 'though', 'this', 'is', 'a', 'regular', 'vodafone', 'no', ',', 'if', 'you', 'respond', 'you', 'get', 'further', 'prem', 'rate', 'msg/subscription', '.', 'other', 'nos', 'used', 'also', '.', 'beware', '!']\n",
      "AFter tokenizer:  ['back', '2', 'work', '2morro', 'half', 'term', 'over', '!', 'can', 'u', 'c', 'me', '2nite', '4', 'some', 'sexy', 'passion', 'b4', 'i', 'have', '2', 'go', 'back', '?', 'chat', 'now', '09099726481', 'luv', 'dena', 'calls', '£1/minmobsmorelkpobox177hp51fl']\n",
      "AFter tokenizer:  ['will', 'you', 'like', 'to', 'be', 'spoiled', '?', ':', ')']\n",
      "AFter tokenizer:  ['thanks', 'for', 'your', 'ringtone', 'order', ',', 'ref', 'number', 'r836', '.', 'your', 'mobile', 'will', 'be', 'charged', '£4.50', '.', 'should', 'your', 'tone', 'not', 'arrive', 'please', 'call', 'customer', 'services', 'on', '09065069154']\n",
      "AFter tokenizer:  ['i', 'am', 'getting', 'threats', 'from', 'your', 'sales', 'executive', 'shifad', 'as', 'i', 'raised', 'complaint', 'against', 'him', '.', 'its', 'an', 'official', 'message', '.']\n",
      "AFter tokenizer:  ['hope', 'things', 'went', 'well', 'at', \"'doctors\", \"'\", ';', ')', 'reminds', 'me', 'i', 'still', 'need', '2go.did', 'u', 'c', 'd', 'little', 'thing', 'i', 'left', 'in', 'the', 'lounge', '?']\n",
      "AFter tokenizer:  ['den', 'wat', 'will', 'e', 'schedule', 'b', 'lk', 'on', 'sun', '?']\n",
      "AFter tokenizer:  ['lol', 'enjoy', 'role', 'playing', 'much', '?']\n",
      "AFter tokenizer:  ['ok.', 'me', 'watching', 'tv', 'too', '.']\n",
      "AFter tokenizer:  ['i', 'just', 'lov', 'this', 'line', ':', '``', 'hurt', 'me', 'with', 'the', 'truth', ',', 'i', 'do', \"n't\", 'mind', ',', 'i', 'wil', 'tolerat.bcs', 'ur', 'my', 'someone', '.....', 'but', ',', 'never', 'comfort', 'me', 'with', 'a', 'lie', \"''\", 'gud', 'ni8', 'and', 'sweet', 'dreams']\n",
      "AFter tokenizer:  ['just', 'checked', 'out', ',', 'heading', 'out', 'to', 'drop', 'off', 'my', 'stuff', 'now']\n",
      "AFter tokenizer:  ['here', 'got', 'lots', 'of', 'hair', 'dresser', 'fr', 'china', '.']\n",
      "AFter tokenizer:  ['sad', 'story', 'of', 'a', 'man', '-', 'last', 'week', 'was', 'my', \"b'day\", '.', 'my', 'wife', \"did'nt\", 'wish', 'me', '.', 'my', 'parents', 'forgot', 'n', 'so', 'did', 'my', 'kids', '.', 'i', 'went', 'to', 'work', '.', 'even', 'my', 'colleagues', 'did', 'not', 'wish', '.']\n",
      "AFter tokenizer:  ['ill', 'call', 'you', 'evening', 'ill', 'some', 'ideas', '.']\n",
      "AFter tokenizer:  ['splashmobile', ':', 'choose', 'from', '1000s', 'of', 'gr8', 'tones', 'each', 'wk', '!', 'this', 'is', 'a', 'subscrition', 'service', 'with', 'weekly', 'tones', 'costing', '300p', '.', 'u', 'have', 'one', 'credit', '-', 'kick', 'back', 'and', 'enjoy']\n",
      "AFter tokenizer:  ['did', 'you', 'show', 'him', 'and', 'wot', 'did', 'he', 'say', 'or', 'could', 'u', 'not', 'c', 'him', '4', 'dust', '?']\n",
      "AFter tokenizer:  ['it', 'should', 'take', 'about', '&', 'lt', ';', '#', '&', 'gt', ';', 'min']\n",
      "AFter tokenizer:  ['not', 'heard', 'from', 'u4', 'a', 'while', '.', 'call', '4', 'rude', 'chat', 'private', 'line', '01223585334', 'to', 'cum', '.', 'wan', '2c', 'pics', 'of', 'me', 'gettin', 'shagged', 'then', 'text', 'pix', 'to', '8552', '.', '2end', 'send', 'stop', '8552', 'sam', 'xxx']\n",
      "AFter tokenizer:  ['<', 'forwarded', 'from', '88877', '>', 'free', 'entry', 'into', 'our', '£250', 'weekly', 'comp', 'just', 'send', 'the', 'word', 'enter', 'to', '88877', 'now', '.', '18', 't', '&', 'c', 'www.textcomp.com']\n",
      "AFter tokenizer:  ['finish', 'liao', '...', 'u', '?']\n",
      "AFter tokenizer:  ['88066', 'from', '88066', 'lost', '3pound', 'help']\n",
      "AFter tokenizer:  ['haha', 'i', 'think', 'i', 'did', 'too']\n",
      "AFter tokenizer:  ['u', 'know', 'we', 'watchin', 'at', 'lido', '?']\n",
      "AFter tokenizer:  ['life', 'spend', 'with', 'someone', 'for', 'a', 'lifetime', 'may', 'be', 'meaningless', 'but', 'a', 'few', 'moments', 'spent', 'with', 'someone', 'who', 'really', 'love', 'you', 'means', 'more', 'than', 'life', 'itself', '..']\n",
      "AFter tokenizer:  ['haha', 'awesome', ',', 'i', \"'ve\", 'been', 'to', '4u', 'a', 'couple', 'times', '.', 'who', 'all', \"'s\", 'coming', '?']\n",
      "AFter tokenizer:  ['cold', '.', 'dont', 'be', 'sad', 'dear']\n",
      "AFter tokenizer:  ['think', 'i', 'could', 'stop', 'by', 'in', 'like', 'an', 'hour', 'or', 'so', '?', 'my', 'roommate', \"'s\", 'looking', 'to', 'stock', 'up', 'for', 'a', 'trip']\n",
      "AFter tokenizer:  ['is', 'that', 'on', 'the', 'telly', '?', 'no', 'its', 'brdget', 'jones', '!']\n",
      "AFter tokenizer:  ['hello', '!', 'how', 'r', 'u', '?', 'im', 'bored', '.', 'inever', 'thought', 'id', 'get', 'bored', 'with', 'the', 'tv', 'but', 'i', 'am', '.', 'tell', 'me', 'something', 'exciting', 'has', 'happened', 'there', '?', 'anything', '!', '=/']\n",
      "AFter tokenizer:  ['hmm', '...', 'bad', 'news', '...', 'hype', 'park', 'plaza', '$', '700', 'studio', 'taken', '...', 'only', 'left', '2', 'bedrm-', '$', '900', '...']\n",
      "AFter tokenizer:  ['sorry', ',', 'i', \"'ll\", 'call', 'later', 'in', 'meeting']\n",
      "AFter tokenizer:  ['r', 'ü', 'comin', 'back', 'for', 'dinner', '?']\n",
      "AFter tokenizer:  ['i', 'hav', 'almost', 'reached', '.', 'call', ',', 'i', 'm', 'unable', 'to', 'connect', 'u', '.']\n",
      "AFter tokenizer:  ['whom', 'you', 'waited', 'for', 'yesterday']\n",
      "AFter tokenizer:  ['i', 'reach', 'home', 'safe', 'n', 'sound', 'liao', '...']\n",
      "AFter tokenizer:  ['velly', 'good', ',', 'yes', 'please', '!']\n",
      "AFter tokenizer:  ['hi', ',', 'wkend', 'ok', 'but', 'journey', 'terrible', '.', 'wk', 'not', 'good', 'as', 'have', 'huge', 'back', 'log', 'of', 'marking', 'to', 'do']\n",
      "AFter tokenizer:  ['i', 'have', 'had', 'two', 'more', 'letters', 'from', '.', 'i', 'will', 'copy', 'them', 'for', 'you', 'cos', 'one', 'has', 'a', 'message', 'for', 'you', '.', 'speak', 'soon']\n",
      "AFter tokenizer:  ['alex', 'knows', 'a', 'guy', 'who', 'sells', 'mids', 'but', 'he', \"'s\", 'down', 'in', 'south', 'tampa', 'and', 'i', 'do', \"n't\", 'think', 'i', 'could', 'set', 'it', 'up', 'before', 'like', '8']\n",
      "AFter tokenizer:  ['dont', 'you', 'have', 'message', 'offer']\n",
      "AFter tokenizer:  ['had', 'your', 'mobile', '11mths', '?', 'update', 'for', 'free', 'to', 'oranges', 'latest', 'colour', 'camera', 'mobiles', '&', 'unlimited', 'weekend', 'calls', '.', 'call', 'mobile', 'upd8', 'on', 'freefone', '08000839402', 'or', '2stoptx']\n",
      "AFter tokenizer:  ['hey', 'there', 'babe', ',', 'how', 'u', 'doin', '?', 'wot', 'u', 'up', '2', '2nite', 'love', 'annie', 'x', '.']\n",
      "AFter tokenizer:  ['remind', 'me', 'how', 'to', 'get', 'there', 'and', 'i', 'shall', 'do', 'so']\n",
      "AFter tokenizer:  [':', '-', '(', 'that', \"'s\", 'not', 'v', 'romantic', '!']\n",
      "AFter tokenizer:  ['hello', '.', 'damn', 'this', 'christmas', 'thing', '.', 'i', 'think', 'i', 'have', 'decided', 'to', 'keep', 'this', 'mp3', 'that', 'doesnt', 'work', '.']\n",
      "AFter tokenizer:  ['you', 'have', '1', 'new', 'message', '.', 'please', 'call', '08718738034', '.']\n",
      "AFter tokenizer:  ['hi', 'darlin', 'im', 'missin', 'u', 'hope', 'you', 'are', 'having', 'a', 'good', 'time', '.', 'when', 'are', 'u', 'back', 'and', 'what', 'time', 'if', 'u', 'can', 'give', 'me', 'a', 'call', 'at', 'home', '.', 'jess', 'xx']\n",
      "AFter tokenizer:  ['<', 'forwarded', 'from', '21870000', '>', 'hi', '-', 'this', 'is', 'your', 'mailbox', 'messaging', 'sms', 'alert', '.', 'you', 'have', '4', 'messages', '.', 'you', 'have', '21', 'matches', '.', 'please', 'call', 'back', 'on', '09056242159', 'to', 'retrieve', 'your', 'messages', 'and', 'matches']\n",
      "AFter tokenizer:  ['draw', 'va', '?', 'i', 'dont', 'think', 'so', ':', ')']\n",
      "AFter tokenizer:  ['dont', 'pick', 'up', 'd', 'call', 'when', 'something', 'important', 'is', 'there', 'to', 'tell', '.', 'hrishi']\n",
      "AFter tokenizer:  ['nothin', 'comes', 'to', 'my', 'mind', '.', 'ü', 'help', 'me', 'buy', 'hanger', 'lor', '.', 'ur', 'laptop', 'not', 'heavy', '?']\n",
      "AFter tokenizer:  ['&', 'lt', ';', '#', '&', 'gt', ';', ',', 'that', \"'s\", 'all', '?', 'guess', 'that', \"'s\", 'easy', 'enough']\n",
      "AFter tokenizer:  ['we', 'can', 'make', 'a', 'baby', 'in', 'yo', 'tho']\n",
      "AFter tokenizer:  ['should', 'i', 'tell', 'my', 'friend', 'not', 'to', 'come', 'round', 'til', 'like', '&', 'lt', ';', '#', '&', 'gt', ';', 'ish', '?']\n",
      "AFter tokenizer:  ['friendship', 'poem', ':', 'dear', 'o', 'dear', 'u', 'r', 'not', 'near', 'but', 'i', 'can', 'hear', 'dont', 'get', 'fear', 'live', 'with', 'cheer', 'no', 'more', 'tear', 'u', 'r', 'always', 'my', 'dear', '.', 'gud', 'ni8']\n",
      "AFter tokenizer:  ['still', 'in', 'the', 'area', 'of', 'the', 'restaurant', '.', 'ill', 'try', 'to', 'come', 'back', 'soon']\n",
      "AFter tokenizer:  ['aight', 'that', \"'ll\", 'work', ',', 'thanks']\n",
      "AFter tokenizer:  ['moby', 'pub', 'quiz.win', 'a', '£100', 'high', 'street', 'prize', 'if', 'u', 'know', 'who', 'the', 'new', 'duchess', 'of', 'cornwall', 'will', 'be', '?', 'txt', 'her', 'first', 'name', 'to', '82277.unsub', 'stop', '£1.50', '008704050406', 'sp', 'arrow']\n",
      "AFter tokenizer:  ['i', 'have', '2', 'sleeping', 'bags', ',', '1', 'blanket', 'and', 'paper', 'and', 'phone', 'details', '.', 'anything', 'else', '?']\n",
      "AFter tokenizer:  ['congratulations', '!', 'thanks', 'to', 'a', 'good', 'friend', 'u', 'have', 'won', 'the', '£2,000', 'xmas', 'prize', '.', '2', 'claim', 'is', 'easy', ',', 'just', 'call', '08718726971', 'now', '!', 'only', '10p', 'per', 'minute', '.', 'bt-national-rate', '.']\n",
      "AFter tokenizer:  ['tddnewsletter', '@', 'emc1.co.uk', '(', 'more', 'games', 'from', 'thedailydraw', ')', 'dear', 'helen', ',', 'dozens', 'of', 'free', 'games', '-', 'with', 'great', 'prizeswith', '..']\n",
      "AFter tokenizer:  ['so', 'what', 'do', 'you', 'guys', 'do', '.']\n",
      "AFter tokenizer:  ['also', 'that', 'chat', 'was', 'awesome', 'but', 'do', \"n't\", 'make', 'it', 'regular', 'unless', 'you', 'can', 'see', 'her', 'in', 'person']\n",
      "AFter tokenizer:  ['that', \"'s\", 'significant', 'but', 'dont', 'worry', '.']\n",
      "AFter tokenizer:  ['that', \"'s\", 'cause', 'your', 'old', '.', 'i', 'live', 'to', 'be', 'high', '.']\n",
      "AFter tokenizer:  ['waqt', 'se', 'pehle', 'or', 'naseeb', 'se', 'zyada', 'kisi', 'ko', 'kuch', 'nahi', 'milta', ',', 'zindgi', 'wo', 'nahi', 'he', 'jo', 'hum', 'sochte', 'hai', 'zindgi', 'wo', 'hai', 'jo', 'ham', 'jeetey', 'hai', '..........']\n",
      "AFter tokenizer:  ['on', 'the', 'way', 'to', 'office', 'da', '..']\n",
      "AFter tokenizer:  ['in', 'which', 'place', 'do', 'you', 'want', 'da', '.']\n",
      "AFter tokenizer:  ['this', 'pain', 'could', \"n't\", 'have', 'come', 'at', 'a', 'worse', 'time', '.']\n",
      "AFter tokenizer:  ['should', 'i', 'be', 'stalking', 'u', '?']\n",
      "AFter tokenizer:  ['sorry', 'dude', '.', 'dont', 'know', 'how', 'i', 'forgot', '.', 'even', 'after', 'dan', 'reminded', 'me', '.', 'sorry', '.', 'hope', 'you', 'guys', 'had', 'fun', '.']\n",
      "AFter tokenizer:  ['ok', 'lor', '.']\n",
      "AFter tokenizer:  ['apps', 'class', 'varaya', 'elaya', '.']\n",
      "AFter tokenizer:  ['urgent', '!', 'your', 'mobile', 'number', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', 'won', 'a', '£2000', 'bonus', 'caller', 'prize', 'on', '10/06/03', '!', 'this', 'is', 'the', '2nd', 'attempt', 'to', 'reach', 'you', '!', 'call', '09066368753', 'asap', '!', 'box', '97n7qp', ',', '150ppm']\n",
      "AFter tokenizer:  ['that', 'day', 'you', 'asked', 'about', 'anand', 'number', '.', 'why', ':', '-', ')']\n",
      "AFter tokenizer:  ['am', 'surfing', 'online', 'store', '.', 'for', 'offers', 'do', 'you', 'want', 'to', 'buy', 'any', 'thing', '.']\n",
      "AFter tokenizer:  ['long', 'beach', 'lor', '.', 'expected', '...', 'u', 'having', 'dinner', 'now', '?']\n",
      "AFter tokenizer:  ['at', 'home', 'by', 'the', 'way']\n",
      "AFter tokenizer:  ['we', 'are', 'both', 'fine', '.', 'thanks']\n",
      "AFter tokenizer:  ['what', 'happen', 'to', 'her', 'tell', 'the', 'truth']\n",
      "AFter tokenizer:  ['do', 'you', 'like', 'italian', 'food', '?']\n",
      "AFter tokenizer:  ['which', 'is', 'weird', 'because', 'i', 'know', 'i', 'had', 'it', 'at', 'one', 'point']\n",
      "AFter tokenizer:  ['aww', 'you', 'must', 'be', 'nearly', 'dead', '!', 'well', 'jez', 'iscoming', 'over', 'todo', 'some', 'workand', 'that', 'whilltake', 'forever', '!']\n",
      "AFter tokenizer:  ['tell', 'your', 'friends', 'what', 'you', 'plan', 'to', 'do', 'on', 'valentines', 'day', '@', '&', 'lt', ';', 'url', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['alright', ',', 'see', 'you', 'in', 'a', 'bit']\n",
      "AFter tokenizer:  ['cheers', 'for', 'the', 'message', 'zogtorius', '.', 'i\\x92ve', 'been', 'staring', 'at', 'my', 'phone', 'for', 'an', 'age', 'deciding', 'whether', 'to', 'text', 'or', 'not', '.']\n",
      "AFter tokenizer:  ['i', 'will', 'take', 'care', 'of', 'financial', 'problem.i', 'will', 'help', ':', ')']\n",
      "AFter tokenizer:  ['tell', 'dear', 'what', 'happen', 'to', 'you', '.', 'why', 'you', 'talking', 'to', 'me', 'like', 'an', 'alian']\n",
      "AFter tokenizer:  ['double', 'your', 'mins', '&', 'txts', 'on', 'orange', 'or', '1/2', 'price', 'linerental', '-', 'motorola', 'and', 'sonyericsson', 'with', 'b/tooth', 'free-nokia', 'free', 'call', 'mobileupd8', 'on', '08000839402', 'or2optout/hv9d']\n",
      "AFter tokenizer:  ['hi', 'this', 'is', 'yijue', ',', 'can', 'i', 'meet', 'u', 'at', '11', 'tmr', '?']\n",
      "AFter tokenizer:  ['its', 'posible', 'dnt', 'live', 'in', '&', 'lt', ';', '#', '&', 'gt', ';', 'century', 'cm', 'frwd', 'n', 'thnk', 'different']\n",
      "AFter tokenizer:  ['but', 'i', 'dint', 'slept', 'in', 'afternoon', '.']\n",
      "AFter tokenizer:  ['that', 'seems', 'unnecessarily', 'affectionate']\n",
      "AFter tokenizer:  ['yar', 'else', 'i', \"'ll\", 'thk', 'of', 'all', 'sorts', 'of', 'funny', 'things', '.']\n",
      "AFter tokenizer:  ['download', 'as', 'many', 'ringtones', 'as', 'u', 'like', 'no', 'restrictions', ',', '1000s', '2', 'choose', '.', 'u', 'can', 'even', 'send', '2', 'yr', 'buddys', '.', 'txt', 'sir', 'to', '80082', '£3']\n",
      "AFter tokenizer:  ['thats', 'cool', '.', 'how', 'was', 'your', 'day', '?']\n",
      "AFter tokenizer:  ['please', 'call', '08712402902', 'immediately', 'as', 'there', 'is', 'an', 'urgent', 'message', 'waiting', 'for', 'you', '.']\n",
      "AFter tokenizer:  ['r', 'we', 'going', 'with', 'the', '&', 'lt', ';', '#', '&', 'gt', ';', 'bus', '?']\n",
      "AFter tokenizer:  ['hello', ',', 'my', 'love', '!', 'how', 'went', 'your', 'day', '?', 'are', 'you', 'alright', '?', 'i', 'think', 'of', 'you', ',', 'my', 'sweet', 'and', 'send', 'a', 'jolt', 'to', 'your', 'heart', 'to', 'remind', 'you', '...', 'i', 'love', 'you', '!', 'can', 'you', 'hear', 'it', '?', 'i', 'screamed', 'it', 'across', 'the', 'sea', 'for', 'all', 'the', 'world', 'to', 'hear', '.', 'ahmad', 'al', 'hallaq', 'is', 'loved', '!', 'and', 'owned', '!', '*', 'possessive', 'passionate', 'kiss', '*']\n",
      "AFter tokenizer:  ['no', '..', 'he', 'joined', 'today', 'itself', '.']\n",
      "AFter tokenizer:  ['okay', 'same', 'with', 'me', '.', 'well', 'thanks', 'for', 'the', 'clarification']\n",
      "AFter tokenizer:  ['i', \"'ll\", 'talk', 'to', 'the', 'others', 'and', 'probably', 'just', 'come', 'early', 'tomorrow', 'then']\n",
      "AFter tokenizer:  ['spook', 'up', 'your', 'mob', 'with', 'a', 'halloween', 'collection', 'of', 'a', 'logo', '&', 'pic', 'message', 'plus', 'a', 'free', 'eerie', 'tone', ',', 'txt', 'card', 'spook', 'to', '8007', 'zed', '08701417012150p', 'per', 'logo/pic']\n",
      "AFter tokenizer:  ['had', 'the', 'money', 'issue', 'weigh', 'me', 'down', 'but', 'thanks', 'to', 'you', ',', 'i', 'can', 'breathe', 'easier', 'now', '.', 'i.ll', 'make', 'sure', 'you', 'dont', 'regret', 'it', '.', 'thanks', '.']\n",
      "AFter tokenizer:  ['hi', '.', 'i', \"'m\", 'sorry', 'i', 'missed', 'your', 'call', '.', 'can', 'you', 'pls', 'call', 'back', '.']\n",
      "AFter tokenizer:  ['fantasy', 'football', 'is', 'back', 'on', 'your', 'tv', '.', 'go', 'to', 'sky', 'gamestar', 'on', 'sky', 'active', 'and', 'play', '£250k', 'dream', 'team', '.', 'scoring', 'starts', 'on', 'saturday', ',', 'so', 'register', 'now', '!', 'sky', 'opt', 'out', 'to', '88088']\n",
      "AFter tokenizer:  ['ok', 'then', 'no', 'need', 'to', 'tell', 'me', 'anything', 'i', 'am', 'going', 'to', 'sleep', 'good', 'night']\n",
      "AFter tokenizer:  ['ok', 'try', 'to', 'do', 'week', 'end', 'course', 'in', 'coimbatore', '.']\n",
      "AFter tokenizer:  ['tone', 'club', ':', 'your', 'subs', 'has', 'now', 'expired', '2', 're-sub', 'reply', 'monoc', '4', 'monos', 'or', 'polyc', '4', 'polys', '1', 'weekly', '@', '150p', 'per', 'week', 'txt', 'stop', '2', 'stop', 'this', 'msg', 'free', 'stream', '0871212025016']\n",
      "AFter tokenizer:  ['v', 'nice', '!', 'off', '2', 'sheffield', 'tom', '2', 'air', 'my', 'opinions', 'on', 'categories', '2', 'b', 'used', '2', 'measure', 'ethnicity', 'in', 'next', 'census', '.', 'busy', 'transcribing', '.', ':', '-', ')']\n",
      "AFter tokenizer:  ['if', 'you', 'r', '@', 'home', 'then', 'come', 'down', 'within', '5', 'min']\n",
      "AFter tokenizer:  ['a', 'boy', 'loved', 'a', 'gal', '.', 'he', 'propsd', 'bt', 'she', 'didnt', 'mind', '.', 'he', 'gv', 'lv', 'lttrs', ',', 'bt', 'her', 'frnds', 'threw', 'thm', '.', 'again', 'd', 'boy', 'decided', '2', 'aproach', 'd', 'gal', ',', 'dt', 'time', 'a', 'truck', 'was', 'speeding', 'towards', 'd', 'gal', '.', 'wn', 'it', 'was', 'about', '2', 'hit', 'd', 'girl', ',', 'd', 'boy', 'ran', 'like', 'hell', 'n', 'saved', 'her', '.', 'she', 'asked', \"'hw\", 'cn', 'u', 'run', 'so', 'fast', '?', \"'\", 'd', 'boy', 'replied', '``', 'boost', 'is', 'd', 'secret', 'of', 'my', 'energy', \"''\", 'n', 'instantly', 'd', 'girl', 'shouted', '``', 'our', 'energy', \"''\", 'n', 'thy', 'lived', 'happily', '2gthr', 'drinking', 'boost', 'evrydy', 'moral', 'of', 'd', 'story', ':', '-', 'i', 'hv', 'free', 'msgs', ':', 'd', ';', ')', ':', 'gud', 'ni8']\n",
      "AFter tokenizer:  ['that', 'day', 'ü', 'say', 'ü', 'cut', 'ur', 'hair', 'at', 'paragon', ',', 'is', 'it', 'called', 'hair', 'sense', '?', 'do', 'ü', 'noe', 'how', 'much', 'is', 'a', 'hair', 'cut', '?']\n",
      "AFter tokenizer:  ['hmm', ',', 'too', 'many', 'of', 'them', 'unfortunately', '...', 'pics', 'obviously', 'arent', 'hot', 'cakes', '.', 'its', 'kinda', 'fun', 'tho']\n",
      "AFter tokenizer:  ['watching', 'tv', 'lor', '...', 'y', 'she', 'so', 'funny', 'we', 'bluff', 'her', '4', 'wat', '.', 'izzit', 'because', 'she', 'thk', 'it', \"'s\", 'impossible', 'between', 'us', '?']\n",
      "AFter tokenizer:  ['xmas', 'prize', 'draws', '!', 'we', 'are', 'trying', 'to', 'contact', 'u.', 'todays', 'draw', 'shows', 'that', 'you', 'have', 'won', 'a', '£2000', 'prize', 'guaranteed', '.', 'call', '09058094565', 'from', 'land', 'line', '.', 'valid', '12hrs', 'only']\n",
      "AFter tokenizer:  ['dunno', 'lei', 'he', 'neva', 'say', '...']\n",
      "AFter tokenizer:  ['thanx', '4', '2day', '!', 'u', 'r', 'a', 'goodmate', 'i', 'think', 'ur', 'rite', 'sary', '!', 'asusual', '!', '1', 'u', 'cheered', 'me', 'up', '!', 'love', 'u', 'franyxxxxx']\n",
      "AFter tokenizer:  ['i', \"'m\", 'on', 'my', 'way', 'home', '.', 'went', 'to', 'change', 'batt', '4', 'my', 'watch', 'then', 'go', 'shop', 'a', 'bit', 'lor', '.']\n",
      "AFter tokenizer:  ['yes', '!', 'the', 'only', 'place', 'in', 'town', 'to', 'meet', 'exciting', 'adult', 'singles', 'is', 'now', 'in', 'the', 'uk', '.', 'txt', 'chat', 'to', '86688', 'now', '!', '150p/msg', '.']\n",
      "AFter tokenizer:  ['hi', ',', 'mobile', 'no', '.', '&', 'lt', ';', '#', '&', 'gt', ';', 'has', 'added', 'you', 'in', 'their', 'contact', 'list', 'on', 'www.fullonsms.com', 'it', 's', 'a', 'great', 'place', 'to', 'send', 'free', 'sms', 'to', 'people', 'for', 'more', 'visit', 'fullonsms.com']\n",
      "AFter tokenizer:  ['good', 'evening', 'sir', ',', 'hope', 'you', 'are', 'having', 'a', 'nice', 'day', '.', 'i', 'wanted', 'to', 'bring', 'it', 'to', 'your', 'notice', 'that', 'i', 'have', 'been', 'late', 'in', 'paying', 'rent', 'for', 'the', 'past', 'few', 'months', 'and', 'have', 'had', 'to', 'pay', 'a', '$', '&', 'lt', ';', '#', '&', 'gt', ';', 'charge', '.', 'i', 'felt', 'it', 'would', 'be', 'inconsiderate', 'of', 'me', 'to', 'nag', 'about', 'something', 'you', 'give', 'at', 'great', 'cost', 'to', 'yourself', 'and', 'that', \"'s\", 'why', 'i', 'didnt', 'speak', 'up', '.', 'i', 'however', 'am', 'in', 'a', 'recession', 'and', 'wont', 'be', 'able', 'to', 'pay', 'the', 'charge', 'this', 'month', 'hence', 'my', 'askin', 'well', 'ahead', 'of', 'month', \"'s\", 'end', '.', 'can', 'you', 'please', 'help', '.', 'thank', 'you', 'for', 'everything', '.']\n",
      "AFter tokenizer:  ['if', 'i', 'let', 'you', 'do', 'this', ',', 'i', 'want', 'you', 'in', 'the', 'house', 'by', '8am', '.']\n",
      "AFter tokenizer:  ['best', 'line', 'said', 'in', 'love', ':', '.', '``', 'i', 'will', 'wait', 'till', 'the', 'day', 'i', 'can', 'forget', 'u', 'or', 'the', 'day', 'u', 'realize', 'that', 'u', 'can', 'not', 'forget', 'me.', \"''\", '...', 'gn']\n",
      "AFter tokenizer:  ['i', 'will', 'reach', 'before', 'ten', 'morning']\n",
      "AFter tokenizer:  ['your', 'pussy', 'is', 'perfect', '!']\n",
      "AFter tokenizer:  ['someone', 'has', 'contacted', 'our', 'dating', 'service', 'and', 'entered', 'your', 'phone', 'becausethey', 'fancy', 'you', '!', 'to', 'find', 'out', 'who', 'it', 'is', 'call', 'from', 'a', 'landline', '09058098002.', 'pobox1', ',', 'w14rg', '150p']\n",
      "AFter tokenizer:  ['no', 'message', '..', 'no', 'responce', '..', 'what', 'happend', '?']\n",
      "AFter tokenizer:  ['also', 'where', \"'s\", 'the', 'piece']\n",
      "AFter tokenizer:  ['wiskey', 'brandy', 'rum', 'gin', 'beer', 'vodka', 'scotch', 'shampain', 'wine', '``', 'kudi', \"''\", 'yarasu', 'dhina', 'vaazhthukkal', '.', '..']\n",
      "AFter tokenizer:  ['boo', '.', 'how', \"'s\", 'things', '?', 'i', \"'m\", 'back', 'at', 'home', 'and', 'a', 'little', 'bored', 'already', ':', '-', '(']\n",
      "AFter tokenizer:  ['first', 'has', 'she', 'gained', 'more', 'than', '&', 'lt', ';', '#', '&', 'gt', ';', 'kg', 'since', 'she', 'took', 'in', '.', 'second', 'has', 'she', 'done', 'the', 'blood', 'sugar', 'tests', '.', 'if', 'she', 'has', 'and', 'its', 'ok', 'and', 'her', 'blood', 'pressure', 'is', 'within', 'normal', 'limits', 'then', 'no', 'worries']\n",
      "AFter tokenizer:  ['pick', 'ur', 'fone', 'up', 'now', 'u', 'dumb', '?']\n",
      "AFter tokenizer:  ['thanks', 'da', 'thangam', ',', 'i', 'feel', 'very', 'very', 'happy', 'dear', '.', 'i', 'also', 'miss', 'you', 'da', '.']\n",
      "AFter tokenizer:  ['okey', 'doke', '.', 'i', \"'m\", 'at', 'home', ',', 'but', 'not', 'dressed', 'cos', 'laying', 'around', 'ill', '!', 'speak', 'to', 'you', 'later', 'bout', 'times', 'and', 'stuff', '.']\n",
      "AFter tokenizer:  ['i', 'do', \"n't\", 'run', 'away', 'frm', 'u', '...', 'i', 'walk', 'slowly', '&', 'amp', ';', 'it', 'kills', 'me', 'that', 'u', 'do', \"n't\", 'care', 'enough', 'to', 'stop', 'me', '...']\n",
      "AFter tokenizer:  ['babe', ',', 'i', \"'m\", 'back', '...', 'come', 'back', 'to', 'me', '...']\n",
      "AFter tokenizer:  ['well', 'you', 'told', 'others', 'you', \"'d\", 'marry', 'them', '...']\n",
      "AFter tokenizer:  ['neshanth', '..', 'tel', 'me', 'who', 'r', 'u', '?']\n",
      "AFter tokenizer:  ['yo', 'yo', 'yo', 'byatch', 'whassup', '?']\n",
      "AFter tokenizer:  ['oh', '...', 'kay', '...', 'on', 'sat', 'right', '?']\n",
      "AFter tokenizer:  ['hi', '!', 'this', 'is', 'roger', 'from', 'cl', '.', 'how', 'are', 'you', '?']\n",
      "AFter tokenizer:  ['babe', ':', 'u', 'want', 'me', 'dont', 'u', 'baby', '!', 'im', 'nasty', 'and', 'have', 'a', 'thing', '4', 'filthyguys', '.', 'fancy', 'a', 'rude', 'time', 'with', 'a', 'sexy', 'bitch', '.', 'how', 'about', 'we', 'go', 'slo', 'n', 'hard', '!', 'txt', 'xxx', 'slo', '(', '4msgs', ')']\n",
      "AFter tokenizer:  ['oh', 'oh', '...', 'wasted', '...', 'den', 'muz', 'chiong', 'on', 'sat', 'n', 'sun', 'liao', '...']\n",
      "AFter tokenizer:  ['jesus', 'christ', 'bitch', 'i', \"'m\", 'trying', 'to', 'give', 'you', 'drugs', 'answer', 'your', 'fucking', 'phone']\n",
      "AFter tokenizer:  ['please', 'give', 'it', '2', 'or', 'i', 'will', 'pick', 'it', 'up', 'on', 'tuesday', 'evening', 'about', '8', 'if', 'that', 'is', 'ok', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'meeting', 'darren', '...']\n",
      "AFter tokenizer:  ['one', 'of', 'best', 'dialogue', 'in', 'cute', 'reltnship', '..', '!', '!', '``', 'wen', 'i', 'die', ',', 'dont', 'come', 'near', 'my', 'body', '..', '!', '!', 'bcoz', 'my', 'hands', 'may', 'not', 'come', '2', 'wipe', 'ur', 'tears', 'off', 'that', 'time', '..', '!', 'gud', 'ni8']\n",
      "AFter tokenizer:  ['solve', 'd', 'case', ':', 'a', 'man', 'was', 'found', 'murdered', 'on', '&', 'lt', ';', 'decimal', '&', 'gt', ';', '.', '&', 'lt', ';', '#', '&', 'gt', ';', 'afternoon', '.', '1', ',', 'his', 'wife', 'called', 'police', '.', '2', ',', 'police', 'questioned', 'everyone', '.', '3', ',', 'wife', ':', 'sir', ',', 'i', 'was', 'sleeping', ',', 'when', 'the', 'murder', 'took', 'place', '.', '4.cook', ':', 'i', 'was', 'cooking', '.', '5.gardener', ':', 'i', 'was', 'picking', 'vegetables', '.', '6.house-maid', ':', 'i', 'went', '2', 'd', 'post', 'office', '.', '7.children', ':', 'we', 'went', '2', 'play', '.', '8.neighbour', ':', 'we', 'went', '2', 'a', 'marriage', '.', 'police', 'arrested', 'd', 'murderer', 'immediately', '.', 'who', \"'s\", 'it', '?', 'reply', 'with', 'reason', ',', 'if', 'u', 'r', 'brilliant', '.']\n",
      "AFter tokenizer:  ['dear', 'where', 'you', 'will', 'be', 'when', 'i', 'reach', 'there']\n",
      "AFter tokenizer:  ['aww', 'that', \"'s\", 'the', 'first', 'time', 'u', 'said', 'u', 'missed', 'me', 'without', 'asking', 'if', 'i', 'missed', 'u', 'first', '.', 'you', 'do', 'love', 'me', '!', ':', ')']\n",
      "AFter tokenizer:  ['ok', '...', 'thanx', '...', 'gd', 'nite', '2', 'ü', 'too', '...']\n",
      "AFter tokenizer:  ['come', 'to', 'me', 'right', 'now', ',', 'ahmad']\n",
      "AFter tokenizer:  ['lol', 'please', 'do', '.', 'actually', 'send', 'a', 'pic', 'of', 'yourself', 'right', 'now', '.', 'i', 'wan', 'na', 'see', '.', 'pose', 'with', 'a', 'comb', 'and', 'hair', 'dryer', 'or', 'something', '.']\n",
      "AFter tokenizer:  ['o', 'was', 'not', 'into', 'fps', 'then', '.']\n",
      "AFter tokenizer:  ['huh', 'means', 'computational', 'science', '...', 'y', 'they', 'like', 'dat', 'one', 'push', 'here', 'n', 'there', '...']\n",
      "AFter tokenizer:  ['could', 'you', 'not', 'read', 'me', ',', 'my', 'love', '?', 'i', 'answered', 'you']\n",
      "AFter tokenizer:  ['oh', '...', 'lk', 'tt', 'den', 'we', 'take', 'e', 'one', 'tt', 'ends', 'at', 'cine', 'lor', '...', 'dun', 'wan', 'yogasana', 'oso', 'can', '...']\n",
      "AFter tokenizer:  ['madam', ',', 'regret', 'disturbance.might', 'receive', 'a', 'reference', 'check', 'from', 'dlf', 'premarica.kindly', 'be', 'informed.rgds', ',', 'rakhesh', ',', 'kerala', '.']\n",
      "AFter tokenizer:  ['sms', 'services', 'for', 'your', 'inclusive', 'text', 'credits', 'pls', 'gotto', 'www.comuk.net', 'login', '3qxj9', 'unsubscribe', 'with', 'stop', 'no', 'extra', 'charge', 'help', '08702840625', 'comuk.220cm2', '9ae']\n",
      "AFter tokenizer:  ['oic', '...', 'then', 'better', 'quickly', 'go', 'bathe', 'n', 'settle', 'down', '...']\n",
      "AFter tokenizer:  ['err', '...', 'cud', 'do', '.', 'i', \"'m\", 'going', 'to', 'at', '8pm', '.', 'i', 'have', \"n't\", 'got', 'a', 'way', 'to', 'contact', 'him', 'until', 'then', '.']\n",
      "AFter tokenizer:  ['a', 'bloo', 'bloo', 'bloo', 'i', \"'ll\", 'miss', 'the', 'first', 'bowl']\n",
      "AFter tokenizer:  ['lmao', 'but', 'its', 'so', 'fun', '...']\n",
      "AFter tokenizer:  ['oh', 'k', 'k', ':', ')', 'but', 'he', 'is', 'not', 'a', 'big', 'hitter.anyway', 'good']\n",
      "AFter tokenizer:  ['hey', '!', '!', '!', 'i', 'almost', 'forgot', '...', 'happy', 'b-day', 'babe', '!', 'i', 'love', 'ya', '!', '!']\n",
      "AFter tokenizer:  ['valentines', 'day', 'special', '!', 'win', 'over', '£1000', 'in', 'our', 'quiz', 'and', 'take', 'your', 'partner', 'on', 'the', 'trip', 'of', 'a', 'lifetime', '!', 'send', 'go', 'to', '83600', 'now', '.', '150p/msg', 'rcvd', '.', 'custcare:08718720201']\n",
      "AFter tokenizer:  ['do', 'you', 'think', 'i', 'can', 'move', '&', 'lt', ';', '#', '&', 'gt', ';', 'in', 'a', 'week']\n",
      "AFter tokenizer:  ['she.s', 'find', '.', 'i', 'sent', 'you', 'an', 'offline', 'message', 'to', 'know', 'how', 'anjola', \"'s\", 'now', '.']\n",
      "AFter tokenizer:  ['guess', 'who', 'am', 'i', '?', 'this', 'is', 'the', 'first', 'time', 'i', 'created', 'a', 'web', 'page', 'www.asjesus.com', 'read', 'all', 'i', 'wrote', '.', 'i', \"'m\", 'waiting', 'for', 'your', 'opinions', '.', 'i', 'want', 'to', 'be', 'your', 'friend', '1/1']\n",
      "AFter tokenizer:  ['how', 'was', 'txting', 'and', 'driving']\n",
      "AFter tokenizer:  ['that', \"'s\", 'good', '.', 'lets', 'thank', 'god', '.', 'please', 'complete', 'the', 'drug', '.', 'have', 'lots', 'of', 'water', '.', 'and', 'have', 'a', 'beautiful', 'day', '.']\n",
      "AFter tokenizer:  ['really', 'dun', 'bluff', 'me', 'leh', '...', 'u', 'sleep', 'early', 'too', '.', 'nite', '...']\n",
      "AFter tokenizer:  ['indians', 'r', 'poor', 'but', 'india', 'is', 'not', 'a', 'poor', 'country', '.', 'says', 'one', 'of', 'the', 'swiss', 'bank', 'directors', '.', 'he', 'says', 'that', '``', '&', 'lt', ';', '#', '&', 'gt', ';', 'lac', 'crore', \"''\", 'of', 'indian', 'money', 'is', 'deposited', 'in', 'swiss', 'banks', 'which', 'can', 'be', 'used', 'for', \"'taxless\", \"'\", 'budget', 'for', '&', 'lt', ';', '#', '&', 'gt', ';', 'yrs', '.', 'can', 'give', '&', 'lt', ';', '#', '&', 'gt', ';', 'crore', 'jobs', 'to', 'all', 'indians', '.', 'from', 'any', 'village', 'to', 'delhi', '4', 'lane', 'roads', '.', 'forever', 'free', 'power', 'suply', 'to', 'more', 'than', '&', 'lt', ';', '#', '&', 'gt', ';', 'social', 'projects', '.', 'every', 'citizen', 'can', 'get', 'monthly', '&', 'lt', ';', '#', '&', 'gt', ';', '/-', 'for', '&', 'lt', ';', '#', '&', 'gt', ';', 'yrs', '.', 'no', 'need', 'of', 'world', 'bank', '&', 'amp', ';', 'imf', 'loan', '.', 'think', 'how', 'our', 'money', 'is', 'blocked', 'by', 'rich', 'politicians', '.', 'we', 'have', 'full', 'rights', 'against', 'corrupt', 'politicians', '.', 'itna', 'forward', 'karo', 'ki', 'pura', 'india', 'padhe.g.m', '.', \"''\"]\n",
      "AFter tokenizer:  ['uncle', 'boye', '.', 'i', 'need', 'movies', 'oh', '.', 'guide', 'me', '.', 'plus', 'you', 'know', 'torrents', 'are', 'not', 'particularly', 'legal', 'here', '.', 'and', 'the', 'system', 'is', 'slowing', 'down', '.', 'what', 'should', 'i', 'do', '.', 'have', 'a', 'gr8', 'day', '.', 'plus', 'have', 'you', 'started', 'cos', 'i', 'dont', 'meet', 'you', 'online', '.', 'how', 'was', 'the', 'honey', 'moon', '.']\n",
      "AFter tokenizer:  ['oh', 'ya', 'ya', '.', 'i', 'remember', 'da', '.', '.']\n",
      "AFter tokenizer:  ['btw', 'regarding', 'that', 'we', 'should', 'really', 'try', 'to', 'see', 'if', 'anyone', 'else', 'can', 'be', 'our', '4th', 'guy', 'before', 'we', 'commit', 'to', 'a', 'random', 'dude']\n",
      "AFter tokenizer:  ['for', 'ur', 'chance', 'to', 'win', '£250', 'cash', 'every', 'wk', 'txt', ':', 'play', 'to', '83370.', 't', \"'s\", '&', 'c', \"'s\", 'www.music-trivia.net', 'custcare', '08715705022', ',', '1x150p/wk', '.']\n",
      "AFter tokenizer:  ['i', 'not', 'busy', 'juz', 'dun', 'wan', '2', 'go', 'so', 'early', '..', 'hee', '..']\n",
      "AFter tokenizer:  ['rightio', '.', '11.48', 'it', 'is', 'then', '.', 'well', 'arent', 'we', 'all', 'up', 'bright', 'and', 'early', 'this', 'morning', '.']\n",
      "AFter tokenizer:  ['great', '.', 'i', \"'m\", 'in', 'church', 'now', ',', 'will', 'holla', 'when', 'i', 'get', 'out']\n",
      "AFter tokenizer:  ['back', 'in', 'brum', '!', 'thanks', 'for', 'putting', 'us', 'up', 'and', 'keeping', 'us', 'all', 'and', 'happy', '.', 'see', 'you', 'soon']\n",
      "AFter tokenizer:  ['i', 'donno', 'if', 'they', 'are', 'scorable']\n",
      "AFter tokenizer:  ['&', 'lt', ';', '#', '&', 'gt', ';', 'great', 'loxahatchee', 'xmas', 'tree', 'burning', 'update', ':', 'you', 'can', 'totally', 'see', 'stars', 'here']\n",
      "AFter tokenizer:  ['yes', 'but', 'i', 'dont', 'care', '!', 'i', 'need', 'you', 'bad', ',', 'princess', '!']\n",
      "AFter tokenizer:  ['the', 'guy', '(', 'kadeem', ')', 'has', \"n't\", 'been', 'selling', 'since', 'the', 'break', ',', 'i', 'know', 'one', 'other', 'guy', 'but', 'he', \"'s\", 'paranoid', 'as', 'fuck', 'and', 'does', \"n't\", 'like', 'selling', 'without', 'me', 'there', 'and', 'i', 'ca', \"n't\", 'be', 'up', 'there', 'til', 'late', 'tonight']\n",
      "AFter tokenizer:  ['tmr', 'then', 'ü', 'brin', 'lar', '...', 'aiya', 'later', 'i', 'come', 'n', 'c', 'lar', '...', 'mayb', 'ü', 'neva', 'set', 'properly', 'ü', 'got', 'da', 'help', 'sheet', 'wif', 'ü', '...']\n",
      "AFter tokenizer:  ['do', 'u', 'knw', 'dis', 'no', '.', '&', 'lt', ';', '#', '&', 'gt', ';', '?']\n",
      "AFter tokenizer:  ['then', 'she', 'dun', 'believe', 'wat', '?']\n",
      "AFter tokenizer:  ['k', '..', 'give', 'back', 'my', 'thanks', '.']\n",
      "AFter tokenizer:  ['i', 'know', 'complain', 'num', 'only', '..', 'bettr', 'directly', 'go', 'to', 'bsnl', 'offc', 'nd', 'apply', 'for', 'it', '..']\n",
      "AFter tokenizer:  ['okay', '.', 'i', \"'ve\", 'seen', 'it', '.', 'so', 'i', 'should', 'pick', 'it', 'on', 'friday', '?']\n",
      "AFter tokenizer:  ['how', 'much', 'she', 'payed', '.', 'suganya', '.']\n",
      "AFter tokenizer:  ['left', 'dessert', '.', 'u', 'wan', 'me', '2', 'go', 'suntec', 'look', '4', 'u', '?']\n",
      "AFter tokenizer:  ['abeg', ',', 'make', 'profit', '.', 'but', 'its', 'a', 'start', '.', 'are', 'you', 'using', 'it', 'to', 'get', 'sponsors', 'for', 'the', 'next', 'event', '?']\n",
      "AFter tokenizer:  ['onum', 'ela', 'pa.', 'normal', 'than', '.']\n",
      "AFter tokenizer:  ['k.k', '..', 'how', 'is', 'your', 'sister', 'kids', '?']\n",
      "AFter tokenizer:  ['cool', ',', 'i', \"'ll\", 'text', 'you', 'when', 'i', \"'m\", 'on', 'the', 'way']\n",
      "AFter tokenizer:  ['nope', '.', 'meanwhile', 'she', 'talk', 'say', 'make', 'i', 'greet', 'you', '.']\n",
      "AFter tokenizer:  ['i', 'cant', 'talk', 'to', 'you', 'now.i', 'will', 'call', 'when', 'i', 'can.dont', 'keep', 'calling', '.']\n",
      "AFter tokenizer:  ['anything', 'lar', '...']\n",
      "AFter tokenizer:  ['rose', 'needs', 'water', ',', 'season', 'needs', 'change', ',', 'poet', 'needs', 'imagination', '..', 'my', 'phone', 'needs', 'ur', 'sms', 'and', 'i', 'need', 'ur', 'lovely', 'frndship', 'forever', '....']\n",
      "AFter tokenizer:  ['good', 'afternoon', ',', 'babe', '.', 'how', 'goes', 'that', 'day', '?', 'any', 'job', 'prospects', 'yet', '?', 'i', 'miss', 'you', ',', 'my', 'love', '...', '*', 'sighs', '*', '...', ':', '-', '(']\n",
      "AFter tokenizer:  ['they', 'will', 'pick', 'up', 'and', 'drop', 'in', 'car.so', 'no', 'problem', '..']\n",
      "AFter tokenizer:  ['s.i', 'think', 'he', 'is', 'waste', 'for', 'rr', '..']\n",
      "AFter tokenizer:  ['he', 'is', 'world', 'famamus', '....']\n",
      "AFter tokenizer:  ['is', 'there', 'coming', 'friday', 'is', 'leave', 'for', 'pongal', '?', 'do', 'you', 'get', 'any', 'news', 'from', 'your', 'work', 'place', '.']\n",
      "AFter tokenizer:  ['lol', 'well', 'do', \"n't\", 'do', 'it', 'without', 'me', '.', 'we', 'could', 'have', 'a', 'big', 'sale', 'together', '.']\n",
      "AFter tokenizer:  ['*', 'am', 'on', 'my', 'way']\n",
      "AFter tokenizer:  ['eat', 'at', 'old', 'airport', 'road', '...', 'but', 'now', '630', 'oredi', '...', 'got', 'a', 'lot', 'of', 'pple', '...']\n",
      "AFter tokenizer:  ['sry', 'ca', \"n't\", 'talk', 'on', 'phone', ',', 'with', 'parents']\n",
      "AFter tokenizer:  ['ok', 'lor', 'wat', 'time', 'ü', 'finish', '?']\n",
      "AFter tokenizer:  ['princess', ',', 'i', 'like', 'to', 'make', 'love', '&', 'lt', ';', '#', '&', 'gt', ';', 'times', 'per', 'night', '.', 'hope', 'thats', 'not', 'a', 'problem', '!']\n",
      "AFter tokenizer:  ['mm', 'i', 'am', 'on', 'the', 'way', 'to', 'railway']\n",
      "AFter tokenizer:  ['i', \"'m\", 'done', '.', 'i', \"'m\", 'sorry', '.', 'i', 'hope', 'your', 'next', 'space', 'gives', 'you', 'everything', 'you', 'want', '.', 'remember', 'all', 'the', 'furniture', 'is', 'yours', '.', 'if', 'i', \"'m\", 'not', 'around', 'when', 'you', 'move', 'it', ',', 'just', 'lock', 'all', 'the', 'locks', 'and', 'leave', 'the', 'key', 'with', 'jenne', '.']\n",
      "AFter tokenizer:  ['not', 'yet', '.', 'just', 'i', \"'d\", 'like', 'to', 'keep', 'in', 'touch', 'and', 'it', 'will', 'be', 'the', 'easiest', 'way', 'to', 'do', 'that', 'from', 'barcelona', '.', 'by', 'the', 'way', 'how', 'ru', 'and', 'how', 'is', 'the', 'house', '?']\n",
      "AFter tokenizer:  ['sppok', 'up', 'ur', 'mob', 'with', 'a', 'halloween', 'collection', 'of', 'nokia', 'logo', '&', 'pic', 'message', 'plus', 'a', 'free', 'eerie', 'tone', ',', 'txt', 'card', 'spook', 'to', '8007']\n",
      "AFter tokenizer:  ['urgent', '!', 'call', '09066612661', 'from', 'landline', '.', 'your', 'complementary', '4', '*', 'tenerife', 'holiday', 'or', '£10,000', 'cash', 'await', 'collection', 'sae', 't', '&', 'cs', 'po', 'box', '3', 'wa14', '2px', '150ppm', '18+', 'sender', ':', 'hol', 'offer']\n",
      "AFter tokenizer:  ['k.', ':', ')', 'do', 'it', 'at', 'evening', 'da', ':', ')', 'urgent', ':', ')']\n",
      "AFter tokenizer:  ['pansy', '!', 'you', \"'ve\", 'been', 'living', 'in', 'a', 'jungle', 'for', 'two', 'years', '!', 'its', 'my', 'driving', 'you', 'should', 'be', 'more', 'worried', 'about', '!']\n",
      "AFter tokenizer:  ['mm', 'have', 'some', 'kanji', 'dont', 'eat', 'anything', 'heavy', 'ok']\n",
      "AFter tokenizer:  ['only', 'if', 'you', 'promise', 'your', 'getting', 'out', 'as', 'soon', 'as', 'you', 'can', '.', 'and', 'you', \"'ll\", 'text', 'me', 'in', 'the', 'morning', 'to', 'let', 'me', 'know', 'you', 'made', 'it', 'in', 'ok', '.']\n",
      "AFter tokenizer:  ['lol', 'that', \"'s\", 'different', '.', 'i', 'do', \"n't\", 'go', 'trying', 'to', 'find', 'every', 'real', 'life', 'photo', 'you', 'ever', 'took', '.']\n",
      "AFter tokenizer:  ['i', 'dont', 'thnk', 'its', 'a', 'wrong', 'calling', 'between', 'us']\n",
      "AFter tokenizer:  ['k', 'ill', 'drink.pa', 'then', 'what', 'doing', '.', 'i', 'need', 'srs', 'model', 'pls', 'send', 'it', 'to', 'my', 'mail', 'id', 'pa', '.']\n",
      "AFter tokenizer:  ['aiyah', 'e', 'rain', 'like', 'quite', 'big', 'leh', '.', 'if', 'drizzling', 'i', 'can', 'at', 'least', 'run', 'home', '.']\n",
      "AFter tokenizer:  ['i', 'have', '2', 'docs', 'appointments', 'next', 'week', '.', ':', '/', 'i', \"'m\", 'tired', 'of', 'them', 'shoving', 'stuff', 'up', 'me', '.', 'ugh', 'why', 'could', \"n't\", 'i', 'have', 'had', 'a', 'normal', 'body', '?']\n",
      "AFter tokenizer:  ['dun', 'b', 'sad', '..', 'it', \"'s\", 'over', '..', 'dun', 'thk', 'abt', 'it', 'already', '.', 'concentrate', 'on', 'ur', 'other', 'papers', 'k', '.']\n",
      "AFter tokenizer:  ['greetings', 'me', ',', '!', 'consider', 'yourself', 'excused', '.']\n",
      "AFter tokenizer:  ['no', 'drama', 'pls.i', 'have', 'had', 'enough', 'from', 'you', 'and', 'family', 'while', 'i', 'am', 'struggling', 'in', 'the', 'hot', 'sun', 'in', 'a', 'strange', 'place.no', 'reason', 'why', 'there', 'should', 'be', 'an', 'ego', 'of', 'not', 'going', \"'if\", 'not', 'invited', \"'\", 'when', 'actually', 'its', 'necessity', 'to', 'go.wait', 'for', 'very', 'serious', 'reppurcussions', '.']\n",
      "AFter tokenizer:  ['they', 'released', 'another', 'italian', 'one', 'today', 'and', 'it', 'has', 'a', 'cosign', 'option']\n",
      "AFter tokenizer:  ['you', 'at', 'mu', '?', 'you', 'should', 'try', 'to', 'figure', 'out', 'how', 'much', 'money', 'everyone', 'has', 'for', 'gas', 'and', 'alcohol', ',', 'jay', 'and', 'i', 'are', 'trying', 'to', 'figure', 'out', 'our', 'weed', 'budget']\n",
      "AFter tokenizer:  ['winner', '!', 'as', 'a', 'valued', 'network', 'customer', 'you', 'hvae', 'been', 'selected', 'to', 'receive', 'a', '£900', 'reward', '!', 'to', 'collect', 'call', '09061701444.', 'valid', '24', 'hours', 'only', '.', 'acl03530150pm']\n",
      "AFter tokenizer:  ['hcl', 'chennai', 'requires', 'freshers', 'for', 'voice', 'process.excellent', 'english', 'needed.salary', 'upto', '&', 'lt', ';', '#', '&', 'gt', ';', '.call', 'ms.suman', '&', 'lt', ';', '#', '&', 'gt', ';', 'for', 'telephonic', 'interview', '-via', 'indyarocks.com']\n",
      "AFter tokenizer:  ['dai', 'what', 'this', 'da', '..', 'can', 'i', 'send', 'my', 'resume', 'to', 'this', 'id', '.']\n",
      "AFter tokenizer:  ['i', 'know', 'where', 'the', '&', 'lt', ';', '#', '&', 'gt', ';', 'is', ',', 'i', \"'ll\", 'be', 'there', 'around', '5']\n",
      "AFter tokenizer:  ['yup', 'i', \"'ve\", 'finished', 'c', 'ü', 'there', '...']\n",
      "AFter tokenizer:  ['remember', 'to', 'ask', 'alex', 'about', 'his', 'pizza']\n",
      "AFter tokenizer:  ['no', 'da', '..', 'today', 'also', 'i', 'forgot', '..']\n",
      "AFter tokenizer:  ['ola', 'would', 'get', 'back', 'to', 'you', 'maybe', 'not', 'today', 'but', 'i', 've', 'told', 'him', 'you', 'can', 'be', 'his', 'direct', 'link', 'in', 'the', 'us', 'in', 'getting', 'cars', 'he', 'bids', 'for', 'online', ',', 'you', 'arrange', 'shipping', 'and', 'you', 'get', 'a', 'cut', '.', 'or', 'u', '?', '?', '?', '?', '?', 'for', 'a', 'partnership', 'where', 'u', '?', '?', '?', '?', '?', 'invest', 'money', 'for', 'shipping', 'and', 'he', 'takes', 'care', 'of', 'the', 'rest', '!', 'u', '?', '?', 'wud', 'b', 'self', 'reliant', 'soon', 'dnt', 'worry']\n",
      "AFter tokenizer:  ['fwiw', 'the', 'reason', 'i', \"'m\", 'only', 'around', 'when', 'it', \"'s\", 'time', 'to', 'smoke', 'is', 'that', 'because', 'of', 'gas', 'i', 'can', 'only', 'afford', 'to', 'be', 'around', 'when', 'someone', 'tells', 'me', 'to', 'be', 'and', 'that', 'apparently', 'only', 'happens', 'when', 'somebody', 'wants', 'to', 'light', 'up']\n",
      "AFter tokenizer:  ['hello', ',', 'my', 'boytoy', '!', 'i', 'made', 'it', 'home', 'and', 'my', 'constant', 'thought', 'is', 'of', 'you', ',', 'my', 'love', '.', 'i', 'hope', 'your', 'having', 'a', 'nice', 'visit', 'but', 'i', 'ca', \"n't\", 'wait', 'till', 'you', 'come', 'home', 'to', 'me', '...', '*', 'kiss', '*']\n",
      "AFter tokenizer:  ['congrats', 'kano', '..', 'whr', 's', 'the', 'treat', 'maga', '?']\n",
      "AFter tokenizer:  ['who', 'u', 'talking', 'about', '?']\n",
      "AFter tokenizer:  ['yup', '...']\n",
      "AFter tokenizer:  ['u', 'wake', 'up', 'already', '?', 'wat', 'u', 'doing', '?', 'u', 'picking', 'us', 'up', 'later', 'rite', '?', 'i', \"'m\", 'taking', 'sq825', ',', 'reaching', 'ard', '7', 'smth', '8', 'like', 'dat', '.', 'u', 'can', 'check', 'e', 'arrival', 'time', '.', 'c', 'ya', 'soon', '...']\n",
      "AFter tokenizer:  ['yunny', 'i', \"'m\", 'walking', 'in', 'citylink', 'now', 'ü', 'faster', 'come', 'down', '...', 'me', 'very', 'hungry', '...']\n",
      "AFter tokenizer:  ['er', 'yep', 'sure', '.', 'props', '?']\n",
      "AFter tokenizer:  ['hiya', ',', 'have', 'u', 'been', 'paying', 'money', 'into', 'my', 'account', '?', 'if', 'so', ',', 'thanks', '.', 'got', 'a', 'pleasant', 'surprise', 'when', 'i', 'checked', 'my', 'balance', '-u', 'c', ',', 'i', 'do', \"n't\", 'get', 'statements', '4', 'that', 'acc']\n",
      "AFter tokenizer:  ['u', 'have', 'won', 'a', 'nokia', '6230', 'plus', 'a', 'free', 'digital', 'camera', '.', 'this', 'is', 'what', 'u', 'get', 'when', 'u', 'win', 'our', 'free', 'auction', '.', 'to', 'take', 'part', 'send', 'nokia', 'to', '83383', 'now', '.', 'pobox114/14tcr/w1', '16']\n",
      "AFter tokenizer:  ['ok', 'ill', 'send', 'you', 'with', 'in', '&', 'lt', ';', 'decimal', '&', 'gt', ';', 'ok', '.']\n",
      "AFter tokenizer:  ['bognor', 'it', 'is', '!', 'should', 'be', 'splendid', 'at', 'this', 'time', 'of', 'year', '.']\n",
      "AFter tokenizer:  ['yes.i', \"'m\", 'in', 'office', 'da', ':', ')']\n",
      "AFter tokenizer:  ['ok.', 'i', 'only', 'ask', 'abt', 'e', 'movie', '.', 'u', 'wan', 'ktv', 'oso', '?']\n",
      "AFter tokenizer:  ['misplaced', 'your', 'number', 'and', 'was', 'sending', 'texts', 'to', 'your', 'old', 'number', '.', 'wondering', 'why', 'i', \"'ve\", 'not', 'heard', 'from', 'you', 'this', 'year', '.', 'all', 'the', 'best', 'in', 'your', 'mcat', '.', 'got', 'this', 'number', 'from', 'my', 'atlanta', 'friends']\n",
      "AFter tokenizer:  ['dunno', 'lei', '...', 'i', 'might', 'b', 'eatin', 'wif', 'my', 'frens', '...', 'if', 'ü', 'wan', 'to', 'eat', 'then', 'i', 'wait', '4', 'ü', 'lar']\n",
      "AFter tokenizer:  ['free', 'entry', 'into', 'our', '£250', 'weekly', 'comp', 'just', 'send', 'the', 'word', 'win', 'to', '80086', 'now', '.', '18', 't', '&', 'c', 'www.txttowin.co.uk']\n",
      "AFter tokenizer:  ['do', 'u', 'noe', 'how', '2', 'send', 'files', 'between', '2', 'computers', '?']\n",
      "AFter tokenizer:  ['mmmmm', '...', 'i', 'loved', 'waking', 'to', 'your', 'words', 'this', 'morning', '!', 'i', 'miss', 'you', 'too', ',', 'my', 'love', '.', 'i', 'hope', 'your', 'day', 'goes', 'well', 'and', 'you', 'are', 'happy', '.', 'i', 'wait', 'for', 'us', 'to', 'be', 'together', 'again']\n",
      "AFter tokenizer:  ['jay', 'says', 'he', \"'ll\", 'put', 'in', '&', 'lt', ';', '#', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['can', 'you', 'just', 'come', 'in', 'for', 'a', 'sec', '?', 'there', \"'s\", 'somebody', 'here', 'i', 'want', 'you', 'to', 'see']\n",
      "AFter tokenizer:  ['so', 'the', 'sun', 'is', 'anti', 'sleep', 'medicine', '.']\n",
      "AFter tokenizer:  ['what', \"'s\", 'happening', 'with', 'you', '.', 'have', 'you', 'gotten', 'a', 'job', 'and', 'have', 'you', 'begun', 'registration', 'for', 'permanent', 'residency']\n",
      "AFter tokenizer:  ['yup', 'ok', '...']\n",
      "AFter tokenizer:  ['glad', 'it', 'went', 'well', ':', ')', 'come', 'over', 'at', '11', 'then', 'we', \"'ll\", 'have', 'plenty', 'of', 'time', 'before', 'claire', 'goes', 'to', 'work', '.']\n",
      "AFter tokenizer:  ['ok', 'enjoy', '.', 'r', 'u', 'there', 'in', 'home', '.']\n",
      "AFter tokenizer:  ['can', 'you', 'pls', 'pls', 'send', 'me', 'a', 'mail', 'on', 'all', 'you', 'know', 'about', 'relatives', 'coming', 'to', 'deliver', 'here', '?', 'all', 'you', 'know', 'about', 'costs', ',', 'risks', ',', 'benefits', 'and', 'anything', 'else', '.', 'thanks', '.']\n",
      "AFter tokenizer:  ['you', 'do', 'what', 'all', 'you', 'like']\n",
      "AFter tokenizer:  ['that', \"'s\", 'y', 'we', 'haf', 'to', 'combine', 'n', 'c', 'how', 'lor', '...']\n",
      "AFter tokenizer:  ['the', 'monthly', 'amount', 'is', 'not', 'that', 'terrible', 'and', 'you', 'will', 'not', 'pay', 'anything', 'till', '6months', 'after', 'finishing', 'school', '.']\n",
      "AFter tokenizer:  ['hmmm', ':', ')', 'how', 'many', 'players', 'selected', '?']\n",
      "AFter tokenizer:  ['they', 'said', 'if', 'its', 'gon', 'na', 'snow', ',', 'it', 'will', 'start', 'around', '8', 'or', '9', 'pm', 'tonite', '!', 'they', 'are', 'predicting', 'an', 'inch', 'of', 'accumulation', '.']\n",
      "AFter tokenizer:  ['i', 'dont', '.', 'can', 'you', 'send', 'it', 'to', 'me', '.', 'plus', 'how', \"'s\", 'mode', '.']\n",
      "AFter tokenizer:  ['aiyo', 'please', 'ü', 'got', 'time', 'meh', '.']\n",
      "AFter tokenizer:  ['package', 'all', 'your', 'programs', 'well']\n",
      "AFter tokenizer:  ['she', 'is', 'our', 'sister', '..', 'she', 'belongs', '2', 'our', 'family', '..', 'she', 'is', 'd', 'hope', 'of', 'tomorrow', '..', 'pray', '4', 'her', ',', 'who', 'was', 'fated', '4', 'd', 'shoranur', 'train', 'incident', '.', 'lets', 'hold', 'our', 'hands', 'together', '&', 'amp', ';', 'fuelled', 'by', 'love', '&', 'amp', ';', 'concern', 'prior', '2', 'her', 'grief', '&', 'amp', ';', 'pain', '.', 'pls', 'join', 'in', 'dis', 'chain', '&', 'amp', ';', 'pass', 'it', '.', 'stop', 'violence', 'against', 'women', '.']\n",
      "AFter tokenizer:  ['so', 'are', 'you', 'guys', 'asking', 'that', 'i', 'get', 'that', 'slippers', 'again', 'or', 'its', 'gone', 'with', 'last', 'year']\n",
      "AFter tokenizer:  ['company', 'is', 'very', 'good.environment', 'is', 'terrific', 'and', 'food', 'is', 'really', 'nice', ':', ')']\n",
      "AFter tokenizer:  ['text82228', '>', '>', 'get', 'more', 'ringtones', ',', 'logos', 'and', 'games', 'from', 'www.txt82228.com', '.', 'questions', ':', 'info', '@', 'txt82228.co.uk']\n",
      "AFter tokenizer:  ['honestly', 'i', \"'ve\", 'just', 'made', 'a', 'lovely', 'cup', 'of', 'tea', 'and', 'promptly', 'dropped', 'my', 'keys', 'in', 'it', 'and', 'then', 'burnt', 'my', 'fingers', 'getting', 'them', 'out', '!']\n",
      "AFter tokenizer:  ['yup', 'but', 'not', 'studying', 'surfing', 'lor', '.', 'i', \"'m\", 'in', 'e', 'lazy', 'mode', 'today', '.']\n",
      "AFter tokenizer:  ['please', 'sen', ':', ')', 'my', 'kind', 'advice', ':', '-', ')', 'please', 'come', 'here', 'and', 'try', ':', '-', ')']\n",
      "AFter tokenizer:  ['i', \"'m\", 'done', '.', 'c', 'ü', 'there', '.']\n",
      "AFter tokenizer:  ['oh', 'fine', ',', 'i', \"'ll\", 'be', 'by', 'tonight']\n",
      "AFter tokenizer:  ['ü', 'give', 'me', 'some', 'time', 'to', 'walk', 'there', '.']\n",
      "AFter tokenizer:  ['i', \"'ll\", 'reach', 'in', 'ard', '20', 'mins', 'ok', '...']\n",
      "AFter tokenizer:  ['freemsg', 'you', 'have', 'been', 'awarded', 'a', 'free', 'mini', 'digital', 'camera', ',', 'just', 'reply', 'snap', 'to', 'collect', 'your', 'prize', '!', '(', 'quizclub', 'opt', 'out', '?', 'stop', '80122300p/wk', 'sp', ':', 'rwm', 'ph:08704050406', ')']\n",
      "AFter tokenizer:  ['fuck', 'babe', '...', 'what', 'happened', 'to', 'you', '?', 'how', 'come', 'you', 'never', 'came', 'back', '?']\n",
      "AFter tokenizer:  ['this', 'message', 'is', 'brought', 'to', 'you', 'by', 'gmw', 'ltd.', 'and', 'is', 'not', 'connected', 'to', 'the']\n",
      "AFter tokenizer:  ['some', 'friends', 'want', 'me', 'to', 'drive', 'em', 'someplace', ',', 'probably', 'take', 'a', 'while']\n",
      "AFter tokenizer:  ['i', 'also', 'thk', 'too', 'fast', '...', 'xy', 'suggest', 'one', 'not', 'me', '.', 'u', 'dun', 'wan', 'it', \"'s\", 'ok.', 'going', '2', 'rain', 'leh', 'where', 'got', 'gd', '.']\n",
      "AFter tokenizer:  ['are', 'you', 'still', 'getting', 'the', 'goods', '.']\n",
      "AFter tokenizer:  ['and', 'maybe', 'some', 'pressies']\n",
      "AFter tokenizer:  ['yeah', 'i', 'am', ',', 'so', 'i', \"'ll\", 'leave', 'maybe', '7ish', '?']\n",
      "AFter tokenizer:  ['i', 'told', 'her', 'i', 'had', 'a', 'dr', 'appt', 'next', 'week', '.', 'she', 'thinks', 'i', \"'m\", 'gon', 'na', 'die', '.', 'i', 'told', 'her', 'its', 'just', 'a', 'check', '.', 'nothing', 'to', 'be', 'worried', 'about', '.', 'but', 'she', 'did', \"n't\", 'listen', '.']\n",
      "AFter tokenizer:  ['you', 'in', 'your', 'room', '?', 'i', 'need', 'a', 'few']\n",
      "AFter tokenizer:  ['i', 'dont', 'want', 'to', 'hear', 'anything']\n",
      "AFter tokenizer:  ['hey', '.', 'for', 'me', 'there', 'is', 'no', 'leave', 'on', 'friday', '.', 'wait', 'i', 'will', 'ask', 'my', 'superior', 'and', 'tell', 'you', '..']\n",
      "AFter tokenizer:  ['ultimately', 'tor', 'motive', 'tui', 'achieve', 'korli', '.']\n",
      "AFter tokenizer:  ['from', '5', 'to', '2', 'only', 'my', 'work', 'timing', '.']\n",
      "AFter tokenizer:  ['…', 'and', 'don', '‘', 't', 'worry', 'we', '‘', 'll', 'have', 'finished', 'by', 'march', '…', 'ish', '!']\n",
      "AFter tokenizer:  ['the', 'house', 'is', 'on', 'the', 'water', 'with', 'a', 'dock', ',', 'a', 'boat', 'rolled', 'up', 'with', 'a', 'newscaster', 'who', 'dabbles', 'in', 'jazz', 'flute', 'behind', 'the', 'wheel']\n",
      "AFter tokenizer:  ['congrats', '2', 'mobile', '3g', 'videophones', 'r', 'yours', '.', 'call', '09063458130', 'now', '!', 'videochat', 'wid', 'ur', 'mates', ',', 'play', 'java', 'games', ',', 'dload', 'polyph', 'music', ',', 'noline', 'rentl', '.', 'bx420', '.', 'ip4', '.', '5we', '.', '150p']\n",
      "AFter tokenizer:  ['your', 'next', 'amazing', 'xxx', 'picsfree1', 'video', 'will', 'be', 'sent', 'to', 'you', 'enjoy', '!', 'if', 'one', 'vid', 'is', 'not', 'enough', 'for', '2day', 'text', 'back', 'the', 'keyword', 'picsfree1', 'to', 'get', 'the', 'next', 'video', '.']\n",
      "AFter tokenizer:  ['now', 'thats', 'going', 'to', 'ruin', 'your', 'thesis', '!']\n",
      "AFter tokenizer:  ['in', 'sch', 'but', 'neva', 'mind', 'u', 'eat', '1st', 'lor', '..']\n",
      "AFter tokenizer:  ['hey', 'whats', 'up', '?', 'u', 'sleeping', 'all', 'morning', '?']\n",
      "AFter tokenizer:  ['erm', '.', 'i', 'thought', 'the', 'contract', 'ran', 'out', 'the4th', 'of', 'october', '.']\n",
      "AFter tokenizer:  ['i', 'dunno', 'until', 'when', '...', 'lets', 'go', 'learn', 'pilates', '...']\n",
      "AFter tokenizer:  ['u', 'are', 'subscribed', 'to', 'the', 'best', 'mobile', 'content', 'service', 'in', 'the', 'uk', 'for', '£3', 'per', 'ten', 'days', 'until', 'you', 'send', 'stop', 'to', '83435.', 'helpline', '08706091795', '.']\n",
      "AFter tokenizer:  ['yup', 'i', \"'m\", 'elaborating', 'on', 'the', 'safety', 'aspects', 'and', 'some', 'other', 'issues', '..']\n",
      "AFter tokenizer:  ['3', 'free', 'tarot', 'texts', '!', 'find', 'out', 'about', 'your', 'love', 'life', 'now', '!', 'try', '3', 'for', 'free', '!', 'text', 'chance', 'to', '85555', '16', 'only', '!', 'after', '3', 'free', ',', 'msgs', '£1.50', 'each']\n",
      "AFter tokenizer:  ['goodmorning', ',', 'today', 'i', 'am', 'late', 'for', '1hr', '.']\n",
      "AFter tokenizer:  ['hi', 'happy', 'birthday', '.', 'hi', 'hi', 'hi', 'hi', 'hi', 'hi', 'hi']\n",
      "AFter tokenizer:  ['i', 'will', 'be', 'outside', 'office', 'take', 'all', 'from', 'there']\n",
      "AFter tokenizer:  ['if', 'you', 'do', \"n't\", 'respond', 'imma', 'assume', 'you', \"'re\", 'still', 'asleep', 'and', 'imma', 'start', 'calling', 'n', 'shit']\n",
      "AFter tokenizer:  ['aight', ',', 'see', 'you', 'in', 'a', 'bit']\n",
      "AFter tokenizer:  ['my', 'superior', 'telling', 'that', 'friday', 'is', 'leave', 'for', 'all', 'other', 'department', 'except', 'ours', ':', ')', 'so', 'it', 'will', 'be', 'leave', 'for', 'you', ':', ')', 'any', 'way', 'call', 'waheed', 'fathima', 'hr', 'and', 'conform', 'it', ':', ')']\n",
      "AFter tokenizer:  ['join', 'the', 'uk', \"'s\", 'horniest', 'dogging', 'service', 'and', 'u', 'can', 'have', 'sex', '2nite', '!', '.', 'just', 'sign', 'up', 'and', 'follow', 'the', 'instructions', '.', 'txt', 'entry', 'to', '69888', 'now', '!', 'nyt.ec2a.3lp.msg', '@', '150p']\n",
      "AFter tokenizer:  ['lol', 'i', 'have', 'to', 'take', 'it', '.', 'member', 'how', 'i', 'said', 'my', 'aunt', 'flow', 'did', \"n't\", 'visit', 'for', '6', 'months', '?', 'it', \"'s\", 'cause', 'i', 'developed', 'ovarian', 'cysts', '.', 'bc', 'is', 'the', 'only', 'way', 'to', 'shrink', 'them', '.']\n",
      "AFter tokenizer:  ['still', 'work', 'going', 'on', ':', ')', 'it', 'is', 'very', 'small', 'house', '.']\n",
      "AFter tokenizer:  ['my', 'friend', 'just', 'got', 'here', 'and', 'says', 'he', \"'s\", 'upping', 'his', 'order', 'by', 'a', 'few', 'grams', '(', 'he', \"'s\", 'got', '$', '&', 'lt', ';', '#', '&', 'gt', ';', ')', ',', 'when', 'can', 'you', 'get', 'here', '?']\n",
      "AFter tokenizer:  ['tmr', 'timin', 'still', 'da', 'same', 'wat', 'cos', 'i', 'got', 'lesson', 'until', '6', '...']\n",
      "AFter tokenizer:  ['that', '‘', 's', 'the', 'thing', 'with', 'apes', ',', 'u', 'can', 'fight', 'to', 'the', 'death', 'to', 'keep', 'something', ',', 'but', 'the', 'minute', 'they', 'have', 'it', 'when', 'u', 'let', 'go', ',', 'thats', 'it', '!']\n",
      "AFter tokenizer:  ['no', 'i', \"'m\", 'not', 'gon', 'na', 'be', 'able', 'to', '.', '||', 'too', 'late', 'notice', '.', '||', 'i', \"'ll\", 'be', 'home', 'in', 'a', 'few', 'weeks', 'anyway', '.', '||', 'what', 'are', 'the', 'plans']\n",
      "AFter tokenizer:  ['got', 'fujitsu', ',', 'ibm', ',', 'hp', ',', 'toshiba', '...', 'got', 'a', 'lot', 'of', 'model', 'how', 'to', 'say', '...']\n",
      "AFter tokenizer:  ['okie', '...', 'thanx', '...']\n",
      "AFter tokenizer:  ['gosh', 'that', ',', 'what', 'a', 'pain', '.', 'spose', 'i', 'better', 'come', 'then', '.']\n",
      "AFter tokenizer:  ['as', 'usual', '..', 'iam', 'fine', ',', 'happy', '&', 'amp', ';', 'doing', 'well', '..', ':', ')']\n",
      "AFter tokenizer:  ['okie']\n",
      "AFter tokenizer:  ['so', 'when', 'you', 'gon', 'na', 'get', 'rimac', 'access']\n",
      "AFter tokenizer:  ['im', 'at', 'arestaurant', 'eating', 'squid', '!', 'i', 'will', 'be', 'out', 'about', '10:30', 'wan', 'na', 'dosomething', 'or', 'is', 'that', 'to', 'late', '?']\n",
      "AFter tokenizer:  ['you', 'call', 'times', 'job', 'today', 'ok', 'umma', 'and', 'ask', 'them', 'to', 'speed', 'up']\n",
      "AFter tokenizer:  ['hello', 'u.call', 'wen', 'u', 'finish', 'wrk.i', 'fancy', 'meetin', 'up', 'wiv', 'u', 'all', 'tonite', 'as', 'i', 'need', 'a', 'break', 'from', 'dabooks', '.', 'did', '4', 'hrs', 'last', 'nite+2', 'today', 'of', 'wrk', '!']\n",
      "AFter tokenizer:  ['r', 'u', '&', 'sam', 'p', 'in', 'eachother', '.', 'if', 'we', 'meet', 'we', 'can', 'go', '2', 'my', 'house']\n",
      "AFter tokenizer:  [':', '-', ')', 'yeah', '!', 'lol', '.', 'luckily', 'i', 'did', \"n't\", 'have', 'a', 'starring', 'role', 'like', 'you', '!']\n",
      "AFter tokenizer:  ['hello', 'madam', 'how', 'are', 'you', '?']\n",
      "AFter tokenizer:  ['awesome', ',', 'text', 'me', 'when', 'you', \"'re\", 'restocked']\n",
      "AFter tokenizer:  ['knock', 'knock', 'txt', 'whose', 'there', 'to', '80082', 'to', 'enter', 'r', 'weekly', 'draw', '4', 'a', '£250', 'gift', 'voucher', '4', 'a', 'store', 'of', 'yr', 'choice', '.', 't', '&', 'cs', 'www.tkls.com', 'age16', 'to', 'stoptxtstop£1.50/week']\n",
      "AFter tokenizer:  ['yes', '.', 'it', \"'s\", 'all', 'innocent', 'fun', '.', 'o', ':', '-', ')']\n",
      "AFter tokenizer:  ['thanks', 'for', 'sending', 'this', 'mental', 'ability', 'question', '..']\n",
      "AFter tokenizer:  ['sir', ',', 'hope', 'your', 'day', 'is', 'going', 'smoothly', '.', 'i', 'really', 'hoped', 'i', 'wont', 'have', 'to', 'bother', 'you', 'about', 'this', '.', 'i', 'have', 'some', 'bills', 'that', 'i', 'ca', \"n't\", 'settle', 'this', 'month', '.', 'i', 'am', 'out', 'of', 'all', 'extra', 'cash', '.', 'i', 'know', 'this', 'is', 'a', 'challenging', 'time', 'for', 'you', 'also', 'but', 'i', 'have', 'to', 'let', 'you', 'know', '.']\n",
      "AFter tokenizer:  ['2marrow', 'only', '.', 'wed', 'at', '&', 'lt', ';', '#', '&', 'gt', ';', 'to', '2', 'aha', '.']\n",
      "AFter tokenizer:  ['i', 'went', 'to', 'ur', 'hon', 'lab', 'but', 'no', 'one', 'is', 'there', '.']\n",
      "AFter tokenizer:  ['hey', 'pple', '...', '$', '700', 'or', '$', '900', 'for', '5', 'nights', '...', 'excellent', 'location', 'wif', 'breakfast', 'hamper', '!', '!', '!']\n",
      "AFter tokenizer:  ['<', 'forwarded', 'from', '21870000', '>', 'hi', '-', 'this', 'is', 'your', 'mailbox', 'messaging', 'sms', 'alert', '.', 'you', 'have', '40', 'matches', '.', 'please', 'call', 'back', 'on', '09056242159', 'to', 'retrieve', 'your', 'messages', 'and', 'matches', 'cc100p/min']\n",
      "AFter tokenizer:  ['how', 'come', '?']\n",
      "AFter tokenizer:  ['lol', '!', 'nah', 'was', \"n't\", 'too', 'bad', 'thanks', '.', 'its', 'good', 'to', 'b', 'home', 'but', 'its', 'been', 'quite', 'a', 'reality', 'check', '.', 'hows', 'ur', 'day', 'been', '?', 'did', 'u', 'do', 'anything', 'with', 'website', '?']\n",
      "AFter tokenizer:  ['ok', 'lor', '...']\n",
      "AFter tokenizer:  ['i', \"'m\", 'coming', 'home', '4', 'dinner', '.']\n",
      "AFter tokenizer:  ['s', 'da', '..', 'al', 'r', 'above', '&', 'lt', ';', '#', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['free', 'ring', 'tone', 'just', 'text', '``', 'polys', \"''\", 'to', '87131.', 'then', 'every', 'week', 'get', 'a', 'new', 'tone', '.', '0870737910216yrs', 'only', '£1.50/wk', '.']\n",
      "AFter tokenizer:  ['unni', 'thank', 'you', 'dear', 'for', 'the', 'recharge', '..', 'rakhesh']\n",
      "AFter tokenizer:  ['i', 'know', 'i', \"'m\", 'lacking', 'on', 'most', 'of', 'this', 'particular', 'dramastorm', \"'s\", 'details', 'but', 'for', 'the', 'most', 'part', 'i', \"'m\", 'not', 'worried', 'about', 'that']\n",
      "AFter tokenizer:  ['haha', '...', 'they', 'cant', 'what', '...', 'at', 'the', 'most', 'tmr', 'forfeit', '...', 'haha', 'so', 'how', '?']\n",
      "AFter tokenizer:  ['hey', 'there', '!', 'glad', 'u', 'r', 'better', 'now', '.', 'i', 'hear', 'u', 'treated', 'urself', 'to', 'a', 'digi', 'cam', ',', 'is', 'it', 'good', '?', 'we', 'r', 'off', 'at', '9pm', '.', 'have', 'a', 'fab', 'new', 'year', ',', 'c', 'u', 'in', 'coupla', 'wks', '!']\n",
      "AFter tokenizer:  ['no', 'way', 'i', \"'m\", 'going', 'back', 'there', '!']\n",
      "AFter tokenizer:  ['urgent', '!', 'your', 'mobile', 'no', '077xxx', 'won', 'a', '£2,000', 'bonus', 'caller', 'prize', 'on', '02/06/03', '!', 'this', 'is', 'the', '2nd', 'attempt', 'to', 'reach', 'you', '!', 'call', '09066362206', 'asap', '!', 'box97n7qp', ',', '150ppm']\n",
      "AFter tokenizer:  ['i', 'will', 'cal', 'you', 'sir', '.', 'in', 'meeting']\n",
      "AFter tokenizer:  ['that', \"'s\", 'what', 'i', 'love', 'to', 'hear', ':', 'v', 'see', 'you', 'sundayish', ',', 'then']\n",
      "AFter tokenizer:  ['sorry', 'da', 'thangam', ',', 'very', 'very', 'sorry', 'i', 'am', 'held', 'up', 'with', 'prasad', '.']\n",
      "AFter tokenizer:  ['tiwary', 'to', 'rcb.battle', 'between', 'bang', 'and', 'kochi', '.']\n",
      "AFter tokenizer:  ['thank', 'god', 'they', 'are', 'in', 'bed', '!']\n",
      "AFter tokenizer:  ['no', 'i', 'do', \"n't\", 'have', 'cancer', '.', 'moms', 'making', 'a', 'big', 'deal', 'out', 'of', 'a', 'regular', 'checkup', 'aka', 'pap', 'smear']\n",
      "AFter tokenizer:  ['am', 'in', 'gobi', 'arts', 'college']\n",
      "AFter tokenizer:  ['why', 'she', 'wants', 'to', 'talk', 'to', 'me']\n",
      "AFter tokenizer:  ['pandy', 'joined', '4w', 'technologies', 'today.he', 'got', 'job', '..']\n",
      "AFter tokenizer:  ['you', 'are', 'guaranteed', 'the', 'latest', 'nokia', 'phone', ',', 'a', '40gb', 'ipod', 'mp3', 'player', 'or', 'a', '£500', 'prize', '!', 'txt', 'word', ':', 'collect', 'to', 'no', ':', '83355', '!', 'ibhltd', 'ldnw15h', '150p/mtmsgrcvd18']\n",
      "AFter tokenizer:  ['they', 'can', 'try', '!', 'they', 'can', 'get', 'lost', ',', 'in', 'fact', '.', 'tee', 'hee']\n",
      "AFter tokenizer:  ['my', 'friends', 'use', 'to', 'call', 'the', 'same', '.']\n",
      "AFter tokenizer:  ['em', ',', 'its', 'olowoyey', '@', 'usc.edu', 'have', 'a', 'great', 'time', 'in', 'argentina', '.', 'not', 'sad', 'about', 'secretary', ',', 'everything', 'is', 'a', 'blessing']\n",
      "AFter tokenizer:  ['it', ',', ',s', 'a', 'taxt', 'massage', '....', 'tie-pos', 'argh', 'ok', '!', 'lool', '!']\n",
      "AFter tokenizer:  ['hi', ',', 'can', 'i', 'please', 'get', 'a', '&', 'lt', ';', '#', '&', 'gt', ';', 'dollar', 'loan', 'from', 'you', '.', 'i.ll', 'pay', 'you', 'back', 'by', 'mid', 'february', '.', 'pls', '.']\n",
      "AFter tokenizer:  ['you', 'might', 'want', 'to', 'pull', 'out', 'more', 'just', 'in', 'case', 'and', 'just', 'plan', 'on', 'not', 'spending', 'it', 'if', 'you', 'can', ',', 'i', 'do', \"n't\", 'have', 'much', 'confidence', 'in', 'derek', 'and', 'taylor', \"'s\", 'money', 'management']\n",
      "AFter tokenizer:  ['do', 'you', 'like', 'shaking', 'your', 'booty', 'on', 'the', 'dance', 'floor', '?']\n",
      "AFter tokenizer:  ['text', 'me', 'when', 'you', 'get', 'off', ',', 'do', \"n't\", 'call', ',', 'my', 'phones', 'having', 'problems']\n",
      "AFter tokenizer:  ['no', 'need', 'for', 'the', 'drug', 'anymore', '.']\n",
      "AFter tokenizer:  ['sorry', 'da', ':', ')', 'i', 'was', 'thought', 'of', 'calling', 'you', 'lot', 'of', 'times', ':', ')', 'lil', 'busy.i', 'will', 'call', 'you', 'at', 'noon', '..']\n",
      "AFter tokenizer:  ['its', 'sarcasm', '..', '.nt', 'scarcasim']\n",
      "AFter tokenizer:  ['great', '!', 'i', 'have', 'to', 'run', 'now', 'so', 'ttyl', '!']\n",
      "AFter tokenizer:  ['feel', 'like', 'trying', 'kadeem', 'again', '?', ':', 'v']\n",
      "AFter tokenizer:  ['dai', '&', 'lt', ';', '#', '&', 'gt', ';', 'naal', 'eruku', '.']\n",
      "AFter tokenizer:  ['not', 'yet', 'chikku', '..', 'wat', 'abt', 'u', '?']\n",
      "AFter tokenizer:  ['want', 'to', 'finally', 'have', 'lunch', 'today', '?']\n",
      "AFter tokenizer:  ['do', 'you', 'know', 'when', 'dad', 'will', 'be', 'back', '?']\n",
      "AFter tokenizer:  ['hello', 'darling', 'how', 'are', 'you', 'today', '?', 'i', 'would', 'love', 'to', 'have', 'a', 'chat', ',', 'why', 'dont', 'you', 'tell', 'me', 'what', 'you', 'look', 'like', 'and', 'what', 'you', 'are', 'in', 'to', 'sexy', '?']\n",
      "AFter tokenizer:  ['8007', 'free', 'for', '1st', 'week', '!', 'no1', 'nokia', 'tone', '4', 'ur', 'mob', 'every', 'week', 'just', 'txt', 'nokia', 'to', '8007', 'get', 'txting', 'and', 'tell', 'ur', 'mates', 'www.getzed.co.uk', 'pobox', '36504', 'w4', '5wq', 'norm', '150p/tone', '16+']\n",
      "AFter tokenizer:  ['he', 'remains', 'a', 'bro', 'amongst', 'bros']\n",
      "AFter tokenizer:  ['r', 'u', 'meeting', 'da', 'ge', 'at', 'nite', 'tmr', '?']\n",
      "AFter tokenizer:  ['*', 'was', 'a', 'nice', 'day', 'and', ',', 'impressively', ',', 'i', 'was', 'sensible', ',', 'went', 'home', 'early', 'and', 'now', 'feel', 'fine', '.', 'or', 'am', 'i', 'just', 'boring', '?', '!', 'when', \"'s\", 'yours', ',', 'i', 'ca', \"n't\", 'remember', '.']\n",
      "AFter tokenizer:  ['why', 'de', '.', 'you', 'looking', 'good', 'only', ':', '-', ')', '..']\n",
      "AFter tokenizer:  ['wan', 'na', 'get', 'laid', '2nite', '?', 'want', 'real', 'dogging', 'locations', 'sent', 'direct', 'to', 'ur', 'mobile', '?', 'join', 'the', 'uk', \"'s\", 'largest', 'dogging', 'network', '.', 'txt', 'park', 'to', '69696', 'now', '!', 'nyt', '.', 'ec2a', '.', '3lp', '£1.50/msg']\n",
      "AFter tokenizer:  ['we', 'tried', 'to', 'contact', 'you', 're', 'your', 'response', 'to', 'our', 'offer', 'of', 'a', 'new', 'nokia', 'fone', 'and', 'camcorder', 'hit', 'reply', 'or', 'call', '08000930705', 'for', 'delivery']\n",
      "AFter tokenizer:  ['yes', '.', 'they', 'replied', 'my', 'mail', '.', 'i', \"'m\", 'going', 'to', 'the', 'management', 'office', 'later', '.', 'plus', 'will', 'in', 'to', 'bank', 'later', 'also.or', 'on', 'wednesday', '.']\n",
      "AFter tokenizer:  ['that', \"'s\", 'cool', ',', 'i', \"'ll\", 'come', 'by', 'like', '&', 'lt', ';', '#', '&', 'gt', ';', 'ish']\n",
      "AFter tokenizer:  ['super', 'msg', 'da', ':', ')', 'nalla', 'timing', '.']\n",
      "AFter tokenizer:  ['good', 'afternoon', ',', 'my', 'boytoy', '...', 'how', 'are', 'you', 'feeling', 'today', '?', 'better', 'i', 'hope', '?', 'are', 'you', 'being', 'my', 'good', 'boy', '?', 'are', 'you', 'my', 'obedient', ',', 'slave', '?', 'do', 'you', 'please', 'your', 'queen', '?']\n",
      "AFter tokenizer:  ['i', 'am', '6', 'ft.', 'we', 'will', 'be', 'a', 'good', 'combination', '!']\n",
      "AFter tokenizer:  ['i', \"'m\", 'sick', '!', '!', 'i', \"'m\", 'needy', '!', '!', 'i', 'want', 'you', '!', '!', '*', 'pouts', '*', '*', 'stomps', 'feet', '*', 'where', 'are', 'you', '?', '!', '*', 'pouts', '*', '*', 'stomps', 'feet', '*', 'i', 'want', 'my', 'slave', '!', '!', 'i', 'want', 'him', 'now', '!', '!']\n",
      "AFter tokenizer:  ['*', 'am', 'on', 'a', 'train', 'back', 'from', 'northampton', 'so', 'i', \"'m\", 'afraid', 'not', '!']\n",
      "AFter tokenizer:  ['where', 'in', 'abj', 'are', 'you', 'serving', '.', 'are', 'you', 'staying', 'with', 'dad', 'or', 'alone', '.']\n",
      "AFter tokenizer:  ['was', 'playng', '9', 'doors', 'game', 'and', 'gt', 'racing', 'on', 'phone', 'lol']\n",
      "AFter tokenizer:  ['new', 'tones', 'this', 'week', 'include', ':', '1', ')', 'mcfly-all', 'ab', '..', ',', '2', ')', 'sara', 'jorge-shock', '..', '3', ')', 'will', 'smith-switch', '..', 'to', 'order', 'follow', 'instructions', 'on', 'next', 'message']\n",
      "AFter tokenizer:  ['i', \"'m\", 'on', 'da', 'bus', 'going', 'home', '...']\n",
      "AFter tokenizer:  ['i', 'got', 'a', 'call', 'from', 'a', 'landline', 'number', '.', '.', '.', 'i', 'am', 'asked', 'to', 'come', 'to', 'anna', 'nagar', '.', '.', '.', 'i', 'will', 'go', 'in', 'the', 'afternoon']\n",
      "AFter tokenizer:  ['i', \"'m\", 'okay', '.', 'chasing', 'the', 'dream', '.', 'what', \"'s\", 'good', '.', 'what', 'are', 'you', 'doing', 'next', '.']\n",
      "AFter tokenizer:  ['yupz', '...', 'i', \"'ve\", 'oredi', 'booked', 'slots', '4', 'my', 'weekends', 'liao', '...']\n",
      "AFter tokenizer:  ['urgent', '!', 'we', 'are', 'trying', 'to', 'contact', 'u.', 'todays', 'draw', 'shows', 'that', 'you', 'have', 'won', 'a', '£800', 'prize', 'guaranteed', '.', 'call', '09050003091', 'from', 'land', 'line', '.', 'claim', 'c52', '.', 'valid', '12hrs', 'only']\n",
      "AFter tokenizer:  ['there', 'r', 'many', 'model', '..', 'sony', 'ericson', 'also', 'der', '..', '&', 'lt', ';', '#', '&', 'gt', ';', '..', 'it', 'luks', 'good', 'bt', 'i', 'forgot', 'modl', 'no']\n",
      "AFter tokenizer:  ['yes', 'i', 'know', 'the', 'cheesy', 'songs', 'from', 'frosty', 'the', 'snowman', ':', ')']\n",
      "AFter tokenizer:  ['ya', 'ok', ',', 'vikky', 'vl', 'c', 'witin', '&', 'lt', ';', '#', '&', 'gt', ';', 'mins', 'and', 'il', 'reply', 'u', '..']\n",
      "AFter tokenizer:  ['sports', 'fans', '-', 'get', 'the', 'latest', 'sports', 'news', 'str', '*', '2', 'ur', 'mobile', '1', 'wk', 'free', 'plus', 'a', 'free', 'tone', 'txt', 'sport', 'on', 'to', '8007', 'www.getzed.co.uk', '0870141701216+', 'norm', '4txt/120p']\n",
      "AFter tokenizer:  ['hey', 'tmr', 'meet', 'at', 'bugis', '930', '?']\n",
      "AFter tokenizer:  ['urgent', 'urgent', '!', 'we', 'have', '800', 'free', 'flights', 'to', 'europe', 'to', 'give', 'away', ',', 'call', 'b4', '10th', 'sept', '&', 'take', 'a', 'friend', '4', 'free', '.', 'call', 'now', 'to', 'claim', 'on', '09050000555.', 'ba128nnfwfly150ppm']\n",
      "AFter tokenizer:  ['all', 'these', 'nice', 'new', 'shirts', 'and', 'the', 'only', 'thing', 'i', 'can', 'wear', 'them', 'to', 'is', 'nudist', 'themed', ';', '_', ';', 'you', 'in', 'mu', '?']\n",
      "AFter tokenizer:  ['hey', 'sexy', 'buns', '!', 'what', 'of', 'that', 'day', '?', 'no', 'word', 'from', 'you', 'this', 'morning', 'on', 'ym', '...', ':', '-', '(', '...', 'i', 'think', 'of', 'you']\n",
      "AFter tokenizer:  ['and', 'whenever', 'you', 'and', 'i', 'see', 'we', 'can', 'still', 'hook', 'up', 'too', '.']\n",
      "AFter tokenizer:  ['nope', 'but', 'i', \"'m\", 'going', 'home', 'now', 'then', 'go', 'pump', 'petrol', 'lor', '...', 'like', 'going', '2', 'rain', 'soon', '...']\n",
      "AFter tokenizer:  ['can', 'you', 'use', 'foreign', 'stamps', 'for', 'whatever', 'you', 'send', 'them', 'off', 'for', '?']\n",
      "AFter tokenizer:  ['from', '88066', 'lost', '£12', 'help']\n",
      "AFter tokenizer:  ['oh', 'baby', 'of', 'the', 'house', '.', 'how', 'come', 'you', 'dont', 'have', 'any', 'new', 'pictures', 'on', 'facebook']\n",
      "AFter tokenizer:  ['feb', '&', 'lt', ';', '#', '&', 'gt', ';', 'is', '``', 'i', 'love', 'u', \"''\", 'day', '.', 'send', 'dis', 'to', 'all', 'ur', '``', 'valued', 'frnds', \"''\", 'evn', 'me', '.', 'if', '3', 'comes', 'back', 'u', \"'ll\", 'gt', 'married', 'd', 'person', 'u', 'luv', '!', 'if', 'u', 'ignore', 'dis', 'u', 'will', 'lose', 'ur', 'luv', '4', 'evr']\n",
      "AFter tokenizer:  ['hiya', ',', 'sorry', 'did', \"n't\", 'hav', 'signal', '.', 'i', 'have', \"n't\", 'seen', 'or', 'heard', 'from', 'and', 'neither', 'has', ',', 'which', 'is', 'unusual', 'in', 'itself', '!', 'i', \"'ll\", 'put', 'on', 'the', 'case', 'and', 'get', 'him', 'to', 'sort', 'it', 'out', '!', 'hugs', 'and', 'snogs', '.']\n",
      "AFter tokenizer:  ['omw', 'back', 'to', 'tampa', 'from', 'west', 'palm', ',', 'you', 'hear', 'what', 'happened', '?']\n",
      "AFter tokenizer:  ['yup', 'no', 'more', 'already', '...', 'thanx', '4', 'printing', 'n', 'handing', 'it', 'up', '.']\n",
      "AFter tokenizer:  ['freemsg', ':', 'fancy', 'a', 'flirt', '?', 'reply', 'date', 'now', '&', 'join', 'the', 'uks', 'fastest', 'growing', 'mobile', 'dating', 'service', '.', 'msgs', 'rcvd', 'just', '25p', 'to', 'optout', 'txt', 'stop', 'to', '83021.', 'reply', 'date', 'now', '!']\n",
      "AFter tokenizer:  ['what', 'i', 'mean', 'is', 'do', 'they', 'come', 'chase', 'you', 'out', 'when', 'its', 'over', 'or', 'is', 'it', 'stated', 'you', 'can', 'watch', 'as', 'many', 'movies', 'as', 'you', 'want', '.']\n",
      "AFter tokenizer:  ['s', 'now', 'only', 'i', 'took', 'tablets', '.', 'reaction', 'morning', 'only', '.']\n",
      "AFter tokenizer:  ['great', 'new', 'offer', '-', 'double', 'mins', '&', 'double', 'txt', 'on', 'best', 'orange', 'tariffs', 'and', 'get', 'latest', 'camera', 'phones', '4', 'free', '!', 'call', 'mobileupd8', 'free', 'on', '08000839402', 'now', '!', 'or', '2stoptxt', 't', '&', 'cs']\n",
      "AFter tokenizer:  ['nah', ',', 'i', \"'m\", 'a', 'perpetual', 'dd']\n",
      "AFter tokenizer:  ['sorry', 'de', 'i', 'went', 'to', 'shop', '.']\n",
      "AFter tokenizer:  ['hope', 'you', 'enjoyed', 'your', 'new', 'content', '.', 'text', 'stop', 'to', '61610', 'to', 'unsubscribe', '.', 'help:08712400602450p', 'provided', 'by', 'tones2you.co.uk']\n",
      "AFter tokenizer:  ['hey', 'you', 'still', 'want', 'to', 'go', 'for', 'yogasana', '?', 'coz', 'if', 'we', 'end', 'at', 'cine', 'then', 'can', 'go', 'bathe', 'and', 'hav', 'the', 'steam', 'bath']\n",
      "AFter tokenizer:  ['nope', 'i', \"'m\", 'not', 'drivin', '...', 'i', 'neva', 'develop', 'da', 'photos', 'lei', '...']\n",
      "AFter tokenizer:  ['i', 'am', 'thinking', 'of', 'going', 'down', 'to', 'reg', 'for', 'pract', 'lessons', '..', 'flung', 'my', 'advance', '..', 'haha', 'wat', 'time', 'u', 'going', '?']\n",
      "AFter tokenizer:  ['cool', '.', 'i', 'am', '&', 'lt', ';', '#', '&', 'gt', ';', 'inches', 'long', '.', 'hope', 'you', 'like', 'them', 'big', '!']\n",
      "AFter tokenizer:  ['house-maid', 'is', 'the', 'murderer', ',', 'coz', 'the', 'man', 'was', 'murdered', 'on', '&', 'lt', ';', '#', '&', 'gt', ';', 'th', 'january', '..', 'as', 'public', 'holiday', 'all', 'govt.instituitions', 'are', 'closed', ',', 'including', 'post', 'office', '..', 'understand', '?']\n",
      "AFter tokenizer:  ['okie', '..', 'thanx', '..']\n",
      "AFter tokenizer:  ['go', 'where', 'n', 'buy', '?', 'juz', 'buy', 'when', 'we', 'get', 'there', 'lar', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'working', 'technical', 'support', ':', ')', 'voice', 'process', '.']\n",
      "AFter tokenizer:  ['it', \"'s\", 'justbeen', 'overa', 'week', 'since', 'we', 'broke', 'up', 'and', 'already', 'our', 'brains', 'are', 'going', 'to', 'mush', '!']\n",
      "AFter tokenizer:  ['tunde', ',', 'how', 'are', 'you', 'doing', '.', 'this', 'is', 'just', 'wishing', 'you', 'a', 'great', 'day', '.', 'abiola', '.']\n",
      "AFter tokenizer:  ['nope', '...', 'c', 'ü', 'then', '...']\n",
      "AFter tokenizer:  ['no', '.', 'but', 'we', \"'ll\", 'do', 'medical', 'missions', 'to', 'nigeria']\n",
      "AFter tokenizer:  ['no', 'i', 'am', 'not', 'having', 'not', 'any', 'movies', 'in', 'my', 'laptop']\n",
      "AFter tokenizer:  ['urgent', 'please', 'call', '09066612661', 'from', 'landline', '.', '£5000', 'cash', 'or', 'a', 'luxury', '4', '*', 'canary', 'islands', 'holiday', 'await', 'collection', '.', 't', '&', 'cs', 'sae', 'award', '.', '20m12aq', '.', '150ppm', '.', '16+', '“']\n",
      "AFter tokenizer:  ['urgent', '!', 'please', 'call', '09066612661', 'from', 'your', 'landline', ',', 'your', 'complimentary', '4', '*', 'lux', 'costa', 'del', 'sol', 'holiday', 'or', '£1000', 'cash', 'await', 'collection', '.', 'ppm', '150', 'sae', 't', '&', 'cs', 'james', '28', ',', 'eh74rr']\n",
      "AFter tokenizer:  ['i', 'havent', 'lei', '..', 'next', 'mon', 'can', '?']\n",
      "AFter tokenizer:  ['mm', 'feeling', 'sleepy', '.', 'today', 'itself', 'i', 'shall', 'get', 'that', 'dear']\n",
      "AFter tokenizer:  ['how', 'dare', 'you', 'stupid', '.', 'i', 'wont', 'tell', 'anything', 'to', 'you', '.', 'hear', 'after', 'i', 'wont', 'talk', 'to', 'you', ':', '-', '.']\n",
      "AFter tokenizer:  ['do', 'ü', 'noe', 'if', 'ben', 'is', 'going', '?']\n",
      "AFter tokenizer:  ['can', 'you', 'do', 'a', 'mag', 'meeting', 'this', 'avo', 'at', 'some', 'point', '?']\n",
      "AFter tokenizer:  ['i', 'meant', 'middle', 'left', 'or', 'right', '?']\n",
      "AFter tokenizer:  ['really', '?', 'i', 'crashed', 'out', 'cuddled', 'on', 'my', 'sofa', '.']\n",
      "AFter tokenizer:  ['hi', 'chachi', 'tried', 'calling', 'u', 'now', 'unable', 'to', 'reach', 'u', '..', 'pl', 'give', 'me', 'a', 'missed', 'cal', 'once', 'u', 'c', 'tiz', 'msg', 'kanagu']\n",
      "AFter tokenizer:  ['i', 'sent', 'you', 'the', 'prices', 'and', 'do', 'you', 'mean', 'the', '&', 'lt', ';', '#', '&', 'gt', ';', 'g', ',']\n",
      "AFter tokenizer:  ['nothing', '.', 'can', '...']\n",
      "AFter tokenizer:  ['no', '*', 'am', 'working', 'on', 'the', 'ringing', 'u', 'thing', 'but', 'have', 'whole', 'houseful', 'of', 'screaming', 'brats', 'so', '*', 'am', 'pulling', 'my', 'hair', 'out', '!', 'loving', 'u']\n",
      "AFter tokenizer:  ['but', 'my', 'family', 'not', 'responding', 'for', 'anything', '.', 'now', 'am', 'in', 'room', 'not', 'went', 'to', 'home', 'for', 'diwali', 'but', 'no', 'one', 'called', 'me', 'and', 'why', 'not', 'coming', '.', 'it', 'makes', 'me', 'feel', 'like', 'died', '.']\n",
      "AFter tokenizer:  ['tick', ',', 'tick', ',', 'tick', '...', 'babe']\n",
      "AFter tokenizer:  ['r', 'ü', 'going', '4', 'today', \"'s\", 'meeting', '?']\n",
      "AFter tokenizer:  ['k', 'da', ':', ')', 'how', 'many', 'page', 'you', 'want', '?']\n",
      "AFter tokenizer:  ['ya', 'had', 'just', 'now.onion', 'roast', '.']\n",
      "AFter tokenizer:  ['send', 'his', 'number', 'and', 'give', 'reply', 'tomorrow', 'morning', 'for', 'why', 'you', 'said', 'that', 'to', 'him', 'like', 'that', 'ok']\n",
      "AFter tokenizer:  ['you', 'said', 'not', 'now', '.', 'no', 'problem', '.', 'when', 'you', 'can', '.', 'let', 'me', 'know', '.']\n",
      "AFter tokenizer:  ['ok', 'but', 'tell', 'me', 'half', 'an', 'hr', 'b4', 'u', 'come', 'i', 'need', '2', 'prepare', '.']\n",
      "AFter tokenizer:  ['play', 'w', 'computer', '?', 'aiyah', 'i', 'tok', '2', 'u', 'lor', '?']\n",
      "AFter tokenizer:  ['sat', 'right', '?', 'okay', 'thanks', '...']\n",
      "AFter tokenizer:  ['derp', '.', 'which', 'is', 'worse', ',', 'a', 'dude', 'who', 'always', 'wants', 'to', 'party', 'or', 'a', 'dude', 'who', 'files', 'a', 'complaint', 'about', 'the', 'three', 'drug', 'abusers', 'he', 'lives', 'with']\n",
      "AFter tokenizer:  ['ok', 'chinese', 'food', 'on', 'its', 'way', '.', 'when', 'i', 'get', 'fat', 'you', \"'re\", 'paying', 'for', 'my', 'lipo', '.']\n",
      "AFter tokenizer:  ['we', 'r', 'outside', 'already', '.']\n",
      "AFter tokenizer:  ['have', 'a', 'good', 'trip', '.', 'watch', 'out', 'for', '.', 'remember', 'when', 'you', 'get', 'back', 'we', 'must', 'decide', 'about', 'easter', '.']\n",
      "AFter tokenizer:  ['yo', 'we', 'are', 'watching', 'a', 'movie', 'on', 'netflix']\n",
      "AFter tokenizer:  ['what', 'time', '.', 'i', '‘', 'm', 'out', 'until', 'prob', '3', 'or', 'so']\n",
      "AFter tokenizer:  ['can', 'meh', '?', 'thgt', 'some', 'will', 'clash', '...', 'really', 'ah', ',', 'i', 'dun', 'mind', '...', 'i', 'dun', 'seen', 'to', 'have', 'lost', 'any', 'weight', '...', 'gee', '...']\n",
      "AFter tokenizer:  ['arr', 'birthday', 'today', ':', ')', 'i', 'wish', 'him', 'to', 'get', 'more', 'oscar', '.']\n",
      "AFter tokenizer:  ['open', 'rebtel', 'with', 'firefox', '.', 'when', 'it', 'loads', 'just', 'put', 'plus', 'sign', 'in', 'the', 'user', 'name', 'place', ',', 'and', 'it', 'will', 'show', 'you', 'two', 'numbers', '.', 'the', 'lower', 'number', 'is', 'my', 'number', '.', 'once', 'you', 'pick', 'that', 'number', 'the', 'pin', 'will', 'display', 'okay', '!']\n",
      "AFter tokenizer:  ['and', 'picking', 'them', 'up', 'from', 'various', 'points']\n",
      "AFter tokenizer:  ['married', 'local', 'women', 'looking', 'for', 'discreet', 'action', 'now', '!', '5', 'real', 'matches', 'instantly', 'to', 'your', 'phone', '.', 'text', 'match', 'to', '69969', 'msg', 'cost', '150p', '2', 'stop', 'txt', 'stop', 'bcmsfwc1n3xx']\n",
      "AFter tokenizer:  ['wow', 'v', 'v', 'impressed', '.', 'have', 'funs', 'shopping', '!']\n",
      "AFter tokenizer:  ['i', 'am', 'on', 'the', 'way', 'to', 'ur', 'home']\n",
      "AFter tokenizer:  ['burger', 'king', '-', 'wan', 'na', 'play', 'footy', 'at', 'a', 'top', 'stadium', '?', 'get', '2', 'burger', 'king', 'before', '1st', 'sept', 'and', 'go', 'large', 'or', 'super', 'with', 'coca-cola', 'and', 'walk', 'out', 'a', 'winner']\n",
      "AFter tokenizer:  ['no', 'problem', '.', 'talk', 'to', 'you', 'later']\n",
      "AFter tokenizer:  ['then', 'ur', 'sis', 'how', '?']\n",
      "AFter tokenizer:  ['still', 'in', 'customer', 'place']\n",
      "AFter tokenizer:  ['how', 'come', 'it', 'takes', 'so', 'little', 'time', 'for', 'a', 'child', 'who', 'is', 'afraid', 'of', 'the', 'dark', 'to', 'become', 'a', 'teenager', 'who', 'wants', 'to', 'stay', 'out', 'all', 'night', '?']\n",
      "AFter tokenizer:  ['dude', 'u', 'knw', 'also', 'telugu', '..', 'thts', 'gud', '..', 'k', ',', 'gud', 'nyt', '..']\n",
      "AFter tokenizer:  ['we', 'confirm', 'eating', 'at', 'esplanade', '?']\n",
      "AFter tokenizer:  ['send', 'me', 'your', 'id', 'and', 'password']\n",
      "AFter tokenizer:  ['kind', 'of', '.', 'took', 'it', 'to', 'garage', '.', 'centre', 'part', 'of', 'exhaust', 'needs', 'replacing', '.', 'part', 'ordered', 'n', 'taking', 'it', 'to', 'be', 'fixed', 'tomo', 'morning', '.']\n",
      "AFter tokenizer:  ['for', 'ur', 'chance', 'to', 'win', 'a', '£250', 'cash', 'every', 'wk', 'txt', ':', 'action', 'to', '80608.', 't', \"'s\", '&', 'c', \"'s\", 'www.movietrivia.tv', 'custcare', '08712405022', ',', '1x150p/wk', '.']\n",
      "AFter tokenizer:  ['well', 'i', 'might', 'not', 'come', 'then', '...']\n",
      "AFter tokenizer:  ['long', 'after', 'i', 'quit', '.', 'i', 'get', 'on', 'only', 'like', '5', 'minutes', 'a', 'day', 'as', 'it', 'is', '.']\n",
      "AFter tokenizer:  ['then', 'its', 'most', 'likely', 'called', 'mittelschmertz', '.', 'google', 'it', '.', 'if', 'you', 'dont', 'have', 'paracetamol', 'dont', 'worry', 'it', 'will', 'go', '.']\n",
      "AFter tokenizer:  ['well', 'at', 'this', 'right', 'i', \"'m\", 'gon', 'na', 'have', 'to', 'get', 'up', 'and', 'check', 'today', \"'s\", 'steam', 'sales/pee', 'so', 'text', 'me', 'when', 'you', 'want', 'me', 'to', 'come', 'get', 'you']\n",
      "AFter tokenizer:  ['just', 'arrived', ',', 'see', 'you', 'in', 'a', 'couple', 'days', '&', 'lt', ';', '3']\n",
      "AFter tokenizer:  ['k', ',', 'wat', 's', 'tht', 'incident', '?']\n",
      "AFter tokenizer:  ['yeah', 'get', 'the', 'unlimited']\n",
      "AFter tokenizer:  ['cthen', 'i', 'thk', 'shd', 'b', 'enuff', '..', 'still', 'got', 'conclusion', 'n', 'contents', 'pg', 'n', 'references', '..', 'i', \"'ll\", 'b', 'doing', 'da', 'contents', 'pg', 'n', 'cover', 'pg', '..']\n",
      "AFter tokenizer:  ['forgot', 'it', 'takes', 'me', '3', 'years', 'to', 'shower', ',', 'sorry', '.', 'where', 'you', 'at/your', 'phone', 'dead', 'yet', '?']\n",
      "AFter tokenizer:  ['ü', 'got', 'wat', 'to', 'buy', 'tell', 'us', 'then', 'ü', 'no', 'need', 'to', 'come', 'in', 'again', '.']\n",
      "AFter tokenizer:  ['when', 'you', 'are', 'big', '..', '|', 'god', 'will', 'bring', 'success', '.']\n",
      "AFter tokenizer:  ['u', '’', 've', 'bin', 'awarded', '£50', 'to', 'play', '4', 'instant', 'cash', '.', 'call', '08715203028', 'to', 'claim', '.', 'every', '9th', 'player', 'wins', 'min', '£50-£500', '.', 'optout', '08718727870']\n",
      "AFter tokenizer:  ['…', 'we', 'r', 'stayin', 'here', 'an', 'extra', 'week', ',', 'back', 'next', 'wed.', 'how', 'did', 'we', 'do', 'in', 'the', 'rugby', 'this', 'weekend', '?', 'hi', 'to', 'and', 'and', ',', 'c', 'u', 'soon', '``']\n",
      "AFter tokenizer:  ['well', 'there', \"'s\", 'still', 'a', 'bit', 'left', 'if', 'you', 'guys', 'want', 'to', 'tonight']\n",
      "AFter tokenizer:  ['not', 'from', 'this', 'campus', '.', 'are', 'you', 'in', 'the', 'library', '?']\n",
      "AFter tokenizer:  ['the', 'affidavit', 'says', '&', 'lt', ';', '#', '&', 'gt', ';', 'e', 'twiggs', 'st', ',', 'division', 'g', ',', 'courtroom', '&', 'lt', ';', '#', '&', 'gt', ';', ',', '&', 'lt', ';', 'time', '&', 'gt', ';', 'am', '.', 'i', \"'ll\", 'double', 'check', 'and', 'text', 'you', 'again', 'tomorrow']\n",
      "AFter tokenizer:  ['how', 'will', 'i', 'creep', 'on', 'you', 'now', '?', ';', '_', ';']\n",
      "AFter tokenizer:  ['if', 'i', 'get', 'there', 'before', 'you', 'after', 'your', 'ten', 'billion', 'calls', 'and', 'texts', 'so', 'help', 'me', 'god']\n",
      "AFter tokenizer:  ['i', \"'ve\", 'told', 'him', 'that', 'i', \"'ve\", 'returned', 'it', '.', 'that', 'should', 'i', 're', 'order', 'it', '.']\n",
      "AFter tokenizer:  ['house-maid', 'is', 'the', 'murderer', ',', 'coz', 'the', 'man', 'was', 'murdered', 'on', '&', 'lt', ';', '#', '&', 'gt', ';', 'th', 'january', '..', 'as', 'public', 'holiday', 'all', 'govt.instituitions', 'are', 'closed', ',', 'including', 'post', 'office', '..']\n",
      "AFter tokenizer:  ['depends', 'on', 'where', 'u', 'going', 'lor', '.']\n",
      "AFter tokenizer:  ['and', 'smile', 'for', 'me', 'right', 'now', 'as', 'you', 'go', 'and', 'the', 'world', 'will', 'wonder', 'what', 'you', 'are', 'smiling', 'about', 'and', 'think', 'your', 'crazy', 'and', 'keep', 'away', 'from', 'you', '...', '*', 'grins', '*']\n",
      "AFter tokenizer:  ['freemsg', '>', 'fav', 'xmas', 'tones', '!', 'reply', 'real']\n",
      "AFter tokenizer:  ['lil', 'fever', ':', ')', 'now', 'fine', ':', ')']\n",
      "AFter tokenizer:  ['i', 'think', 'it', \"'s\", 'all', 'still', 'in', 'my', 'car']\n",
      "AFter tokenizer:  ['can', 'a', 'not', '?']\n",
      "AFter tokenizer:  ['yes', 'princess', '!', 'i', 'want', 'to', 'catch', 'you', 'with', 'my', 'big', 'strong', 'hands', '...']\n",
      "AFter tokenizer:  ['oh', 'yeah', 'i', 'forgot', '.', 'u', 'can', 'only', 'take', '2', 'out', 'shopping', 'at', 'once', '.']\n",
      "AFter tokenizer:  ['mm', 'so', 'you', 'asked', 'me', 'not', 'to', 'call', 'radio']\n",
      "AFter tokenizer:  ['thinkin', 'about', 'someone', 'is', 'all', 'good', '.', 'no', 'drugs', 'for', 'that']\n",
      "AFter tokenizer:  ['enjoy', 'the', 'showers', 'of', 'possessiveness', 'poured', 'on', 'u', 'by', 'ur', 'loved', 'ones', ',', 'bcoz', 'in', 'this', 'world', 'of', 'lies', ',', 'it', 'is', 'a', 'golden', 'gift', 'to', 'be', 'loved', 'truly', '..']\n",
      "AFter tokenizer:  ['alright', 'if', 'you', \"'re\", 'sure', ',', 'let', 'me', 'know', 'when', 'you', \"'re\", 'leaving']\n",
      "AFter tokenizer:  ['some', 'are', 'lasting', 'as', 'much', 'as', '2', 'hours', '.', 'you', 'might', 'get', 'lucky', '.']\n",
      "AFter tokenizer:  ['genius', 'what', \"'s\", 'up', '.', 'how', 'your', 'brother', '.', 'pls', 'send', 'his', 'number', 'to', 'my', 'skype', '.']\n",
      "AFter tokenizer:  ['gr8', 'poly', 'tones', '4', 'all', 'mobs', 'direct', '2u', 'rply', 'with', 'poly', 'title', 'to', '8007', 'eg', 'poly', 'breathe1', 'titles', ':', 'crazyin', ',', 'sleepingwith', ',', 'finest', ',', 'ymca', ':', 'getzed.co.uk', 'pobox365o4w45wq', '300p']\n",
      "AFter tokenizer:  ['thk', 'some', 'of', 'em', 'find', 'wtc', 'too', 'far', '...', 'weiyi', 'not', 'goin', '...', 'e', 'rest', 'i', 'dunno', 'yet', '...', 'r', 'ur', 'goin', '4', 'dinner', 'den', 'i', 'might', 'b', 'able', 'to', 'join', '...']\n",
      "AFter tokenizer:  ['do', \"n't\", 'forget', 'who', 'owns', 'you', 'and', 'who', \"'s\", 'private', 'property', 'you', 'are', '...', 'and', 'be', 'my', 'good', 'boy', 'always', '..', '*', 'passionate', 'kiss', '*']\n",
      "AFter tokenizer:  ['interflora', '-', '\\x93it', \"'s\", 'not', 'too', 'late', 'to', 'order', 'interflora', 'flowers', 'for', 'christmas', 'call', '0800', '505060', 'to', 'place', 'your', 'order', 'before', 'midnight', 'tomorrow', '.']\n",
      "AFter tokenizer:  ['oh', 'god', '..', 'taken', 'the', 'teeth', '?', 'is', 'it', 'paining']\n",
      "AFter tokenizer:  ['romcapspam', 'everyone', 'around', 'should', 'be', 'responding', 'well', 'to', 'your', 'presence', 'since', 'you', 'are', 'so', 'warm', 'and', 'outgoing', '.', 'you', 'are', 'bringing', 'in', 'a', 'real', 'breath', 'of', 'sunshine', '.']\n",
      "AFter tokenizer:  ['then', 'u', 'ask', 'darren', 'go', 'n', 'pick', 'u', 'lor', '...', 'but', 'i', 'oso', 'sian', 'tmr', 'haf', '2', 'meet', 'lect', '...']\n",
      "AFter tokenizer:  ['no', 'need', 'to', 'buy', 'lunch', 'for', 'me', '..', 'i', 'eat', 'maggi', 'mee', '..']\n",
      "AFter tokenizer:  ['congratulations', '-', 'thanks', 'to', 'a', 'good', 'friend', 'u', 'have', 'won', 'the', '£2,000', 'xmas', 'prize', '.', '2', 'claim', 'is', 'easy', ',', 'just', 'call', '08712103738', 'now', '!', 'only', '10p', 'per', 'minute', '.', 'bt-national-rate']\n",
      "AFter tokenizer:  ['oh', 'right', ',', 'ok.', 'i', \"'ll\", 'make', 'sure', 'that', 'i', 'do', 'loads', 'of', 'work', 'during', 'the', 'day', '!', 'got', 'a', 'really', 'nasty', 'cough', 'today', 'and', 'is', 'dry', 'n', 'shot', 'so', 'that', 'should', 'really', 'help', 'it', '!']\n",
      "AFter tokenizer:  ['send', 'a', 'logo', '2', 'ur', 'lover', '-', '2', 'names', 'joined', 'by', 'a', 'heart', '.', 'txt', 'love', 'name1', 'name2', 'mobno', 'eg', 'love', 'adam', 'eve', '07123456789', 'to', '87077', 'yahoo', '!', 'pobox36504w45wq', 'txtno', '4', 'no', 'ads', '150p', '.']\n",
      "AFter tokenizer:  ['thanx', '4', 'sending', 'me', 'home', '...']\n",
      "AFter tokenizer:  ['its', 'normally', 'hot', 'mail', '.', 'com', 'you', 'see', '!']\n",
      "AFter tokenizer:  ['you', \"'ve\", 'won', 'tkts', 'to', 'the', 'euro2004', 'cup', 'final', 'or', '£800', 'cash', ',', 'to', 'collect', 'call', '09058099801', 'b4190604', ',', 'pobox', '7876150ppm']\n",
      "AFter tokenizer:  ['u', 'sick', 'still', 'can', 'go', 'shopping', '?']\n",
      "AFter tokenizer:  ['ya', 'they', 'are', 'well', 'and', 'fine.', ',', 'bbd', '(', 'pooja', ')', 'full', 'pimples', '..', 'even', 'she', 'become', 'quite', 'black', '..', 'and', 'ur', 'rite', 'here', 'its', 'too', 'cold', ',', 'wearing', 'sweatter', '..']\n",
      "AFter tokenizer:  ['nice.nice.how', 'is', 'it', 'working', '?']\n",
      "AFter tokenizer:  ['1', \"'s\", 'reach', 'home', 'call', 'me', '.']\n",
      "AFter tokenizer:  ['were', 'trying', 'to', 'find', 'a', 'chinese', 'food', 'place', 'around', 'here']\n",
      "AFter tokenizer:  ['easy', 'mate', ',', '*', 'guess', 'the', 'quick', 'drink', 'was', 'bit', 'ambitious', '.']\n",
      "AFter tokenizer:  ['babe', '!', '!', '!', 'i', 'miiiiiiissssssssss', 'you', '!', 'i', 'need', 'you', '!', '!', '!', 'i', 'crave', 'you', '!', '!', '!', ':', '-', '(', '...', 'geeee', '...', 'i', \"'m\", 'so', 'sad', 'without', 'you', 'babe', '...', 'i', 'love', 'you', '...']\n",
      "AFter tokenizer:  ['ok', 'thanx', '...']\n",
      "AFter tokenizer:  ['tunji', ',', 'how', \"'s\", 'the', 'queen', '?', 'how', 'are', 'you', 'doing', '.', 'this', 'is', 'just', 'wishing', 'you', 'a', 'great', 'day', '.', 'abiola', '.']\n",
      "AFter tokenizer:  ['today', 'iz', 'yellow', 'rose', 'day', '.', 'if', 'u', 'love', 'my', 'frndship', 'give', 'me', '1', 'misscall', '&', 'amp', ';', 'send', 'this', 'to', 'ur', 'frndz', '&', 'amp', ';', 'see', 'how', 'many', 'miss', 'calls', 'u', 'get', '.', 'if', 'u', 'get', '6missed', 'u', 'marry', 'ur', 'lover', '.']\n",
      "AFter tokenizer:  ['will', 'be', 'out', 'of', 'class', 'in', 'a', 'few', 'hours', '.', 'sorry']\n",
      "AFter tokenizer:  ['wat', 'time', 'u', 'finish', 'ur', 'lect', 'today', '?']\n",
      "AFter tokenizer:  ['free-message', ':', 'jamster', '!', 'get', 'the', 'crazy', 'frog', 'sound', 'now', '!', 'for', 'poly', 'text', 'mad1', ',', 'for', 'real', 'text', 'mad2', 'to', '88888', '.', '6', 'crazy', 'sounds', 'for', 'just', '3', 'gbp/week', '!', '16+only', '!', 't', '&', 'c', \"'s\", 'apply']\n",
      "AFter tokenizer:  ['your', 'chance', 'to', 'be', 'on', 'a', 'reality', 'fantasy', 'show', 'call', 'now', '=', '08707509020', 'just', '20p', 'per', 'min', 'ntt', 'ltd', ',', 'po', 'box', '1327', 'croydon', 'cr9', '5wb', '0870', 'is', 'a', 'national', '=', 'rate', 'call']\n",
      "AFter tokenizer:  ['she', \"'s\", 'fine', '.', 'good', 'to', 'hear', 'from', 'you', '.', 'how', 'are', 'you', 'my', 'dear', '?', 'happy', 'new', 'year', 'oh', '.']\n",
      "AFter tokenizer:  ['are', 'you', 'going', 'to', 'wipro', 'interview', 'today', '?']\n",
      "AFter tokenizer:  ['how', 'tall', 'are', 'you', 'princess', '?']\n",
      "AFter tokenizer:  ['i', 'doubt', 'you', 'could', 'handle', '5', 'times', 'per', 'night', 'in', 'any', 'case', '...']\n",
      "AFter tokenizer:  ['haha', '...', 'hope', 'ü', 'can', 'hear', 'the', 'receipt', 'sound', '...', 'gd', 'luck', '!']\n",
      "AFter tokenizer:  ['your', 'gon', 'na', 'be', 'the', 'death', 'if', 'me', '.', 'i', \"'m\", 'gon', 'na', 'leave', 'a', 'note', 'that', 'says', 'its', 'all', 'robs', 'fault', '.', 'avenge', 'me', '.']\n",
      "AFter tokenizer:  ['japanese', 'proverb', ':', 'if', 'one', 'can', 'do', 'it', ',', 'u', 'too', 'can', 'do', 'it', ',', 'if', 'none', 'can', 'do', 'it', ',', 'u', 'must', 'do', 'it', 'indian', 'version', ':', 'if', 'one', 'can', 'do', 'it', ',', 'let', 'him', 'do', 'it', '..', 'if', 'none', 'can', 'do', 'it', ',', 'leave', 'it', '!', '!', 'and', 'finally', 'kerala', 'version', ':', 'if', 'one', 'can', 'do', 'it', ',', 'stop', 'him', 'doing', 'it', '..', 'if', 'none', 'can', 'do', 'it', ',', 'make', 'a', 'strike', 'against', 'it', '...']\n",
      "AFter tokenizer:  ['today', 'i', \"'m\", 'not', 'workin', 'but', 'not', 'free', 'oso', '...', 'gee', '...', 'thgt', 'u', 'workin', 'at', 'ur', 'fren', \"'s\", 'shop', '?']\n",
      "AFter tokenizer:  ['in', 'life', 'when', 'you', 'face', 'choices', 'just', 'toss', 'a', 'coin', 'not', 'becoz', 'its', 'settle', 'the', 'question', 'but', 'while', 'the', 'coin', 'in', 'the', 'air', 'u', 'will', 'know', 'what', 'your', 'heart', 'is', 'hoping', 'for', '.', 'gudni8']\n",
      "AFter tokenizer:  ['i', 'want', 'to', 'be', 'there', 'so', 'i', 'can', 'kiss', 'you', 'and', 'feel', 'you', 'next', 'to', 'me']\n",
      "AFter tokenizer:  ['i', 'am', 'not', 'at', 'all', 'happy', 'with', 'what', 'you', 'saying', 'or', 'doing']\n",
      "AFter tokenizer:  ['adult', '18', 'content', 'your', 'video', 'will', 'be', 'with', 'you', 'shortly']\n",
      "AFter tokenizer:  ['ok', 'that', 'would', 'b', 'lovely', ',', 'if', 'u', 'r', 'sure', '.', 'think', 'about', 'wot', 'u', 'want', 'to', 'do', ',', 'drinkin', ',', 'dancin', ',', 'eatin', ',', 'cinema', ',', 'in', ',', 'out', ',', 'about', '...', 'up', 'to', 'u', '!', 'wot', 'about', '?']\n",
      "AFter tokenizer:  ['what', 'i', \"'m\", 'saying', 'is', 'if', 'you', 'have', \"n't\", 'explicitly', 'told', 'nora', 'i', 'know', 'someone', 'i', \"'m\", 'probably', 'just', 'not', 'gon', 'na', 'bother']\n",
      "AFter tokenizer:  ['smith', 'waste', 'da.i', 'wan', 'na', 'gayle', '.']\n",
      "AFter tokenizer:  ['mum', ',', 'i', \"'ve\", 'sent', 'you', 'many', 'many', 'messages', 'since', 'i', 'got', 'here', '.', 'i', 'just', 'want', 'to', 'know', 'that', 'you', 'are', 'actually', 'getting', 'them', '.', 'do', 'enjoy', 'the', 'rest', 'of', 'your', 'day', '.']\n",
      "AFter tokenizer:  ['aight', ',', 'tomorrow', 'around', '&', 'lt', ';', '#', '&', 'gt', ';', 'it', 'is']\n",
      "AFter tokenizer:  ['your', 'chance', 'to', 'be', 'on', 'a', 'reality', 'fantasy', 'show', 'call', 'now', '=', '08707509020', 'just', '20p', 'per', 'min', 'ntt', 'ltd', ',', 'po', 'box', '1327', 'croydon', 'cr9', '5wb', '0870', 'is', 'a', 'national', '=', 'rate', 'call', '.']\n",
      "AFter tokenizer:  ['i', 'actually', 'did', 'for', 'the', 'first', 'time', 'in', 'a', 'while', '.', 'i', 'went', 'to', 'bed', 'not', 'too', 'long', 'after', 'i', 'spoke', 'with', 'you', '.', 'woke', 'up', 'at', '7.', 'how', 'was', 'your', 'night', '?']\n",
      "AFter tokenizer:  ['see', 'you', 'there', '!']\n",
      "AFter tokenizer:  ['i', 'dont', 'understand', 'your', 'message', '.']\n",
      "AFter tokenizer:  ['crucify', 'is', 'c', 'not', 's.', 'you', 'should', 'have', 'told', 'me', 'earlier', '.']\n",
      "AFter tokenizer:  ['idk', '.', 'you', 'keep', 'saying', 'that', 'you', \"'re\", 'not', ',', 'but', 'since', 'he', 'moved', ',', 'we', 'keep', 'butting', 'heads', 'over', 'freedom', 'vs.', 'responsibility', '.', 'and', 'i', \"'m\", 'tired', '.', 'i', 'have', 'so', 'much', 'other', 'shit', 'to', 'deal', 'with', 'that', 'i', \"'m\", 'barely', 'keeping', 'myself', 'together', 'once', 'this', 'gets', 'added', 'to', 'it', '.']\n",
      "AFter tokenizer:  ['fuck', 'cedar', 'key', 'and', 'fuck', 'her', '(', 'come', 'over', 'anyway', 'tho', ')']\n",
      "AFter tokenizer:  ['twenty', 'past', 'five', 'he', 'said', 'will', 'this', 'train', 'have', 'been', 'to', 'durham', 'already', 'or', 'not', 'coz', 'i', 'am', 'in', 'a', 'reserved', 'seat']\n",
      "AFter tokenizer:  ['hey', 'boys', '.', 'want', 'hot', 'xxx', 'pics', 'sent', 'direct', '2', 'ur', 'phone', '?', 'txt', 'porn', 'to', '69855', ',', '24hrs', 'free', 'and', 'then', 'just', '50p', 'per', 'day', '.', 'to', 'stop', 'text', 'stopbcm', 'sf', 'wc1n3xx']\n",
      "AFter tokenizer:  ['u', 'still', 'painting', 'ur', 'wall', '?']\n",
      "AFter tokenizer:  ['printer', 'is', 'cool', '.', 'i', 'mean', 'groovy', '.', 'wine', 'is', 'groovying']\n",
      "AFter tokenizer:  ['hi', 'harish', \"'s\", 'rent', 'has', 'been', 'transfred', 'to', 'ur', 'acnt', '.']\n",
      "AFter tokenizer:  ['anything', 'lor', 'is', 'she', 'coming', '?']\n",
      "AFter tokenizer:  ['cbe', 'is', 'really', 'good', 'nowadays', ':', ')', 'lot', 'of', 'shop', 'and', 'showrooms', ':', ')', 'city', 'is', 'shaping', 'good', '.']\n",
      "AFter tokenizer:  ['ü', 'still', 'attending', 'da', 'talks', '?']\n",
      "AFter tokenizer:  ['no', 'probs', 'hon', '!', 'how', 'u', 'doinat', 'the', 'mo', '?']\n",
      "AFter tokenizer:  ['k', 'i', \"'ll\", 'take', 'care', 'of', 'it']\n",
      "AFter tokenizer:  ['i', 'take', 'it', 'we', 'did', \"n't\", 'have', 'the', 'phone', 'callon', 'friday', '.', 'can', 'we', 'assume', 'we', 'wo', \"n't\", 'have', 'it', 'this', 'year', 'now', '?']\n",
      "AFter tokenizer:  ['my', 'battery', 'is', 'low', 'babe']\n",
      "AFter tokenizer:  ['shuhui', 'has', 'bought', 'ron', \"'s\", 'present', 'it', \"'s\", 'a', 'swatch', 'watch', '...']\n",
      "AFter tokenizer:  ['yeah', 'there', \"'s\", 'quite', 'a', 'bit', 'left', ',', 'i', \"'ll\", 'swing', 'by', 'tomorrow', 'when', 'i', 'get', 'up']\n",
      "AFter tokenizer:  ['babe', '?', 'you', 'said', '2', 'hours', 'and', 'it', \"'s\", 'been', 'almost', '4', '...', 'is', 'your', 'internet', 'down', '?']\n",
      "AFter tokenizer:  ['k', 'i', \"'ll\", 'be', 'sure', 'to', 'get', 'up', 'before', 'noon', 'and', 'see', 'what', \"'s\", 'what']\n",
      "AFter tokenizer:  ['k', '...', 'k', '...', 'yesterday', 'i', 'was', 'in', 'cbe', '.']\n",
      "AFter tokenizer:  ['went', 'to', 'ganesh', 'dress', 'shop']\n",
      "AFter tokenizer:  ['pdate_now', '-', 'double', 'mins', 'and', '1000', 'txts', 'on', 'orange', 'tariffs', '.', 'latest', 'motorola', ',', 'sonyericsson', '&', 'nokia', '&', 'bluetooth', 'free', '!', 'call', 'mobileupd8', 'on', '08000839402', 'or', 'call2optout/', '!', 'yhl']\n",
      "AFter tokenizer:  ['ü', 'collecting', 'ur', 'laptop', 'then', 'going', 'to', 'configure', 'da', 'settings', 'izzit', '?']\n",
      "AFter tokenizer:  ['aight', ',', 'i', 'should', 'be', 'there', 'by', '8', 'at', 'the', 'latest', ',', 'probably', 'closer', 'to', '7.', 'are', 'jay', 'and', 'tyler', 'down', 'or', 'should', 'we', 'just', 'do', 'two', 'trips', '?']\n",
      "AFter tokenizer:  ['come', 'aftr', '&', 'lt', ';', 'decimal', '&', 'gt', ';', '..', 'now', 'i', 'm', 'cleaning', 'the', 'house']\n",
      "AFter tokenizer:  ['ur', 'cash-balance', 'is', 'currently', '500', 'pounds', '-', 'to', 'maximize', 'ur', 'cash-in', 'now', 'send', 'cash', 'to', '86688', 'only', '150p/msg', '.', 'cc', ':', '08718720201', 'po', 'box', '114/14', 'tcr/w1']\n",
      "AFter tokenizer:  ['bill', ',', 'as', 'in', ':', 'are', 'there', 'any', 'letters', 'for', 'me', '.', 'i', '’', 'm', 'expecting', 'one', 'from', 'orange', 'that', 'isn', '’', 't', 'a', 'bill', 'but', 'may', 'still', 'say', 'orange', 'on', 'it', '.']\n",
      "AFter tokenizer:  ['tell', 'me', 'pa.', 'how', 'is', 'pain', 'de', '.']\n",
      "AFter tokenizer:  ['hi', 'darlin', 'i', 'hope', 'you', 'had', 'a', 'nice', 'night', 'i', 'wish', 'i', 'had', 'come', 'cant', 'wait', 'to', 'see', 'you', 'love', 'fran', 'ps', 'i', 'want', 'dirty', 'anal', 'sex', 'and', 'i', 'want', 'a', '10', 'man', 'gang', 'bang']\n",
      "AFter tokenizer:  ['ha', '.', 'you', 'don', '‘', 't', 'know', 'either', '.', 'i', 'did', 'a', 'a', 'clever', 'but', 'simple', 'thing', 'with', 'pears', 'the', 'other', 'day', ',', 'perfect', 'for', 'christmas', '.']\n",
      "AFter tokenizer:  ['helloooo', '...', 'wake', 'up', '..', '!', '``', 'sweet', \"''\", '``', 'morning', \"''\", '``', 'welcomes', \"''\", '``', 'you', \"''\", '``', 'enjoy', \"''\", '``', 'this', 'day', \"''\", '``', 'with', 'full', 'of', 'joy', \"''\", '..', '``', 'gud', 'mrng', \"''\", '.']\n",
      "AFter tokenizer:  ['alrite']\n",
      "AFter tokenizer:  ['why', 'must', 'we', 'sit', 'around', 'and', 'wait', 'for', 'summer', 'days', 'to', 'celebrate', '.', 'such', 'a', 'magical', 'sight', 'when', 'the', 'worlds', 'dressed', 'in', 'white', '.', 'oooooh', 'let', 'there', 'be', 'snow', '.']\n",
      "AFter tokenizer:  ['urgent', '!', 'your', 'mobile', 'number', 'has', 'been', 'awarded', 'with', 'a', '£2000', 'prize', 'guaranteed', '.', 'call', '09058094454', 'from', 'land', 'line', '.', 'claim', '3030.', 'valid', '12hrs', 'only']\n",
      "AFter tokenizer:  ['how', 'do', 'you', 'guys', 'go', 'to', 'see', 'movies', 'on', 'your', 'side', '.']\n",
      "AFter tokenizer:  ['you', 'did', \"n't\", 'have', 'to', 'tell', 'me', 'that', '...', 'now', 'i', \"'m\", 'thinking', '.', 'plus', 'he', \"'s\", 'going', 'to', 'stop', 'all', 'your', 'runs']\n",
      "AFter tokenizer:  ['kindly', 'send', 'some', 'one', 'to', 'our', 'flat', 'before', '&', 'lt', ';', 'decimal', '&', 'gt', ';', 'today', '.']\n",
      "AFter tokenizer:  ['sorry', '!', 'u', 'can', 'not', 'unsubscribe', 'yet', '.', 'the', 'mob', 'offer', 'package', 'has', 'a', 'min', 'term', 'of', '54', 'weeks', '>', 'pls', 'resubmit', 'request', 'after', 'expiry', '.', 'reply', 'themob', 'help', '4', 'more', 'info']\n",
      "AFter tokenizer:  ['nothing', 'lor', '...', 'a', 'bit', 'bored', 'too', '...', 'then', 'y', 'dun', 'u', 'go', 'home', 'early', '2', 'sleep', 'today', '...']\n",
      "AFter tokenizer:  ['what', 'time', 'should', 'i', 'tell', 'my', 'friend', 'to', 'be', 'around', '?']\n",
      "AFter tokenizer:  ['yes', '.', 'that', 'will', 'be', 'fine', '.', 'love', 'you', '.', 'be', 'safe', '.']\n",
      "AFter tokenizer:  ['thanks', 'chikku', '..', ':', '-', ')', 'gud', 'nyt', ':', '-', '*']\n",
      "AFter tokenizer:  ['is', 'xy', 'in', 'ur', 'car', 'when', 'u', 'picking', 'me', 'up', '?']\n",
      "AFter tokenizer:  ['thanx', '4', 'the', 'time', 'we\\x92ve', 'spent', '2geva', ',', 'its', 'bin', 'mint', '!', 'ur', 'my', 'baby', 'and', 'all', 'i', 'want', 'is', 'u', '!', 'xxxx']\n",
      "AFter tokenizer:  ['yo', ',', 'any', 'way', 'we', 'could', 'pick', 'something', 'up', 'tonight', '?']\n",
      "AFter tokenizer:  ['i', \"'ve\", 'not', 'sent', 'it', '.', 'he', 'can', 'send', 'me', '.']\n",
      "AFter tokenizer:  ['fine', 'am', 'simply', 'sitting', '.']\n",
      "AFter tokenizer:  ['thts', 'god', \"'s\", 'gift', 'for', 'birds', 'as', 'humans', 'hav', 'some', 'natural', 'gift', 'frm', 'god', '..']\n",
      "AFter tokenizer:  ['are', 'you', 'coming', 'to', 'day', 'for', 'class', '.']\n",
      "AFter tokenizer:  ['im', 'done', '.', 'just', 'studyn', 'in', 'library']\n",
      "AFter tokenizer:  ['ok', '...', 'u', 'enjoy', 'ur', 'shows', '...']\n",
      "AFter tokenizer:  ['anything', '...']\n",
      "AFter tokenizer:  ['where', 'wuld', 'i', 'be', 'without', 'my', 'baby', '?', 'the', 'thought', 'alone', 'mite', 'break', 'me', 'and', 'i', 'don\\x92t', 'wan', 'na', 'go', 'crazy', 'but', 'everyboy', 'needs', 'his', 'lady', 'xxxxxxxx']\n",
      "AFter tokenizer:  ['wat', \"'s\", 'my', 'dear', 'doing', '?', 'sleeping', 'ah', '?']\n",
      "AFter tokenizer:  ['hi', \"'\", 'test', 'on', '&', 'lt', ';', '#', '&', 'gt', ';', 'rd', '....']\n",
      "AFter tokenizer:  ['only', '2', '%', 'students', 'solved', 'this', 'cat', 'question', 'in', \"'xam\", '...', '5+3+2=', '&', 'lt', ';', '#', '&', 'gt', ';', '9+2+4=', '&', 'lt', ';', '#', '&', 'gt', ';', '8+6+3=', '&', 'lt', ';', '#', '&', 'gt', ';', 'then', '7+2+5=', '?', '?', '?', '?', '?', 'tell', 'me', 'the', 'answer', 'if', 'u', 'r', 'brilliant', '...', '1thing.i', 'got', 'd', 'answr', '.']\n",
      "AFter tokenizer:  ['yo', 'do', 'you', 'know', 'anyone', '&', 'lt', ';', '#', '&', 'gt', ';', 'or', 'otherwise', 'able', 'to', 'buy', 'liquor', '?', 'our', 'guy', 'flaked', 'and', 'right', 'now', 'if', 'we', 'do', \"n't\", 'get', 'a', 'hold', 'of', 'somebody', 'its', 'just', '4', 'loko', 'all', 'night']\n",
      "AFter tokenizer:  ['yup', 'n', 'her', 'fren', 'lor', '.', 'i', \"'m\", 'meeting', 'my', 'fren', 'at', '730', '.']\n",
      "AFter tokenizer:  ['yeah', ',', 'we', 'got', 'one', 'lined', 'up', 'for', 'us']\n",
      "AFter tokenizer:  ['and', 'stop', 'wondering', '``', 'wow', 'is', 'she', 'ever', 'going', 'to', 'stop', \"tm'ing\", 'me', '?', '!', \"''\", 'because', 'i', 'will', 'tm', 'you', 'whenever', 'i', 'want', 'because', 'you', 'are', 'mine', '...', '*', 'laughs', '*']\n",
      "AFter tokenizer:  ['lol', 'yep', 'did', 'that', 'yesterday', '.', 'already', 'got', 'my', 'fireplace', '.', 'now', 'its', 'just', 'another', 'icon', 'sitting', 'there', 'for', 'me', '.']\n",
      "AFter tokenizer:  ['hey', 'i', \"'ve\", 'booked', 'the', 'pilates', 'and', 'yoga', 'lesson', 'already', '...', 'haha']\n",
      "AFter tokenizer:  ['are', 'you', 'ok.', 'what', 'happen', 'to', 'behave', 'like', 'this']\n",
      "AFter tokenizer:  ['you', 'have', '1', 'new', 'message', '.', 'please', 'call', '08712400200', '.']\n",
      "AFter tokenizer:  ['my', 'supervisor', 'find', '4', 'me', 'one', 'lor', 'i', 'thk', 'his', 'students', '.', 'i', 'havent', 'ask', 'her', 'yet', '.', 'tell', 'u', 'aft', 'i', 'ask', 'her', '.']\n",
      "AFter tokenizer:  ['hello', '.', 'no', 'news', 'on', 'job', ',', 'they', 'are', 'making', 'me', 'wait', 'a', 'fifth', 'week', '!', 'yeah', 'im', 'up', 'for', 'some', 'woozles', 'and', 'weasels', '...', 'in', 'exeter', 'still', ',', 'but', 'be', 'home', 'about', '3', '.']\n",
      "AFter tokenizer:  ['we', 'currently', 'have', 'a', 'message', 'awaiting', 'your', 'collection', '.', 'to', 'collect', 'your', 'message', 'just', 'call', '08718723815', '.']\n",
      "AFter tokenizer:  ['hey', 'babe', ',', 'sorry', 'i', 'did', \"n't\", 'get', 'sooner', '.', 'gary', 'can', 'come', 'and', 'fix', 'it', 'cause', 'he', 'thinks', 'he', 'knows', 'what', 'it', 'is', 'but', 'he', 'does', \"n't\", 'go', 'as', 'far', 'a', 'ptbo', 'and', 'he', 'says', 'it', 'will', 'cost', '&', 'lt', ';', '#', '&', 'gt', ';', 'bucks', '.', 'i', 'do', \"n't\", 'know', 'if', 'it', 'might', 'be', 'cheaper', 'to', 'find', 'someone', 'there', '?', 'we', 'do', \"n't\", 'have', 'any', 'second', 'hand', 'machines', 'at', 'all', 'right', 'now', ',', 'let', 'me', 'know', 'what', 'you', 'want', 'to', 'do', 'babe']\n",
      "AFter tokenizer:  ['make', 'that', '3', '!', '4', 'fucks', 'sake', '?', '!', 'x']\n",
      "AFter tokenizer:  ['leave', 'it', '.', 'u', 'will', 'always', 'be', 'ignorant', '.']\n",
      "AFter tokenizer:  ['nope', 'but', 'i', \"'ll\", 'b', 'going', '2', 'sch', 'on', 'fri', 'quite', 'early', 'lor', 'cos', 'mys', 'sis', 'got', 'paper', 'in', 'da', 'morn', ':', '-', ')']\n",
      "AFter tokenizer:  ['at', 'bruce', 'b', 'downs', '&', 'amp', ';', 'fletcher', 'now']\n",
      "AFter tokenizer:  ['where', 'are', 'you', '?', 'you', 'said', 'you', 'would', 'be', 'here', 'when', 'i', 'woke', '...', ':', '-', '(']\n",
      "AFter tokenizer:  ['hey', 'now', 'am', 'free', 'you', 'can', 'call', 'me', '.']\n",
      "AFter tokenizer:  ['tell', 'me', 'whos', 'this', 'pls', ':', '-', ')']\n",
      "AFter tokenizer:  ['urgent', '!', 'your', 'mobile', 'was', 'awarded', 'a', '£1,500', 'bonus', 'caller', 'prize', 'on', '27/6/03', '.', 'our', 'final', 'attempt', '2', 'contact', 'u', '!', 'call', '08714714011']\n",
      "AFter tokenizer:  ['think', 'i', 'might', 'have', 'to', 'give', 'it', 'a', 'miss', '.', 'am', 'teaching', 'til', 'twelve', ',', 'then', 'have', 'lecture', 'at', 'two', '.', 'damn', 'this', 'working', 'thing', '.']\n",
      "AFter tokenizer:  ['id', 'have', 'to', 'check', 'but', 'there', \"'s\", 'only', 'like', '1', 'bowls', 'worth', 'left']\n",
      "AFter tokenizer:  ['yes', 'there', 'were', 'many', 'sweets']\n",
      "AFter tokenizer:  ['i', 'would', 'but', 'i', \"'m\", 'still', 'cozy', '.', 'and', 'exhausted', 'from', 'last', 'night.nobody', 'went', 'to', 'school', 'or', 'work', '.', 'everything', 'is', 'closed', '.']\n",
      "AFter tokenizer:  ['buzzzz', '!', '*', 'grins', '*', 'did', 'i', 'buzz', 'your', 'ass', '?', 'buzz', 'your', 'chest', '?', 'buzz', 'your', 'cock', '?', 'where', 'do', 'you', 'keep', 'your', 'phone', '?', 'is', 'the', 'vibrator', 'on', '?', 'did', 'you', 'feel', 'it', 'shake', '?']\n",
      "AFter tokenizer:  ['sir', 'send', 'to', 'group', 'mail', 'check', 'it', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'doing', 'da', 'intro', 'covers', 'energy', 'trends', 'n', 'pros', 'n', 'cons', '...', 'brief', 'description', 'of', 'nuclear', 'fusion', 'n', 'oso', 'brief', 'history', 'of', 'iter', 'n', 'jet', 'got', 'abt', '7', 'n', 'half', 'pages', '..']\n",
      "AFter tokenizer:  ['none', '!', 'nowhere', 'ikno', 'doesdiscount', '!', 'shitinnit']\n",
      "AFter tokenizer:  ['you', 'dont', 'know', 'you', 'jabo', 'me', 'abi', '.']\n",
      "AFter tokenizer:  ['do', 'you', 'ever', 'notice', 'that', 'when', 'you', \"'re\", 'driving', ',', 'anyone', 'going', 'slower', 'than', 'you', 'is', 'an', 'idiot', 'and', 'everyone', 'driving', 'faster', 'than', 'you', 'is', 'a', 'maniac', '?']\n",
      "AFter tokenizer:  ['not', 'yet', 'had', '..', 'ya', 'sapna', 'aunty', 'manege', \"y'day\", 'hogidhe', '..', 'chinnu', 'full', 'weak', 'and', 'swalpa', 'black', 'agidhane', '..']\n",
      "AFter tokenizer:  ['are', 'you', 'being', 'good', ',', 'baby', '?', ':', ')']\n",
      "AFter tokenizer:  ['mostly', 'sports', 'type', '..', 'lyk', 'footbl', ',', 'crckt', '..']\n",
      "AFter tokenizer:  ['ma', 'head', 'dey', 'swell', 'oh', '.', 'thanks', 'for', 'making', 'my', 'day']\n",
      "AFter tokenizer:  ['u', 'should', 'make', 'a', 'fb', 'list']\n",
      "AFter tokenizer:  ['sary', 'just', 'need', 'tim', 'in', 'the', 'bollox', '&', 'it', 'hurt', 'him', 'a', 'lot', 'so', 'he', 'tol', 'me', '!']\n",
      "AFter tokenizer:  ['happy', 'new', 'year', 'princess', '!']\n",
      "AFter tokenizer:  ['i', \"'ll\", 'text', 'carlos', 'and', 'let', 'you', 'know', ',', 'hang', 'on']\n",
      "AFter tokenizer:  ['do', \"n't\", 'worry', ',', '*', 'is', 'easy', 'once', 'have', 'ingredients', '!']\n",
      "AFter tokenizer:  ['i', 'love', 'u', '2', 'my', 'little', 'pocy', 'bell', 'i', 'am', 'sorry', 'but', 'i', 'love', 'u']\n",
      "AFter tokenizer:  ['ok', 'omw', 'now', ',', 'you', 'at', 'castor', '?']\n",
      "AFter tokenizer:  ['yar', 'lor', '...', 'keep', 'raining', 'non', 'stop', '...', 'or', 'u', 'wan', '2', 'go', 'elsewhere', '?']\n",
      "AFter tokenizer:  ['xmas', 'offer', '!', 'latest', 'motorola', ',', 'sonyericsson', '&', 'nokia', '&', 'free', 'bluetooth', 'or', 'dvd', '!', 'double', 'mins', '&', '1000', 'txt', 'on', 'orange', '.', 'call', 'mobileupd8', 'on', '08000839402', 'or', 'call2optout/4qf2']\n",
      "AFter tokenizer:  ['what', 'u', 'mean', 'u', 'almost', 'done', '?', 'done', 'wif', 'sleeping', '?', 'but', 'i', 'tot', 'u', 'going', 'to', 'take', 'a', 'nap', '..', 'yup', 'i', 'send', 'her', 'liao', 'so', 'i', \"'m\", 'picking', 'her', 'up', 'at', 'ard', '4', 'smth', 'lor', '..']\n",
      "AFter tokenizer:  ['tonight', '?', 'yeah', ',', 'i', \"'d\", 'be', 'down', 'for', 'that']\n",
      "AFter tokenizer:  ['what', 'should', 'i', 'eat', 'fo', 'lunch', 'senor']\n",
      "AFter tokenizer:  ['he', 'said', 'that', 'he', 'had', 'a', 'right', 'giggle', 'when', 'he', 'saw', 'u', 'again', '!', 'you', 'would', 'possibly', 'be', 'the', 'first', 'person2die', 'from', 'nvq', ',', 'but', 'think', 'how', 'much', 'you', 'could', 'for', '!']\n",
      "AFter tokenizer:  ['no', 'break', 'time', 'one', '...', 'how', '...', 'i', 'come', 'out', 'n', 'get', 'my', 'stuff', 'fr', 'ü', '?']\n",
      "AFter tokenizer:  ['reply', 'to', 'win', '£100', 'weekly', '!', 'what', 'professional', 'sport', 'does', 'tiger', 'woods', 'play', '?', 'send', 'stop', 'to', '87239', 'to', 'end', 'service']\n",
      "AFter tokenizer:  ['i', \"'m\", 'there', 'and', 'i', 'can', 'see', 'you', ',', 'but', 'you', 'ca', \"n't\", 'see', 'me', '?', 'maybe', 'you', 'should', 'reboot', 'ym', '?', 'i', 'seen', 'the', 'buzz']\n",
      "AFter tokenizer:  ['do', 'you', 'still', 'have', 'the', 'grinder', '?']\n",
      "AFter tokenizer:  ['no', '1', 'polyphonic', 'tone', '4', 'ur', 'mob', 'every', 'week', '!', 'just', 'txt', 'pt2', 'to', '87575', '.', '1st', 'tone', 'free', '!', 'so', 'get', 'txtin', 'now', 'and', 'tell', 'ur', 'friends', '.', '150p/tone', '.', '16', 'reply', 'hl', '4info']\n",
      "AFter tokenizer:  ['k.i', \"did't\", 'see', 'you', '.', ':', ')', 'k', ':', ')', 'where', 'are', 'you', 'now', '?']\n",
      "AFter tokenizer:  ['so', 'i', \"'m\", 'doing', 'a', 'list', 'of', 'buyers', '.']\n",
      "AFter tokenizer:  ['no', 'idea', ',', 'i', 'guess', 'we', \"'ll\", 'work', 'that', 'out', 'an', 'hour', 'after', 'we', \"'re\", 'supposed', 'to', 'leave', 'since', 'as', 'usual', 'nobody', 'has', 'any', 'interest', 'in', 'figuring', 'shit', 'out', 'before', 'the', 'last', 'second']\n",
      "AFter tokenizer:  ['mm', 'not', 'entirely', 'sure', 'i', 'understood', 'that', 'text', 'but', 'hey', '.', 'ho', '.', 'which', 'weekend', '?']\n",
      "AFter tokenizer:  ['they', 'released', 'vday', 'shirts', 'and', 'when', 'u', 'put', 'it', 'on', 'it', 'makes', 'your', 'bottom', 'half', 'naked', 'instead', 'of', 'those', 'white', 'underwear', '.']\n",
      "AFter tokenizer:  ['don', 'know', '..', 'he', 'is', 'watching', 'film', 'in', 'computer', '..']\n",
      "AFter tokenizer:  ['no', 'b4', 'thursday']\n",
      "AFter tokenizer:  ['oh', ',', 'then', 'your', 'phone', 'phoned', 'me', 'but', 'it', 'disconnected']\n",
      "AFter tokenizer:  ['id', 'onluy', 'matters', 'when', 'getting', 'on', 'from', 'offcampus']\n",
      "AFter tokenizer:  ['this', 'message', 'is', 'free', '.', 'welcome', 'to', 'the', 'new', '&', 'improved', 'sex', '&', 'dogging', 'club', '!', 'to', 'unsubscribe', 'from', 'this', 'service', 'reply', 'stop', '.', 'msgs', '@', '150p', '18+only']\n",
      "AFter tokenizer:  ['excellent', ',', 'i', \"'ll\", 'see', 'what', 'riley', \"'s\", 'plans', 'are']\n",
      "AFter tokenizer:  ['ew', 'are', 'you', 'one', 'of', 'them', '?']\n",
      "AFter tokenizer:  ['also', 'hi', 'wesley', 'how', \"'ve\", 'you', 'been']\n",
      "AFter tokenizer:  ['ah', 'you', 'see', '.', 'you', 'have', 'to', 'be', 'in', 'the', 'lingo', '.', 'i', 'will', 'let', 'you', 'know', 'wot', 'on', 'earth', 'it', 'is', 'when', 'has', 'finished', 'making', 'it', '!']\n",
      "AFter tokenizer:  ['update_now', '-', '12mths', 'half', 'price', 'orange', 'line', 'rental', ':', '400mins', '...', 'call', 'mobileupd8', 'on', '08000839402', 'or', 'call2optout=j5q']\n",
      "AFter tokenizer:  ['imagine', 'life', 'without', 'me', '...', 'see', '..', 'how', 'fast', 'u', 'are', 'searching', 'me', '?', 'do', \"n't\", 'worry', '..', 'l', \"'m\", 'always', 'there', 'to', 'disturb', 'u', '..', 'goodnoon', '..', ':', ')']\n",
      "AFter tokenizer:  ['hm', 'good', 'morning', ',', 'headache', 'anyone', '?', ':', '-', ')']\n",
      "AFter tokenizer:  ['yeah', 'no', 'probs', '-', 'last', 'night', 'is', 'obviously', 'catching', 'up', 'with', 'you', '...', 'speak', 'soon']\n",
      "AFter tokenizer:  ['free', 'unlimited', 'hardcore', 'porn', 'direct', '2', 'your', 'mobile', 'txt', 'porn', 'to', '69200', '&', 'get', 'free', 'access', 'for', '24', 'hrs', 'then', 'chrgd', '@', '50p', 'per', 'day', 'txt', 'stop', '2exit', '.', 'this', 'msg', 'is', 'free']\n",
      "AFter tokenizer:  ['i', 'might', 'go', '2', 'sch', '.', 'yar', 'at', 'e', 'salon', 'now', 'v', 'boring', '.']\n",
      "AFter tokenizer:  ['&', 'lt', ';', '#', '&', 'gt', ';', 'mins', 'but', 'i', 'had', 'to', 'stop', 'somewhere', 'first', '.']\n",
      "AFter tokenizer:  ['&', 'lt', ';', '#', '&', 'gt', ';', 'is', 'fast', 'approaching', '.', 'so', ',', 'wish', 'u', 'a', 'very', 'happy', 'new', 'year', 'happy', 'sankranti', 'happy', 'republic', 'day', 'happy', 'valentines', 'day', 'happy', 'shivratri', 'happy', 'ugadi', 'happy', 'fools', 'day', 'happy', 'may', 'day', 'happy', 'independence', 'day', ',', 'happy', 'friendship', ',', 'mother', ',', 'father', ',', 'teachers', ',', 'childrens', 'day', ',', '&', 'amp', ';', 'happy', 'birthday', '4', 'u.', 'happy', 'ganesh', 'festival', 'happy', 'dasara', 'happy', 'diwali', 'happy', 'christmas', '&', 'lt', ';', '#', '&', 'gt', ';', 'good', 'mornings', 'afternoons', ',', 'evenings', 'nights', '.', 'rememberi', 'am', 'the', 'first', 'to', 'wishing', 'u', 'all', 'these', '...', 'your', \"'s\", 'raj']\n",
      "AFter tokenizer:  ['one', 'of', 'the', 'joys', 'in', 'lifeis', 'waking', 'up', 'each', 'daywith', 'thoughts', 'that', 'somewheresomeone', 'cares', 'enough', 'tosend', 'a', 'warm', 'morning', 'greeting', '..', '-']\n",
      "AFter tokenizer:  ['i', 'did', \"n't\", 'get', 'the', 'second', 'half', 'of', 'that', 'message']\n",
      "AFter tokenizer:  ['wat', 'time', 'do', 'u', 'wan', '2', 'meet', 'me', 'later', '?']\n",
      "AFter tokenizer:  ['i', 'thank', 'you', 'so', 'much', 'for', 'all', 'you', 'do', 'with', 'selflessness', '.', 'i', 'love', 'you', 'plenty', '.']\n",
      "AFter tokenizer:  ['am', 'in', 'film', 'ill', 'call', 'you', 'later', '.']\n",
      "AFter tokenizer:  ['how', 'dare', 'you', 'change', 'my', 'ring']\n",
      "AFter tokenizer:  ['you', 'are', 'a', 'very', 'very', 'very', 'very', 'bad', 'girl', '.', 'or', 'lady', '.']\n",
      "AFter tokenizer:  ['i', 'love', 'ya', 'too', 'but', 'try', 'and', 'budget', 'your', 'money', 'better', 'babe', '.', 'gary', 'would', 'freak', 'on', 'me', 'if', 'he', 'knew']\n",
      "AFter tokenizer:  ['what', 'part', 'of', '``', 'do', \"n't\", 'initiate', \"''\", 'do', \"n't\", 'you', 'understand']\n",
      "AFter tokenizer:  ['i', 'finished', 'my', 'lunch', 'already', '.', 'u', 'wake', 'up', 'already', '?']\n",
      "AFter tokenizer:  ['you', 'still', 'at', 'the', 'game', '?']\n",
      "AFter tokenizer:  ['you', 'have', 'got', 'tallent', 'but', 'you', 'are', 'wasting', '.']\n",
      "AFter tokenizer:  ['what', 'is', 'your', 'record', 'for', 'one', 'night', '?', ':', ')']\n",
      "AFter tokenizer:  ['also', 'sir', ',', 'i', 'sent', 'you', 'an', 'email', 'about', 'how', 'to', 'log', 'into', 'the', 'usc', 'payment', 'portal', '.', 'i.ll', 'send', 'you', 'another', 'message', 'that', 'should', 'explain', 'how', 'things', 'are', 'back', 'home', '.', 'have', 'a', 'great', 'weekend', '.']\n",
      "AFter tokenizer:  ['gon', 'na', 'let', 'me', 'know', 'cos', 'comes', 'bak', 'from', 'holiday', 'that', 'day', '.', 'is', 'coming', '.', \"don't4get2text\", 'me', 'number', '.']\n",
      "AFter tokenizer:  ['jokin', 'only', 'lar', '...', ':', '-', ')', 'depends', 'on', 'which', 'phone', 'my', 'father', 'can', 'get', 'lor', '...']\n",
      "AFter tokenizer:  ['aight', ',', 'lem', 'me', 'know', 'what', \"'s\", 'up']\n",
      "AFter tokenizer:  ['get', 'ready', 'for', '&', 'lt', ';', '#', '&', 'gt', ';', 'inches', 'of', 'pleasure', '...']\n",
      "AFter tokenizer:  [';', '-', ')', 'ok.', 'i', 'feel', 'like', 'john', 'lennon', '.']\n",
      "AFter tokenizer:  ['cos', 'darren', 'say', 'ü', 'considering', 'mah', 'so', 'i', 'ask', 'ü', '...']\n",
      "AFter tokenizer:  ['you', 'are', 'not', 'bothering', 'me', 'but', 'you', 'have', 'to', 'trust', 'my', 'answers', '.', 'pls', '.']\n",
      "AFter tokenizer:  ['one', 'day', 'a', 'crab', 'was', 'running', 'on', 'the', 'sea', 'shore', '..', 'the', 'waves', 'came', 'n', 'cleared', 'the', 'footprints', 'of', 'the', 'crab', '..', 'crab', 'asked', ':', 'being', 'my', 'frnd', 'y', 'r', 'u', 'clearing', 'my', 'beautiful', 'footprints', '?', 'waves', 'replied', ':', 'a', 'fox', 'was', 'following', 'ur', 'footprints', 'to', 'catch', 'you', '!', 'thats', 'y', 'i', 'cleared', 'it', 'off', ':', ')', 'frndsship', 'never', 'lets', 'u', 'dwn', ':', '-', ')', 'gud', 'nyt', '..']\n",
      "AFter tokenizer:  ['aight', 'what', 'time', 'you', 'want', 'me', 'to', 'come', 'up', '?']\n",
      "AFter tokenizer:  ['slaaaaave', '!', 'where', 'are', 'you', '?', 'must', 'i', 'summon', 'you', 'to', 'me', 'all', 'the', 'time', 'now', '?', 'do', \"n't\", 'you', 'wish', 'to', 'come', 'to', 'me', 'on', 'your', 'own', 'anymore', '?']\n",
      "AFter tokenizer:  ['your', 'bill', 'at', '3', 'is', '£33.65', 'so', 'thats', 'not', 'bad', '!']\n",
      "AFter tokenizer:  ['let', 'me', 'know', 'how', 'it', 'changes', 'in', 'the', 'next', '6hrs', '.', 'it', 'can', 'even', 'be', 'appendix', 'but', 'you', 'are', 'out', 'of', 'that', 'age', 'range', '.', 'however', 'its', 'not', 'impossible', '.', 'so', 'just', 'chill', 'and', 'let', 'me', 'know', 'in', '6hrs']\n",
      "AFter tokenizer:  ['hello', ',', 'yeah', 'i', \"'ve\", 'just', 'got', 'out', 'of', 'the', 'bath', 'and', 'need', 'to', 'do', 'my', 'hair', 'so', 'i', \"'ll\", 'come', 'up', 'when', 'i', \"'m\", 'done', ',', 'yeah', '?']\n",
      "AFter tokenizer:  ['so', 'how', \"'s\", 'the', 'weather', 'over', 'there', '?']\n",
      "AFter tokenizer:  ['ok.', 'not', 'much', 'to', 'do', 'here', 'though', '.', 'h', '&', 'm', 'friday', ',', 'cant', 'wait', '.', 'dunno', 'wot', 'the', 'hell', 'im', 'gon', 'na', 'do', 'for', 'another', '3', 'weeks', '!', 'become', 'a', 'slob-', 'oh', 'wait', ',', 'already', 'done', 'that', '!']\n",
      "AFter tokenizer:  ['die', '...', 'now', 'i', 'have', 'e', 'toot', 'fringe', 'again', '...']\n",
      "AFter tokenizer:  ['lol', 'they', 'do', \"n't\", 'know', 'about', 'my', 'awesome', 'phone', '.', 'i', 'could', 'click', 'delete', 'right', 'now', 'if', 'i', 'want', '.']\n",
      "AFter tokenizer:  ['awesome', 'question', 'with', 'a', 'cute', 'answer', ':', 'someone', 'asked', 'a', 'boy', '``', 'how', 'is', 'ur', 'life', '?', \"''\", '.', '.', 'he', 'smiled', '&', 'amp', ';', 'answered', ':', '.', '.', '``', 'she', 'is', 'fine', '!', \"''\", 'gudnite']\n",
      "AFter tokenizer:  ['please', 'leave', 'this', 'topic', '..', 'sorry', 'for', 'telling', 'that', '..']\n",
      "AFter tokenizer:  ['pls', 'send', 'me', 'the', 'correct', 'name', 'da', '.']\n",
      "AFter tokenizer:  ['what', 'happened', 'to', 'our', 'yo', 'date', '?']\n",
      "AFter tokenizer:  ['webpage', 's', 'not', 'available', '!']\n",
      "AFter tokenizer:  ['just', 'woke', 'up', '.', 'yeesh', 'its', 'late', '.', 'but', 'i', 'did', \"n't\", 'fall', 'asleep', 'til', '&', 'lt', ';', '#', '&', 'gt', ';', 'am', ':', '/']\n",
      "AFter tokenizer:  ['you', 'are', 'now', 'unsubscribed', 'all', 'services', '.', 'get', 'tons', 'of', 'sexy', 'babes', 'or', 'hunks', 'straight', 'to', 'your', 'phone', '!', 'go', 'to', 'http', ':', '//gotbabes.co.uk', '.', 'no', 'subscriptions', '.']\n",
      "AFter tokenizer:  ['dear', 'all', ',', 'as', 'we', 'know', '&', 'lt', ';', '#', '&', 'gt', ';', 'th', 'is', 'the', '&', 'lt', ';', '#', '&', 'gt', ';', 'th', 'birthday', 'of', 'our', 'loving', 'gopalettan', '.', 'we', 'are', 'planning', 'to', 'give', 'a', 'small', 'gift', 'on', 'that', 'day', '.', 'those', 'who', 'like', 'to', 'participate', 'in', 'that', 'you', 'are', 'welcome', '.', 'please', 'contact', 'our', 'admin', 'team', 'for', 'more', 'details']\n",
      "AFter tokenizer:  ['k', '..', 'k', '...', 'from', 'tomorrow', 'onwards', 'started', 'ah', '?']\n",
      "AFter tokenizer:  ['what', 'u', 'talking', 'bout', 'early', 'morning', '?', 'it', \"'s\", 'almost', 'noon', 'where', 'your', 'at', '!']\n",
      "AFter tokenizer:  ['fine', '.', 'do', 'you', 'remember', 'me', '.']\n",
      "AFter tokenizer:  ['hi', 'babe', 'its', 'jordan', ',', 'how', 'r', 'u', '?', 'im', 'home', 'from', 'abroad', 'and', 'lonely', ',', 'text', 'me', 'back', 'if', 'u', 'wan', 'na', 'chat', 'xxsp', 'visionsms.com', 'text', 'stop', 'to', 'stopcost', '150p', '08712400603']\n",
      "AFter tokenizer:  ['ok.', 'how', 'many', 'should', 'i', 'buy', '.']\n",
      "AFter tokenizer:  ['sounds', 'good', ',', 'keep', 'me', 'posted']\n",
      "AFter tokenizer:  ['get', 'a', 'brand', 'new', 'mobile', 'phone', 'by', 'being', 'an', 'agent', 'of', 'the', 'mob', '!', 'plus', 'loads', 'more', 'goodies', '!', 'for', 'more', 'info', 'just', 'text', 'mat', 'to', '87021', '.']\n",
      "AFter tokenizer:  ['ok.', 'so', 'april', '.', 'cant', 'wait']\n",
      "AFter tokenizer:  ['boy', 'you', 'best', 'get', 'yo', 'ass', 'out', 'here', 'quick']\n",
      "AFter tokenizer:  ['ay', 'wana', 'meet', 'on', 'sat', '?', 'ü', 'wkg', 'on', 'sat', '?']\n",
      "AFter tokenizer:  ['i', \"'m\", 'now', 'but', 'have', 'to', 'wait', 'till', '2', 'for', 'the', 'bus', 'to', 'pick', 'me', '.']\n",
      "AFter tokenizer:  ['apart', 'from', 'the', 'one', 'i', 'told', 'you', 'about', 'yesterday', '?']\n",
      "AFter tokenizer:  ['ok', 'lor', '...', 'but', 'buy', 'wat', '?']\n",
      "AFter tokenizer:  ['somebody', 'should', 'go', 'to', 'andros', 'and', 'steal', 'ice']\n",
      "AFter tokenizer:  ['don', 'know', '.', 'i', \"did't\", 'msg', 'him', 'recently', '.']\n",
      "AFter tokenizer:  ['take', 'us', 'out', 'shopping', 'and', 'mark', 'will', 'distract', 'isaiah.=d']\n",
      "AFter tokenizer:  ['mum', ',', 'hope', 'you', 'are', 'having', 'a', 'great', 'day', '.', 'hoping', 'this', 'text', 'meets', 'you', 'well', 'and', 'full', 'of', 'life', '.', 'have', 'a', 'great', 'day', '.', 'abiola']\n",
      "AFter tokenizer:  ['there', 'is', 'no', 'sense', 'in', 'my', 'foot', 'and', 'penis', '.']\n",
      "AFter tokenizer:  ['okay', 'but', 'i', 'thought', 'you', 'were', 'the', 'expert']\n",
      "AFter tokenizer:  ['*', 'deep', 'sigh', '*', '...', 'i', 'miss', 'you', ':', '-', '(', '...', 'i', 'am', 'really', 'surprised', 'you', 'have', \"n't\", 'gone', 'to', 'the', 'net', 'cafe', 'yet', 'to', 'get', 'to', 'me', '...', 'do', \"n't\", 'you', 'miss', 'me', '?']\n",
      "AFter tokenizer:  ['s.s', ':', ')', 'i', 'thinl', 'role', 'is', 'like', 'sachin.just', 'standing', '.', 'others', 'have', 'to', 'hit', '.']\n",
      "AFter tokenizer:  ['have', 'a', 'great', 'trip', 'to', 'india', '.', 'and', 'bring', 'the', 'light', 'to', 'everyone', 'not', 'just', 'with', 'the', 'project', 'but', 'with', 'everyone', 'that', 'is', 'lucky', 'to', 'see', 'you', 'smile', '.', 'bye', '.', 'abiola']\n",
      "AFter tokenizer:  ['and', 'very', 'importantly', ',', 'all', 'we', 'discuss', 'is', 'between', 'u', 'and', 'i', 'only', '.']\n",
      "AFter tokenizer:  ['k', '..', 'k', ':', ')', 'how', 'about', 'your', 'training', 'process', '?']\n",
      "AFter tokenizer:  ['ok', 'lor', '.', 'i', 'ned', '2', 'go', 'toa', 'payoh', '4', 'a', 'while', '2', 'return', 'smth', 'u', 'wan', '2', 'send', 'me', 'there', 'or', 'wat', '?']\n",
      "AFter tokenizer:  ['in', 'da', 'car', 'park']\n",
      "AFter tokenizer:  ['i', 'wish', 'that', 'i', 'was', 'with', 'you', '.', 'holding', 'you', 'tightly', '.', 'making', 'you', 'see', 'how', 'important', 'you', 'are', '.', 'how', 'much', 'you', 'mean', 'to', 'me', '...', 'how', 'much', 'i', 'need', 'you', '...', 'in', 'my', 'life', '...']\n",
      "AFter tokenizer:  ['so', 'i', 'asked', 'how', \"'s\", 'anthony', '.', 'dad', '.', 'and', 'your', 'bf']\n",
      "AFter tokenizer:  ['wnevr', 'i', 'wana', 'fal', 'in', 'luv', 'vth', 'my', 'books', ',', 'my', 'bed', 'fals', 'in', 'luv', 'vth', 'me', '..', '!', \"''\", '.', 'yen', 'madodu', ',', 'nav', 'pretsorginta', ',', 'nammanna', 'pretsovru', 'important', 'alwa', '....', '!', '!', ':', ')', 'gud', 'eveb-', ')', '.']\n",
      "AFter tokenizer:  ['am', 'going', 'to', 'take', 'bath', 'ill', 'place', 'the', 'key', 'in', 'window', ':', '-', ')']\n",
      "AFter tokenizer:  ['lord', 'of', 'the', 'rings', ':', 'return', 'of', 'the', 'king', 'in', 'store', 'now', '!', 'reply', 'lotr', 'by', '2', 'june', '4', 'chance', '2', 'win', 'lotr', 'soundtrack', 'cds', 'stdtxtrate', '.', 'reply', 'stop', 'to', 'end', 'txts']\n",
      "AFter tokenizer:  ['dear', ',', 'take', 'care', '.', 'i', 'am', 'just', 'reaching', 'home.love', 'u', 'a', 'lot', '.']\n",
      "AFter tokenizer:  ['staff.science.nus.edu.sg/~phyhcmk/teaching/pc1323']\n",
      "AFter tokenizer:  ['have', 'you', 'emigrated', 'or', 'something', '?', 'ok', 'maybe', '5.30', 'was', 'a', 'bit', 'hopeful', '...']\n",
      "AFter tokenizer:  ['olol', 'i', 'printed', 'out', 'a', 'forum', 'post', 'by', 'a', 'guy', 'with', 'the', 'exact', 'same', 'prob', 'which', 'was', 'fixed', 'with', 'a', 'gpu', 'replacement', '.', 'hopefully', 'they', 'dont', 'ignore', 'that', '.']\n",
      "AFter tokenizer:  ['we', 'walked', 'from', 'my', 'moms', '.', 'right', 'on', 'stagwood', 'pass', 'right', 'on', 'winterstone', 'left', 'on', 'victors', 'hill', '.', 'address', 'is', '&', 'lt', ';', '#', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['yo', ',', 'you', 'at', 'jp', 'and', 'hungry', 'like', 'a', 'mofo', '?']\n",
      "AFter tokenizer:  ['this', 'is', 'all', 'just', 'creepy', 'and', 'crazy', 'to', 'me', '.']\n",
      "AFter tokenizer:  ['ok', '...', 'i', 'din', 'get', 'ur', 'msg', '...']\n",
      "AFter tokenizer:  ['pathaya', 'enketa', 'maraikara', 'pa', \"'\"]\n",
      "AFter tokenizer:  ['even', 'if', 'he', 'my', 'friend', 'he', 'is', 'a', 'priest', 'call', 'him', 'now']\n",
      "AFter tokenizer:  ['u', 'so', 'lousy', ',', 'run', 'already', 'come', 'back', 'then', 'half', 'dead', '...', 'hee', '...']\n",
      "AFter tokenizer:  ['that', \"'s\", 'y', 'i', 'said', 'it', \"'s\", 'bad', 'dat', 'all', 'e', 'gals', 'know', 'u', '...', 'wat', 'u', 'doing', 'now', '?']\n",
      "AFter tokenizer:  ['or', 'remind', 'me', 'in', 'a', 'few', 'hrs', '.']\n",
      "AFter tokenizer:  ['i', 'had', 'been', 'hoping', 'i', 'would', 'not', 'have', 'to', 'send', 'you', 'this', 'message', '.', 'my', 'rent', 'is', 'due', 'and', 'i', 'dont', 'have', 'enough', 'for', 'it', '.', 'my', 'reserves', 'are', 'completely', 'gone', '.', 'its', 'a', 'loan', 'i', 'need', 'and', 'was', 'hoping', 'you', 'could', 'her', '.', 'the', 'balance', 'is', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'is', 'there', 'a', 'way', 'i', 'could', 'get', 'that', 'from', 'you', ',', 'till', 'mid', 'march', 'when', 'i', 'hope', 'to', 'pay', 'back', '.']\n",
      "AFter tokenizer:  ['hi', '.', 'happy', 'new', 'year', '.', 'i', 'dont', 'mean', 'to', 'intrude', 'but', 'can', 'you', 'pls', 'let', 'me', 'know', 'how', 'much', 'tuition', 'you', 'paid', 'last', 'semester', 'and', 'how', 'much', 'this', 'semester', 'is', '.', 'thanks']\n",
      "AFter tokenizer:  ['hello', 'hun', 'how', 'ru', '?', 'its', 'here', 'by', 'the', 'way', '.', 'im', 'good', '.', 'been', 'on', '2', 'dates', 'with', 'that', 'guy', 'i', 'met', 'in', 'walkabout', 'so', 'far', '.', 'we', 'have', 'to', 'meet', 'up', 'soon', '.', 'hows', 'everyone', 'else', '?']\n",
      "AFter tokenizer:  ['lol', 'i', 'was', 'gon', 'na', 'last', 'month', '.', 'i', 'cashed', 'some', 'in', 'but', 'i', 'left', '&', 'lt', ';', '#', '&', 'gt', ';', 'just', 'in', 'case', '.', 'i', 'was', 'collecting', 'more', 'during', 'the', 'week', 'cause', 'they', 'announced', 'it', 'on', 'the', 'blog', '.']\n",
      "AFter tokenizer:  ['good', 'luck', '!', 'draw', 'takes', 'place', '28th', 'feb', '06.', 'good', 'luck', '!', 'for', 'removal', 'send', 'stop', 'to', '87239', 'customer', 'services', '08708034412']\n",
      "AFter tokenizer:  ['short', 'but', 'cute', ':', '``', 'be', 'a', 'good', 'person', ',', 'but', 'dont', 'try', 'to', 'prove', \"''\", '.....', 'gud', 'mrng', '...']\n",
      "AFter tokenizer:  ['just', 'have', \"n't\", 'decided', 'where', 'yet', 'eh', '?']\n",
      "AFter tokenizer:  ['wat', 'time', 'liao', ',', 'where', 'still', 'got', '.']\n",
      "AFter tokenizer:  ['yes', 'watching', 'footie', 'but', 'worried', 'we', \"'re\", 'going', 'to', 'blow', 'it', '-', 'phil', 'neville', '?']\n",
      "AFter tokenizer:  ['i', 'wait', '4', 'ü', 'inside', 'da', 'car', 'park', '...']\n",
      "AFter tokenizer:  ['uncle', 'abbey', '!', 'happy', 'new', 'year', '.', 'abiola']\n",
      "AFter tokenizer:  ['now', 'am', 'free', 'call', 'me', 'pa', '.']\n",
      "AFter tokenizer:  ['r', 'u', 'saying', 'i', 'should', 're', 'order', 'the', 'slippers', 'cos', 'i', 'had', 'to', 'pay', 'for', 'returning', 'it', '.']\n",
      "AFter tokenizer:  ['stop', 'knowing', 'me', 'so', 'well', '!']\n",
      "AFter tokenizer:  ['good', 'evening', '!', 'this', 'is', 'roger', '.', 'how', 'are', 'you', '?']\n",
      "AFter tokenizer:  ['small', 'problem', 'in', 'auction', ':', ')', 'punj', 'now', 'asking', 'tiwary']\n",
      "AFter tokenizer:  ['he', 'telling', 'not', 'to', 'tell', 'any', 'one', '.', 'if', 'so', 'treat', 'for', 'me', 'hi', 'hi', 'hi']\n",
      "AFter tokenizer:  ['1st', 'wk', 'free', '!', 'gr8', 'tones', 'str8', '2', 'u', 'each', 'wk', '.', 'txt', 'nokia', 'on', 'to', '8007', 'for', 'classic', 'nokia', 'tones', 'or', 'hit', 'on', 'to', '8007', 'for', 'polys', '.', 'nokia/150p', 'poly/200p', '16+']\n",
      "AFter tokenizer:  ['u', 'coming', '2', 'pick', 'me', '?']\n",
      "AFter tokenizer:  ['thats', 'cool', '.', 'i', 'liked', 'your', 'photos', '.', 'you', 'are', 'very', 'sexy', '!']\n",
      "AFter tokenizer:  ['would', 'u', 'fuckin', 'believe', 'it', 'they', 'didnt', 'know', 'i', 'had', 'thurs', 'pre', 'booked', 'off', 'so', 'they', 're', 'cancelled', 'me', 'again', '!', 'that', 'needs', 'to', 'b', 'sacked']\n",
      "AFter tokenizer:  ['haha', 'better', 'late', 'than', 'ever', ',', 'any', 'way', 'i', 'could', 'swing', 'by', '?']\n",
      "AFter tokenizer:  ['ok.', 'but', 'i', 'finish', 'at', '6', '.']\n",
      "AFter tokenizer:  ['lookatme', '!', ':', 'thanks', 'for', 'your', 'purchase', 'of', 'a', 'video', 'clip', 'from', 'lookatme', '!', ',', 'you', \"'ve\", 'been', 'charged', '35p', '.', 'think', 'you', 'can', 'do', 'better', '?', 'why', 'not', 'send', 'a', 'video', 'in', 'a', 'mmsto', '32323', '.']\n",
      "AFter tokenizer:  ['i', \"'ve\", 'been', 'barred', 'from', 'all', 'b', 'and', 'q', 'stores', 'for', 'life', '!', '?', 'this', 'twat', 'in', 'orange', 'dungerees', 'came', 'up', 'to', 'me', 'and', 'asked', 'if', 'i', 'wanted', 'decking', '?', 'so', 'i', 'got', 'the', 'first', 'punch', 'in', '!', '!']\n",
      "AFter tokenizer:  ['so', 'no', 'messages', '.', 'had', 'food', '?']\n",
      "AFter tokenizer:  ['ok', 'going', 'to', 'sleep', '.', 'hope', 'i', 'can', 'meet', 'her', '.']\n",
      "AFter tokenizer:  ['can', 'you', 'let', 'me', 'know', 'details', 'of', 'fri', 'when', 'u', 'find', 'out', 'cos', 'i', \"'m\", 'not', 'in', 'tom', 'or', 'fri.', 'mentionned', 'chinese', '.', 'thanks']\n",
      "AFter tokenizer:  ['you', \"'re\", 'right', 'i', 'have', 'now', 'that', 'i', 'think', 'about', 'it']\n",
      "AFter tokenizer:  ['wat', 'r', 'u', 'doing', 'now', '?']\n",
      "AFter tokenizer:  ['is', 'ur', 'lecture', 'over', '?']\n",
      "AFter tokenizer:  ['sexy', 'sexy', 'cum', 'and', 'text', 'me', 'im', 'wet', 'and', 'warm', 'and', 'ready', 'for', 'some', 'porn', '!', 'u', 'up', 'for', 'some', 'fun', '?', 'this', 'msg', 'is', 'free', 'recd', 'msgs', '150p', 'inc', 'vat', '2', 'cancel', 'text', 'stop']\n",
      "AFter tokenizer:  ['customer', 'place', 'i', 'will', 'call', 'you']\n",
      "AFter tokenizer:  ['not', 'planned', 'yet', ':', ')', 'going', 'to', 'join', 'company', 'on', 'jan', '5', 'only.don', 'know', 'what', 'will', 'happen', 'after', 'that', '.']\n",
      "AFter tokenizer:  ['boy', ';', 'i', 'love', 'u', 'grl', ':', 'hogolo', 'boy', ':', 'gold', 'chain', 'kodstini', 'grl', ':', 'agalla', 'boy', ':', 'necklace', 'madstini', 'grl', ':', 'agalla', 'boy', ':', 'hogli', '1', 'mutai', 'eerulli', 'kodthini', '!', 'grl', ':', 'i', 'love', 'u', 'kano', ';', '-', ')']\n",
      "AFter tokenizer:  ['haha', 'i', 'heard', 'that', ',', 'text', 'me', 'when', 'you', \"'re\", 'around']\n",
      "AFter tokenizer:  ['i.ll', 'get', 'there', 'tomorrow', 'and', 'send', 'it', 'to', 'you']\n",
      "AFter tokenizer:  ['shit', 'babe', '..', 'thasa', 'bit', 'messed', 'up.yeh', ',', 'she', 'shudvetold', 'u.', 'did', 'urgran', 'know', '?', 'neway', ',', 'illspeak', '2', 'u2moro', 'wen', 'im', 'not', 'asleep', '...']\n",
      "AFter tokenizer:  ['oh', 'thats', 'late', '!', 'well', 'have', 'a', 'good', 'night', 'and', 'i', 'will', 'give', 'u', 'a', 'call', 'tomorrow', '.', 'iam', 'now', 'going', 'to', 'go', 'to', 'sleep', 'night', 'night']\n",
      "AFter tokenizer:  ['cheers', 'u', 'tex', 'mecause', 'u', 'werebored', '!', 'yeah', 'okden', 'hunny', 'r', 'uin', 'wk', 'sat', '?', 'sound\\x92s', 'likeyour', 'havin', 'gr8fun', 'j', '!', 'keep', 'updat', 'countinlots', 'of', 'loveme', 'xxxxx', '.']\n",
      "AFter tokenizer:  ['sorry', ',', 'in', 'meeting', 'i', \"'ll\", 'call', 'you', 'later']\n",
      "AFter tokenizer:  ['yo', '!', 'howz', 'u', '?', 'girls', 'never', 'rang', 'after', 'india', '.', 'l']\n",
      "AFter tokenizer:  ['yeah', 'but', 'which', 'is', 'worse', 'for', 'i']\n",
      "AFter tokenizer:  ['i', 'tagged', 'my', 'friends', 'that', 'you', 'seemed', 'to', 'count', 'as', 'your', 'friends', '.']\n",
      "AFter tokenizer:  ['long', 'time', '.', 'you', 'remember', 'me', 'today', '.']\n",
      "AFter tokenizer:  ['havent', 'shopping', 'now', 'lor', 'i', 'juz', 'arrive', 'only']\n",
      "AFter tokenizer:  ['thank', 'u.', 'it', 'better', 'work', 'out', 'cause', 'i', 'will', 'feel', 'used', 'otherwise']\n",
      "AFter tokenizer:  ['are', 'you', 'up', 'for', 'the', 'challenge', '?', 'i', 'know', 'i', 'am', ':', ')']\n",
      "AFter tokenizer:  ['how', 'much', 'did', 'ur', 'hdd', 'casing', 'cost', '.']\n",
      "AFter tokenizer:  ['mystery', 'solved', '!', 'just', 'opened', 'my', 'email', 'and', 'he', \"'s\", 'sent', 'me', 'another', 'batch', '!', 'is', \"n't\", 'he', 'a', 'sweetie']\n",
      "AFter tokenizer:  ['i', 'ca', \"n't\", 'describe', 'how', 'lucky', 'you', 'are', 'that', 'i', \"'m\", 'actually', 'awake', 'by', 'noon']\n",
      "AFter tokenizer:  ['this', 'is', 'the', '2nd', 'time', 'we', 'have', 'tried', 'to', 'contact', 'u.', 'u', 'have', 'won', 'the', '£1450', 'prize', 'to', 'claim', 'just', 'call', '09053750005', 'b4', '310303.', 't', '&', 'cs/stop', 'sms', '08718725756', '.', '140ppm']\n",
      "AFter tokenizer:  ['cheers', 'for', 'the', 'card', '...', 'is', 'it', 'that', 'time', 'of', 'year', 'already', '?']\n",
      "AFter tokenizer:  ['ugh', 'hopefully', 'the', 'asus', 'ppl', 'dont', 'randomly', 'do', 'a', 'reformat', '.']\n",
      "AFter tokenizer:  ['have', \"n't\", 'seen', 'my', 'facebook', ',', 'huh', '?', 'lol', '!']\n",
      "AFter tokenizer:  ['mah', 'b', ',', 'i', \"'ll\", 'pick', 'it', 'up', 'tomorrow']\n",
      "AFter tokenizer:  ['still', 'otside', 'le', '..', 'u', 'come', '2morrow', 'maga', '..']\n",
      "AFter tokenizer:  ['do', 'u', 'still', 'have', 'plumbers', 'tape', 'and', 'a', 'wrench', 'we', 'could', 'borrow', '?']\n",
      "AFter tokenizer:  ['dear', 'voucher', 'holder', ',', 'to', 'claim', 'this', 'weeks', 'offer', ',', 'at', 'you', 'pc', 'please', 'go', 'to', 'http', ':', '//www.e-tlp.co.uk/reward', '.', 'ts', '&', 'cs', 'apply', '.']\n",
      "AFter tokenizer:  ['it', 'vl', 'bcum', 'more', 'difficult', '..']\n",
      "AFter tokenizer:  ['havent', 'still', 'waitin', 'as', 'usual', '...', 'ü', 'come', 'back', 'sch', 'oredi', '?']\n",
      "AFter tokenizer:  ['in', 'meeting', 'da', '.', 'i', 'will', 'call', 'you']\n",
      "AFter tokenizer:  ['k', 'k', ':', '-', ')', ':', '-', ')', 'then', 'watch', 'some', 'films', '.']\n",
      "AFter tokenizer:  ['does', 'cinema', 'plus', 'drink', 'appeal', 'tomo', '?', '*', 'is', 'a', 'fr', 'thriller', 'by', 'director', 'i', 'like', 'on', 'at', 'mac', 'at', '8.30', '.']\n",
      "AFter tokenizer:  ['there', 'the', 'size', 'of', 'elephant', 'tablets', '&', 'u', 'shove', 'um', 'up', 'ur', 'ass', '!', '!']\n",
      "AFter tokenizer:  ['so', 'many', 'people', 'seems', 'to', 'be', 'special', 'at', 'first', 'sight', ',', 'but', 'only', 'very', 'few', 'will', 'remain', 'special', 'to', 'you', 'till', 'your', 'last', 'sight', '..', 'maintain', 'them', 'till', 'life', 'ends', '..', 'take', 'cr', 'da']\n",
      "AFter tokenizer:  ['my', 'parents', ',', 'my', 'kidz', ',', 'my', 'friends', 'n', 'my', 'colleagues', '.', 'all', 'screaming', '..', 'surprise', '!', '!', 'and', 'i', 'was', 'waiting', 'on', 'the', 'sofa', '..', '...', '.....', \"'\", 'naked', '...', '!']\n",
      "AFter tokenizer:  ['dunno', 'i', 'juz', 'askin', 'cos', 'i', 'got', 'a', 'card', 'got', '20', '%', 'off', '4', 'a', 'salon', 'called', 'hair', 'sense', 'so', 'i', 'tot', 'it', \"'s\", 'da', 'one', 'ü', 'cut', 'ur', 'hair', '.']\n",
      "AFter tokenizer:  ['good', 'morning', 'pookie', 'pie', '!', 'lol', 'hope', 'i', 'did', \"n't\", 'wake', 'u', 'up']\n",
      "AFter tokenizer:  ['maybe', 'if', 'you', 'woke', 'up', 'before', 'fucking', '3', 'this', 'would', \"n't\", 'be', 'a', 'problem', '.']\n",
      "AFter tokenizer:  ['happy', 'birthday', 'to', 'you', '....', 'dear.with', 'lots', 'of', 'love.rakhesh', 'nri']\n",
      "AFter tokenizer:  ['this', 'is', 'the', '2nd', 'time', 'we', 'have', 'tried', '2', 'contact', 'u.', 'u', 'have', 'won', 'the', '750', 'pound', 'prize', '.', '2', 'claim', 'is', 'easy', ',', 'call', '08712101358', 'now', '!', 'only', '10p', 'per', 'min', '.', 'bt-national-rate']\n",
      "AFter tokenizer:  ['x2', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'are', 'you', 'going', 'to', 'get', 'that']\n",
      "AFter tokenizer:  ['hi', 'neva', 'worry', 'bout', 'da', 'truth', 'coz', 'the', 'truth', 'will', 'lead', 'me', '2', 'ur', 'heart', '.', 'it\\x92s', 'the', 'least', 'a', 'unique', 'person', 'like', 'u', 'deserve', '.', 'sleep', 'tight', 'or', 'morning']\n",
      "AFter tokenizer:  ['ur', 'awarded', 'a', 'city', 'break', 'and', 'could', 'win', 'a', '£200', 'summer', 'shopping', 'spree', 'every', 'wk', '.', 'txt', 'store', 'to', '88039.skilgme.tscs087147403231winawk', '!', 'age16+£1.50perwksub']\n",
      "AFter tokenizer:  ['is', 'ur', 'paper', 'today', 'in', 'e', 'morn', 'or', 'aft', '?']\n",
      "AFter tokenizer:  ['i', 'will', 'lick', 'up', 'every', 'drop', ':', ')', 'are', 'you', 'ready', 'to', 'use', 'your', 'mouth', 'as', 'well', '?']\n",
      "AFter tokenizer:  ['and', 'you', '!', 'will', 'expect', 'you', 'whenever', 'you', 'text', '!', 'hope', 'all', 'goes', 'well', 'tomo']\n",
      "AFter tokenizer:  ['great', '.', 'p', 'diddy', 'is', 'my', 'neighbor', 'and', 'comes', 'for', 'toothpaste', 'every', 'morning']\n",
      "AFter tokenizer:  ['i', 'av', 'a', 'new', 'number', ',', '.', 'wil', 'u', 'only', 'use', 'this', 'one', ',', 'ta', '.']\n",
      "AFter tokenizer:  ['so', 'its', 'to', 'be', 'poking', 'man', 'everyday', 'that', 'they', 'teach', 'you', 'in', 'canada', 'abi', '!', 'how', 'are', 'you', '.', 'just', 'saying', 'hi', '.']\n",
      "AFter tokenizer:  ['7', 'lor', '...', 'change', '2', 'suntec', '...', 'wat', 'time', 'u', 'coming', '?']\n",
      "AFter tokenizer:  ['no', 'de.am', 'seeing', 'in', 'online', 'shop', 'so', 'that', 'i', 'asked', '.']\n",
      "AFter tokenizer:  ['just', 'curious', 'because', 'my', 'cuz', 'asked', 'what', 'i', 'was', 'up', 'to']\n",
      "AFter tokenizer:  ['okay', 'lor', '...', 'wah', '...', 'like', 'that', 'def', 'they', 'wont', 'let', 'us', 'go', '...', 'haha', '...', 'what', 'did', 'they', 'say', 'in', 'the', 'terms', 'and', 'conditions', '?']\n",
      "AFter tokenizer:  ['haha', '...', 'yup', 'hopefully', 'we', 'will', 'lose', 'a', 'few', 'kg', 'by', 'mon', '.', 'after', 'hip', 'hop', 'can', 'go', 'orchard', 'and', 'weigh', 'again']\n",
      "AFter tokenizer:  ['she', \"'s\", 'good', '.', 'how', 'are', 'you', '.', 'where', 'r', 'u', 'working', 'now']\n",
      "AFter tokenizer:  ['oh', ',', 'yes', ',', 'i', \"'ve\", 'just', 'been', 'a', 'little', 'under', 'the', 'weather', 'so', 'i', \"'ve\", 'kind', 'of', 'been', 'coccooning', 'at', 'home']\n",
      "AFter tokenizer:  ['at', 'home', 'also', '.']\n",
      "AFter tokenizer:  ['this', 'phone', 'has', 'the', 'weirdest', 'auto', 'correct', '.']\n",
      "AFter tokenizer:  ['oops', 'my', 'phone', 'died', 'and', 'i', 'did', \"n't\", 'even', 'know', '.', 'yeah', 'i', 'like', 'it', 'better', '.']\n",
      "AFter tokenizer:  ['havent', 'mus', 'ask', 'if', 'u', 'can', '1st', 'wat', '.', 'of', 'meet', '4', 'lunch', 'den', 'u', 'n', 'him', 'meet', 'can', 'already', 'lor', '.', 'or', 'u', 'wan', '2', 'go', 'ask', 'da', 'ge', '1st', 'then', 'confirm', 'w', 'me', 'asap', '?']\n",
      "AFter tokenizer:  ['she', 'said', ',', \"''\", 'do', 'u', 'mind', 'if', 'i', 'go', 'into', 'the', 'bedroom', 'for', 'a', 'minute', '?', '``', \"''\", 'ok', \"''\", ',', 'i', 'sed', 'in', 'a', 'sexy', 'mood', '.', 'she', 'came', 'out', '5', 'minuts', 'latr', 'wid', 'a', 'cake', '...', 'n', 'my', 'wife', ',']\n",
      "AFter tokenizer:  ['oh', 'yeah', ',', 'and', 'hav', 'a', 'great', 'time', 'in', 'newquay-send', 'me', 'a', 'postcard', '!', '1', 'look', 'after', 'all', 'the', 'girls', 'while', 'im', 'gone', '(', 'u', 'know', 'the', '1im', 'talkin', 'bout', '!', ')', 'xx']\n",
      "AFter tokenizer:  ['we', 'got', 'a', 'divorce', '.', 'lol', '.', 'she.s', 'here']\n",
      "AFter tokenizer:  ['what', \"'s\", 'ur', 'pin', '?']\n",
      "AFter tokenizer:  ['babe', ',', 'have', 'you', 'got', 'enough', 'money', 'to', 'pick', 'up', 'bread', 'and', 'milk', '?', 'and', 'i', \"'ll\", 'give', 'you', 'it', 'back', 'when', 'you', 'get', 'home', '?']\n",
      "AFter tokenizer:  ['i', 'want', 'snow', '.', 'it', \"'s\", 'just', 'freezing', 'and', 'windy', '.']\n",
      "AFter tokenizer:  ['urgent', '!', 'we', 'are', 'trying', 'to', 'contact', 'u.', 'todays', 'draw', 'shows', 'that', 'you', 'have', 'won', 'a', '£2000', 'prize', 'guaranteed', '.', 'call', '09066358361', 'from', 'land', 'line', '.', 'claim', 'y87', '.', 'valid', '12hrs', 'only']\n",
      "AFter tokenizer:  ['come', 'to', 'mahal', 'bus', 'stop', '..', '&', 'lt', ';', 'decimal', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['don', 'know', ':', ')', 'this', 'week', 'i', \"'m\", 'going', 'to', 'tirunelvai', 'da', '.']\n",
      "AFter tokenizer:  ['me', 'too', 'baby', '!', 'i', 'promise', 'to', 'treat', 'you', 'well', '!', 'i', 'bet', 'you', 'will', 'take', 'good', 'care', 'of', 'me', '...']\n",
      "AFter tokenizer:  ['its', 'like', 'that', 'hotel', 'dusk', 'game', 'i', 'think', '.', 'you', 'solve', 'puzzles', 'in', 'a', 'area', 'thing']\n",
      "AFter tokenizer:  ['thanks', 'for', 'your', 'ringtone', 'order', ',', 'reference', 'number', 'x29', '.', 'your', 'mobile', 'will', 'be', 'charged', '4.50.', 'should', 'your', 'tone', 'not', 'arrive', 'please', 'call', 'customer', 'services', '09065989180']\n",
      "AFter tokenizer:  ['hi', ',', 'my', 'love', '!', 'how', 'goes', 'that', 'day', '?', 'fuck', ',', 'this', 'morning', 'i', 'woke', 'and', 'dropped', 'my', 'cell', 'on', 'the', 'way', 'down', 'the', 'stairs', 'but', 'it', 'seems', 'alright', '...', '*', 'phews', '*', 'i', 'miss', 'you', '!']\n",
      "AFter tokenizer:  ['well', 'that', 'must', 'be', 'a', 'pain', 'to', 'catch']\n",
      "AFter tokenizer:  ['sorry', 'da', 'thangam.it', \"'s\", 'my', 'mistake', '.']\n",
      "AFter tokenizer:  ['i', 'need', '...', 'coz', 'i', 'never', 'go', 'before']\n",
      "AFter tokenizer:  ['rose', 'for', 'red', ',', 'red', 'for', 'blood', ',', 'blood', 'for', 'heart', ',', 'heart', 'for', 'u.', 'but', 'u', 'for', 'me', '....', 'send', 'tis', 'to', 'all', 'ur', 'friends', '..', 'including', 'me', '..', 'if', 'u', 'like', 'me', '..', 'if', 'u', 'get', 'back', ',', '1-u', 'r', 'poor', 'in', 'relation', '!', '2-u', 'need', 'some', '1', 'to', 'support', '3-u', 'r', 'frnd', '2', 'many', '4-some1', 'luvs', 'u', '5+-', 'some1', 'is', 'praying', 'god', 'to', 'marry', 'u.', ':', '-', ')', 'try', 'it', '....']\n",
      "AFter tokenizer:  ['ur', 'cash-balance', 'is', 'currently', '500', 'pounds', '-', 'to', 'maximize', 'ur', 'cash-in', 'now', 'send', 'collect', 'to', '83600', 'only', '150p/msg', '.', 'cc', ':', '08718720201', 'po', 'box', '114/14', 'tcr/w1']\n",
      "AFter tokenizer:  ['i', 'feel', 'like', 'a', 'dick', 'because', 'i', 'keep', 'sleeping', 'through', 'your', 'texts', 'and', 'facebook', 'messages', '.', 'sup', ',', 'you', 'in', 'town', '?']\n",
      "AFter tokenizer:  ['no', 'plm', 'i', 'will', 'come', 'da', '.', 'on', 'the', 'way', '.']\n",
      "AFter tokenizer:  ['guess', 'he', 'wants', 'alone', 'time', '.', 'we', 'could', 'just', 'show', 'up', 'and', 'watch', 'when', 'they', 'do', '..']\n",
      "AFter tokenizer:  ['height', 'of', 'recycling', ':', 'read', 'twice-', 'people', 'spend', 'time', 'for', 'earning', 'money', 'and', 'the', 'same', 'money', 'is', 'spent', 'for', 'spending', 'time', '!', ';', '-', ')', 'good', 'morning', '..', 'keep', 'smiling', ':', '-', ')']\n",
      "AFter tokenizer:  ['yup', 'ü', 'not', 'comin', ':', '-', '(']\n",
      "AFter tokenizer:  ['yes', ',', 'princess', '.', 'toledo', '.']\n",
      "AFter tokenizer:  ['aight', 'text', 'me', 'when', 'you', \"'re\", 'back', 'at', 'mu', 'and', 'i', \"'ll\", 'swing', 'by', ',', 'need', 'somebody', 'to', 'get', 'the', 'door', 'for', 'me']\n",
      "AFter tokenizer:  ['ron', 'say', 'fri', 'leh', '.', 'n', 'he', 'said', 'ding', 'tai', 'feng', 'cant', 'make', 'reservations', '.', 'but', 'he', 'said', 'wait', 'lor', '.']\n",
      "AFter tokenizer:  ['good', '.', 'no', 'swimsuit', 'allowed', ':', ')']\n",
      "AFter tokenizer:  ['am', 'okay', '.', 'will', 'soon', 'be', 'over', '.', 'all', 'the', 'best']\n",
      "AFter tokenizer:  ['a', 'cute', 'thought', 'for', 'friendship', ':', '``', 'its', 'not', 'necessary', 'to', 'share', 'every', 'secret', 'with', 'ur', 'close', 'frnd', ',', 'but', 'watever', 'u', 'shared', 'should', 'be', 'true', \"''\", '....']\n",
      "AFter tokenizer:  ['ok', 'i', \"'ve\", 'sent', 'u', 'da', 'latest', 'version', 'of', 'da', 'project', '.']\n",
      "AFter tokenizer:  ['pls', 'accept', 'me', 'for', 'one', 'day', '.', 'or', 'am', 'begging', 'you', 'change', 'the', 'number', '.']\n",
      "AFter tokenizer:  ['squeeeeeze', '!', '!', 'this', 'is', 'christmas', 'hug', '..', 'if', 'u', 'lik', 'my', 'frndshp', 'den', 'hug', 'me', 'back', '..', 'if', 'u', 'get', '3', 'u', 'r', 'cute', ':', ')', '6', 'u', 'r', 'luvd', ':', '*', '9', 'u', 'r', 'so', 'lucky', ';', ')', 'none', '?', 'people', 'hate', 'u', ':']\n",
      "AFter tokenizer:  ['its', 'ok', ',', 'if', 'anybody', 'asks', 'abt', 'me', ',', 'u', 'tel', 'them', '..', ':', '-p']\n",
      "AFter tokenizer:  ['funny', 'fact', 'nobody', 'teaches', 'volcanoes', '2', 'erupt', ',', 'tsunamis', '2', 'arise', ',', 'hurricanes', '2', 'sway', 'aroundn', 'no', '1', 'teaches', 'hw', '2', 'choose', 'a', 'wife', 'natural', 'disasters', 'just', 'happens']\n",
      "AFter tokenizer:  ['*', 'you', 'gon', 'na', 'ring', 'this', 'weekend', 'or', 'wot', '?']\n",
      "AFter tokenizer:  ['also', 'track', 'down', 'any', 'lighters', 'you', 'can', 'find']\n",
      "AFter tokenizer:  ['babe', ',', 'i', 'need', 'your', 'advice']\n",
      "AFter tokenizer:  ['i', '‘', 'll', 'leave', 'around', 'four', ',', 'ok', '?']\n",
      "AFter tokenizer:  ['come', 'to', 'medical', 'college', 'at', '7pm', '......', 'forward', 'it', 'da']\n",
      "AFter tokenizer:  ['k', ':', ')', 'k', '..', 'its', 'good', ':', ')', 'when', 'are', 'you', 'going', '?']\n",
      "AFter tokenizer:  ['i', 'can', 'make', 'lasagna', 'for', 'you', '...', 'vodka', '...']\n",
      "AFter tokenizer:  ['hi', 'its', 'kate', 'can', 'u', 'give', 'me', 'a', 'ring', 'asap', 'xxx']\n",
      "AFter tokenizer:  ['who', 'were', 'those', 'people', '?', 'were', 'you', 'in', 'a', 'tour', '?', 'i', 'thought', 'you', 'were', 'doing', 'that', 'sofa', 'thing', 'you', 'sent', 'me', '?', 'your', 'curious', 'sugar']\n",
      "AFter tokenizer:  ['no', ',', 'but', 'you', 'told', 'me', 'you', 'were', 'going', ',', 'before', 'you', 'got', 'drunk', '!']\n",
      "AFter tokenizer:  ['he', 'fucking', 'chickened', 'out', '.', 'he', 'messaged', 'me', 'he', 'would', 'be', 'late', 'and', 'woould', 'buzz', 'me', 'and', 'then', 'i', 'did', \"n't\", 'hear', 'a', 'word', 'from', 'him']\n",
      "AFter tokenizer:  ['congratulations', '!', 'thanks', 'to', 'a', 'good', 'friend', 'u', 'have', 'won', 'the', '£2,000', 'xmas', 'prize', '.', '2', 'claim', 'is', 'easy', ',', 'just', 'call', '08718726978', 'now', '!', 'only', '10p', 'per', 'minute', '.', 'bt-national-rate']\n",
      "AFter tokenizer:  ['i', \"'m\", 'always', 'looking', 'for', 'an', 'excuse', 'to', 'be', 'in', 'the', 'city', '.']\n",
      "AFter tokenizer:  ['yup', 'i', \"'m\", 'still', 'having', 'coffee', 'wif', 'my', 'frens', '...', 'my', 'fren', 'drove', 'she', \"'ll\", 'give', 'me', 'a', 'lift', '...']\n",
      "AFter tokenizer:  ['o', 'shore', 'are', 'you', 'takin', 'the', 'bus']\n",
      "AFter tokenizer:  ['so', 'u', 'gon', 'na', 'get', 'deus', 'ex', '?']\n",
      "AFter tokenizer:  ['i', 'will', 'send', 'them', 'to', 'your', 'email', '.', 'do', 'you', 'mind', '&', 'lt', ';', '#', '&', 'gt', ';', 'times', 'per', 'night', '?']\n",
      "AFter tokenizer:  ['44', '7732584351', ',', 'do', 'you', 'want', 'a', 'new', 'nokia', '3510i', 'colour', 'phone', 'deliveredtomorrow', '?', 'with', '300', 'free', 'minutes', 'to', 'any', 'mobile', '+', '100', 'free', 'texts', '+', 'free', 'camcorder', 'reply', 'or', 'call', '08000930705', '.']\n",
      "AFter tokenizer:  ['tap', '&', 'spile', 'at', 'seven', '.', '*', 'is', 'that', 'pub', 'on', 'gas', 'st', 'off', 'broad', 'st', 'by', 'canal', '.', 'ok', '?']\n",
      "AFter tokenizer:  ['ok', 'then', 'i', 'come', 'n', 'pick', 'u', 'at', 'engin', '?']\n",
      "AFter tokenizer:  ['which', 'is', 'why', 'i', 'never', 'wanted', 'to', 'tell', 'you', 'any', 'of', 'this', '.', 'which', 'is', 'why', 'i', \"'m\", 'so', 'short', 'with', 'you', 'and', 'on-edge', 'as', 'of', 'late', '.']\n",
      "AFter tokenizer:  ['raviyog', 'peripherals', 'bhayandar', 'east']\n",
      "AFter tokenizer:  ['k', 'actually', 'can', 'you', 'guys', 'meet', 'me', 'at', 'the', 'sunoco', 'on', 'howard', '?', 'it', 'should', 'be', 'right', 'on', 'the', 'way']\n",
      "AFter tokenizer:  ['moon', 'has', 'come', 'to', 'color', 'your', 'dreams', ',', 'stars', 'to', 'make', 'them', 'musical', 'and', 'my', 'sms', 'to', 'give', 'you', 'warm', 'and', 'peaceful', 'sleep', '.', 'good', 'night']\n",
      "AFter tokenizer:  ['just', 'finished', 'eating', '.', 'got', 'u', 'a', 'plate', '.', 'not', 'leftovers', 'this', 'time', '.']\n",
      "AFter tokenizer:  ['thanx', 'a', 'lot', '...']\n",
      "AFter tokenizer:  ['hurry', 'home', 'u', 'big', 'butt', '.', 'hang', 'up', 'on', 'your', 'last', 'caller', 'if', 'u', 'have', 'to', '.', 'food', 'is', 'done', 'and', 'i', \"'m\", 'starving', '.', 'do', \"n't\", 'ask', 'what', 'i', 'cooked', '.']\n",
      "AFter tokenizer:  ['lol', 'your', 'right', '.', 'what', 'diet', '?', 'everyday', 'i', 'cheat', 'anyway', '.', 'i', \"'m\", 'meant', 'to', 'be', 'a', 'fatty', ':', '(']\n",
      "AFter tokenizer:  ['its', 'a', 'great', 'day', '.', 'do', 'have', 'yourself', 'a', 'beautiful', 'one', '.']\n",
      "AFter tokenizer:  ['what', 'happened', 'in', 'interview', '?']\n",
      "AFter tokenizer:  ['badrith', 'is', 'only', 'for', 'chennai', ':', ')', 'i', 'will', 'surely', 'pick', 'for', 'us', ':', ')', 'no', 'competition', 'for', 'him', '.']\n",
      "AFter tokenizer:  ['i', 'tot', 'it', \"'s\", 'my', 'group', 'mate', '...', 'lucky', 'i', 'havent', 'reply', '...', 'wat', 'time', 'do', 'ü', 'need', 'to', 'leave', '...']\n",
      "AFter tokenizer:  ['hey', 'you', 'around', '?', 'i', \"'ve\", 'got', 'enough', 'for', 'a', 'half', '+', 'the', 'ten', 'i', 'owe', 'you']\n",
      "AFter tokenizer:  ['hey', 'tmr', 'maybe', 'can', 'meet', 'you', 'at', 'yck']\n",
      "AFter tokenizer:  ['alrite', 'sam', 'its', 'nic', 'just', 'checkin', 'that', 'this', 'is', 'ur', 'number-so', 'is', 'it', '?', 't.b', '*']\n",
      "AFter tokenizer:  ['they', 'are', 'just', 'making', 'it', 'easy', 'to', 'pay', 'back', '.', 'i', 'have', '&', 'lt', ';', '#', '&', 'gt', ';', 'yrs', 'to', 'say', 'but', 'i', 'can', 'pay', 'back', 'earlier', '.', 'you', 'get', '?']\n",
      "AFter tokenizer:  ['not', 'to', 'worry', '.', 'i', \"'m\", 'sure', 'you', \"'ll\", 'get', 'it', '.']\n",
      "AFter tokenizer:  ['the', 'gas', 'station', 'is', 'like', 'a', 'block', 'away', 'from', 'my', 'house', ',', 'you', \"'ll\", 'drive', 'right', 'by', 'it', 'since', 'armenia', 'ends', 'at', 'swann', 'and', 'you', 'have', 'to', 'take', 'howard']\n",
      "AFter tokenizer:  ['someone', 'u', 'know', 'has', 'asked', 'our', 'dating', 'service', '2', 'contact', 'you', '!', 'cant', 'guess', 'who', '?', 'call', '09058097189', 'now', 'all', 'will', 'be', 'revealed', '.', 'pobox', '6', ',', 'ls15hb', '150p']\n",
      "AFter tokenizer:  ['camera', '-', 'you', 'are', 'awarded', 'a', 'sipix', 'digital', 'camera', '!', 'call', '09061221066', 'fromm', 'landline', '.', 'delivery', 'within', '28', 'days']\n",
      "AFter tokenizer:  ['my', 'tuition', 'is', 'at', '330.', 'hm', 'we', 'go', 'for', 'the', '1120', 'to', '1205', 'one', '?', 'do', 'you', 'mind', '?']\n",
      "AFter tokenizer:  ['i', \"'m\", 'not', 'smoking', 'while', 'people', 'use', '``', 'wylie', 'smokes', 'too', 'much', \"''\", 'to', 'justify', 'ruining', 'my', 'shit']\n",
      "AFter tokenizer:  ['dear', 'good', 'morning', 'how', 'you', 'feeling', 'dear']\n",
      "AFter tokenizer:  ['a', 'little', '.', 'meds', 'say', 'take', 'once', 'every', '8', 'hours', '.', 'it', \"'s\", 'only', 'been', '5', 'but', 'pain', 'is', 'back', '.', 'so', 'i', 'took', 'another', '.', 'hope', 'i', 'do', \"n't\", 'die']\n",
      "AFter tokenizer:  ['beautiful', 'tomorrow', 'never', 'comes', '..', 'when', 'it', 'comes', ',', 'it', \"'s\", 'already', 'today', '..', 'in', 'the', 'hunt', 'of', 'beautiful', 'tomorrow', 'do', \"n't\", 'waste', 'your', 'wonderful', 'today', '..', 'goodmorning', ':', ')']\n",
      "AFter tokenizer:  ['dunno', 'lei', 'ü', 'all', 'decide', 'lor', '.', 'how', 'abt', 'leona', '?', 'oops', 'i', 'tot', 'ben', 'is', 'going', 'n', 'i', 'msg', 'him', '.']\n",
      "AFter tokenizer:  ['hi', 'there', '.', 'we', 'have', 'now', 'moved', 'in2', 'our', 'pub', '.', 'would', 'be', 'great', '2', 'c', 'u', 'if', 'u', 'cud', 'come', 'up', '.']\n",
      "AFter tokenizer:  ['todays', 'voda', 'numbers', 'ending', '5226', 'are', 'selected', 'to', 'receive', 'a', '?', '350', 'award', '.', 'if', 'you', 'hava', 'a', 'match', 'please', 'call', '08712300220', 'quoting', 'claim', 'code', '1131', 'standard', 'rates', 'app']\n",
      "AFter tokenizer:  ['this', 'message', 'is', 'free', '.', 'welcome', 'to', 'the', 'new', '&', 'improved', 'sex', '&', 'dogging', 'club', '!', 'to', 'unsubscribe', 'from', 'this', 'service', 'reply', 'stop', '.', 'msgs', '@', '150p', '18', 'only']\n",
      "AFter tokenizer:  ['just', 'do', 'what', 'ever', 'is', 'easier', 'for', 'you']\n",
      "AFter tokenizer:  ['rct', \"'\", 'thnq', 'adrian', 'for', 'u', 'text', '.', 'rgds', 'vatian']\n",
      "AFter tokenizer:  ['stop', 'calling', 'everyone', 'saying', 'i', 'might', 'have', 'cancer', '.', 'my', 'throat', 'hurts', 'to', 'talk', '.', 'i', 'ca', \"n't\", 'be', 'answering', 'everyones', 'calls', '.', 'if', 'i', 'get', 'one', 'more', 'call', 'i', \"'m\", 'not', 'babysitting', 'on', 'monday']\n",
      "AFter tokenizer:  ['it', \"'ll\", 'be', 'tough', ',', 'but', 'i', \"'ll\", 'do', 'what', 'i', 'have', 'to']\n",
      "AFter tokenizer:  ['im', 'gonnamissu', 'so', 'much', '!', '!', 'i', 'would', 'say', 'il', 'send', 'u', 'a', 'postcard', 'buttheres', 'aboutas', 'much', 'chance', 'of', 'merememberin', 'asthere', 'is', 'ofsi', 'not', 'breakin', 'his', 'contract', '!', '!', 'luv', 'yaxx']\n",
      "AFter tokenizer:  ['ee', 'msg', 'na', 'poortiyagi', 'odalebeku', ':', 'hanumanji', '7', 'name', '1-hanuman', '2-bajarangabali', '3-maruti', '4-pavanaputra', '5-sankatmochan', '6-ramaduth', '7-mahaveer', 'ee', '7', 'name', '&', 'lt', ';', '#', '&', 'gt', ';', 'janarige', 'ivatte', 'kalisidare', 'next', 'saturday', 'olage', 'ondu', 'good', 'news', 'keluviri', '...', '!', 'maretare', 'inde', '1', 'dodda', 'problum', 'nalli', 'siguviri', 'idu', 'matra', '&', 'lt', ';', '#', '&', 'gt', ';', '%', 'true', '..', 'do', \"n't\", 'neglet', '.']\n",
      "AFter tokenizer:  ['hi', 'darlin', 'i', 'finish', 'at', '3', 'do', 'u', '1', '2', 'pick', 'me', 'up', 'or', 'meet', 'me', '?', 'text', 'back', 'on', 'this', 'number', 'luv', 'kate', 'xxx']\n",
      "AFter tokenizer:  ['set', 'a', 'place', 'for', 'me', 'in', 'your', 'heart', 'and', 'not', 'in', 'your', 'mind', ',', 'as', 'the', 'mind', 'easily', 'forgets', 'but', 'the', 'heart', 'will', 'always', 'remember', '.', 'wish', 'you', 'happy', 'valentines', 'day', '!']\n",
      "AFter tokenizer:  ['but', 'i', \"'m\", 'surprised', 'she', 'still', 'can', 'guess', 'right', 'lor', '...']\n",
      "AFter tokenizer:  ['okie', 'ü', 'wan', 'meet', 'at', 'bishan', '?', 'cos', 'me', 'at', 'bishan', 'now', '.', 'i', \"'m\", 'not', 'driving', 'today', '.']\n",
      "AFter tokenizer:  ['hi', 'darlin', 'how', 'was', 'work', 'did', 'u', 'get', 'into', 'trouble', '?', 'ijust', 'talked', 'to', 'your', 'mum', 'all', 'morning', '!', 'i', 'had', 'a', 'really', 'good', 'time', 'last', 'night', 'im', 'goin', 'out', 'soon', 'but', 'call', 'me', 'if', 'u', 'can']\n",
      "AFter tokenizer:  ['i', 'know', 'you', 'are', 'serving', '.', 'i', 'mean', 'what', 'are', 'you', 'doing', 'now', '.']\n",
      "AFter tokenizer:  ['huh', '...', 'hyde', 'park', 'not', 'in', 'mel', 'ah', ',', 'opps', ',', 'got', 'confused', '...', 'anyway', ',', 'if', 'tt', \"'s\", 'e', 'best', 'choice', 'den', 'we', 'juz', 'have', 'to', 'take', 'it', '...']\n",
      "AFter tokenizer:  ['oh', 'gei', '.', 'that', 'happend', 'to', 'me', 'in', 'tron', '.', 'maybe', 'ill', 'dl', 'it', 'in', '3d', 'when', 'its', 'out']\n",
      "AFter tokenizer:  ['i', 'know', 'girls', 'always', 'safe', 'and', 'selfish', 'know', 'i', 'got', 'it', 'pa.', 'thank', 'you', '.', 'good', 'night', '.']\n",
      "AFter tokenizer:  ['no', 'worries', ',', 'hope', 'photo', 'shoot', 'went', 'well', '.', 'have', 'a', 'spiffing', 'fun', 'at', 'workage', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'freezing', 'and', 'craving', 'ice', '.', 'fml']\n",
      "AFter tokenizer:  ['kay', '...', 'since', 'we', 'are', 'out', 'already']\n",
      "AFter tokenizer:  ['eh', 'sorry', 'leh', '...', 'i', 'din', 'c', 'ur', 'msg', '.', 'not', 'sad', 'already', 'lar', '.', 'me', 'watching', 'tv', 'now', '.', 'u', 'still', 'in', 'office', '?']\n",
      "AFter tokenizer:  ['yo', 'im', 'right', 'by', 'yo', 'work']\n",
      "AFter tokenizer:  ['ok', 'darlin', 'i', 'supose', 'it', 'was', 'ok', 'i', 'just', 'worry', 'too', 'much.i', 'have', 'to', 'do', 'some', 'film', 'stuff', 'my', 'mate', 'and', 'then', 'have', 'to', 'babysit', 'again', '!', 'but', 'you', 'can', 'call', 'me', 'there.xx']\n",
      "AFter tokenizer:  ['i', 'don', 'wake', 'since', '.', 'i', 'checked', 'that', 'stuff', 'and', 'saw', 'that', 'its', 'true', 'no', 'available', 'spaces', '.', 'pls', 'call', 'the', 'embassy', 'or', 'send', 'a', 'mail', 'to', 'them', '.']\n",
      "AFter tokenizer:  ['nope', '...', 'juz', 'off', 'from', 'work', '...']\n",
      "AFter tokenizer:  ['huh', 'so', 'fast', '...', 'dat', 'means', 'u', 'havent', 'finished', 'painting', '?']\n",
      "AFter tokenizer:  ['what', 'number', 'do', 'u', 'live', 'at', '?', 'is', 'it', '11', '?']\n",
      "AFter tokenizer:  ['no', 'we', 'put', 'party', '7', 'days', 'a', 'week', 'and', 'study', 'lightly', ',', 'i', 'think', 'we', 'need', 'to', 'draw', 'in', 'some', 'custom', 'checkboxes', 'so', 'they', 'know', 'we', \"'re\", 'hardcore']\n",
      "AFter tokenizer:  ['sac', 'will', 'score', 'big', 'hundred.he', 'is', 'set', 'batsman', ':', '-', ')']\n",
      "AFter tokenizer:  ['send', 'me', 'yetty', \"'s\", 'number', 'pls', '.']\n",
      "AFter tokenizer:  ['how', 'much', 'it', 'will', 'cost', 'approx', '.', 'per', 'month', '.']\n",
      "AFter tokenizer:  ['ok', '...', 'the', 'theory', 'test', '?', 'when', 'are', 'ü', 'going', 'to', 'book', '?', 'i', 'think', 'it', \"'s\", 'on', '21', 'may', '.', 'coz', 'thought', 'wan', 'na', 'go', 'out', 'with', 'jiayin', '.', 'but', 'she', 'isnt', 'free']\n",
      "AFter tokenizer:  ['you', 'are', 'being', 'contacted', 'by', 'our', 'dating', 'service', 'by', 'someone', 'you', 'know', '!', 'to', 'find', 'out', 'who', 'it', 'is', ',', 'call', 'from', 'a', 'land', 'line', '09050000928.', 'pobox45w2tg150p']\n",
      "AFter tokenizer:  ['that', \"'s\", 'fine', ',', 'have', 'him', 'give', 'me', 'a', 'call', 'if', 'he', 'knows', 'what', 'he', 'wants', 'or', 'has', 'any', 'questions']\n",
      "AFter tokenizer:  ['sorry', ',', 'got', 'a', 'late', 'start', ',', 'we', \"'re\", 'on', 'the', 'way']\n",
      "AFter tokenizer:  ['then', 'u', 'go', 'back', 'urself', 'lor', '...']\n",
      "AFter tokenizer:  ['i', 'am', 'at', 'the', 'gas', 'station', '.', 'go', 'there', '.']\n",
      "AFter tokenizer:  ['k', ',', 'if', 'u', 'bored', 'up', 'just', 'come', 'to', 'my', 'home', '..']\n",
      "AFter tokenizer:  ['babe', '!', '!', '!', '!', 'i', 'love', 'you', '!', '!', '!', '!', '*', 'covers', 'your', 'face', 'in', 'kisses', '*']\n",
      "AFter tokenizer:  ['like', 'i', 'made', 'him', 'throw', 'up', 'when', 'we', 'were', 'smoking', 'in', 'our', 'friend', \"'s\", 'car', 'one', 'time', ',', 'it', 'was', 'awesome']\n",
      "AFter tokenizer:  ['still', 'i', 'have', 'not', 'checked', 'it', 'da', '.', '.', '.']\n",
      "AFter tokenizer:  ['you', 'will', 'go', 'to', 'walmart', '.', 'i.ll', 'stay', '.']\n",
      "AFter tokenizer:  ['i', 'have', \"n't\", 'forgotten', 'you', ',', 'i', 'might', 'have', 'a', 'couple', 'bucks', 'to', 'send', 'you', 'tomorrow', ',', 'k', '?', 'i', 'love', 'ya', 'too']\n",
      "AFter tokenizer:  ['oh', 'great', '.', 'i.ll', 'disturb', 'him', 'more', 'so', 'that', 'we', 'can', 'talk', '.']\n",
      "AFter tokenizer:  ['reverse', 'is', 'cheating', '.', 'that', 'is', 'not', 'mathematics', '.']\n",
      "AFter tokenizer:  ['u', \"'re\", 'welcome', '...', 'caught', 'u', 'using', 'broken', 'english', 'again', '...']\n",
      "AFter tokenizer:  ['no', 'problem', 'baby', '.', 'is', 'this', 'is', 'a', 'good', 'time', 'to', 'talk', '?', 'i', 'called', 'and', 'left', 'a', 'message', '.']\n",
      "AFter tokenizer:  ['oh', 'is', 'it', '!', 'which', 'brand', '?']\n",
      "AFter tokenizer:  ['sorry', 'i', 'cant', 'take', 'your', 'call', 'right', 'now', '.', 'it', 'so', 'happens', 'that', 'there', 'r', '2waxsto', 'do', 'wat', 'you', 'want', '.', 'she', 'can', 'come', 'and', 'ill', 'get', 'her', 'medical', 'insurance', '.', 'and', 'she', \"'ll\", 'be', 'able', 'to', 'deliver', 'and', 'have', 'basic', 'care', '.', 'i', \"'m\", 'currently', 'shopping', 'for', 'the', 'right', 'medical', 'insurance', 'for', 'her', '.', 'so', 'just', 'give', 'me', 'til', 'friday', 'morning', '.', 'thats', 'when', 'i.ll', 'see', 'the', 'major', 'person', 'that', 'can', 'guide', 'me', 'to', 'the', 'right', 'insurance', '.']\n",
      "AFter tokenizer:  ['at', 'what', 'time', 'are', 'you', 'coming', '.']\n",
      "AFter tokenizer:  ['call', 'him', 'and', 'say', 'you', 'not', 'coming', 'today', 'ok', 'and', 'tell', 'them', 'not', 'to', 'fool', 'me', 'like', 'this', 'ok']\n",
      "AFter tokenizer:  ['i', 'emailed', 'yifeng', 'my', 'part', 'oredi', '..', 'can', 'ü', 'get', 'it', 'fr', 'him', '..']\n",
      "AFter tokenizer:  ['r', 'u', 'sure', 'they', \"'ll\", 'understand', 'that', '!', 'wine', '*', 'good', 'idea', 'just', 'had', 'a', 'slurp', '!']\n",
      "AFter tokenizer:  ['minimum', 'walk', 'is', '3miles', 'a', 'day', '.']\n",
      "AFter tokenizer:  ['ok', 'not', 'a', 'problem', 'will', 'get', 'them', 'a', 'taxi', '.', 'c', 'ing', 'tomorrow', 'and', 'tuesday', '.', 'on', 'tuesday', 'think', 'we', 'r', 'all', 'going', 'to', 'the', 'cinema', '.']\n",
      "AFter tokenizer:  ['brainless', 'baby', 'doll', '..', ':', '-d', ';', '-', ')', ',', 'vehicle', 'sariyag', 'drive', 'madoke', 'barolla', '..']\n",
      "AFter tokenizer:  ['sorry', 'i', 'missed', 'your', 'call', 'let', \"'s\", 'talk', 'when', 'you', 'have', 'the', 'time', '.', 'i', \"'m\", 'on', '07090201529']\n",
      "AFter tokenizer:  ['please', 'attend', 'the', 'phone', ':', ')']\n",
      "AFter tokenizer:  ['you', 'only', 'hate', 'me', '.', 'you', 'can', 'call', 'any', 'but', 'you', 'didnt', 'accept', 'even', 'a', 'single', 'call', 'of', 'mine', '.', 'or', 'even', 'you', 'messaged']\n",
      "AFter tokenizer:  ['no', 'messages', 'on', 'her', 'phone', '.', 'i', \"'m\", 'holding', 'it', 'now']\n",
      "AFter tokenizer:  ['can', '...', 'i', \"'m\", 'free', '...']\n",
      "AFter tokenizer:  ['yo', 'my', 'trip', 'got', 'postponed', ',', 'you', 'still', 'stocked', 'up', '?']\n",
      "AFter tokenizer:  ['i', 'am', 'waiting', 'for', 'your', 'call', 'sir', '.']\n",
      "AFter tokenizer:  ['hey', 'what', 'are', 'you', 'doing', '.', 'y', 'no', 'reply', 'pa', '..']\n",
      "AFter tokenizer:  ['hey', 'elaine', ',', 'is', 'today', \"'s\", 'meeting', 'still', 'on', '?']\n",
      "AFter tokenizer:  ['sorry', 'i', \"'ve\", 'not', 'gone', 'to', 'that', 'place', '.', 'i.ll', 'do', 'so', 'tomorrow', '.', 'really', 'sorry', '.']\n",
      "AFter tokenizer:  ['most', 'of', 'the', 'tiime', 'when', 'i', 'do', \"n't\", 'let', 'you', 'hug', 'me', 'it', \"'s\", 'so', 'i', 'do', \"n't\", 'break', 'into', 'tears', '.']\n",
      "AFter tokenizer:  ['tomorrow', 'i', 'am', 'not', 'going', 'to', 'theatre', '.', '.', '.', 'so', 'i', 'can', 'come', 'wherever', 'u', 'call', 'me', '.', '.', '.', 'tell', 'me', 'where', 'and', 'when', 'to', 'come', 'tomorrow']\n",
      "AFter tokenizer:  ['and', 'now', 'electricity', 'just', 'went', 'out', 'fml', '.']\n",
      "AFter tokenizer:  ['looks', 'like', 'you', 'found', 'something', 'to', 'do', 'other', 'than', 'smoke', ',', 'great', 'job', '!']\n",
      "AFter tokenizer:  ['also', 'andros', 'ice', 'etc', 'etc']\n",
      "AFter tokenizer:  [':', ')']\n",
      "AFter tokenizer:  ['good', 'afternon', ',', 'my', 'love', '.', 'how', 'are', 'today', '?', 'i', 'hope', 'your', 'good', 'and', 'maybe', 'have', 'some', 'interviews', '.', 'i', 'wake', 'and', 'miss', 'you', 'babe', '.', 'a', 'passionate', 'kiss', 'from', 'across', 'the', 'sea']\n",
      "AFter tokenizer:  ['yup', '.', 'wun', 'believe', 'wat', '?', 'u', 'really', 'neva', 'c', 'e', 'msg', 'i', 'sent', 'shuhui', '?']\n",
      "AFter tokenizer:  ['hows', 'that', 'watch', 'resizing']\n",
      "AFter tokenizer:  ['dear', 'umma', 'she', 'called', 'me', 'now', ':', '-', ')']\n",
      "AFter tokenizer:  ['just', 'finished', '.', 'missing', 'you', 'plenty']\n",
      "AFter tokenizer:  ['complimentary', '4', 'star', 'ibiza', 'holiday', 'or', '£10,000', 'cash', 'needs', 'your', 'urgent', 'collection', '.', '09066364349', 'now', 'from', 'landline', 'not', 'to', 'lose', 'out', '!', 'box434sk38wp150ppm18+']\n",
      "AFter tokenizer:  ['well', ',', 'i', 'meant', 'as', 'opposed', 'to', 'my', 'drunken', 'night', 'of', 'before']\n",
      "AFter tokenizer:  ['k', '...', 'must', 'book', 'a', 'not', 'huh', '?', 'so', 'going', 'for', 'yoga', 'basic', 'on', 'sunday', '?']\n",
      "AFter tokenizer:  ['free', 'msg', ':', 'we', 'billed', 'your', 'mobile', 'number', 'by', 'mistake', 'from', 'shortcode', '83332.please', 'call', '08081263000', 'to', 'have', 'charges', 'refunded.this', 'call', 'will', 'be', 'free', 'from', 'a', 'bt', 'landline']\n",
      "AFter tokenizer:  ['ok', 'can', '...']\n",
      "AFter tokenizer:  ['oops', '-', 'am', 'at', 'my', 'mum', \"'s\", 'in', 'somerset', '...', 'bit', 'far', '!', 'back', 'tomo', ',', 'see', 'you', 'soon', 'x']\n",
      "AFter tokenizer:  ['so', 'u', 'workin', 'overtime', 'nigpun', '?']\n",
      "AFter tokenizer:  ['same', 'as', 'kallis', 'dismissial', 'in', '2nd', 'test', ':', '-', ')', '.']\n",
      "AFter tokenizer:  ['o.', 'guess', 'they', 'both', 'got', 'screwd']\n",
      "AFter tokenizer:  ['please', 'call', '08712402972', 'immediately', 'as', 'there', 'is', 'an', 'urgent', 'message', 'waiting', 'for', 'you']\n",
      "AFter tokenizer:  ['what', 'r', 'u', 'cooking', 'me', 'for', 'dinner', '?']\n",
      "AFter tokenizer:  ['bull', '.', 'your', 'plan', 'was', 'to', 'go', 'floating', 'off', 'to', 'ikea', 'with', 'me', 'without', 'a', 'care', 'in', 'the', 'world', '.', 'so', 'i', 'have', 'to', 'live', 'with', 'your', 'mess', 'another', 'day', '.']\n",
      "AFter tokenizer:  ['then', 'i', 'buy', '.']\n",
      "AFter tokenizer:  ['urgent', '!', 'your', 'mobile', 'number', 'has', 'been', 'awarded', 'with', 'a', '£2000', 'bonus', 'caller', 'prize', '.', 'call', '09058095201', 'from', 'land', 'line', '.', 'valid', '12hrs', 'only']\n",
      "AFter tokenizer:  ['heehee', 'that', 'was', 'so', 'funny', 'tho']\n",
      "AFter tokenizer:  ['it', 'only', 'does', 'simple', 'arithmetic', 'not', 'percentages', '.']\n",
      "AFter tokenizer:  ['yeah', 'we', 'would', \"n't\", 'leave', 'for', 'an', 'hour', 'at', 'least', ',', 'how', \"'s\", '4', 'sound', '?']\n",
      "AFter tokenizer:  ['thanks', 'honey', '.', 'have', 'a', 'great', 'day', '.']\n",
      "AFter tokenizer:  ['an', 'amazing', 'quote', \"''\", '-', '``', 'sometimes', 'in', 'life', 'its', 'difficult', 'to', 'decide', 'whats', 'wrong', '!', '!', 'a', 'lie', 'that', 'brings', 'a', 'smile', 'or', 'the', 'truth', 'that', 'brings', 'a', 'tear', '....', \"''\"]\n",
      "AFter tokenizer:  ['then', 'ü', 'ask', 'dad', 'to', 'pick', 'ü', 'up', 'lar', '...', 'ü', 'wan', '2', 'stay', 'until', '6', 'meh', '...']\n",
      "AFter tokenizer:  ['jus', 'chillaxin', ',', 'what', 'up']\n",
      "AFter tokenizer:  ['hey', 'das', 'cool', '...', 'iknow', 'all', '2', 'wellda', 'peril', 'of', 'studentfinancial', 'crisis', '!', 'spk', '2', 'u', 'l8r', '.']\n",
      "AFter tokenizer:  ['do', 'you', 'want', 'a', 'new', 'nokia', '3510i', 'colour', 'phone', 'deliveredtomorrow', '?', 'with', '300', 'free', 'minutes', 'to', 'any', 'mobile', '+', '100', 'free', 'texts', '+', 'free', 'camcorder', 'reply', 'or', 'call', '08000930705']\n",
      "AFter tokenizer:  ['whats', 'that', 'coming', 'over', 'the', 'hill', '.....', 'is', 'it', 'a', 'monster', '!', 'hope', 'you', 'have', 'a', 'great', 'day', '.', 'things', 'r', 'going', 'fine', 'here', ',', 'busy', 'though', '!']\n",
      "AFter tokenizer:  ['joy', \"'s\", 'father', 'is', 'john', '.', 'then', 'john', 'is', 'the', '____', 'of', 'joy', \"'s\", 'father', '.', 'if', 'u', 'ans', 'ths', 'you', 'hav', '&', 'lt', ';', '#', '&', 'gt', ';', 'iq', '.', 'tis', 's', 'ias', 'question', 'try', 'to', 'answer', '.']\n",
      "AFter tokenizer:  ['only', 'once', 'then', 'after', 'ill', 'obey', 'all', 'yours', '.']\n",
      "AFter tokenizer:  ['no', 'she', 'didnt', '.', 'i', 'will', 'search', 'online', 'and', 'let', 'you', 'know', '.']\n",
      "AFter tokenizer:  ['where', 'do', 'you', 'need', 'to', 'go', 'to', 'get', 'it', '?']\n",
      "AFter tokenizer:  ['no', 'pic', '.', 'please', 're-send', '.']\n",
      "AFter tokenizer:  ['uhhhhrmm', 'isnt', 'having', 'tb', 'test', 'bad', 'when', 'youre', 'sick']\n",
      "AFter tokenizer:  ['but', 'i', 'haf', 'enuff', 'space', 'got', 'like', '4', 'mb', '...']\n",
      "AFter tokenizer:  ['life', 'has', 'never', 'been', 'this', 'much', 'fun', 'and', 'great', 'until', 'you', 'came', 'in', '.', 'you', 'made', 'it', 'truly', 'special', 'for', 'me', '.', 'i', 'wo', \"n't\", 'forget', 'you', '!', 'enjoy', '@', 'one', 'gbp/sms']\n",
      "AFter tokenizer:  ['do', 'you', 'want', 'a', 'new', 'video', 'phone', '?', '600', 'anytime', 'any', 'network', 'mins', '400', 'inclusive', 'video', 'calls', 'and', 'downloads', '5', 'per', 'week', 'free', 'deltomorrow', 'call', '08002888812', 'or', 'reply', 'now']\n",
      "AFter tokenizer:  ['as', 'a', 'valued', 'customer', ',', 'i', 'am', 'pleased', 'to', 'advise', 'you', 'that', 'following', 'recent', 'review', 'of', 'your', 'mob', 'no', '.', 'you', 'are', 'awarded', 'with', 'a', '£1500', 'bonus', 'prize', ',', 'call', '09066368470']\n",
      "AFter tokenizer:  ['welcome', '!', 'please', 'reply', 'with', 'your', 'age', 'and', 'gender', 'to', 'begin', '.', 'e.g', '24m']\n",
      "AFter tokenizer:  ['freemsg', ':', '1-month', 'unlimited', 'free', 'calls', '!', 'activate', 'smartcall', 'txt', ':', 'call', 'to', 'no', ':', '68866.', 'subscriptn3gbp/wk', 'unlimited', 'calls', 'help', ':', '08448714184', 'stop', '?', 'txt', 'stop', 'landlineonly']\n",
      "AFter tokenizer:  ['had', 'your', 'mobile', '10', 'mths', '?', 'update', 'to', 'latest', 'orange', 'camera/video', 'phones', 'for', 'free', '.', 'save', '£s', 'with', 'free', 'texts/weekend', 'calls', '.', 'text', 'yes', 'for', 'a', 'callback', 'orno', 'to', 'opt', 'out']\n",
      "AFter tokenizer:  ['am', 'new', '2', 'club', '&', 'dont', 'fink', 'we', 'met', 'yet', 'will', 'b', 'gr8', '2', 'c', 'u', 'please', 'leave', 'msg', '2day', 'wiv', 'ur', 'area', '09099726553', 'reply', 'promised', 'carlie', 'x', 'calls£1/minmobsmore', 'lkpobox177hp51fl']\n",
      "AFter tokenizer:  ['true', '.', 'its', 'easier', 'with', 'her', 'here', '.']\n",
      "AFter tokenizer:  ['sure', 'but', 'since', 'my', 'parents', 'will', 'be', 'working', 'on', 'tuesday', 'i', 'do', \"n't\", 'really', 'need', 'a', 'cover', 'story']\n",
      "AFter tokenizer:  ['haha', 'okay', '...', 'today', 'weekend', 'leh', '...']\n",
      "AFter tokenizer:  ['hi', 'darlin', 'did', 'youphone', 'me', '?', 'im', 'athome', 'if', 'youwanna', 'chat', '.']\n",
      "AFter tokenizer:  ['i', 'do', \"n't\", 'know', 'jack', 'shit', 'about', 'anything', 'or', 'i', \"'d\", 'say/ask', 'something', 'helpful', 'but', 'if', 'you', 'want', 'you', 'can', 'pretend', 'that', 'i', 'did', 'and', 'just', 'text', 'me', 'whatever', 'in', 'response', 'to', 'the', 'hypotheticalhuagauahahuagahyuhagga']\n",
      "AFter tokenizer:  ['you', \"'ve\", 'always', 'been', 'the', 'brainy', 'one', '.']\n",
      "AFter tokenizer:  ['yeah', 'if', 'we', 'do', 'have', 'to', 'get', 'a', 'random', 'dude', 'we', 'need', 'to', 'change', 'our', 'info', 'sheets', 'to', 'party', '&', 'lt', ';', '#', '&', 'gt', ';', '/7', 'never', 'study', 'just', 'to', 'be', 'safe']\n",
      "AFter tokenizer:  ['camera', '-', 'you', 'are', 'awarded', 'a', 'sipix', 'digital', 'camera', '!', 'call', '09061221066', 'fromm', 'landline', '.', 'delivery', 'within', '28', 'days', '.']\n",
      "AFter tokenizer:  ['christmas', 'is', 'an', 'occasion', 'that', 'is', 'celebrated', 'as', 'a', 'reflection', 'of', 'ur', '...', 'values', '...', ',', 'desires', '...', ',', 'affections', '...', '&', 'amp', ';', 'traditions', '....', 'have', 'an', 'ideal', 'christmas', '...']\n",
      "AFter tokenizer:  ['sending', 'you', 'greetings', 'of', 'joy', 'and', 'happiness', '.', 'do', 'have', 'a', 'gr8', 'evening']\n",
      "AFter tokenizer:  ['hi', 'darlin', 'i', 'cantdo', 'anythingtomorrow', 'as', 'myparents', 'aretaking', 'me', 'outfor', 'a', 'meal', '.', 'when', 'are', 'u', 'free', '?', 'katexxx']\n",
      "AFter tokenizer:  ['if', 'india', 'win', 'or', 'level', 'series', 'means', 'this', 'is', 'record', ':', ')']\n",
      "AFter tokenizer:  ['then', 'what', 'about', 'further', 'plan', '?']\n",
      "AFter tokenizer:  ['its', 'good', 'to', 'hear', 'from', 'you']\n",
      "AFter tokenizer:  ['awesome', ',', 'how', 'do', 'i', 'deal', 'with', 'the', 'gate', '?', 'charles', 'told', 'me', 'last', 'night', 'but', ',', 'uh', ',', 'yeah']\n",
      "AFter tokenizer:  ['what', 'time', 'you', 'thinkin', 'of', 'goin', '?']\n",
      "AFter tokenizer:  ['get', 'a', 'free', 'mobile', 'video', 'player', 'free', 'movie', '.', 'to', 'collect', 'text', 'go', 'to', '89105.', 'its', 'free', '!', 'extra', 'films', 'can', 'be', 'ordered', 't', \"'s\", 'and', 'c', \"'s\", 'apply', '.', '18', 'yrs', 'only']\n",
      "AFter tokenizer:  ['save', 'money', 'on', 'wedding', 'lingerie', 'at', 'www.bridal.petticoatdreams.co.uk', 'choose', 'from', 'a', 'superb', 'selection', 'with', 'national', 'delivery', '.', 'brought', 'to', 'you', 'by', 'weddingfriend']\n",
      "AFter tokenizer:  ['your', 'board', 'is', 'working', 'fine', '.', 'the', 'issue', 'of', 'overheating', 'is', 'also', 'reslove', '.', 'but', 'still', 'software', 'inst', 'is', 'pending', '.', 'i', 'will', 'come', 'around', '8', \"'\", 'o', 'clock', '.']\n",
      "AFter tokenizer:  ['yes', 'but', 'i', 'do', \"n't\", 'care', 'cause', 'i', 'know', 'its', 'there', '!']\n",
      "AFter tokenizer:  ['mon', 'okie', 'lor', '...', 'haha', ',', 'best', 'is', 'cheap', 'n', 'gd', 'food', 'la', ',', 'ex', 'oso', 'okie', '...', 'depends', 'on', 'whether', 'wana', 'eat', 'western', 'or', 'chinese', 'food', '...', 'den', 'which', 'u', 'prefer', '...']\n",
      "AFter tokenizer:  ['sitting', 'ard', 'nothing', 'to', 'do', 'lor', '.', 'u', 'leh', 'busy', 'w', 'work', '?']\n",
      "AFter tokenizer:  ['its', '&', 'lt', ';', '#', '&', 'gt', ';', 'k', 'here', 'oh', '.', 'should', 'i', 'send', 'home', 'for', 'sale', '.']\n",
      "AFter tokenizer:  ['sorry', '.', '||', 'mail', '?', '||']\n",
      "AFter tokenizer:  ['ya', 'just', 'telling', 'abt', 'tht', 'incident', '..']\n",
      "AFter tokenizer:  ['yes', 'we', 'were', 'outside', 'for', 'like', '2', 'hours', '.', 'and', 'i', 'called', 'my', 'whole', 'family', 'to', 'wake', 'them', 'up', 'cause', 'it', 'started', 'at', '1', 'am']\n",
      "AFter tokenizer:  ['ugh', 'just', 'got', 'outta', 'class']\n",
      "AFter tokenizer:  ['nowadays', 'people', 'are', 'notixiquating', 'the', 'laxinorficated', 'opportunity', 'for', 'bambling', 'of', 'entropication', '....', 'have', 'you', 'ever', 'oblisingately', 'opted', 'ur', 'books', 'for', 'the', 'masteriastering', 'amplikater', 'of', 'fidalfication', '?', 'it', 'is', 'very', 'champlaxigating', ',', 'i', 'think', 'it', 'is', 'atrocious', '..', 'wotz', 'ur', 'opinion', '?', '?', '?', '?', 'junna']\n",
      "AFter tokenizer:  ['no', 'need', 'lar', '.', 'jus', 'testing', 'e', 'phone', 'card', '.', 'dunno', 'network', 'not', 'gd', 'i', 'thk', '.', 'me', 'waiting', '4', 'my', 'sis', '2', 'finish', 'bathing', 'so', 'i', 'can', 'bathe', '.', 'dun', 'disturb', 'u', 'liao', 'u', 'cleaning', 'ur', 'room', '.']\n",
      "AFter tokenizer:  ['ok.', 'i.ll', 'do', 'you', 'right', 'later', '.']\n",
      "AFter tokenizer:  ['have', 'your', 'lunch', 'and', 'come', 'quickly', 'and', 'open', 'the', 'door', ':', ')']\n",
      "AFter tokenizer:  ['not', 'heard', 'from', 'u4', 'a', 'while', '.', 'call', 'me', 'now', 'am', 'here', 'all', 'night', 'with', 'just', 'my', 'knickers', 'on', '.', 'make', 'me', 'beg', 'for', 'it', 'like', 'u', 'did', 'last', 'time', '01223585236', 'xx', 'luv', 'nikiyu4.net']\n",
      "AFter tokenizer:  ['i', 'am', 'back', '.', 'bit', 'long', 'cos', 'of', 'accident', 'on', 'a30', '.', 'had', 'to', 'divert', 'via', 'wadebridge.i', 'had', 'a', 'brilliant', 'weekend', 'thanks', '.', 'speak', 'soon', '.', 'lots', 'of', 'love']\n",
      "AFter tokenizer:  ['k', '..', 'i', 'yan', 'jiu', 'liao', '...', 'sat', 'we', 'can', 'go', '4', 'bugis', 'vill', 'one', 'frm', '10', 'to', '3', 'den', 'hop', 'to', 'parco', '4', 'nb', '.', 'sun', 'can', 'go', 'cine', 'frm', '1030', 'to', '2', ',', 'den', 'hop', 'to', 'orc', 'mrt', '4', 'hip', 'hop', 'at', '4', '...']\n",
      "AFter tokenizer:  ['bloomberg', '-message', 'center', '+447797706009', 'why', 'wait', '?', 'apply', 'for', 'your', 'future', 'http', ':', '//careers', '.', 'bloomberg.com']\n",
      "AFter tokenizer:  ['i', 'am', 'seeking', 'a', 'lady', 'in', 'the', 'street', 'and', 'a', 'freak', 'in', 'the', 'sheets', '.', 'is', 'that', 'you', '?']\n",
      "AFter tokenizer:  ['my', 'phone']\n",
      "AFter tokenizer:  ['haha', 'figures', ',', 'well', 'i', 'found', 'the', 'piece', 'and', 'priscilla', \"'s\", 'bowl']\n",
      "AFter tokenizer:  ['actually', 'fuck', 'that', ',', 'just', 'do', 'whatever', ',', 'do', 'find', 'an', 'excuse', 'to', 'be', 'in', 'tampa', 'at', 'some', 'point', 'before', 'january', 'though']\n",
      "AFter tokenizer:  ['yay', '!', 'finally', 'lol', '.', 'i', 'missed', 'our', 'cinema', 'trip', 'last', 'week', ':', '-', '(']\n",
      "AFter tokenizer:  ['all', 'day', 'working', 'day', ':', ')', 'except', 'saturday', 'and', 'sunday', '..']\n",
      "AFter tokenizer:  ['heart', 'is', 'empty', 'without', 'love', '..', 'mind', 'is', 'empty', 'without', 'wisdom', '..', 'eyes', 'r', 'empty', 'without', 'dreams', '&', 'amp', ';', 'life', 'is', 'empty', 'without', 'frnds', '..', 'so', 'alwys', 'be', 'in', 'touch', '.', 'good', 'night', '&', 'amp', ';', 'sweet', 'dreams']\n",
      "AFter tokenizer:  ['i', 'think', 'i', '‘', 'm', 'waiting', 'for', 'the', 'same', 'bus', '!', 'inform', 'me', 'when', 'you', 'get', 'there', ',', 'if', 'you', 'ever', 'get', 'there', '.']\n",
      "AFter tokenizer:  ['you', 'getting', 'back', 'any', 'time', 'soon', '?']\n",
      "AFter tokenizer:  [',', 'how', \"'s\", 'things', '?', 'just', 'a', 'quick', 'question', '.']\n",
      "AFter tokenizer:  ['i', 'can', 'probably', 'come', 'by', ',', 'everybody', \"'s\", 'done', 'around', '&', 'lt', ';', '#', '&', 'gt', ';', 'right', '?']\n",
      "AFter tokenizer:  ['i', 'got', 'it', 'before', 'the', 'new', 'year', 'cos', 'yetunde', 'said', 'she', 'wanted', 'to', 'surprise', 'you', 'with', 'it', 'but', 'when', 'i', 'didnt', 'see', 'money', 'i', 'returned', 'it', 'mid', 'january', 'before', 'the', '&', 'lt', ';', '#', '&', 'gt', ';', 'day', 'return', 'period', 'ended', '.']\n",
      "AFter tokenizer:  ['i', 'can', 'ask', 'around', 'but', 'there', \"'s\", 'not', 'a', 'lot', 'in', 'terms', 'of', 'mids', 'up', 'here']\n",
      "AFter tokenizer:  ['be', 'sure', 'to', 'check', 'your', 'yahoo', 'email', '.', 'we', 'sent', 'photos', 'yesterday']\n",
      "AFter tokenizer:  ['what', 'was', 'she', 'looking', 'for', '?']\n",
      "AFter tokenizer:  ['wherre', \"'s\", 'my', 'boytoy', '?', ':', '-', '(']\n",
      "AFter tokenizer:  ['do', 'you', 'want', 'a', 'new', 'video', 'phone750', 'anytime', 'any', 'network', 'mins', '150', 'text', 'for', 'only', 'five', 'pounds', 'per', 'week', 'call', '08000776320', 'now', 'or', 'reply', 'for', 'delivery', 'tomorrow']\n",
      "AFter tokenizer:  ['hello', ',', 'my', 'love', '!', 'how', 'goes', 'that', 'day', '?', 'i', 'wish', 'your', 'well', 'and', 'fine', 'babe', 'and', 'hope', 'that', 'you', 'find', 'some', 'job', 'prospects', '.', 'i', 'miss', 'you', ',', 'boytoy', '...', '*', 'a', 'teasing', 'kiss', '*']\n",
      "AFter tokenizer:  ['tell', 'my', 'bad', 'character', 'which', 'u', 'dnt', 'lik', 'in', 'me', '.', 'i', \"'ll\", 'try', 'to', 'change', 'in', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'i', 'll', 'add', 'tat', '2', 'my', 'new', 'year', 'resolution', '.', 'waiting', 'for', 'ur', 'reply.be', 'frank', '...', 'good', 'morning', '.']\n",
      "AFter tokenizer:  ['yeah', ',', 'probably', 'earlier', 'than', 'that']\n",
      "AFter tokenizer:  ['change', 'windows', 'logoff', 'sound', '..']\n",
      "AFter tokenizer:  ['i', \"'m\", 'also', 'came', 'to', 'room', '.']\n",
      "AFter tokenizer:  ['huh', 'but', 'i', 'got', 'lesson', 'at', '4', 'lei', 'n', 'i', 'was', 'thinkin', 'of', 'going', 'to', 'sch', 'earlier', 'n', 'i', 'tot', 'of', 'parkin', 'at', 'kent', 'vale', '...']\n",
      "AFter tokenizer:  ['i', 'will', 'reach', 'office', 'around', '&', 'lt', ';', 'decimal', '&', 'gt', ';', '.', '&', 'amp', ';', 'my', 'mobile', 'have', 'problem', '.', 'you', 'can', \"n't\", 'get', 'my', 'voice', '.', 'so', 'call', 'you', 'asa', 'i', \"'ll\", 'free']\n",
      "AFter tokenizer:  ['cool', ',', 'text', 'me', 'when', 'you', 'head', 'out']\n",
      "AFter tokenizer:  ['you', 'are', 'being', 'contacted', 'by', 'our', 'dating', 'service', 'by', 'someone', 'you', 'know', '!', 'to', 'find', 'out', 'who', 'it', 'is', ',', 'call', 'from', 'a', 'land', 'line', '09050000878.', 'pobox45w2tg150p']\n",
      "AFter tokenizer:  ['wan2', 'win', 'a', 'meet+greet', 'with', 'westlife', '4', 'u', 'or', 'a', 'm8', '?', 'they', 'are', 'currently', 'on', 'what', 'tour', '?', '1', ')', 'unbreakable', ',', '2', ')', 'untamed', ',', '3', ')', 'unkempt', '.', 'text', '1,2', 'or', '3', 'to', '83049.', 'cost', '50p', '+std', 'text']\n",
      "AFter tokenizer:  ['happy', 'birthday', '...', 'may', 'u', 'find', 'ur', 'prince', 'charming', 'soon', 'n', 'dun', 'work', 'too', 'hard', '...']\n",
      "AFter tokenizer:  ['oh', ',', 'the', 'grand', 'is', 'having', 'a', 'bit', 'of', 'a', 'party', 'but', 'it', 'does', \"n't\", 'mention', 'any', 'cover', 'charge', 'so', 'it', \"'s\", 'probably', 'first', 'come', 'first', 'served']\n",
      "AFter tokenizer:  ['you', 'said', 'to', 'me', 'before', 'i', 'went', 'back', 'to', 'bed', 'that', 'you', 'ca', \"n't\", 'sleep', 'for', 'anything', '.']\n",
      "AFter tokenizer:  ['i', 'hope', 'you', 'arnt', 'pissed', 'off', 'but', 'id', 'would', 'really', 'like', 'to', 'see', 'you', 'tomorrow', '.', 'love', 'me', 'xxxxxxxxxxxxxx']\n",
      "AFter tokenizer:  ['dorothy', '@', 'kiefer.com', '(', 'bank', 'of', 'granite', 'issues', 'strong-buy', ')', 'explosive', 'pick', 'for', 'our', 'members', '*', '*', '*', '*', '*', 'up', 'over', '300', '%', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', 'nasdaq', 'symbol', 'cdgt', 'that', 'is', 'a', '$', '5.00', 'per', '..']\n",
      "AFter tokenizer:  ['says', 'the', '&', 'lt', ';', '#', '&', 'gt', ';', 'year', 'old', 'with', 'a', 'man', 'and', 'money', '.', 'i', \"'m\", 'down', 'to', 'my', 'last', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'still', 'waiting', 'for', 'that', 'check', '.']\n",
      "AFter tokenizer:  ['i', 'will', 'come', 'to', 'ur', 'home', 'now']\n",
      "AFter tokenizer:  ['free', 'any', 'day', 'but', 'i', 'finish', 'at', '6', 'on', 'mon', 'n', 'thurs', '...']\n",
      "AFter tokenizer:  ['will', 'you', 'be', 'here', 'for', 'food']\n",
      "AFter tokenizer:  ['life', 'alle', 'mone', ',', 'eppolum', 'oru', 'pole', 'allalo']\n",
      "AFter tokenizer:  ['nite', '...']\n",
      "AFter tokenizer:  ['two', 'fundamentals', 'of', 'cool', 'life', ':', '``', 'walk', ',', 'like', 'you', 'are', 'the', 'king', \"''\", '...', '!', 'or', '``', 'walk', 'like', 'you', 'dont', 'care', ',', 'whoever', 'is', 'the', 'king', \"''\", '!', '...', 'gud', 'nyt']\n",
      "AFter tokenizer:  ['camera', 'quite', 'good', ',', '10.1mega', 'pixels', ',', '3optical', 'and', '5digital', 'dooms', '.', 'have', 'a', 'lovely', 'holiday', ',', 'be', 'safe', 'and', 'i', 'hope', 'you', 'hav', 'a', 'good', 'journey', '!', 'happy', 'new', 'year', 'to', 'you', 'both', '!', 'see', 'you', 'in', 'a', 'couple', 'of', 'weeks', '!']\n",
      "AFter tokenizer:  ['hi', 'petey', '!', 'noi\\x92m', 'ok', 'just', 'wanted', '2', 'chat', 'coz', 'avent', 'spoken', '2', 'u', '4', 'a', 'long', 'time-hope', 'ur', 'doin', 'alrite.have', 'good', 'nit', 'at', 'js', 'love', 'ya', 'am.x']\n",
      "AFter tokenizer:  ['i', 'just', 'saw', 'ron', 'burgundy', 'captaining', 'a', 'party', 'boat', 'so', 'yeah']\n",
      "AFter tokenizer:  ['i', \"'m\", 'serious', '.', 'you', 'are', 'in', 'the', 'money', 'base']\n",
      "AFter tokenizer:  ['already', 'one', 'guy', 'loving', 'you', ':', '-', '.']\n",
      "AFter tokenizer:  ['staff', 'of', 'placement', 'training', 'in', 'amrita', 'college', '.']\n",
      "AFter tokenizer:  ['i', 'always', 'chat', 'with', 'you', '.', 'in', 'fact', 'i', 'need', 'money', 'can', 'you', 'raise', 'me', '?']\n",
      "AFter tokenizer:  ['i', \"'m\", 'job', 'profile', 'seems', 'like', 'bpo', '..']\n",
      "AFter tokenizer:  ['well', ',', 'i', 'was', 'about', 'to', 'give', 'up', 'cos', 'they', 'all', 'said', 'no', 'they', 'didn', '‘', 't', 'do', 'one', 'nighters', '.', 'i', 'persevered', 'and', 'found', 'one', 'but', 'it', 'is', 'very', 'cheap', 'so', 'i', 'apologise', 'in', 'advance', '.', 'it', 'is', 'just', 'somewhere', 'to', 'sleep', 'isnt', 'it', '?']\n",
      "AFter tokenizer:  ['so', 'you', 'think', 'i', 'should', 'actually', 'talk', 'to', 'him', '?', 'not', 'call', 'his', 'boss', 'in', 'the', 'morning', '?', 'i', 'went', 'to', 'this', 'place', 'last', 'year', 'and', 'he', 'told', 'me', 'where', 'i', 'could', 'go', 'and', 'get', 'my', 'car', 'fixed', 'cheaper', '.', 'he', 'kept', 'telling', 'me', 'today', 'how', 'much', 'he', 'hoped', 'i', 'would', 'come', 'back', 'in', ',', 'how', 'he', 'always', 'regretted', 'not', 'getting', 'my', 'number', ',', 'etc', '.']\n",
      "AFter tokenizer:  ['are', 'you', 'willing', 'to', 'go', 'for', 'apps', 'class', '.']\n",
      "AFter tokenizer:  ['hanging', 'out', 'with', 'my', 'brother', 'and', 'his', 'family']\n",
      "AFter tokenizer:  ['no', 'it', 'will', 'reach', 'by', '9', 'only', '.', 'she', 'telling', 'she', 'will', 'be', 'there', '.', 'i', 'dont', 'know']\n",
      "AFter tokenizer:  ['hey', '...', 'are', 'you', 'going', 'to', 'quit', 'soon', '?', 'xuhui', 'and', 'i', 'working', 'till', 'end', 'of', 'the', 'month']\n",
      "AFter tokenizer:  ['im', 'sorry', 'bout', 'last', 'nite', 'it', 'wasn\\x92t', 'ur', 'fault', 'it', 'was', 'me', ',', 'spouse', 'it', 'was', 'pmt', 'or', 'sumthin', '!', 'u', '4give', 'me', '?', 'i', 'think', 'u', 'shldxxxx']\n",
      "AFter tokenizer:  ['try', 'neva', 'mate', '!', '!']\n",
      "AFter tokenizer:  ['yeah', 'that', \"'d\", 'pretty', 'much', 'be', 'the', 'best', 'case', 'scenario']\n",
      "AFter tokenizer:  ['i', 'not', 'free', 'today', 'i', 'haf', '2', 'pick', 'my', 'parents', 'up', 'tonite', '...']\n",
      "AFter tokenizer:  ['hey', 'babe', '!', 'far', '2', 'spun-out', '2', 'spk', 'at', 'da', 'mo', '...', 'dead', '2', 'da', 'wrld', '.', 'been', 'sleeping', 'on', 'da', 'sofa', 'all', 'day', ',', 'had', 'a', 'cool', 'nytho', ',', 'tx', '4', 'fonin', 'hon', ',', 'call', '2mwen', 'im', 'bk', 'frmcloud', '9', '!', 'j', 'x']\n",
      "AFter tokenizer:  ['should', 'i', 'send', 'you', 'naughty', 'pix', '?', ':', ')']\n",
      "AFter tokenizer:  ['you', 'are', 'a', '£1000', 'winner', 'or', 'guaranteed', 'caller', 'prize', ',', 'this', 'is', 'our', 'final', 'attempt', 'to', 'contact', 'you', '!', 'to', 'claim', 'call', '09071517866', 'now', '!', '150ppmpobox10183bhamb64xe']\n",
      "AFter tokenizer:  ['xmas', '&', 'new', 'years', 'eve', 'tickets', 'are', 'now', 'on', 'sale', 'from', 'the', 'club', ',', 'during', 'the', 'day', 'from', '10am', 'till', '8pm', ',', 'and', 'on', 'thurs', ',', 'fri', '&', 'sat', 'night', 'this', 'week', '.', 'they', \"'re\", 'selling', 'fast', '!']\n",
      "AFter tokenizer:  ['tyler', '(', 'getting', 'an', '8th', ')', 'has', 'to', 'leave', 'not', 'long', 'after', '9', ',', 'can', 'you', 'get', 'here', 'in', 'like', 'an', 'hour', '?']\n",
      "AFter tokenizer:  ['prepare', 'to', 'be', 'pounded', 'every', 'night', '...']\n",
      "AFter tokenizer:  ['actually', ',', 'my', 'mobile', 'is', 'full', 'of', 'msg', '.', 'and', 'i', 'm', 'doing', 'a', 'work', 'online', ',', 'where', 'i', 'need', 'to', 'send', 'them', '&', 'lt', ';', '#', '&', 'gt', ';', 'sent', 'msg', 'i', 'wil', 'explain', 'u', 'later', '.']\n",
      "AFter tokenizer:  ['good', 'evening', '!', 'how', 'are', 'you', '?']\n",
      "AFter tokenizer:  ['i', \"'m\", 'at', 'home', '.', 'please', 'call']\n",
      "AFter tokenizer:  ['oic', 'cos', 'me', 'n', 'my', 'sis', 'got', 'no', 'lunch', 'today', 'my', 'dad', 'went', 'out', '...', 'so', 'dunno', 'whether', '2', 'eat', 'in', 'sch', 'or', 'wat', '...']\n",
      "AFter tokenizer:  ['mmmmm', '...', 'it', 'was', 'sooooo', 'good', 'to', 'wake', 'to', 'your', 'words', 'this', 'morning', ',', 'my', 'love', '!', '!', 'mmmm', 'fuck', '...', 'i', 'love', 'you', 'too', ',', 'my', 'lion', '...', '*', 'devouring', 'kiss', 'from', 'across', 'the', 'sea', '*']\n",
      "AFter tokenizer:  ['we', 'are', 'pleased', 'to', 'inform', 'that', 'your', 'application', 'for', 'airtel', 'broadband', 'is', 'processed', 'successfully', '.', 'your', 'installation', 'will', 'happen', 'within', '3', 'days', '.']\n",
      "AFter tokenizer:  ['what', 'happen', 'dear', '.', 'why', 'you', 'silent', '.', 'i', 'am', 'tensed']\n",
      "AFter tokenizer:  ['i', \"'ll\", 'get', 'there', 'at', '3', ',', 'unless', 'you', 'guys', 'want', 'me', 'to', 'come', 'some', 'time', 'sooner']\n",
      "AFter tokenizer:  ['if', 'you', 'are', 'not', 'coughing', 'then', 'its', 'nothing']\n",
      "AFter tokenizer:  ['ü', 'come', 'lt', '25', 'n', 'pass', 'to', 'me', 'lar']\n",
      "AFter tokenizer:  ['i', \"'m\", 'e', 'person', 'who', \"'s\", 'doing', 'e', 'sms', 'survey', '...']\n",
      "AFter tokenizer:  ['lol', 'ok', 'ill', 'try', 'to', 'send', '.', 'be', 'warned', 'sprint', 'is', 'dead', 'slow', '.', 'you', \"'ll\", 'prolly', 'get', 'it', 'tomorrow']\n",
      "AFter tokenizer:  ['thank', 'you', 'meet', 'you', 'monday']\n",
      "AFter tokenizer:  ['so', 'is', 'th', 'gower', 'mate', 'which', 'is', 'where', 'i', 'am', '!', '?', '!', 'how', 'r', 'u', 'man', '?', 'all', 'is', 'good', 'in', 'wales', 'ill', 'b', 'back', '\\x91morrow', '.', 'c', 'u', 'this', 'wk', '?', 'who', 'was', 'the', 'msg', '4', '?', '\\x96', 'random', '!']\n",
      "AFter tokenizer:  ['rock', 'yr', 'chik', '.', 'get', '100', \"'s\", 'of', 'filthy', 'films', '&', 'xxx', 'pics', 'on', 'yr', 'phone', 'now', '.', 'rply', 'filth', 'to', '69669.', 'saristar', 'ltd', ',', 'e14', '9yt', '08701752560', '.', '450p', 'per', '5', 'days', '.', 'stop2', 'cancel']\n",
      "AFter tokenizer:  ['i', 'got', 'like', '$', '&', 'lt', ';', '#', '&', 'gt', ';', ',', 'i', 'can', 'get', 'some', 'more', 'later', 'though', '.', 'get', 'whatever', 'you', 'feel', 'like']\n",
      "AFter tokenizer:  ['dad', 'wanted', 'to', 'talk', 'about', 'the', 'apartment', 'so', 'i', 'got', 'a', 'late', 'start', ',', 'omw', 'now']\n",
      "AFter tokenizer:  ['i', 'love', 'you', 'both', 'too', ':', '-', ')']\n",
      "AFter tokenizer:  ['lol', 'u', 'still', 'feeling', 'sick', '?']\n",
      "AFter tokenizer:  ['din', 'i', 'tell', 'u', 'jus', 'now', '420']\n",
      "AFter tokenizer:  ['am', 'up', 'to', 'my', 'eyes', 'in', 'philosophy']\n",
      "AFter tokenizer:  ['from', 'next', 'month', 'get', 'upto', '50', '%', 'more', 'calls', '4', 'ur', 'standard', 'network', 'charge', '2', 'activate', 'call', '9061100010', 'c', 'wire3.net', '1st4terms', 'pobox84', 'm26', '3uz', 'cost', '£1.50', 'min', 'mobcudb', 'more']\n",
      "AFter tokenizer:  ['ok', 'lor', '.', 'i', \"'m\", 'in', 'town', 'now', 'lei', '.']\n",
      "AFter tokenizer:  ['i', 'had', 'it', 'already', '..', 'sabarish', 'asked', 'me', 'to', 'go', '..']\n",
      "AFter tokenizer:  ['no', 'da', '.', '.', 'vijay', 'going', 'to', 'talk', 'in', 'jaya', 'tv']\n",
      "AFter tokenizer:  ['urgent', '!', 'we', 'are', 'trying', 'to', 'contact', 'u', 'todays', 'draw', 'shows', 'that', 'you', 'have', 'won', 'a', '£800', 'prize', 'guaranteed', '.', 'call', '09050000460', 'from', 'land', 'line', '.', 'claim', 'j89', '.', 'po', 'box245c2150pm']\n",
      "AFter tokenizer:  ['lol', 'i', 'know', '!', 'hey', 'someone', 'did', 'a', 'great', 'inpersonation', 'of', 'flea', 'on', 'the', 'forums', '.', 'i', 'love', 'it', '!']\n",
      "AFter tokenizer:  ['text', 'banneduk', 'to', '89555', 'to', 'see', '!', 'cost', '150p', 'textoperator', 'g696ga', '18+', 'xxx']\n",
      "AFter tokenizer:  ['still', 'chance', 'there', '.', 'if', 'you', 'search', 'hard', 'you', 'will', 'get', 'it', '..', 'let', 'have', 'a', 'try', ':', ')']\n",
      "AFter tokenizer:  ['auction', 'round', '4.', 'the', 'highest', 'bid', 'is', 'now', '£54', '.', 'next', 'maximum', 'bid', 'is', '£71', '.', 'to', 'bid', ',', 'send', 'bids', 'e.', 'g.', '10', '(', 'to', 'bid', '£10', ')', 'to', '83383.', 'good', 'luck', '.']\n",
      "AFter tokenizer:  ['do', 'you', 'always', 'celebrate', 'ny', \"'s\", 'with', 'your', 'family', '?']\n",
      "AFter tokenizer:  ['we', 'know', 'taj', 'mahal', 'as', 'symbol', 'of', 'love', '.', 'but', 'the', 'other', 'lesser', 'known', 'facts', '1.', 'mumtaz', 'was', 'shahjahan', \"'s\", '4th', 'wife', ',', 'out', 'of', 'his', '7', 'wifes', '.', '2.', 'shahjahan', 'killed', 'mumtaz', \"'s\", 'husband', 'to', 'marry', 'her', '.', '3.', 'mumtaz', 'died', 'in', 'her', '&', 'lt', ';', '#', '&', 'gt', ';', 'th', 'delivery', '.', '4.', 'he', 'then', 'married', 'mumtaz', \"'s\", 'sister', '.', 'question', 'arises', 'where', 'the', 'hell', 'is', 'the', 'love', '?', ':', '-|', '-the', 'great', 'hari-']\n",
      "AFter tokenizer:  ['its', 'ok', '..', 'come', 'to', 'my', 'home', 'it', 'vl', 'nice', 'to', 'meet', 'and', 'v', 'can', 'chat', '..']\n",
      "AFter tokenizer:  ['collect', 'your', 'valentine', \"'s\", 'weekend', 'to', 'paris', 'inc', 'flight', '&', 'hotel', '+', '£200', 'prize', 'guaranteed', '!', 'text', ':', 'paris', 'to', 'no', ':', '69101.', 'www.rtf.sphosting.com']\n",
      "AFter tokenizer:  ['sent', 'me', 'de', 'webadres', 'for', 'geting', 'salary', 'slip']\n",
      "AFter tokenizer:  ['she', \"'s\", 'fine', '.', 'sends', 'her', 'greetings']\n",
      "AFter tokenizer:  ['customer', 'loyalty', 'offer', ':', 'the', 'new', 'nokia6650', 'mobile', 'from', 'only', '£10', 'at', 'txtauction', '!', 'txt', 'word', ':', 'start', 'to', 'no', ':', '81151', '&', 'get', 'yours', 'now', '!', '4t', '&', 'ctxt', 'tc', '150p/mtmsg']\n",
      "AFter tokenizer:  ['but', 'you', 'dint', 'in', 'touch', 'with', 'me', '.']\n",
      "AFter tokenizer:  ['yup', ',', 'leaving', 'right', 'now', ',', 'be', 'back', 'soon']\n",
      "AFter tokenizer:  ['you', 'wo', \"n't\", 'believe', 'it', 'but', 'it', \"'s\", 'true', '.', 'it', \"'s\", 'incredible', 'txts', '!', 'reply', 'g', 'now', 'to', 'learn', 'truly', 'amazing', 'things', 'that', 'will', 'blow', 'your', 'mind', '.', 'from', 'o2fwd', 'only', '18p/txt']\n",
      "AFter tokenizer:  ['yeah', 'sure', 'i', \"'ll\", 'leave', 'in', 'a', 'min']\n",
      "AFter tokenizer:  ['and', 'do', 'you', 'have', 'any', 'one', 'that', 'can', 'teach', 'me', 'how', 'to', 'ship', 'cars', '.']\n",
      "AFter tokenizer:  ['the', 'sign', 'of', 'maturity', 'is', 'not', 'when', 'we', 'start', 'saying', 'big', 'things', '..', 'but', 'actually', 'it', 'is', ',', 'when', 'we', 'start', 'understanding', 'small', 'things', '...', '*', 'have', 'a', 'nice', 'evening', '*', 'bslvyl']\n",
      "AFter tokenizer:  ['yeah', 'confirmed', 'for', 'you', 'staying', 'at', 'that', 'weekend']\n",
      "AFter tokenizer:  ['they', 'said', 'ü', 'dun', 'haf', 'passport', 'or', 'smth', 'like', 'dat', '..', 'or', 'ü', 'juz', 'send', 'to', 'my', 'email', 'account', '..']\n",
      "AFter tokenizer:  ['multiply', 'the', 'numbers', 'independently', 'and', 'count', 'decimal', 'points', 'then', ',', 'for', 'the', 'division', ',', 'push', 'the', 'decimal', 'places', 'like', 'i', 'showed', 'you', '.']\n",
      "AFter tokenizer:  ['have', 'a', 'lovely', 'night', 'and', 'when', 'you', 'wake', 'up', 'to', 'see', 'this', 'message', ',', 'i', 'hope', 'you', 'smile', 'knowing', 'all', 'is', 'as', 'should', 'be', '.', 'have', 'a', 'great', 'morning']\n",
      "AFter tokenizer:  ['ard', '4', 'lor', '...']\n",
      "AFter tokenizer:  ['you', 'are', 'right', '.', 'meanwhile', 'how', \"'s\", 'project', 'twins', 'comin', 'up']\n",
      "AFter tokenizer:  ['i', 'sent', 'your', 'maga', 'that', 'money', 'yesterday', 'oh', '.']\n",
      "AFter tokenizer:  ['i', 'am', 'hot', 'n', 'horny', 'and', 'willing', 'i', 'live', 'local', 'to', 'you', '-', 'text', 'a', 'reply', 'to', 'hear', 'strt', 'back', 'from', 'me', '150p', 'per', 'msg', 'netcollex', 'ltdhelpdesk', ':', '02085076972', 'reply', 'stop', 'to', 'end']\n",
      "AFter tokenizer:  ['our', 'ride', 'equally', 'uneventful', '-', 'not', 'too', 'many', 'of', 'those', 'pesky', 'cyclists', 'around', 'at', 'that', 'time', 'of', 'night', ';', ')', '.']\n",
      "AFter tokenizer:  ['if', 'you', 'were/are', 'free', 'i', 'can', 'give', '.', 'otherwise', 'nalla', 'adi', 'entey', 'nattil', 'kittum']\n",
      "AFter tokenizer:  ['i', \"'ve\", 'sent', 'my', 'wife', 'your', 'text', '.', 'after', 'we', 'buy', 'them', 'she', \"'ll\", 'tell', 'you', 'what', 'to', 'do', '.', 'so', 'just', 'relax', '.', 'we', 'should', 'go', 'get', 'them', 'this', 'wkend', '.']\n",
      "AFter tokenizer:  ['i', 'am', 'in', 'escape', 'theatre', 'now', '.', '.', 'going', 'to', 'watch', 'kavalan', 'in', 'a', 'few', 'minutes']\n",
      "AFter tokenizer:  ['how', 'much', 'would', 'it', 'cost', 'to', 'hire', 'a', 'hitman']\n",
      "AFter tokenizer:  ['i', 'anything', 'lor', '...']\n",
      "AFter tokenizer:  ['do', 'you', 'want', 'a', 'new', 'nokia', '3510i', 'colour', 'phone', 'delivered', 'tomorrow', '?', 'with', '200', 'free', 'minutes', 'to', 'any', 'mobile', '+', '100', 'free', 'text', '+', 'free', 'camcorder', 'reply', 'or', 'call', '08000930705']\n",
      "AFter tokenizer:  ['huh', 'but', 'i', 'cant', 'go', '2', 'ur', 'house', 'empty', 'handed', 'right', '?']\n",
      "AFter tokenizer:  ['good', 'morning', 'princess', '!', 'happy', 'new', 'year', '!']\n",
      "AFter tokenizer:  ['congratulations', 'you', \"'ve\", 'won', '.', 'you', \"'re\", 'a', 'winner', 'in', 'our', 'august', '£1000', 'prize', 'draw', '.', 'call', '09066660100', 'now', '.', 'prize', 'code', '2309', '.']\n",
      "AFter tokenizer:  ['aight', ',', 'we', \"'ll\", 'head', 'out', 'in', 'a', 'few']\n",
      "AFter tokenizer:  ['then', 'wat', 'r', 'u', 'doing', 'now', '?', 'busy', 'wif', 'work', '?']\n",
      "AFter tokenizer:  ['i', 'know', 'you', 'mood', 'off', 'today']\n",
      "AFter tokenizer:  ['jay', 'told', 'me', 'already', ',', 'will', 'do']\n",
      "AFter tokenizer:  ['cps', 'is', 'causing', 'the', 'outages', 'to', 'conserve', 'energy', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'not', 'sure', ',', 'i', 'was', 'just', 'checking', 'out', 'what', 'was', 'happening', 'around', 'the', 'area']\n",
      "AFter tokenizer:  ['hey', 'morning', 'what', 'you', 'come', 'to', 'ask', ':', '-', ')', 'pa', '...']\n",
      "AFter tokenizer:  ['jordan', 'got', 'voted', 'out', 'last', 'nite', '!']\n",
      "AFter tokenizer:  ['that', 'means', 'you', 'got', 'an', 'a', 'in', 'epi', ',', 'she.s', 'fine', '.', 'she.s', 'here', 'now', '.']\n",
      "AFter tokenizer:  ['i', 'have', 'no', 'idea', 'where', 'you', 'are']\n",
      "AFter tokenizer:  ['pls', 'come', 'quick', 'cant', 'bare', 'this', '.']\n",
      "AFter tokenizer:  ['call', 'me', '.', 'i', 'm', 'unable', 'to', 'cal', '.', 'lets', 'meet', 'bhaskar', ',', 'and', 'deep']\n",
      "AFter tokenizer:  ['no', '.', 'i.ll', 'meet', 'you', 'in', 'the', 'library']\n",
      "AFter tokenizer:  ['k', ',', 'my', 'roommate', 'also', 'wants', 'a', 'dubsack', 'and', 'another', 'friend', 'may', 'also', 'want', 'some', 'so', 'plan', 'on', 'bringing', 'extra', ',', 'i', \"'ll\", 'tell', 'you', 'when', 'they', 'know', 'for', 'sure']\n",
      "AFter tokenizer:  ['depends', 'on', 'individual', 'lor', 'e', 'hair', 'dresser', 'say', 'pretty', 'but', 'my', 'parents', 'say', 'look', 'gong', '.', 'u', 'kaypoh', '..', 'i', 'also', 'dunno', 'wat', 'she', 'collecting', '.']\n",
      "AFter tokenizer:  ['ok', 'c', 'ü', 'then', '.']\n",
      "AFter tokenizer:  ['i', 'enjoy', 'watching', 'and', 'playing', 'football', 'and', 'basketball', '.', 'anything', 'outdoors', '.', 'and', 'you', '?']\n",
      "AFter tokenizer:  ['can', 'you', 'please', 'ask', 'macho', 'what', 'his', 'price', 'range', 'is', ',', 'does', 'he', 'want', 'something', 'new', 'or', 'used', 'plus', 'it', 'he', 'only', 'interfued', 'in', 'the', 'blackberry', 'bold', '&', 'lt', ';', '#', '&', 'gt', ';', 'or', 'any', 'bb']\n",
      "AFter tokenizer:  ['sorry', 'sent', 'blank', 'msg', 'again', '.', 'yup', 'but', 'trying', '2', 'do', 'some', 'serious', 'studying', 'now', '.']\n",
      "AFter tokenizer:  ['hey', 'check', 'it', 'da', '.', 'i', 'have', 'listed', 'da', '.']\n",
      "AFter tokenizer:  ['8007', '25p', '4', 'alfie', 'moon', \"'s\", 'children', 'in', 'need', 'song', 'on', 'ur', 'mob', '.', 'tell', 'ur', 'm8s', '.', 'txt', 'tone', 'charity', 'to', '8007', 'for', 'nokias', 'or', 'poly', 'charity', 'for', 'polys', ':', 'zed', '08701417012', 'profit', '2', 'charity']\n",
      "AFter tokenizer:  ['i', 'meant', 'as', 'an', 'apology', 'from', 'me', 'for', 'texting', 'you', 'to', 'get', 'me', 'drugs', 'at', '&', 'lt', ';', '#', '&', 'gt', ';', 'at', 'night']\n",
      "AFter tokenizer:  ['that', 'means', 'from', 'february', 'to', 'april', 'i', \"'ll\", 'be', 'getting', 'a', 'place', 'to', 'stay', 'down', 'there', 'so', 'i', 'do', \"n't\", 'have', 'to', 'hustle', 'back', 'and', 'forth', 'during', 'audition', 'season', 'as', 'i', 'have', 'since', 'my', 'sister', 'moved', 'away', 'from', 'harlem', '.']\n",
      "AFter tokenizer:  ['goin', 'to', 'workout', 'lor', '...', 'muz', 'lose', 'e', 'fats', '...']\n",
      "AFter tokenizer:  ['damn', ',', 'poor', 'zac', 'does', \"n't\", 'stand', 'a', 'chance']\n",
      "AFter tokenizer:  ['i', 'want', 'to', 'tel', 'u', 'one', 'thing', 'u', 'should', 'not', 'mistake', 'me', 'k', 'this', 'is', 'the', 'message', 'that', 'you', 'sent', ':', ')']\n",
      "AFter tokenizer:  ['yeah', 'right', '!', 'i', \"'ll\", 'bring', 'my', 'tape', 'measure', 'fri', '!']\n",
      "AFter tokenizer:  ['should', 'i', 'head', 'straight', 'there', 'or', 'what']\n",
      "AFter tokenizer:  ['get', 'the', 'official', 'england', 'poly', 'ringtone', 'or', 'colour', 'flag', 'on', 'yer', 'mobile', 'for', 'tonights', 'game', '!', 'text', 'tone', 'or', 'flag', 'to', '84199.', 'optout', 'txt', 'eng', 'stop', 'box39822', 'w111wx', '£1.50']\n",
      "AFter tokenizer:  ['thank', 'you', 'princess', '!', 'you', 'are', 'so', 'sexy', '...']\n",
      "AFter tokenizer:  ['oooh', 'i', 'got', 'plenty', 'of', 'those', '!']\n",
      "AFter tokenizer:  ['hui', 'xin', 'is', 'in', 'da', 'lib', '.']\n",
      "AFter tokenizer:  ['its', 'a', 'big', 'difference', '.', '&', 'lt', ';', '#', '&', 'gt', ';', 'versus', '&', 'lt', ';', '#', '&', 'gt', ';', 'every', '&', 'lt', ';', '#', '&', 'gt', ';', 'hrs']\n",
      "AFter tokenizer:  ['it', \"'s\", 'not', 'that', 'you', 'make', 'me', 'cry', '.', 'it', \"'s\", 'just', 'that', 'when', 'all', 'our', 'stuff', 'happens', 'on', 'top', 'of', 'everything', 'else', ',', 'it', 'pushes', 'me', 'over', 'the', 'edge', '.', 'you', 'do', \"n't\", 'underdtand', 'how', 'often', 'i', 'cry', 'over', 'my', 'sorry', ',', 'sorry', 'life', '.']\n",
      "AFter tokenizer:  ['me', '2', 'babe', 'i', 'feel', 'the', 'same', 'lets', 'just', '4get', 'about', 'it+both', 'try', '+cheer', 'up+not', 'fit', 'soo', 'muchxxlove', 'u', 'locaxx']\n",
      "AFter tokenizer:  ['you', 'know', 'what', 'hook', 'up', 'means', 'right', '?']\n",
      "AFter tokenizer:  ['customer', 'service', 'announcement', '.', 'we', 'recently', 'tried', 'to', 'make', 'a', 'delivery', 'to', 'you', 'but', 'were', 'unable', 'to', 'do', 'so', ',', 'please', 'call', '07090298926', 'to', 're-schedule', '.', 'ref:9307622']\n",
      "AFter tokenizer:  ['wat', \"'s\", 'da', 'model', 'num', 'of', 'ur', 'phone', '?']\n",
      "AFter tokenizer:  ['he', \"'s\", 'really', 'into', 'skateboarding', 'now', 'despite', 'the', 'fact', 'that', 'he', 'gets', 'thrown', 'off', 'of', 'it', 'and', 'winds', 'up', 'with', 'bandages', 'and', 'shit', 'all', 'over', 'his', 'arms', 'every', 'five', 'minutes']\n",
      "AFter tokenizer:  ['you', 'can', 'stop', 'further', 'club', 'tones', 'by', 'replying', '``', 'stop', 'mix', \"''\", 'see', 'my-tone.com/enjoy', '.', 'html', 'for', 'terms', '.', 'club', 'tones', 'cost', 'gbp4.50/week', '.', 'mfl', ',', 'po', 'box', '1146', 'mk45', '2wt', '(', '2/3', ')']\n",
      "AFter tokenizer:  ['my', 'house', 'here', 'e', 'sky', 'quite', 'dark', 'liao', '...', 'if', 'raining', 'then', 'got', 'excuse', 'not', '2', 'run', 'already', 'rite', '...', 'hee', '...']\n",
      "AFter tokenizer:  ['sorry', ',', 'left', 'phone', 'upstairs', '.', 'ok', ',', 'might', 'be', 'hectic', 'but', 'would', 'be', 'all', 'my', 'birds', 'with', 'one', 'fell', 'swoop', '.', 'it', \"'s\", 'a', 'date', '.']\n",
      "AFter tokenizer:  ['*', 'thought', 'i', 'did', \"n't\", 'see', 'you', '.']\n",
      "AFter tokenizer:  ['wamma', 'get', 'laid', '?', 'want', 'real', 'doggin', 'locations', 'sent', 'direct', 'to', 'your', 'mobile', '?', 'join', 'the', 'uks', 'largest', 'dogging', 'network', '.', 'txt', 'dogs', 'to', '69696', 'now', '!', 'nyt', '.', 'ec2a', '.', '3lp', '£1.50/msg', '.']\n",
      "AFter tokenizer:  ['carlos', 'says', 'we', 'can', 'pick', 'up', 'from', 'him', 'later', 'so', 'yeah', 'we', \"'re\", 'set']\n",
      "AFter tokenizer:  ['hey', 'babe', ',', 'my', 'friend', 'had', 'to', 'cancel', ',', 'still', 'up', 'for', 'a', 'visit', '?']\n",
      "AFter tokenizer:  ['hmm', 'ill', 'have', 'to', 'think', 'about', 'it', '...', 'ok', 'you', \"'re\", 'forgiven', '!', '=d']\n",
      "AFter tokenizer:  ['we', 'are', 'hoping', 'to', 'get', 'away', 'by', '7', ',', 'from', 'langport', '.', 'you', 'still', 'up', 'for', 'town', 'tonight', '?']\n",
      "AFter tokenizer:  ['want', 'to', 'send', 'me', 'a', 'virtual', 'hug', '?', '...', 'i', 'need', 'one']\n",
      "AFter tokenizer:  ['probably', 'not', ',', 'still', 'going', 'over', 'some', 'stuff', 'here']\n",
      "AFter tokenizer:  ['it', 'has', 'issues', 'right', 'now', '.', 'ill', 'fix', 'for', 'her', 'by', 'tomorrow', '.']\n",
      "AFter tokenizer:  ['why', 'i', 'come', 'in', 'between', 'you', 'people']\n",
      "AFter tokenizer:  ['senthil', 'group', 'company', 'apnt', '5pm', '.']\n",
      "AFter tokenizer:  ['oh', 'really', '?', '?', 'did', 'you', 'make', 'it', 'on', 'air', '?', 'what', \"'s\", 'your', 'talent', '?']\n",
      "AFter tokenizer:  ['studying', '.', 'but', 'i.ll', 'be', 'free', 'next', 'weekend', '.']\n",
      "AFter tokenizer:  ['r', 'u', 'here', 'yet', '?', 'i', \"'m\", 'wearing', 'blue', 'shirt', 'n', 'black', 'pants', '.']\n",
      "AFter tokenizer:  ['wait.i', 'will', 'come', 'out', '..', '&', 'lt', ';', '#', '&', 'gt', ';', 'min', ':', ')']\n",
      "AFter tokenizer:  ['i', 'will', 'reach', 'ur', 'home', 'in', '&', 'lt', ';', '#', '&', 'gt', ';', 'minutes']\n",
      "AFter tokenizer:  ['well', 'then', 'you', 'have', 'a', 'great', 'weekend', '!']\n",
      "AFter tokenizer:  ['what', 'are', 'you', 'doing', 'in', 'langport', '?', 'sorry', ',', 'but', 'i', \"'ll\", 'probably', 'be', 'in', 'bed', 'by', '9pm', '.', 'it', 'sucks', 'being', 'ill', 'at', 'xmas', '!', 'when', 'do', 'you', 'and', 'go2sri', 'lanka', '?']\n",
      "AFter tokenizer:  ['frnd', 's', 'not', 'juz', 'a', 'word', '.....', 'not', 'merely', 'a', 'relationship', '.....', 'its', 'a', 'silent', 'promise', 'which', 'says', '...', '``', 'i', 'will', 'be', 'with', 'you', '``', 'wherevr', '..', 'whenevr', '..', 'forevr', '...', 'gudnyt', 'dear', '..']\n",
      "AFter tokenizer:  ['huh', '?', '6', 'also', 'can', 'not', '?', 'then', 'only', 'how', 'many', 'mistakes', '?']\n",
      "AFter tokenizer:  ['ha', '...', 'u', 'jus', 'ate', 'honey', 'ar', '?', 'so', 'sweet', '...']\n",
      "AFter tokenizer:  ['i', \"'m\", 'turning', 'off', 'my', 'phone', '.', 'my', 'moms', 'telling', 'everyone', 'i', 'have', 'cancer', '.', 'and', 'my', 'sister', 'wo', \"n't\", 'stop', 'calling', '.', 'it', 'hurts', 'to', 'talk', '.', 'ca', \"n't\", 'put', 'up', 'with', 'it', '.', 'see', 'u', 'when', 'u', 'get', 'home', '.', 'love', 'u']\n",
      "AFter tokenizer:  ['honey', '?', 'sweetheart', '?', 'darling', '?', 'sexy', 'buns', '?', 'sugar', 'plum', '?', 'loverboy', '?', 'i', 'miss', 'you', ',', 'boytoy', '...', '*', 'smacks', 'your', 'ass', '*', 'did', 'you', 'go', 'to', 'the', 'gym', 'too', '?']\n",
      "AFter tokenizer:  ['thanks', 'for', 'loving', 'me', 'so', '.', 'you', 'rock']\n",
      "AFter tokenizer:  ['yeah', 'imma', 'come', 'over', 'cause', 'jay', 'wants', 'to', 'do', 'some', 'drugs']\n",
      "AFter tokenizer:  ['ok', 'thanx', '...', 'take', 'care', 'then', '...']\n",
      "AFter tokenizer:  ['yup', '.', 'thk', 'of', 'u', 'oso', 'boring', 'wat', '.']\n",
      "AFter tokenizer:  ['came', 'to', 'look', 'at', 'the', 'flat', ',', 'seems', 'ok', ',', 'in', 'his', '50s', '?', '*', 'is', 'away', 'alot', 'wiv', 'work', '.', 'got', 'woman', 'coming', 'at', '6.30', 'too', '.']\n",
      "AFter tokenizer:  ['moji', 'just', 'informed', 'me', 'that', 'you', 'saved', 'our', 'lives', '.', 'thanks', '.']\n",
      "AFter tokenizer:  ['whos', 'this', 'am', 'in', 'class', ':', '-', ')']\n",
      "AFter tokenizer:  ['hey', 'r', 'ü', 'still', 'online', '?', 'i', \"'ve\", 'finished', 'the', 'formatting', '...']\n",
      "AFter tokenizer:  ['great', '!', 'so', 'what', 'attracts', 'you', 'to', 'the', 'brothas', '?']\n",
      "AFter tokenizer:  ['promotion', 'number', ':', '8714714', '-', 'ur', 'awarded', 'a', 'city', 'break', 'and', 'could', 'win', 'a', '£200', 'summer', 'shopping', 'spree', 'every', 'wk', '.', 'txt', 'store', 'to', '88039', '.', 'skilgme', '.', 'tscs087147403231winawk', '!', 'age16', '£1.50perwksub']\n",
      "AFter tokenizer:  ['lol', 'what', 'happens', 'in', 'vegas', 'stays', 'in', 'vegas']\n",
      "AFter tokenizer:  ['hello', ',', 'hello', ',', 'hi', 'lou', 'sorry', 'it', 'took', 'so', 'long', '2', 'reply-', 'i', 'left', 'mobile', 'at', 'friends', 'in', 'lancaster', ',', 'just', 'got', 'it', 'bak', 'neway', 'im', 'sorry', 'i', 'couldn\\x92t', 'make', 'ur', 'b\\x92day', '2', 'hun', '!']\n",
      "AFter tokenizer:  ['when', 'did', 'i', 'use', 'soc', '...', 'i', 'use', 'it', 'only', 'at', 'home', '...', 'ü', 'dunno', 'how', '2', 'type', 'it', 'in', 'word', 'ar', '...']\n",
      "AFter tokenizer:  ['dad', 'says', 'hurry', 'the', 'hell', 'up']\n",
      "AFter tokenizer:  ['wake', 'me', 'up', 'at', '&', 'lt', ';', '#', '&', 'gt', ';', 'am', 'morning', ':', ')']\n",
      "AFter tokenizer:  ['i', 'get', 'out', 'of', 'class', 'in', 'bsn', 'in', 'like', '&', 'lt', ';', '#', '&', 'gt', ';', 'minutes', ',', 'you', 'know', 'where', 'advising', 'is', '?']\n",
      "AFter tokenizer:  ['great', '!', 'i', 'shoot', 'big', 'loads', 'so', 'get', 'ready', '!']\n",
      "AFter tokenizer:  ['i', \"'ll\", 'meet', 'you', 'in', 'the', 'lobby']\n",
      "AFter tokenizer:  ['you', 'still', 'coming', 'tonight', '?']\n",
      "AFter tokenizer:  ['what', 'happen', 'dear', 'tell', 'me']\n",
      "AFter tokenizer:  ['sir', ',', 'i', 'am', 'waiting', 'for', 'your', 'call', ',', 'once', 'free', 'please', 'call', 'me', '.']\n",
      "AFter tokenizer:  ['i', 'was', 'about', 'to', 'do', 'it', 'when', 'i', 'texted', '.', 'i', 'finished', 'a', 'long', 'time', 'ago', 'and', 'showered', 'and', \"er'ything\", '!']\n",
      "AFter tokenizer:  ['ok', 'im', 'not', 'sure', 'what', 'time', 'i', 'finish', 'tomorrow', 'but', 'i', 'wan', 'na', 'spend', 'the', 'evening', 'with', 'you', 'cos', 'that', 'would', 'be', 'vewy', 'vewy', 'lubly', '!', 'love', 'me', 'xxx']\n",
      "AFter tokenizer:  ['hello', ',', 'as', 'per', 'request', 'from', '&', 'lt', ';', '#', '&', 'gt', ';', 'rs.5', 'has', 'been', 'transfered', 'to', 'you']\n",
      "AFter tokenizer:  ['i', 'am', 'in', 'tirupur', '.', 'call', 'you', 'da', '.']\n",
      "AFter tokenizer:  ['you', 'are', 'a', 'winner', 'you', 'have', 'been', 'specially', 'selected', 'to', 'receive', '£1000', 'cash', 'or', 'a', '£2000', 'award', '.', 'speak', 'to', 'a', 'live', 'operator', 'to', 'claim', 'call', '087147123779am-7pm', '.', 'cost', '10p']\n",
      "AFter tokenizer:  ['s', ':', ')', 'but', 'he', 'had', 'some', 'luck.2', 'catches', 'put', 'down', ':', ')']\n",
      "AFter tokenizer:  ['how', 'i', 'noe', '...', 'did', 'ü', 'specify', 'da', 'domain', 'as', 'nusstu', '...', 'ü', 'still', 'in', 'sch', '...']\n",
      "AFter tokenizer:  ['oh', '...', 'i', 'asked', 'for', 'fun', '.', 'haha', '...', 'take', 'care', '.', 'ü']\n",
      "AFter tokenizer:  ['shall', 'i', 'get', 'my', 'pouch', '?']\n",
      "AFter tokenizer:  ['hey', 'loverboy', '!', 'i', 'love', 'you', '!', '!', 'i', 'had', 'to', 'tell', '...', 'i', 'look', 'at', 'your', 'picture', 'and', 'ache', 'to', 'feel', 'you', 'between', 'my', 'legs', '...', 'fuck', 'i', 'want', 'you', '...', 'i', 'need', 'you', '...', 'i', 'crave', 'you', '.']\n",
      "AFter tokenizer:  ['how', 'is', 'my', 'boy', '?', 'no', 'sweet', 'words', 'left', 'for', 'me', 'this', 'morning', '...', '*', 'sighs', '*', '...', 'how', 'goes', 'you', 'day', ',', 'my', 'love', '?', 'did', 'you', 'start', 'your', 'studying', '?']\n",
      "AFter tokenizer:  ['kent', 'vale', 'lor', '...', 'ü', 'wait', '4', 'me', 'there', 'ar', '?']\n",
      "AFter tokenizer:  ['ok.', 'very', 'good', '.', 'its', 'all', 'about', 'making', 'that', 'money', '.']\n",
      "AFter tokenizer:  ['reading', 'gud', 'habit', '..', 'nan', 'bari', 'hudgi', 'yorge', 'pataistha', 'ertini', 'kano', ':', '-', ')']\n",
      "AFter tokenizer:  ['aight', 'do', 'you', 'still', 'want', 'to', 'get', 'money']\n",
      "AFter tokenizer:  ['are', 'you', 'in', 'town', '?', 'this', 'is', 'v.', 'important']\n",
      "AFter tokenizer:  ['sorry', 'pa', ',', 'i', 'dont', 'knw', 'who', 'ru', 'pa', '?']\n",
      "AFter tokenizer:  ['wat', 'u', 'doing', 'there', '?']\n",
      "AFter tokenizer:  ['if', 'i', 'not', 'meeting', 'ü', 'all', 'rite', 'then', 'i', \"'ll\", 'go', 'home', 'lor', '.', 'if', 'ü', 'dun', 'feel', 'like', 'comin', 'it', \"'s\", 'ok', '.']\n",
      "AFter tokenizer:  ['oh', ',', 'i', 'will', 'get', 'paid', '.', 'the', 'most', 'outstanding', 'one', 'is', 'for', 'a', 'commercial', 'i', 'did', 'for', 'hasbro', '...', 'in', 'august', '!', 'they', 'made', 'us', 'jump', 'through', 'so', 'many', 'hoops', 'to', 'get', 'paid', '.', 'still', 'not', '.']\n",
      "AFter tokenizer:  ['i', 'am', 'late', ',', 'so', 'call', 'you', 'tomorrow', 'morning.take', 'care', 'sweet', 'dreams', '....', 'u', 'and', 'me', '...', 'ummifying', '...', 'bye', '.']\n",
      "AFter tokenizer:  ['networking', 'technical', 'support', 'associate', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'gon', 'na', 'rip', 'out', 'my', 'uterus', '.']\n",
      "AFter tokenizer:  ['cool', '.', 'do', 'you', 'like', 'swimming', '?', 'i', 'have', 'a', 'pool', 'and', 'jacuzzi', 'at', 'my', 'house', '.']\n",
      "AFter tokenizer:  ['thanks', 'for', 'your', 'ringtone', 'order', ',', 'reference', 'number', 'x49', '.', 'your', 'mobile', 'will', 'be', 'charged', '4.50.', 'should', 'your', 'tone', 'not', 'arrive', 'please', 'call', 'customer', 'services', '09065989182.', 'from', ':', '[', 'colour=red', ']', 'text', '[', '/colour', ']', 'txtstar']\n",
      "AFter tokenizer:  ['yeah', 'why', 'not', ',', 'is', 'the', 'gang', 'all', 'ready']\n",
      "AFter tokenizer:  ['blank', 'is', 'blank', '.', 'but', 'wat', 'is', 'blank', '?', 'lol']\n",
      "AFter tokenizer:  ['i', \"'m\", 'in', 'a', 'movie', '...', 'collect', 'car', 'oredi', '...']\n",
      "AFter tokenizer:  ['we', 'left', 'already', 'we', 'at', 'orchard', 'now', '.']\n",
      "AFter tokenizer:  ['hi', 'there', ',', '2nights', 'ur', 'lucky', 'night', '!', 'uve', 'been', 'invited', '2', 'xchat', ',', 'the', 'uks', 'wildest', 'chat', '!', 'txt', 'chat', 'to', '86688', 'now', '!', '150p/msgrcvdhg/suite342/2lands/row/w1j6hl', 'ldn', '18yrs']\n",
      "AFter tokenizer:  ['nothing', 'spl', '..', 'wat', 'abt', 'u', 'and', 'whr', 'ru', '?']\n",
      "AFter tokenizer:  ['no', 'chikku', 'nt', 'yet', '..', 'ya', 'i', \"'m\", 'free']\n",
      "AFter tokenizer:  ['aldrine', ',', 'rakhesh', 'ex', 'rtm', 'here.pls', 'call.urgent', '.']\n",
      "AFter tokenizer:  ['the', 'search', '4', 'happiness', 'is', '1', 'of', 'd', 'main', 'sources', 'of', 'unhappiness', '!', 'accept', 'life', 'the', 'way', 'it', 'comes', '!', 'u', 'will', 'find', 'happiness', 'in', 'every', 'moment', 'u', 'live', '.']\n",
      "AFter tokenizer:  ['i', 'guess', 'you', 'could', 'be', 'as', 'good', 'an', 'excuse', 'as', 'any', ',', 'lol', '.']\n",
      "AFter tokenizer:  ['is', \"n't\", 'frnd', 'a', 'necesity', 'in', 'life', '?', 'imagine', 'urself', 'witout', 'a', 'frnd', '..', 'hw', \"'d\", 'u', 'feel', 'at', 'ur', 'colleg', '?', 'wat', \"'ll\", 'u', 'do', 'wth', 'ur', 'cell', '?', 'wat', 'abt', 'functions', '?', 'thnk', 'abt', 'events', 'espe', \"'ll\", 'cared', ',', 'missed', '&', 'amp', ';', 'irritated', 'u', '?', '4wrd', 'it', 'to', 'all', 'those', 'dear-loving', 'frnds', 'wthout', 'whom', 'u', 'cant', 'live', '..', 'i', 'jst', 'did', 'it', '..', 'takecare', '..', ':', ')', 'goodmorning']\n",
      "AFter tokenizer:  ['old', 'orchard', 'near', 'univ', '.', 'how', 'about', 'you', '?']\n",
      "AFter tokenizer:  ['4', 'tacos', '+', '1', 'rajas', 'burrito', ',', 'right', '?']\n",
      "AFter tokenizer:  ['it', '‘', 's', '£6', 'to', 'get', 'in', ',', 'is', 'that', 'ok', '?']\n",
      "AFter tokenizer:  ['hows', 'the', 'street', 'where', 'the', 'end', 'of', 'library', 'walk', 'is', '?']\n",
      "AFter tokenizer:  ['plz', 'note', ':', 'if', 'anyone', 'calling', 'from', 'a', 'mobile', 'co.', '&', 'amp', ';', 'asks', 'u', 'to', 'type', '#', '&', 'lt', ';', '#', '&', 'gt', ';', 'or', '#', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'do', 'not', 'do', 'so', '.', 'disconnect', 'the', 'call', ',', 'coz', 'it', 'iz', 'an', 'attempt', 'of', \"'terrorist\", \"'\", 'to', 'make', 'use', 'of', 'the', 'sim', 'card', 'no', '.', 'itz', 'confirmd', 'by', 'nokia', 'n', 'motorola', 'n', 'has', 'been', 'verified', 'by', 'cnn', 'ibn', '.']\n",
      "AFter tokenizer:  ['we', 'stopped', 'to', 'get', 'ice', 'cream', 'and', 'will', 'go', 'back', 'after']\n",
      "AFter tokenizer:  ['did', 'you', 'stitch', 'his', 'trouser']\n",
      "AFter tokenizer:  ['2/2', '146tf150p']\n",
      "AFter tokenizer:  ['hey', 'i', \"'m\", 'bored', '...', 'so', 'i', \"'m\", 'thinking', 'of', 'u', '...', 'so', 'wat', 'r', 'u', 'doing', '?']\n",
      "AFter tokenizer:  ['nah', ',', 'wednesday', '.', 'when', 'should', 'i', 'bring', 'the', 'mini', 'cheetos', 'bag', 'over', '?']\n",
      "AFter tokenizer:  ['nobody', 'names', 'their', 'penis', 'a', 'girls', 'name', 'this', 'story', 'does', \"n't\", 'add', 'up', 'at', 'all']\n",
      "AFter tokenizer:  ['aight', ',', 'let', 'me', 'know', 'when', 'you', \"'re\", 'gon', 'na', 'be', 'around', 'usf']\n",
      "AFter tokenizer:  ['i', \"'m\", 'not', '.', 'she', 'lip', 'synced', 'with', 'shangela', '.']\n",
      "AFter tokenizer:  ['ü', 'neva', 'tell', 'me', 'how', 'i', 'noe', '...', 'i', \"'m\", 'not', 'at', 'home', 'in', 'da', 'aft', 'wat', '...']\n",
      "AFter tokenizer:  ['a', 'bit', 'of', 'ur', 'smile', 'is', 'my', 'hppnss', ',', 'a', 'drop', 'of', 'ur', 'tear', 'is', 'my', 'sorrow', ',', 'a', 'part', 'of', 'ur', 'heart', 'is', 'my', 'life', ',', 'a', 'heart', 'like', 'mine', 'wil', 'care', 'for', 'u', ',', 'forevr', 'as', 'my', 'goodfriend']\n",
      "AFter tokenizer:  ['dear', 'voucher', 'holder', '2', 'claim', 'your', '1st', 'class', 'airport', 'lounge', 'passes', 'when', 'using', 'your', 'holiday', 'voucher', 'call', '08704439680.', 'when', 'booking', 'quote', '1st', 'class', 'x', '2']\n",
      "AFter tokenizer:  ['buzz', '!', 'hey', ',', 'my', 'love', '!', 'i', 'think', 'of', 'you', 'and', 'hope', 'your', 'day', 'goes', 'well', '.', 'did', 'you', 'sleep', 'in', '?', 'i', 'miss', 'you', 'babe', '.', 'i', 'long', 'for', 'the', 'moment', 'we', 'are', 'together', 'again', '*', 'loving', 'smile', '*']\n",
      "AFter tokenizer:  ['haha', '...', 'sounds', 'crazy', ',', 'dunno', 'can', 'tahan', 'anot', '...']\n",
      "AFter tokenizer:  ['why', 'are', 'u', 'up', 'so', 'early', '?']\n",
      "AFter tokenizer:  ['ya', 'that', 'one', 'is', 'slow', 'as', 'poo']\n",
      "AFter tokenizer:  ['im', 'on', 'gloucesterroad', 'what', 'are', 'uup', 'to', 'later', '?']\n",
      "AFter tokenizer:  ['lol', 'no', 'ouch', 'but', 'wish', 'i', \"'d\", 'stayed', 'out', 'a', 'bit', 'longer']\n",
      "AFter tokenizer:  ['god', 'asked', ',', '``', 'what', 'is', 'forgiveness', '?', \"''\", 'a', 'little', 'child', 'gave', 'lovely', 'reply', ',', '``', 'it', 'is', 'd', 'wonderful', 'fruit', 'that', 'a', 'tree', 'gives', 'when', 'it', 'is', 'being', 'hurt', 'by', 'a', 'stone', '..', 'good', 'night', '......']\n",
      "AFter tokenizer:  ['we', \"'ll\", 'join', 'the', '&', 'lt', ';', '#', '&', 'gt', ';', 'bus']\n",
      "AFter tokenizer:  ['was', 'just', 'about', 'to', 'ask', '.', 'will', 'keep', 'this', 'one', '.', 'maybe', 'that', \"'s\", 'why', 'you', 'did', \"n't\", 'get', 'all', 'the', 'messages', 'we', 'sent', 'you', 'on', 'glo']\n",
      "AFter tokenizer:  ['k.i', 'will', 'send', 'in', '&', 'lt', ';', '#', '&', 'gt', ';', 'min', ':', ')']\n",
      "AFter tokenizer:  ['would', 'me', 'smoking', 'you', 'out', 'help', 'us', 'work', 'through', 'this', 'difficult', 'time']\n",
      "AFter tokenizer:  ['someone', 'u', 'know', 'has', 'asked', 'our', 'dating', 'service', '2', 'contact', 'you', '!', 'cant', 'guess', 'who', '?', 'call', '09058095107', 'now', 'all', 'will', 'be', 'revealed', '.', 'pobox', '7', ',', 's3xy', '150p']\n",
      "AFter tokenizer:  ['yes.mum', 'lookin', 'strong', ':', ')']\n",
      "AFter tokenizer:  ['sir', 'goodmorning', ',', 'once', 'free', 'call', 'me', '.']\n",
      "AFter tokenizer:  ['where', 'are', 'you', 'call', 'me', '.']\n",
      "AFter tokenizer:  ['love', 'it', '!', 'the', 'girls', 'at', 'the', 'office', 'may', 'wonder', 'why', 'you', 'are', 'smiling', 'but', 'sore', '...']\n",
      "AFter tokenizer:  ['hi', ',', 'wlcome', 'back', ',', 'did', 'wonder', 'if', 'you', 'got', 'eaten', 'by', 'a', 'lion', 'or', 'something', ',', 'nothing', 'much']\n",
      "AFter tokenizer:  ['does', 'uncle', 'timi', 'help', 'in', 'clearing', 'cars']\n",
      "AFter tokenizer:  ['i', 'came', 'hostel', '.', 'i', 'm', 'going', 'to', 'sleep', '.', 'plz', 'call', 'me', 'up', 'before', 'class', '.', 'hrishi', '.']\n",
      "AFter tokenizer:  ['ok', '...', 'but', 'bag', 'again', '..']\n",
      "AFter tokenizer:  ['ok', 'lor', '.', 'msg', 'me', 'b4', 'u', 'call', '.']\n",
      "AFter tokenizer:  ['mila', ',', 'age23', ',', 'blonde', ',', 'new', 'in', 'uk', '.', 'i', 'look', 'sex', 'with', 'uk', 'guys', '.', 'if', 'u', 'like', 'fun', 'with', 'me', '.', 'text', 'mtalk', 'to', '69866.18', '.', '30pp/txt', '1st', '5free', '.', '£1.50', 'increments', '.', 'help08718728876']\n",
      "AFter tokenizer:  ['once', 'a', 'fishrman', 'woke', 'early', 'in', 'd', 'mrng', '.', 'it', 'was', 'very', 'dark', '.', 'he', 'waited', 'a', 'while', '&', 'amp', ';', 'found', 'a', 'sack', 'ful', 'of', 'stones', '.', 'he', 'strtd', 'throwin', 'thm', 'in2', 'd', 'sea', '2', 'pass', 'time', '.', 'atlast', 'he', 'had', 'jus', '1stone', ',', 'sun', 'rose', 'up', '&', 'amp', ';', 'he', 'found', 'out', 'tht', 'those', 'r', 'nt', 'stones', ',', 'those', 'were', 'diamonds', '.', 'moral', ':', \"''\", 'dont', 'wake', 'up', 'early', 'in', 'd', 'mrng', \"''\", 'good', 'night']\n",
      "AFter tokenizer:  ['claim', 'a', '200', 'shopping', 'spree', ',', 'just', 'call', '08717895698', 'now', '!', 'have', 'you', 'won', '!', 'mobstorequiz10ppm']\n",
      "AFter tokenizer:  ['then', 'ur', 'physics', 'get', 'a-', '?']\n",
      "AFter tokenizer:  ['dear', 'friends', ',', 'sorry', 'for', 'the', 'late', 'information', '.', 'today', 'is', 'the', 'birthday', 'of', 'our', 'loving', 'ar.praveesh', '.', 'for', 'more', 'details', 'log', 'on', 'to', 'face', 'book', 'and', 'see', '.', 'its', 'his', 'number', '+', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'dont', 'miss', 'a', 'delicious', 'treat', '.']\n",
      "AFter tokenizer:  ['how', 'r', 'ü', 'going', 'to', 'send', 'it', 'to', 'me', '?']\n",
      "AFter tokenizer:  ['can', 'you', 'do', 'online', 'transaction', '?']\n",
      "AFter tokenizer:  ['dear', 'got', 'train', 'and', 'seat', 'mine', 'lower', 'seat']\n",
      "AFter tokenizer:  ['let', 'me', 'know', 'if', 'you', 'need', 'anything', 'else', '.', 'salad', 'or', 'desert', 'or', 'something', '...', 'how', 'many', 'beers', 'shall', 'i', 'get', '?']\n",
      "AFter tokenizer:  ['whore', 'you', 'are', 'unbelievable', '.']\n",
      "AFter tokenizer:  ['want', 'to', 'funk', 'up', 'ur', 'fone', 'with', 'a', 'weekly', 'new', 'tone', 'reply', 'tones2u', '2', 'this', 'text', '.', 'www.ringtones.co.uk', ',', 'the', 'original', 'n', 'best', '.', 'tones', '3gbp', 'network', 'operator', 'rates', 'apply']\n",
      "AFter tokenizer:  ['are', 'you', 'sure', 'you', 'do', \"n't\", 'mean', '``', 'get', 'here', ',', 'we', 'made', 'you', 'hold', 'all', 'the', 'weed', \"''\"]\n",
      "AFter tokenizer:  ['i', 'love', 'you', '!', '!', '!', 'you', 'know', '?', 'can', 'you', 'feel', 'it', '?', 'does', 'it', 'make', 'your', 'belly', 'warm', '?', 'i', 'wish', 'it', 'does', ',', 'my', 'love', '...', 'i', 'shall', 'meet', 'you', 'in', 'your', 'dreams', ',', 'ahmad', '...', '*', 'adoring', 'kiss', '*']\n",
      "AFter tokenizer:  ['twinks', ',', 'bears', ',', 'scallies', ',', 'skins', 'and', 'jocks', 'are', 'calling', 'now', '.', 'do', \"n't\", 'miss', 'the', 'weekend', \"'s\", 'fun', '.', 'call', '08712466669', 'at', '10p/min', '.', '2', 'stop', 'texts', 'call', '08712460324', '(', 'nat', 'rate', ')']\n",
      "AFter tokenizer:  ['love', 'it', '!', 'i', 'want', 'to', 'flood', 'that', 'pretty', 'pussy', 'with', 'cum', '...']\n",
      "AFter tokenizer:  ['hey', 'are', 'you', 'angry', 'with', 'me', '.', 'reply', 'me', 'dr', '.']\n",
      "AFter tokenizer:  ['short', 'but', 'cute', ':', '``', 'be', 'a', 'good', 'person', ',', 'but', 'dont', 'try', 'to', 'prove', 'it', '..', \"''\", '.gud', 'noon', '....']\n",
      "AFter tokenizer:  ['also', 'remember', 'the', 'beads', 'do', \"n't\", 'come', 'off', '.', 'ever', '.']\n",
      "AFter tokenizer:  ['they', 'have', 'a', 'thread', 'on', 'the', 'wishlist', 'section', 'of', 'the', 'forums', 'where', 'ppl', 'post', 'nitro', 'requests', '.', 'start', 'from', 'the', 'last', 'page', 'and', 'collect', 'from', 'the', 'bottom', 'up', '.']\n",
      "AFter tokenizer:  ['for', 'the', 'first', 'time', 'in', 'the', 'history', \"'need\", \"'\", \"'comfort\", \"'\", 'and', \"'luxury\", \"'\", 'are', 'sold', 'at', 'same', 'price', 'in', 'india', '..', '!', '!', 'onion-rs', '.', '&', 'lt', ';', '#', '&', 'gt', ';', 'petrol-rs', '.', '&', 'lt', ';', '#', '&', 'gt', ';', 'beer-rs', '.', '&', 'lt', ';', '#', '&', 'gt', ';', 'shesil', '&', 'lt', ';', '#', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['actually', 'nvm', ',', 'got', 'hella', 'cash', ',', 'we', 'still', 'on', 'for', '&', 'lt', ';', '#', '&', 'gt', ';', 'ish', '?']\n",
      "AFter tokenizer:  ['we', 'tried', 'to', 'contact', 'you', 're', 'your', 'reply', 'to', 'our', 'offer', 'of', 'a', 'video', 'handset', '?', '750', 'anytime', 'any', 'networks', 'mins', '?', 'unlimited', 'text', '?', 'camcorder', '?', 'reply', 'or', 'call', '08000930705', 'now']\n",
      "AFter tokenizer:  ['it', \"'s\", 'ok', ',', 'at', 'least', 'armand', \"'s\", 'still', 'around']\n",
      "AFter tokenizer:  ['no', 'da', '.', 'i', 'am', 'happy', 'that', 'we', 'sit', 'together', 'na']\n",
      "AFter tokenizer:  ['yup', 'song', 'bro', '.', 'no', 'creative', '.', 'neva', 'test', 'quality', '.', 'he', 'said', 'check', 'review', 'online', '.']\n",
      "AFter tokenizer:  ['no', 'dude', ',', 'its', 'not', 'fake', '..', 'my', 'frnds', 'got', 'money', ',', 'thts', 'y', 'i', \"'m\", 'reffering', 'u', '..', 'if', 'u', 'member', 'wit', 'my', 'mail', 'link', ',', 'u', 'vl', 'be', 'credited', '&', 'lt', ';', '#', '&', 'gt', ';', 'rs', 'and', 'il', 'be', 'getiing', '&', 'lt', ';', '#', '&', 'gt', ';', 'rs', '..', 'i', 'can', 'draw', 'my', 'acc', 'wen', 'it', 'is', '&', 'lt', ';', '#', '&', 'gt', ';', 'rs', '..']\n",
      "AFter tokenizer:  ['dude', 'while', 'were', 'makin', 'those', 'weirdy', 'brownies', 'my', 'sister', 'made', 'awesome', 'cookies', '.', 'i', 'took', 'pics', '.']\n",
      "AFter tokenizer:  ['urgent', '!', 'we', 'are', 'trying', 'to', 'contact', 'you', '.', 'last', 'weekends', 'draw', 'shows', 'that', 'you', 'have', 'won', 'a', '£900', 'prize', 'guaranteed', '.', 'call', '09061701851.', 'claim', 'code', 'k61', '.', 'valid', '12hours', 'only']\n",
      "AFter tokenizer:  ['pls', 'dont', 'restrict', 'her', 'from', 'eating', 'anythin', 'she', 'likes', 'for', 'the', 'next', 'two', 'days', '.']\n",
      "AFter tokenizer:  ['mm', 'you', 'ask', 'him', 'to', 'come', 'its', 'enough', ':', '-', ')']\n",
      "AFter tokenizer:  ['at', 'the', 'funeral', 'home', 'with', 'audrey', 'and', 'dad']\n",
      "AFter tokenizer:  ['aight', ',', 'can', 'you', 'text', 'me', 'the', 'address', '?']\n",
      "AFter tokenizer:  ['excellent', '!', 'wish', 'we', 'were', 'together', 'right', 'now', '!']\n",
      "AFter tokenizer:  ['yep', 'then', 'is', 'fine', '7.30', 'or', '8.30', 'for', 'ice', 'age', '.']\n",
      "AFter tokenizer:  ['pls', 'i', 'wont', 'belive', 'god.not', 'only', 'jesus', '.']\n",
      "AFter tokenizer:  ['can', '.', 'dunno', 'wat', 'to', 'get', '4', 'her', '...']\n",
      "AFter tokenizer:  ['not', 'yet', 'chikku', '..', 'k', ',', 'then', 'wat', 'abt', 'tht', 'guy', 'did', 'he', 'stopped', 'irritating', 'or', 'msging', 'to', 'u', '..']\n",
      "AFter tokenizer:  ['how', 'long', 'does', 'it', 'take', 'to', 'get', 'it', '.']\n",
      "AFter tokenizer:  ['this', 'is', 'my', 'number', 'by', 'vivek', '..']\n",
      "AFter tokenizer:  ['74355', 'xmas', 'iscoming', '&', 'ur', 'awarded', 'either', '£500', 'cd', 'gift', 'vouchers', '&', 'free', 'entry', '2', 'r', '£100', 'weekly', 'draw', 'txt', 'music', 'to', '87066', 'tnc']\n",
      "AFter tokenizer:  ['sorry', 'brah', ',', 'just', 'finished', 'the', 'last', 'of', 'my', 'exams', ',', 'what', 'up']\n",
      "AFter tokenizer:  ['i', 'got', 'arrested', 'for', 'possession', 'at', ',', 'i', 'shit', 'you', 'not', ',', '&', 'lt', ';', 'time', '&', 'gt', ';', 'pm']\n",
      "AFter tokenizer:  ['you', 'are', 'right', 'though', '.', 'i', 'ca', \"n't\", 'give', 'you', 'the', 'space', 'you', 'want', 'and', 'need', '.', 'this', 'is', 'really', 'starting', 'to', 'become', 'an', 'issue', '.', 'i', 'was', 'going', 'to', 'suggest', 'setting', 'a', 'definite', 'move', 'out', '--', 'if', 'i', \"'m\", 'still', 'there', '--', 'after', 'greece', '.', 'but', 'maybe', 'you', 'are', 'ready', 'and', 'should', 'do', 'it', 'now', '.']\n",
      "AFter tokenizer:  ['just', 'normal', 'only', 'here', ':', ')']\n",
      "AFter tokenizer:  ['please', 'protect', 'yourself', 'from', 'e-threats', '.', 'sib', 'never', 'asks', 'for', 'sensitive', 'information', 'like', 'passwords', ',', 'atm/sms', 'pin', 'thru', 'email', '.', 'never', 'share', 'your', 'password', 'with', 'anybody', '.']\n",
      "AFter tokenizer:  ['i', 'miss', 'you', 'so', 'much', 'i', \"'m\", 'so', 'desparate', 'i', 'have', 'recorded', 'the', 'message', 'you', 'left', 'for', 'me', 'the', 'other', 'day', 'and', 'listen', 'to', 'it', 'just', 'to', 'hear', 'the', 'sound', 'of', 'your', 'voice', '.', 'i', 'love', 'you']\n",
      "AFter tokenizer:  ['hi', '.', 'i', \"'m\", 'always', 'online', 'on', 'yahoo', 'and', 'would', 'like', 'to', 'chat', 'with', 'you', 'someday']\n",
      "AFter tokenizer:  ['goodmorning', ',', 'my', 'grandfather', 'expired', '..', 'so', 'am', 'on', 'leave', 'today', '.']\n",
      "AFter tokenizer:  ['congratulations', 'u', 'can', 'claim', '2', 'vip', 'row', 'a', 'tickets', '2', 'c', 'blu', 'in', 'concert', 'in', 'november', 'or', 'blu', 'gift', 'guaranteed', 'call', '09061104276', 'to', 'claim', 'ts', '&', 'cs', 'www.smsco.net', 'cost£3.75max']\n",
      "AFter tokenizer:  ['where', 'are', 'you', '?', 'what', 'are', 'you', 'doing', '?', 'are', 'yuou', 'working', 'on', 'getting', 'the', 'pc', 'to', 'your', 'mom', \"'s\", '?', 'did', 'you', 'find', 'a', 'spot', 'that', 'it', 'would', 'work', '?', 'i', 'need', 'you']\n",
      "AFter tokenizer:  ['sure', ',', 'i', \"'ll\", 'see', 'if', 'i', 'can', 'come', 'by', 'in', 'a', 'bit']\n",
      "AFter tokenizer:  ['i', 'agree', '.', 'so', 'i', 'can', 'stop', 'thinkin', 'about', 'ipad', '.', 'can', 'you', 'please', 'ask', 'macho', 'the', 'same', 'question', '.']\n",
      "AFter tokenizer:  ['let', \"'s\", 'pool', 'our', 'money', 'together', 'and', 'buy', 'a', 'bunch', 'of', 'lotto', 'tickets', '.', 'if', 'we', 'win', 'i', 'get', '&', 'lt', ';', '#', '&', 'gt', ';', '%', 'u', 'get', '&', 'lt', ';', '#', '&', 'gt', ';', '%', '.', 'deal', '?']\n",
      "AFter tokenizer:  ['watching', 'tv', 'lor', '.', 'nice', 'one', 'then', 'i', 'like', 'lor', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'thinking', 'that', 'chennai', 'forgot', 'to', 'come', 'for', 'auction', '..']\n",
      "AFter tokenizer:  ['then', 'ü', 'come', 'n', 'pick', 'me', 'at', '530', 'ar', '?']\n",
      "AFter tokenizer:  ['early', 'bird', '!', 'any', 'purchases', 'yet', '?']\n",
      "AFter tokenizer:  ['went', 'to', 'pay', 'rent', '.', 'so', 'i', 'had', 'to', 'go', 'to', 'the', 'bank', 'to', 'authorise', 'the', 'payment', '.']\n",
      "AFter tokenizer:  ['erm', '…', 'ill', 'pick', 'you', 'up', 'at', 'about', '6.45pm', '.', 'that', \"'ll\", 'give', 'enough', 'time', 'to', 'get', 'there', ',', 'park', 'and', 'that', '.']\n",
      "AFter tokenizer:  ['hey', 'mate', '!', 'hows', 'u', 'honey', '?', 'did', 'u', 'ave', 'good', 'holiday', '?', 'gimmi', 'de', 'goss', '!', 'x']\n",
      "AFter tokenizer:  ['howz', 'pain.it', 'will', 'come', 'down', 'today.do', 'as', 'i', 'said', 'ystrday.ice', 'and', 'medicine', '.']\n",
      "AFter tokenizer:  ['chile', ',', 'please', '!', 'it', \"'s\", 'only', 'a', '&', 'lt', ';', 'decimal', '&', 'gt', ';', 'hour', 'drive', 'for', 'me', '.', 'i', 'come', 'down', 'all', 'the', 'time', 'and', 'will', 'be', 'subletting', 'feb-april', 'for', 'audition', 'season', '.']\n",
      "AFter tokenizer:  ['yes', 'ammae', '....', 'life', 'takes', 'lot', 'of', 'turns', 'you', 'can', 'only', 'sit', 'and', 'try', 'to', 'hold', 'the', 'steering', '...']\n",
      "AFter tokenizer:  ['yeah', 'that', \"'s\", 'what', 'i', 'thought', ',', 'lem', 'me', 'know', 'if', 'anything', \"'s\", 'goin', 'on', 'later']\n",
      "AFter tokenizer:  ['mmmm', '....', 'i', 'cant', 'wait', 'to', 'lick', 'it', '!']\n",
      "AFter tokenizer:  ['pls', 'go', 'there', 'today', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'i', 'dont', 'want', 'any', 'excuses']\n",
      "AFter tokenizer:  ['can', 'you', 'plz', 'tell', 'me', 'the', 'ans', '.', 'bslvyl', 'sent', 'via', 'fullonsms.com']\n",
      "AFter tokenizer:  ['u', 'in', 'town', 'alone', '?']\n",
      "AFter tokenizer:  ['i', 'to', 'am', 'looking', 'forward', 'to', 'all', 'the', 'sex', 'cuddling', '..', 'only', 'two', 'more', 'sleeps']\n",
      "AFter tokenizer:  ['we', 'have', 'all', 'rounder', ':', ')', 'so', 'not', 'required', ':', ')']\n",
      "AFter tokenizer:  ['no', ',', 'its', 'true', '..', 'k', ',', 'do', 'u', 'knw', 'dis', 'no', '.', '&', 'lt', ';', '#', '&', 'gt', ';', '?']\n",
      "AFter tokenizer:  ['dont', 'worry', ',', '1', 'day', 'very', 'big', 'lambu', 'ji', 'vl', 'come', '..', 'til', 'then', 'enjoy', 'batchlor', 'party', ':', '-', ')']\n",
      "AFter tokenizer:  ['oh', 'ya', '...', 'got', 'hip', 'hop', 'open', '.', 'haha', 'i', 'was', 'thinking', 'can', 'go', 'for', 'jazz', 'then', 'zoom', 'to', 'cine', '...', 'actually', 'tonight', 'i', \"'m\", 'free', 'leh', '...', 'and', 'there', \"'s\", 'a', 'kb', 'lesson', 'tonight']\n",
      "AFter tokenizer:  ['free', 'msg', ':', 'single', '?', 'find', 'a', 'partner', 'in', 'your', 'area', '!', '1000s', 'of', 'real', 'people', 'are', 'waiting', 'to', 'chat', 'now', '!', 'send', 'chat', 'to', '62220cncl', 'send', 'stopcs', '08717890890£1.50', 'per', 'msg']\n",
      "AFter tokenizer:  ['i', \"'m\", 'ok.', 'will', 'do', 'my', 'part', 'tomorrow']\n",
      "AFter tokenizer:  ['no', '!', 'but', 'we', 'found', 'a', 'diff', 'farm', 'shop', 'to', 'buy', 'some', 'cheese', '.', 'on', 'way', 'back', 'now', ',', 'can', 'i', 'call', 'in', '?']\n",
      "AFter tokenizer:  ['r', 'u', 'still', 'working', 'now', '?']\n",
      "AFter tokenizer:  ['win', 'the', 'newest', '\\x93harry', 'potter', 'and', 'the', 'order', 'of', 'the', 'phoenix', '(', 'book', '5', ')', 'reply', 'harry', ',', 'answer', '5', 'questions', '-', 'chance', 'to', 'be', 'the', 'first', 'among', 'readers', '!']\n",
      "AFter tokenizer:  ['yep', '.', 'i', 'do', 'like', 'the', 'pink', 'furniture', 'tho', '.']\n",
      "AFter tokenizer:  ['free', 'msg', ':', 'ringtone', '!', 'from', ':', 'http', ':', '//tms', '.', 'widelive.com/index', '.', 'wml', '?', 'id=1b6a5ecef91ff9', '*', '37819', '&', 'first=true18:0430-jul-05']\n",
      "AFter tokenizer:  ['customer', 'place', ',', 'i', 'wil', 'cal', 'u', 'sir', '.']\n",
      "AFter tokenizer:  ['oh', 'my', 'god', '!', 'i', \"'ve\", 'found', 'your', 'number', 'again', '!', 'i', \"'m\", 'so', 'glad', ',', 'text', 'me', 'back', 'xafter', 'this', 'msgs', 'cst', 'std', 'ntwk', 'chg', '£1.50']\n",
      "AFter tokenizer:  ['a', 'pure', 'hearted', 'person', 'can', 'have', 'a', 'wonderful', 'smile', 'that', 'makes', 'even', 'his/her', 'enemies', 'to', 'feel', 'guilty', 'for', 'being', 'an', 'enemy', '..', 'so', 'catch', 'the', 'world', 'with', 'your', 'smile', '..', ':', ')', 'goodmorning', '&', 'amp', ';', 'have', 'a', 'smiley', 'sunday', '..', ':', ')']\n",
      "AFter tokenizer:  ['that\\x92s', 'alrite', 'girl', ',', 'u', 'know', 'gail', 'is', 'neva', 'wrong', '!', '!', 'take', 'care', 'sweet', 'and', 'don\\x92t', 'worry.c', 'u', 'l8tr', 'hun', '!', 'love', 'yaxxx']\n",
      "AFter tokenizer:  ['theoretically', 'yeah', ',', 'he', 'could', 'be', 'able', 'to', 'come']\n",
      "AFter tokenizer:  ['alright', 'we', \"'re\", 'hooked', 'up', ',', 'where', 'you', 'guys', 'at']\n",
      "AFter tokenizer:  ['not', 'that', 'i', 'know', 'of', ',', 'most', 'people', 'up', 'here', 'are', 'still', 'out', 'of', 'town']\n",
      "AFter tokenizer:  ['no', 'let', 'me', 'do', 'the', 'math', '.', 'your', 'not', 'good', 'at', 'it', '.']\n",
      "AFter tokenizer:  ['oh', 'ok', 'wait', '4', 'me', 'there', '...', 'my', 'lect', 'havent', 'finish']\n",
      "AFter tokenizer:  ['yeah', 'my', 'usual', 'guy', \"'s\", 'out', 'of', 'town', 'but', 'there', \"'re\", 'definitely', 'people', 'around', 'i', 'know']\n",
      "AFter tokenizer:  ['i', 'am', 'joining', 'today', 'formally.pls', 'keep', 'praying.will', 'talk', 'later', '.']\n",
      "AFter tokenizer:  ['happy', 'or', 'sad', ',', 'one', 'thing', 'about', 'past', 'is-', '``', 'its', 'no', 'more', \"''\", 'good', 'morning', ':', '-', ')', ':', '-', ')', '.']\n",
      "AFter tokenizer:  ['no', '.', 'did', 'you', 'multimedia', 'message', 'them', 'or', 'e-mail', '?']\n",
      "AFter tokenizer:  ['okie', 'but', 'i', 'scared', 'u', 'say', 'i', 'fat', '...', 'then', 'u', 'dun', 'wan', 'me', 'already', '...']\n",
      "AFter tokenizer:  ['did', 'u', 'get', 'that', 'message']\n",
      "AFter tokenizer:  ['sorry', 'sir', ',', 'i', 'will', 'call', 'you', 'tomorrow', '.', 'senthil.hsbc']\n",
      "AFter tokenizer:  ['what', 'you', 'need', '.', 'you', 'have', 'a', 'person', 'to', 'give', 'na', '.']\n",
      "AFter tokenizer:  ['she', 'left', 'it', 'very', 'vague', '.', 'she', 'just', 'said', 'she', 'would', 'inform', 'the', 'person', 'in', 'accounting', 'about', 'the', 'delayed', 'rent', 'and', 'that', 'i', 'should', 'discuss', 'with', 'the', 'housing', 'agency', 'about', 'my', 'renting', 'another', 'place', '.', 'but', 'checking', 'online', 'now', 'and', 'all', 'places', 'around', 'usc', 'are', '&', 'lt', ';', '#', '&', 'gt', ';', 'and', 'up']\n",
      "AFter tokenizer:  ['hi', 'juan', '.', 'im', 'coming', 'home', 'on', 'fri', 'hey', '.', 'of', 'course', 'i', 'expect', 'a', 'welcome', 'party', 'and', 'lots', 'of', 'presents', '.', 'ill', 'phone', 'u', 'when', 'i', 'get', 'back', '.', 'loads', 'of', 'love', 'nicky', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "AFter tokenizer:  ['gumby', \"'s\", 'has', 'a', 'special', 'where', 'a', '&', 'lt', ';', '#', '&', 'gt', ';', '``', 'cheese', 'pizza', 'is', '$', '2', 'so', 'i', 'know', 'what', 'we', \"'re\", 'doin', 'tonight']\n",
      "AFter tokenizer:  ['a', 'link', 'to', 'your', 'picture', 'has', 'been', 'sent', '.', 'you', 'can', 'also', 'use', 'http', ':', '//alto18.co.uk/wave/wave.asp', '?', 'o=44345']\n",
      "AFter tokenizer:  ['like', 'a', 'personal', 'sized', 'or', 'what']\n",
      "AFter tokenizer:  ['same', ',', 'i', \"'m\", 'at', 'my', 'great', 'aunts', 'anniversary', 'party', 'in', 'tarpon', 'springs']\n",
      "AFter tokenizer:  ['cab', 'is', 'available.they', 'pick', 'up', 'and', 'drop', 'at', 'door', 'steps', '.']\n",
      "AFter tokenizer:  ['ok', '....', 'take', 'care.umma', 'to', 'you', 'too', '...']\n",
      "AFter tokenizer:  ['unlimited', 'texts', '.', 'limited', 'minutes', '.']\n",
      "AFter tokenizer:  ['double', 'mins', '&', '1000', 'txts', 'on', 'orange', 'tariffs', '.', 'latest', 'motorola', ',', 'sonyericsson', '&', 'nokia', 'with', 'bluetooth', 'free', '!', 'call', 'mobileupd8', 'on', '08000839402', 'or', 'call2optout/hf8']\n",
      "AFter tokenizer:  ['no', 'problem', '.', 'we', 'will', 'be', 'spending', 'a', 'lot', 'of', 'quality', 'time', 'together', '...']\n",
      "AFter tokenizer:  ['urgent', 'this', 'is', 'our', '2nd', 'attempt', 'to', 'contact', 'u.', 'your', '£900', 'prize', 'from', 'yesterday', 'is', 'still', 'awaiting', 'collection', '.', 'to', 'claim', 'call', 'now', '09061702893.', 'acl03530150pm']\n",
      "AFter tokenizer:  ['have', 'you', 'heard', 'from', 'this', 'week', '?']\n",
      "AFter tokenizer:  ['dear', 'dave', 'this', 'is', 'your', 'final', 'notice', 'to', 'collect', 'your', '4', '*', 'tenerife', 'holiday', 'or', '#', '5000', 'cash', 'award', '!', 'call', '09061743806', 'from', 'landline', '.', 'tcs', 'sae', 'box326', 'cw25wx', '150ppm']\n",
      "AFter tokenizer:  ['yes', '.', 'last', 'practice']\n",
      "AFter tokenizer:  ['tells', 'u', '2', 'call', '09066358152', 'to', 'claim', '£5000', 'prize', '.', 'u', 'have', '2', 'enter', 'all', 'ur', 'mobile', '&', 'personal', 'details', '@', 'the', 'prompts', '.', 'careful', '!']\n",
      "AFter tokenizer:  ['no', '.', 'thank', 'you', '.', 'you', \"'ve\", 'been', 'wonderful']\n",
      "AFter tokenizer:  ['ü', 'mean', 'it', \"'s\", 'confirmed', '...', 'i', 'tot', 'they', 'juz', 'say', 'oni', '...', 'ok', 'then', '...']\n",
      "AFter tokenizer:  ['that', 'depends', '.', 'how', 'would', 'you', 'like', 'to', 'be', 'treated', '?', ':', ')']\n",
      "AFter tokenizer:  ['right', 'on', 'brah', ',', 'see', 'you', 'later']\n",
      "AFter tokenizer:  ['waiting', 'in', 'e', 'car', '4', 'my', 'mum', 'lor', '.', 'u', 'leh', '?', 'reach', 'home', 'already', '?']\n",
      "AFter tokenizer:  ['your', '2004', 'account', 'for', '07xxxxxxxxx', 'shows', '786', 'unredeemed', 'points', '.', 'to', 'claim', 'call', '08719181259', 'identifier', 'code', ':', 'xxxxx', 'expires', '26.03.05']\n",
      "AFter tokenizer:  ['do', 'you', 'want', 'a', 'new', 'video', 'handset', '?', '750', 'anytime', 'any', 'network', 'mins', '?', 'half', 'price', 'line', 'rental', '?', 'camcorder', '?', 'reply', 'or', 'call', '08000930705', 'for', 'delivery', 'tomorrow']\n",
      "AFter tokenizer:  ['went', 'fast', 'asleep', 'dear.take', 'care', '.']\n",
      "AFter tokenizer:  ['no', 'that', 'just', 'means', 'you', 'have', 'a', 'fat', 'head']\n",
      "AFter tokenizer:  ['sounds', 'like', 'a', 'plan', '!', 'cardiff', 'is', 'still', 'here', 'and', 'still', 'cold', '!', 'i', \"'m\", 'sitting', 'on', 'the', 'radiator', '!']\n",
      "AFter tokenizer:  ['serious', '?', 'what', 'like', 'proper', 'tongued', 'her']\n",
      "AFter tokenizer:  ['she.s', 'good', '.', 'she', 'was', 'wondering', 'if', 'you', 'wont', 'say', 'hi', 'but', 'she.s', 'smiling', 'now', '.', 'so', 'how', 'are', 'you', 'coping', 'with', 'the', 'long', 'distance']\n",
      "AFter tokenizer:  ['how', 'i', 'noe', '...', 'she', \"'s\", 'in', 'da', 'car', 'now', '...', 'later', 'then', 'c', 'lar', '...', 'i', \"'m\", 'wearing', 'shorts', '...']\n",
      "AFter tokenizer:  ['yeah', 'whatever', 'lol']\n",
      "AFter tokenizer:  ['ard', '530', 'lor', '.', 'i', 'ok', 'then', 'message', 'ü', 'lor', '.']\n",
      "AFter tokenizer:  ['ok.', 'c', 'u', 'then', '.']\n",
      "AFter tokenizer:  ['eh', 'ur', 'laptop', 'got', 'no', 'stock', 'lei', '...', 'he', 'say', 'mon', 'muz', 'come', 'again', 'to', 'take', 'a', 'look', 'c', 'got', 'a', 'not', '...']\n",
      "AFter tokenizer:  ['no', 'need', 'to', 'ke', 'qi', '...', 'ü', 'too', 'bored', 'izzit', 'y', 'suddenly', 'thk', 'of', 'this', '...']\n",
      "AFter tokenizer:  ['i', 'wish', '!', 'i', 'do', \"n't\", 'think', 'its', 'gon', 'na', 'snow', 'that', 'much', '.', 'but', 'it', 'will', 'be', 'more', 'than', 'those', 'flurries', 'we', 'usually', 'get', 'that', 'melt', 'before', 'they', 'hit', 'the', 'ground', '.', 'eek', '!', 'we', 'have', \"n't\", 'had', 'snow', 'since', '&', 'lt', ';', '#', '&', 'gt', ';', 'before', 'i', 'was', 'even', 'born', '!']\n",
      "AFter tokenizer:  ['free', '>', 'ringtone', '!', 'reply', 'real', 'or', 'poly', 'eg', 'real1', '1.', 'pushbutton', '2.', 'dontcha', '3.', 'babygoodbye', '4.', 'golddigger', '5.', 'webeburnin', '1st', 'tone', 'free', 'and', '6', 'more', 'when', 'u', 'join', 'for', '£3/wk']\n",
      "AFter tokenizer:  ['oh', 'really', '?', 'perform', ',', 'write', 'a', 'paper', ',', 'go', 'to', 'a', 'movie', 'and', 'be', 'home', 'by', 'midnight', ',', 'huh', '?']\n",
      "AFter tokenizer:  ['okay', 'lor', '...', 'will', 'they', 'still', 'let', 'us', 'go', 'a', 'not', 'ah', '?', 'coz', 'they', 'will', 'not', 'know', 'until', 'later', '.', 'we', 'drop', 'our', 'cards', 'into', 'the', 'box', 'right', '?']\n",
      "AFter tokenizer:  ['how', '?', 'izzit', 'still', 'raining', '?']\n",
      "AFter tokenizer:  ['as', 'if', 'i', 'was', \"n't\", 'having', 'enough', 'trouble', 'sleeping', '.']\n",
      "AFter tokenizer:  ['i', 'havent', 'add', 'ü', 'yet', 'right', '..']\n",
      "AFter tokenizer:  ['lol', '...', 'i', 'really', 'need', 'to', 'remember', 'to', 'eat', 'when', 'i', \"'m\", 'drinking', 'but', 'i', 'do', 'appreciate', 'you', 'keeping', 'me', 'company', 'that', 'night', 'babe', '*', 'smiles', '*']\n",
      "AFter tokenizer:  ['babe', '?', 'i', 'lost', 'you', '...', 'will', 'you', 'try', 'rebooting', '?']\n",
      "AFter tokenizer:  ['yes', '.', 'nigh', 'you', 'cant', 'aha', '.']\n",
      "AFter tokenizer:  ['i', 'thk', 'ü', 'got', 'ta', 'go', 'home', 'by', 'urself', '.', 'cos', 'i', \"'ll\", 'b', 'going', 'out', 'shopping', '4', 'my', 'frens', 'present', '.']\n",
      "AFter tokenizer:  ['nooooooo', 'i', \"'m\", 'gon', 'na', 'be', 'bored', 'to', 'death', 'all', 'day', '.', 'cable', 'and', 'internet', 'outage', '.']\n",
      "AFter tokenizer:  ['sos', '!', 'any', 'amount', 'i', 'can', 'get', 'pls', '.']\n",
      "AFter tokenizer:  ['playin', 'space', 'poker', ',', 'u', '?']\n",
      "AFter tokenizer:  ['how', 'come', 'guoyang', 'go', 'n', 'tell', 'her', '?', 'then', 'u', 'told', 'her', '?']\n",
      "AFter tokenizer:  ['you', 'need', 'to', 'get', 'up', '.', 'now', '.']\n",
      "AFter tokenizer:  ['they', 'r', 'giving', 'a', 'second', 'chance', 'to', 'rahul', 'dengra', '.']\n",
      "AFter tokenizer:  ['yeah', ',', 'in', 'fact', 'he', 'just', 'asked', 'if', 'we', 'needed', 'anything', 'like', 'an', 'hour', 'ago', '.', 'when', 'and', 'how', 'much', '?']\n",
      "AFter tokenizer:  ['when', 'the', 'first', 'strike', 'is', 'a', 'red', 'one', '.', 'the', 'bird', '+', 'antelope', 'begin', 'toplay', 'in', 'the', 'fieldof', 'selfindependence', 'believe', 'this', '+', 'the', 'flower', 'of', 'contention', 'will', 'grow.random', '!']\n",
      "AFter tokenizer:  ['y', 'ü', 'wan', 'to', 'go', 'there', '?', 'c', 'doctor', '?']\n",
      "AFter tokenizer:  ['does', 'daddy', 'have', 'a', 'bb', 'now', '.']\n",
      "AFter tokenizer:  ['free', 'msg', ':', 'get', 'gnarls', 'barkleys', '``', 'crazy', \"''\", 'ringtone', 'totally', 'free', 'just', 'reply', 'go', 'to', 'this', 'message', 'right', 'now', '!']\n",
      "AFter tokenizer:  ['she', \"'s\", 'borderline', 'but', 'yeah', 'whatever', '.']\n",
      "AFter tokenizer:  ['until', '545', 'lor', '...', 'ya', ',', 'can', 'go', '4', 'dinner', 'together', '...']\n",
      "AFter tokenizer:  ['i', 'will', 'be', 'gentle', 'princess', '!', 'we', 'will', 'make', 'sweet', 'gentle', 'love', '...']\n",
      "AFter tokenizer:  ['how', 'u', 'doin', 'baby', 'girl', '?', '?', 'hope', 'u', 'are', 'okay', 'every', 'time', 'i', 'call', 'ure', 'phone', 'is', 'off', '!', 'i', 'miss', 'u', 'get', 'in', 'touch']\n",
      "AFter tokenizer:  ['sorry', ',', 'went', 'to', 'bed', 'early', ',', 'nightnight']\n",
      "AFter tokenizer:  ['i', 'like', 'to', 'think', 'there', \"'s\", 'always', 'the', 'possibility', 'of', 'being', 'in', 'a', 'pub', 'later', '.']\n",
      "AFter tokenizer:  ['hmm', 'yeah', 'if', 'your', 'not', 'too', 'grooved', 'out', '!', 'and', 'im', 'looking', 'forward', 'to', 'my', 'pound', 'special', ':', ')']\n",
      "AFter tokenizer:  ['i', 'got', 'to', 'video', 'tape', 'pple', 'type', 'in', 'message', 'lor', '.', 'u', 'so', 'free', 'wan', '2', 'help', 'me', '?', 'hee', '...', 'cos', 'i', 'noe', 'u', 'wan', '2', 'watch', 'infernal', 'affairs', 'so', 'ask', 'u', 'along', '.', 'asking', 'shuhui', 'oso', '.']\n",
      "AFter tokenizer:  ['hi', 'dude', 'hw', 'r', 'u', 'da', 'realy', 'mising', 'u', 'today']\n",
      "AFter tokenizer:  ['me', 'hungry', 'buy', 'some', 'food', 'good', 'lei', '...', 'but', 'mum', 'n', 'yun', 'dun', 'wan', 'juz', 'buy', 'a', 'little', 'bit', '...']\n",
      "AFter tokenizer:  ['refused', 'a', 'loan', '?', 'secured', 'or', 'unsecured', '?', 'ca', \"n't\", 'get', 'credit', '?', 'call', 'free', 'now', '0800', '195', '6669', 'or', 'text', 'back', \"'help\", \"'\", '&', 'we', 'will', '!']\n",
      "AFter tokenizer:  ['i', 'probably', 'wo', \"n't\", 'eat', 'at', 'all', 'today', '.', 'i', 'think', 'i', \"'m\", 'gon', 'na', 'pop', '.', 'how', 'was', 'your', 'weekend', '?', 'did', 'u', 'miss', 'me', '?']\n",
      "AFter tokenizer:  ['i', 'knew', 'it', '...', 'u', 'slept', 'v', 'late', 'yest', '?', 'wake', 'up', 'so', 'late', '...']\n",
      "AFter tokenizer:  ['haha', '...', 'dont', 'be', 'angry', 'with', 'yourself', '...', 'take', 'it', 'as', 'a', 'practice', 'for', 'the', 'real', 'thing', '.', '=', ')']\n",
      "AFter tokenizer:  ['where', 'is', 'that', 'one', 'day', 'training', ':', '-', ')']\n",
      "AFter tokenizer:  ['so', 'i', 'could', 'kiss', 'and', 'feel', 'you', 'next', 'to', 'me', '...']\n",
      "AFter tokenizer:  ['have', 'a', 'nice', 'day', 'my', 'dear', '.']\n",
      "AFter tokenizer:  ['i', 'sent', 'lanre', 'fakeye', \"'s\", 'eckankar', 'details', 'to', 'the', 'mail', 'box']\n",
      "AFter tokenizer:  ['your', 'dad', 'is', 'back', 'in', 'ph', '?']\n",
      "AFter tokenizer:  ['you', 'have', 'been', 'specially', 'selected', 'to', 'receive', 'a', '``', '3000', 'award', '!', 'call', '08712402050', 'before', 'the', 'lines', 'close', '.', 'cost', '10ppm', '.', '16+', '.', 't', '&', 'cs', 'apply', '.', 'ag', 'promo']\n",
      "AFter tokenizer:  ['if', 'you', 'ask', 'her', 'or', 'she', 'say', 'any', 'please', 'message', '.']\n",
      "AFter tokenizer:  ['if', 'e', 'timing', 'can', ',', 'then', 'i', 'go', 'w', 'u', 'lor', '...']\n",
      "AFter tokenizer:  ['i', 'was', 'just', 'callin', 'to', 'say', 'hi', '.', 'take', 'care', 'bruv', '!']\n",
      "AFter tokenizer:  ['you', 'have', 'won', '!', 'as', 'a', 'valued', 'vodafone', 'customer', 'our', 'computer', 'has', 'picked', 'you', 'to', 'win', 'a', '£150', 'prize', '.', 'to', 'collect', 'is', 'easy', '.', 'just', 'call', '09061743386']\n",
      "AFter tokenizer:  ['did', 'u', 'turn', 'on', 'the', 'heater', '?', 'the', 'heater', 'was', 'on', 'and', 'set', 'to', '&', 'lt', ';', '#', '&', 'gt', ';', 'degrees', '.']\n",
      "AFter tokenizer:  ['thanks', 'for', 'your', 'message', '.', 'i', 'really', 'appreciate', 'your', 'sacrifice', '.', 'i', \"'m\", 'not', 'sure', 'of', 'the', 'process', 'of', 'direct', 'pay', 'but', 'will', 'find', 'out', 'on', 'my', 'way', 'back', 'from', 'the', 'test', 'tomorrow', '.', 'i', \"'m\", 'in', 'class', 'now', '.', 'do', 'have', 'a', 'wonderful', 'day', '.']\n",
      "AFter tokenizer:  ['that', \"'s\", 'the', 'trouble', 'with', 'classes', 'that', 'go', 'well', '-', 'you', \"'re\", 'due', 'a', 'dodgey', 'one', '…', 'expecting', 'mine', 'tomo', '!', 'see', 'you', 'for', 'recovery', ',', 'same', 'time', ',', 'same', 'place']\n",
      "AFter tokenizer:  ['free', 'video', 'camera', 'phones', 'with', 'half', 'price', 'line', 'rental', 'for', '12', 'mths', 'and', '500', 'cross', 'ntwk', 'mins', '100', 'txts', '.', 'call', 'mobileupd8', '08001950382', 'or', 'call2optout/674', '&']\n",
      "AFter tokenizer:  ['wot', 'u', 'up', '2', 'j', '?']\n",
      "AFter tokenizer:  ['night', 'night', ',', 'see', 'you', 'tomorrow']\n",
      "AFter tokenizer:  ['roger', 'that', '.', 'we', '‘', 're', 'probably', 'going', 'to', 'rem', 'in', 'about', '20']\n",
      "AFter tokenizer:  ['do', 'u', 'think', 'that', 'any', 'girl', 'will', 'propose', 'u', 'today', 'by', 'seing', 'ur', 'bloody', 'funky', 'shit', 'fucking', 'face', '...............', 'asssssholeeee', '................']\n",
      "AFter tokenizer:  ['i', 'wish', 'u', 'were', 'here', '.', 'i', 'feel', 'so', 'alone']\n",
      "AFter tokenizer:  ['reason', 'is', 'if', 'the', 'team', 'budget', 'is', 'available', 'at', 'last', 'they', 'buy', 'the', 'unsold', 'players', 'for', 'at', 'base', 'rate', '..']\n",
      "AFter tokenizer:  ['ceri', 'u', 'rebel', '!', 'sweet', 'dreamz', 'me', 'little', 'buddy', '!', '!', 'c', 'ya', '2moro', '!', 'who', 'needs', 'blokes']\n",
      "AFter tokenizer:  ['ringtoneking', '84484']\n",
      "AFter tokenizer:  ['huh', 'i', 'cant', 'thk', 'of', 'more', 'oredi', 'how', 'many', 'pages', 'do', 'we', 'have', '?']\n",
      "AFter tokenizer:  ['his', 'frens', 'go', 'then', 'he', 'in', 'lor', '.', 'not', 'alone', 'wif', 'my', 'mum', 'n', 'sis', 'lor', '.']\n",
      "AFter tokenizer:  ['nationwide', 'auto', 'centre', '(', 'or', 'something', 'like', 'that', ')', 'on', 'newport', 'road', '.', 'i', 'liked', 'them', 'there']\n",
      "AFter tokenizer:  ['hey', ',', 'i', 'missed', 'you', 'tm', 'of', 'last', 'night', 'as', 'my', 'phone', 'was', 'on', 'the', 'charge', '...', '*', 'smiles', '*', '...', 'i', 'am', 'meeting', 'a', 'friend', 'shortly']\n",
      "AFter tokenizer:  ['whatever', ',', 'juliana', '.', 'do', 'whatever', 'you', 'want', '.']\n",
      "AFter tokenizer:  ['ringtone', 'club', ':', 'gr8', 'new', 'polys', 'direct', 'to', 'your', 'mobile', 'every', 'week', '!']\n",
      "AFter tokenizer:  ['hello', '.', 'sort', 'of', 'out', 'in', 'town', 'already', '.', 'that', '.', 'so', 'dont', 'rush', 'home', ',', 'i', 'am', 'eating', 'nachos', '.', 'will', 'let', 'you', 'know', 'eta', '.']\n",
      "AFter tokenizer:  ['ok', 'lor', '.', 'anyway', 'i', 'thk', 'we', 'cant', 'get', 'tickets', 'now', 'cos', 'like', 'quite', 'late', 'already', '.', 'u', 'wan', '2', 'go', 'look', '4', 'ur', 'frens', 'a', 'not', '?', 'darren', 'is', 'wif', 'them', 'now', '...']\n",
      "AFter tokenizer:  ['(', 'bank', 'of', 'granite', 'issues', 'strong-buy', ')', 'explosive', 'pick', 'for', 'our', 'members', '*', '*', '*', '*', '*', 'up', 'over', '300', '%', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', 'nasdaq', 'symbol', 'cdgt', 'that', 'is', 'a', '$', '5.00', 'per', '..']\n",
      "AFter tokenizer:  ['dizzamn', ',', 'aight', 'i', \"'ll\", 'ask', 'my', 'suitemates', 'when', 'i', 'get', 'back']\n",
      "AFter tokenizer:  ['nimbomsons', '.', 'yep', 'phone', 'knows', 'that', 'one', '.', 'obviously', ',', 'cos', 'thats', 'a', 'real', 'word']\n",
      "AFter tokenizer:  ['i', 'love', 'to', 'cuddle', '!', 'i', 'want', 'to', 'hold', 'you', 'in', 'my', 'strong', 'arms', 'right', 'now', '...']\n",
      "AFter tokenizer:  ['r', 'u', 'in', 'this', 'continent', '?']\n",
      "AFter tokenizer:  ['we', \"'ll\", 'you', 'pay', 'over', 'like', '&', 'lt', ';', '#', '&', 'gt', ';', 'yrs', 'so', 'its', 'not', 'too', 'difficult']\n",
      "AFter tokenizer:  ['bored', 'housewives', '!', 'chat', 'n', 'date', 'now', '!', '0871750.77.11', '!', 'bt-national', 'rate', '10p/min', 'only', 'from', 'landlines', '!']\n",
      "AFter tokenizer:  ['we', 'tried', 'to', 'call', 'you', 're', 'your', 'reply', 'to', 'our', 'sms', 'for', 'a', 'video', 'mobile', '750', 'mins', 'unlimited', 'text', 'free', 'camcorder', 'reply', 'or', 'call', 'now', '08000930705', 'del', 'thurs']\n",
      "AFter tokenizer:  ['k', '...', 'k', '...', 'when', 'will', 'you', 'give', 'treat', '?']\n",
      "AFter tokenizer:  ['this', 'is', 'the', '2nd', 'time', 'we', 'have', 'tried', 'to', 'contact', 'u.', 'u', 'have', 'won', 'the', '£400', 'prize', '.', '2', 'claim', 'is', 'easy', ',', 'just', 'call', '087104711148', 'now', '!', 'only', '10p', 'per', 'minute', '.', 'bt-national-rate']\n",
      "AFter tokenizer:  ['he', \"'s\", 'just', 'gon', 'na', 'worry', 'for', 'nothing', '.', 'and', 'he', 'wo', \"n't\", 'give', 'you', 'money', 'its', 'no', 'use', '.']\n",
      "AFter tokenizer:  ['did', 'you', 'get', 'any', 'gift', '?', 'this', 'year', 'i', 'didnt', 'get', 'anything', '.', 'so', 'bad']\n",
      "AFter tokenizer:  ['well', 'there', \"'s\", 'a', 'pattern', 'emerging', 'of', 'my', 'friends', 'telling', 'me', 'to', 'drive', 'up', 'and', 'come', 'smoke', 'with', 'them', 'and', 'then', 'telling', 'me', 'that', 'i', \"'m\", 'a', 'weed', 'fiend/make', 'them', 'smoke', 'too', 'much/impede', 'their', 'doing', 'other', 'things', 'so', 'you', 'see', 'how', 'i', \"'m\", 'hesitant']\n",
      "AFter tokenizer:  [',', 'ow', 'u', 'dey.i', 'paid', '60,400thousad.i', 'told', 'u', 'would', 'call', '.']\n",
      "AFter tokenizer:  ['im', 'fine', 'babes', 'aint', 'been', 'up', '2', 'much', 'tho', '!', 'saw', 'scary', 'movie', 'yest', 'its', 'quite', 'funny', '!', 'want', '2mrw', 'afternoon', '?', 'at', 'town', 'or', 'mall', 'or', 'sumthin', '?', 'xx']\n",
      "AFter tokenizer:  ['i', \"'m\", 'reaching', 'home', 'in', '5', 'min', '.']\n",
      "AFter tokenizer:  ['forgot', 'you', 'were', 'working', 'today', '!', 'wan', 'na', 'chat', ',', 'but', 'things', 'are', 'ok', 'so', 'drop', 'me', 'a', 'text', 'when', 'you', \"'re\", 'free', '/', 'bored', 'etc', 'and', 'i', \"'ll\", 'ring', '.', 'hope', 'all', 'is', 'well', ',', 'nose', 'essay', 'and', 'all', 'xx']\n",
      "AFter tokenizer:  ['ha', '...', 'then', 'we', 'must', 'walk', 'to', 'everywhere', '...', 'can', 'not', 'take', 'tram', '.', 'my', 'cousin', 'said', 'can', 'walk', 'to', 'vic', 'market', 'from', 'our', 'hotel']\n",
      "AFter tokenizer:  ['discussed', 'with', 'your', 'mother', 'ah', '?']\n",
      "AFter tokenizer:  ['sorry', ',', 'i', 'ca', \"n't\", 'text', '&', 'amp', ';', 'drive', 'coherently', ',', 'see', 'you', 'in', 'twenty']\n",
      "AFter tokenizer:  ['you', 'will', 'be', 'receiving', 'this', 'week', \"'s\", 'triple', 'echo', 'ringtone', 'shortly', '.', 'enjoy', 'it', '!']\n",
      "AFter tokenizer:  ['in', 'which', 'place', 'i', 'can', 'get', 'rooms', 'cheap', ':', '-', ')']\n",
      "AFter tokenizer:  ['eek', 'that', \"'s\", 'a', 'lot', 'of', 'time', 'especially', 'since', 'american', 'pie', 'is', 'like', '8', 'minutes', 'long', '.', 'i', 'ca', \"n't\", 'stop', 'singing', 'it', '.']\n",
      "AFter tokenizer:  ['gran', 'onlyfound', 'out', 'afew', 'days', 'ago.cusoon', 'honi']\n",
      "AFter tokenizer:  ['u', \"'ve\", 'been', 'selected', 'to', 'stay', 'in', '1', 'of', '250', 'top', 'british', 'hotels', '-', 'for', 'nothing', '!', 'holiday', 'valued', 'at', '£350', '!', 'dial', '08712300220', 'to', 'claim', '-', 'national', 'rate', 'call', '.', 'bx526', ',', 'sw73ss']\n",
      "AFter tokenizer:  ['university', 'of', 'southern', 'california', '.']\n",
      "AFter tokenizer:  ['we', 'have', 'to', 'pick', 'rayan', 'macleran', 'there', '.']\n",
      "AFter tokenizer:  ['u', 'gd', 'lor', 'go', 'shopping', 'i', 'got', 'stuff', 'to', 'do', '.', 'u', 'wan', '2', 'watch', 'infernal', 'affairs', 'a', 'not', '?', 'come', 'lar', '...']\n",
      "AFter tokenizer:  ['well', '.', 'balls', '.', 'time', 'to', 'make', 'calls']\n",
      "AFter tokenizer:  ['wat', 'time', 'ü', 'wan', 'today', '?']\n",
      "AFter tokenizer:  ['&', 'lt', ';', '#', '&', 'gt', ';', 'in', 'mca', '.', 'but', 'not', 'conform', '.']\n",
      "AFter tokenizer:  ['oh', 'ok', '..', 'wat', \"'s\", 'ur', 'email', '?']\n",
      "AFter tokenizer:  ['yes', ',', 'princess', '.', 'are', 'you', 'going', 'to', 'make', 'me', 'moan', '?']\n",
      "AFter tokenizer:  ['lol', 'its', 'ok', 'i', 'did', \"n't\", 'remember', 'til', 'last', 'nite']\n",
      "AFter tokenizer:  ['[', '…', ']', 'anyway', ',', 'many', 'good', 'evenings', 'to', 'u', '!', 's']\n",
      "AFter tokenizer:  ['cool', ',', 'i', \"'ll\", 'text', 'you', 'in', 'a', 'few']\n",
      "AFter tokenizer:  ['sorry', 'vikky', ',', 'i', \"'m\", 'watching', 'olave', 'mandara', 'movie', 'kano', 'in', 'trishul', 'theatre', 'wit', 'my', 'frnds', '..']\n",
      "AFter tokenizer:  ['i', \"'m\", 'very', 'happy', 'for', 'you', 'babe', '!', 'woo', 'hoo', 'party', 'on', 'dude', '!']\n",
      "AFter tokenizer:  ['i', 'am', 'taking', 'you', 'for', 'italian', 'food', '.', 'how', 'about', 'a', 'pretty', 'dress', 'with', 'no', 'panties', '?', ':', ')']\n",
      "AFter tokenizer:  ['wot', 'u', 'up', '2', '?', 'thout', 'u', 'were', 'gon', 'na', 'call', 'me', '!', '!', 'txt', 'bak', 'luv', 'k']\n",
      "AFter tokenizer:  ['you', 'are', 'chosen', 'to', 'receive', 'a', '£350', 'award', '!', 'pls', 'call', 'claim', 'number', '09066364311', 'to', 'collect', 'your', 'award', 'which', 'you', 'are', 'selected', 'to', 'receive', 'as', 'a', 'valued', 'mobile', 'customer', '.']\n",
      "AFter tokenizer:  ['how', 'are', 'you', 'holding', 'up', '?']\n",
      "AFter tokenizer:  ['dont', 'flatter', 'yourself', '...', 'tell', 'that', 'man', 'of', 'mine', 'two', 'pints', 'of', 'carlin', 'in', 'ten', 'minutes', 'please', '....']\n",
      "AFter tokenizer:  ['hope', 'you', 'are', 'not', 'scared', '!']\n",
      "AFter tokenizer:  ['i', \"'m\", 'at', 'home', 'n', 'ready', '...']\n",
      "AFter tokenizer:  ['what', 'time', 'do', 'u', 'get', 'out', '?']\n",
      "AFter tokenizer:  ['i', 'am', 'literally', 'in', 'bed', 'and', 'have', 'been', 'up', 'for', 'like', '&', 'lt', ';', '#', '&', 'gt', ';', 'hours']\n",
      "AFter tokenizer:  ['yes', ',', 'my', 'reg', 'is', 'ciao', '!']\n",
      "AFter tokenizer:  ['if', 'you', 'mean', 'the', 'website', '.', 'yes', '.']\n",
      "AFter tokenizer:  ['win', 'a', '£1000', 'cash', 'prize', 'or', 'a', 'prize', 'worth', '£5000']\n",
      "AFter tokenizer:  ['thanks', 'for', 'your', 'ringtone', 'order', ',', 'reference', 'number', 'x49.your', 'mobile', 'will', 'be', 'charged', '4.50.', 'should', 'your', 'tone', 'not', 'arrive', 'please', 'call', 'customer', 'services', '09065989182']\n",
      "AFter tokenizer:  ['lol', 'or', 'i', 'could', 'just', 'starve', 'and', 'lose', 'a', 'pound', 'by', 'the', 'end', 'of', 'the', 'day', '.']\n",
      "AFter tokenizer:  ['yeah', 'that', \"'s\", 'the', 'impression', 'i', 'got']\n",
      "AFter tokenizer:  ['ok', 'ok', 'take', 'care', '.', 'i', 'can', 'understand', '.']\n",
      "AFter tokenizer:  ['motivate', 'behind', 'every', 'darkness', ',', 'there', 'is', 'a', 'shining', 'light', 'waiting', 'for', 'you', 'to', 'find', 'it', '...', 'behind', 'every', 'best', 'friend', ',', 'there', 'is', 'always', 'trust', 'and', 'love', '...', 'bslvyl']\n",
      "AFter tokenizer:  ['ya', 'ok', ',', 'then', 'had', 'dinner', '?']\n",
      "AFter tokenizer:  ['i', 'was', 'slept', 'that', 'time.you', 'there', '?']\n",
      "AFter tokenizer:  ['dont', 'make', 'ne', 'plans', 'for', 'nxt', 'wknd', 'coz', 'she', 'wants', 'us', 'to', 'come', 'down', 'then', 'ok']\n",
      "AFter tokenizer:  ['when', 'is', 'school', 'starting', '.', 'where', 'will', 'you', 'stay', '.', 'what', \"'s\", 'the', 'weather', 'like', '.', 'and', 'the', 'food', '.', 'do', 'you', 'have', 'a', 'social', 'support', 'system', 'like', 'friends', 'in', 'the', 'school', '.', 'all', 'these', 'things', 'are', 'important', '.']\n",
      "AFter tokenizer:  ['ha', 'ha', 'nan', 'yalrigu', 'heltini', '..', 'iyo', 'kothi', 'chikku', ',', 'u', 'shared', 'many', 'things', 'wit', 'me', '..', 'so', 'far', 'i', 'did', \"n't\", 'told', 'any', 'body', 'and', 'even', 'uttered', 'a', 'word', 'abt', 'u', '..', 'if', 'ur', 'trusting', 'me', 'so', 'much', 'how', 'can', 'i', 'tell', 'these', 'to', 'others', '..', 'plz', 'nxt', 'time', 'dont', 'use', 'those', 'words', 'to', 'me', '..', 'ok', ',', 'chikku', ':', '-', ')', ';', '-', ')', 'b-', ')']\n",
      "AFter tokenizer:  ['noice', '.', 'text', 'me', 'when', 'you', \"'re\", 'here']\n",
      "AFter tokenizer:  ['hi', 'di', 'is', 'yijue', 'we', \"'re\", 'meeting', 'at', '7', 'pm', 'at', 'esaplanade', 'tonight', '.']\n",
      "AFter tokenizer:  ['moby', 'pub', 'quiz.win', 'a', '£100', 'high', 'street', 'prize', 'if', 'u', 'know', 'who', 'the', 'new', 'duchess', 'of', 'cornwall', 'will', 'be', '?', 'txt', 'her', 'first', 'name', 'to', '82277.unsub', 'stop', '£1.50', '008704050406', 'sp']\n",
      "AFter tokenizer:  ['this', 'weeks', 'savamob', 'member', 'offers', 'are', 'now', 'accessible', '.', 'just', 'call', '08709501522', 'for', 'details', '!', 'savamob', ',', 'pobox', '139', ',', 'la3', '2wu', '.', 'only', '£1.50/week', '.', 'savamob', '-', 'offers', 'mobile', '!']\n",
      "AFter tokenizer:  ['aight', 'i', \"'ve\", 'been', 'set', 'free', ',', 'think', 'you', 'could', 'text', 'me', 'blake', \"'s\", 'address', '?', 'it', 'occurs', 'to', 'me', 'i', \"'m\", 'not', 'quite', 'as', 'sure', 'what', 'i', \"'m\", 'doing', 'as', 'i', 'thought', 'i', 'was']\n",
      "AFter tokenizer:  ['hi', 'dear', 'we', 'saw', 'dear', '.', 'we', 'both', 'are', 'happy', '.', 'where', 'you', 'my', 'battery', 'is', 'low']\n",
      "AFter tokenizer:  ['how', 'are', 'you', '.', 'its', 'been', 'ages', '.', 'how', \"'s\", 'abj']\n",
      "AFter tokenizer:  ['prof', ':', 'you', 'have', 'passed', 'in', 'all', 'the', 'papers', 'in', 'this', 'sem', 'congrats', '.', '.', '.', '.', 'student', ':', 'enna', 'kalaachutaarama', '..', '!', '!', 'prof', ':', '?', '?', '?', '?', 'gud', 'mrng', '!']\n",
      "AFter tokenizer:  ['dont', 'kick', 'coco', 'when', 'he', \"'s\", 'down']\n",
      "AFter tokenizer:  ['fyi', 'i', \"'m\", 'gon', 'na', 'call', 'you', 'sporadically', 'starting', 'at', 'like', '&', 'lt', ';', '#', '&', 'gt', ';', 'bc', 'we', 'are', 'not', 'not', 'doin', 'this', 'shit']\n",
      "AFter tokenizer:  ['you', 'are', 'being', 'contacted', 'by', 'our', 'dating', 'service', 'by', 'someone', 'you', 'know', '!', 'to', 'find', 'out', 'who', 'it', 'is', ',', 'call', 'from', 'your', 'mobile', 'or', 'landline', '09064017305', 'pobox75ldns7']\n",
      "AFter tokenizer:  ['tbs/persolvo', '.', 'been', 'chasing', 'us', 'since', 'sept', 'for£38', 'definitely', 'not', 'paying', 'now', 'thanks', 'to', 'your', 'information', '.', 'we', 'will', 'ignore', 'them', '.', 'kath', '.', 'manchester', '.']\n",
      "AFter tokenizer:  ['hope', 'you\\x92re', 'not', 'having', 'too', 'much', 'fun', 'without', 'me', '!', '!', 'see', 'u', 'tomorrow', 'love', 'jess', 'x']\n",
      "AFter tokenizer:  ['ok', 'i', 'wont', 'call', 'or', 'disturb', 'any', 'one', '.', 'i', 'know', 'all', 'are', 'avoiding', 'me', '.', 'i', 'am', 'a', 'burden', 'for', 'all']\n",
      "AFter tokenizer:  ['i', \"'ve\", 'reached', 'home', 'n', 'i', 'bathe', 'liao', '...', 'u', 'can', 'call', 'me', 'now', '...']\n",
      "AFter tokenizer:  ['loans', 'for', 'any', 'purpose', 'even', 'if', 'you', 'have', 'bad', 'credit', '!', 'tenants', 'welcome', '.', 'call', 'noworriesloans.com', 'on', '08717111821']\n",
      "AFter tokenizer:  ['was', 'the', 'actual', 'exam', 'harder', 'than', 'nbme']\n",
      "AFter tokenizer:  ['a', 'lot', 'of', 'this', 'sickness', 'thing', 'going', 'round', '.', 'take', 'it', 'easy', '.', 'hope', 'u', 'feel', 'better', 'soon', '.', 'lol']\n",
      "AFter tokenizer:  ['87077', ':', 'kick', 'off', 'a', 'new', 'season', 'with', '2wks', 'free', 'goals', '&', 'news', 'to', 'ur', 'mobile', '!', 'txt', 'ur', 'club', 'name', 'to', '87077', 'eg', 'villa', 'to', '87077']\n",
      "AFter tokenizer:  ['hey', 'sathya', 'till', 'now', 'we', 'dint', 'meet', 'not', 'even', 'a', 'single', 'time', 'then', 'how', 'can', 'i', 'saw', 'the', 'situation', 'sathya', '.']\n",
      "AFter tokenizer:  ['gam', 'gone', 'after', 'outstanding', 'innings', '.']\n",
      "AFter tokenizer:  ['o', 'i', 'played', 'smash', 'bros', '&', 'lt', ';', '#', '&', 'gt', ';', 'religiously', '.']\n",
      "AFter tokenizer:  ['sir', ',', 'good', 'morning', '.', 'hope', 'you', 'had', 'a', 'good', 'weekend', '.', 'i', 'called', 'to', 'let', 'you', 'know', 'that', 'i', 'was', 'able', 'to', 'raise', '&', 'lt', ';', '#', '&', 'gt', ';', 'from', 'my', 'dad', '.', 'he', 'however', 'said', 'he', 'would', 'make', 'the', 'rest', 'available', 'by', 'mid', 'feb.', 'this', 'amount', 'is', 'still', 'quite', 'short', 'and', 'i', 'was', 'hoping', 'you', 'would', 'help', '.', 'do', 'have', 'a', 'good', 'day', '.', 'abiola']\n",
      "AFter tokenizer:  ['hurry', 'home', '.', 'soup', 'is', 'done', '!']\n",
      "AFter tokenizer:  ['good', 'afternoon', ',', 'my', 'love', '.', 'it', 'was', 'good', 'to', 'see', 'your', 'words', 'on', 'ym', 'and', 'get', 'your', 'tm', '.', 'very', 'smart', 'move', ',', 'my', 'slave', '...', '*', 'smiles', '*', '...', 'i', 'drink', 'my', 'coffee', 'and', 'await', 'you', '.']\n",
      "AFter tokenizer:  ['quite', 'ok', 'but', 'a', 'bit', 'ex', '...', 'u', 'better', 'go', 'eat', 'smth', 'now', 'else', 'i', \"'ll\", 'feel', 'guilty', '...']\n",
      "AFter tokenizer:  ['orange', 'brings', 'you', 'ringtones', 'from', 'all', 'time', 'chart', 'heroes', ',', 'with', 'a', 'free', 'hit', 'each', 'week', '!', 'go', 'to', 'ringtones', '&', 'pics', 'on', 'wap', '.', 'to', 'stop', 'receiving', 'these', 'tips', 'reply', 'stop', '.']\n",
      "AFter tokenizer:  ['lem', 'me', 'know', 'when', 'you', \"'re\", 'here']\n",
      "AFter tokenizer:  ['private', '!', 'your', '2003', 'account', 'statement', 'for', '07973788240', 'shows', '800', 'un-redeemed', 's.', 'i.', 'm.', 'points', '.', 'call', '08715203649', 'identifier', 'code', ':', '40533', 'expires', '31/10/04']\n",
      "AFter tokenizer:  ['he', 'needs', 'to', 'stop', 'going', 'to', 'bed', 'and', 'make', 'with', 'the', 'fucking', 'dealing']\n",
      "AFter tokenizer:  ['how', 'are', 'you', ',', 'my', 'love', '?', 'are', 'you', 'with', 'your', 'brother', '?', 'time', 'to', 'talk', 'english', 'with', 'him', '?', '*', 'grins', '*', 'say', ':', 'hey', 'muhommad', ',', 'penny', 'says', 'hello', 'from', 'across', 'the', 'sea']\n",
      "AFter tokenizer:  ['we', 'tried', 'to', 'call', 'you', 're', 'your', 'reply', 'to', 'our', 'sms', 'for', 'a', 'video', 'mobile', '750', 'mins', 'unlimited', 'text', '+', 'free', 'camcorder', 'reply', 'of', 'call', '08000930705', 'now']\n",
      "AFter tokenizer:  ['hey', 'doc', 'pls', 'i', 'want', 'to', 'get', 'nice', 't', 'shirt', 'for', 'my', 'hubby', 'nice', 'fiting', 'ones', 'my', 'budget', 'is', '&', 'lt', ';', '#', '&', 'gt', ';', 'k', 'help', 'pls', 'i', 'will', 'load', 'd', 'card', 'abi', 'hw', ',', 'keep', 'me', 'posted', 'luv', '.', '2', 'mj']\n",
      "AFter tokenizer:  ['i', 'remain', 'unconvinced', 'that', 'this', 'is', \"n't\", 'an', 'elaborate', 'test', 'of', 'my', 'willpower']\n",
      "AFter tokenizer:  ['life', 'is', 'nothing', 'wen', 'v', 'get', 'everything', '.', 'but', '``', 'life', 'is', 'everything', 'wen', 'v', 'miss', 'something', '``', '.', 'real', 'value', 'of', 'people', 'wil', 'be', 'realized', 'only', 'in', 'their', 'absence', '....', 'gud', 'mrng']\n",
      "AFter tokenizer:  ['how', 'are', 'you', '?', 'i', 'miss', 'you', '!']\n",
      "AFter tokenizer:  ['i', 'ai', \"n't\", 'answerin', 'no', 'phone', 'at', 'what', 'is', 'actually', 'a', 'pretty', 'reasonable', 'hour', 'but', 'i', \"'m\", 'sleepy']\n",
      "AFter tokenizer:  ['hey', ',', 'is', '*', 'rite', 'u', 'put', '»', '10', 'evey', 'mnth', 'is', 'that', 'all', '?']\n",
      "AFter tokenizer:  ['i', 'am', 'going', 'to', 'bed', 'now', 'prin']\n",
      "AFter tokenizer:  ['i', 'think', 'just', 'yourself', '…thanks', 'and', 'see', 'you', 'tomo']\n",
      "AFter tokenizer:  ['if', 'u', 'dun', 'drive', 'then', 'how', 'i', 'go', '2', 'sch', '.']\n",
      "AFter tokenizer:  ['i', 'not', 'at', 'home', 'now', 'lei', '...']\n",
      "AFter tokenizer:  ['gsoh', '?', 'good', 'with', 'spam', 'the', 'ladies', '?', 'u', 'could', 'b', 'a', 'male', 'gigolo', '?', '2', 'join', 'the', 'uk', \"'s\", 'fastest', 'growing', 'mens', 'club', 'reply', 'oncall', '.', 'mjzgroup', '.', '08714342399.2stop', 'reply', 'stop', '.', 'msg', '@', '£1.50rcvd']\n",
      "AFter tokenizer:  ['do', 'u', 'hav', 'any', 'frnd', 'by', 'name', 'ashwini', 'in', 'ur', 'college', '?']\n",
      "AFter tokenizer:  ['jus', 'finish', 'my', 'lunch', 'on', 'my', 'way', 'home', 'lor', '...', 'i', 'tot', 'u', 'dun', 'wan', '2', 'stay', 'in', 'sch', 'today', '...']\n",
      "AFter tokenizer:  ['k', 'then', '2marrow', 'are', 'you', 'coming', 'to', 'class', '.']\n",
      "AFter tokenizer:  ['hot', 'live', 'fantasies', 'call', 'now', '08707500020', 'just', '20p', 'per', 'min', 'ntt', 'ltd', ',', 'po', 'box', '1327', 'croydon', 'cr9', '5wb', '0870', 'is', 'a', 'national', 'rate', 'call']\n",
      "AFter tokenizer:  ['pls', 'send', 'me', 'your', 'address', 'sir', '.']\n",
      "AFter tokenizer:  ['i', 'want', 'to', 'lick', 'your', 'pussy', 'now', '...']\n",
      "AFter tokenizer:  ['yo', ',', 'you', 'gon', 'na', 'still', 'be', 'in', 'stock', 'tomorrow/today', '?', 'i', \"'m\", 'trying', 'to', 'get', 'a', 'dubsack']\n",
      "AFter tokenizer:  ['urgent', '!', 'your', 'mobile', 'number', 'has', 'been', 'awarded', 'a', '<', 'ukp', '>', '2000', 'prize', 'guaranteed', '.', 'call', '09061790125', 'from', 'landline', '.', 'claim', '3030.', 'valid', '12hrs', 'only', '150ppm']\n",
      "AFter tokenizer:  ['i', \"'ll\", 'see', ',', 'but', 'prolly', 'yeah']\n",
      "AFter tokenizer:  ['thought', 'we', 'could', 'go', 'out', 'for', 'dinner', '.', 'i', \"'ll\", 'treat', 'you', '!', 'seem', 'ok', '?']\n",
      "AFter tokenizer:  ['where', 'are', 'you', '?', 'what', 'do', 'you', 'do', '?', 'how', 'can', 'you', 'stand', 'to', 'be', 'away', 'from', 'me', '?', 'does', \"n't\", 'your', 'heart', 'ache', 'without', 'me', '?', 'do', \"n't\", 'you', 'wonder', 'of', 'me', '?', 'do', \"n't\", 'you', 'crave', 'me', '?']\n",
      "AFter tokenizer:  ['sorry', '.', 'you', 'never', 'hear', 'unless', 'you', 'book', 'it', '.', 'one', 'was', 'kinda', 'a', 'joke', '--', 'thet', 'were', 'really', 'looking', 'for', 'skinny', 'white', 'girls', '.', 'the', 'other', 'was', 'one', 'line', '--', 'you', 'can', 'only', 'do', 'so', 'much', 'on', 'camera', 'with', 'that', '.', 'something', 'like', 'that', 'they', \"'re\", 'casting', 'on', 'the', 'look', '.']\n",
      "AFter tokenizer:  ['sure', 'thing', 'big', 'man', '.', 'i', 'have', 'hockey', 'elections', 'at', '6', ',', 'shouldn', '‘', 't', 'go', 'on', 'longer', 'than', 'an', 'hour', 'though']\n",
      "AFter tokenizer:  ['watch', 'lor', '.', 'i', 'saw', 'a', 'few', 'swatch', 'one', 'i', 'thk', 'quite', 'ok.', 'ard', '116', 'but', 'i', 'need', '2nd', 'opinion', 'leh', '...']\n",
      "AFter tokenizer:  ['hiya', 'do', 'u', 'like', 'the', 'hlday', 'pics', 'looked', 'horrible', 'in', 'them', 'so', 'took', 'mo', 'out', '!', 'hows', 'the', 'camp', 'amrca', 'thing', '?', 'speak', 'soon', 'serena', ':', ')']\n",
      "AFter tokenizer:  ['babe', '!', 'how', 'goes', 'that', 'day', '?', 'what', 'are', 'you', 'up', 'to', '?', 'i', 'miss', 'you', 'already', ',', 'my', 'love', '...', '*', 'loving', 'kiss', '*', '...', 'i', 'hope', 'everything', 'goes', 'well', '.']\n",
      "AFter tokenizer:  ['yunny', '...', 'i', \"'m\", 'goin', 'to', 'be', 'late']\n",
      "AFter tokenizer:  ['doc', 'prescribed', 'me', 'morphine', 'cause', 'the', 'other', 'pain', 'meds', 'are', \"n't\", 'enough', '.', 'waiting', 'for', 'my', 'mom', 'to', 'bring', 'it', '.', 'that', 'med', 'should', 'kick', 'in', 'fast', 'so', 'i', \"'m\", 'gon', 'na', 'try', 'to', 'be', 'on', 'later']\n",
      "AFter tokenizer:  ['cool', ',', 'want', 'me', 'to', 'go', 'to', 'kappa', 'or', 'should', 'i', 'meet', 'you', 'outside', 'mu']\n",
      "AFter tokenizer:  ['hey', 'sexy', 'buns', '!', 'have', 'i', 'told', 'you', '?', 'i', 'adore', 'you', ',', 'loverboy', '.', 'i', 'hope', 'you', 'remember', 'to', 'thank', 'your', 'sister', 'in', 'law', 'for', 'those', 'meatballs', '*', 'grins', '*', '...', 'i', 'love', 'you', ',', 'babe']\n",
      "AFter tokenizer:  ['may', 'b', 'approve', 'panalam', '...', 'but', 'it', 'should', 'have', 'more', 'posts', '..']\n",
      "AFter tokenizer:  ['spjanuary', 'male', 'sale', '!', 'hot', 'gay', 'chat', 'now', 'cheaper', ',', 'call', '08709222922.', 'national', 'rate', 'from', '1.5p/min', 'cheap', 'to', '7.8p/min', 'peak', '!', 'to', 'stop', 'texts', 'call', '08712460324', '(', '10p/min', ')']\n",
      "AFter tokenizer:  ['me', 'i', \"'m\", 'not', 'workin', '.', 'once', 'i', 'get', 'job', '...']\n",
      "AFter tokenizer:  ['and', 'by', 'when', 'you', \"'re\", 'done', 'i', 'mean', 'now']\n",
      "AFter tokenizer:  ['its', 'ur', 'luck', 'to', 'love', 'someone', '.', 'its', 'ur', 'fortune', 'to', 'love', 'the', 'one', 'who', 'loves', 'u.', 'but', ',', 'its', 'a', 'miracle', 'to', 'love', 'a', 'person', 'who', 'ca', \"n't\", 'love', 'anyone', 'except', 'u', '...', 'gud', 'nyt', '...']\n",
      "AFter tokenizer:  ['hi', 'baby', 'ive', 'just', 'got', 'back', 'from', 'work', 'and', 'i', 'was', 'wanting', 'to', 'see', 'u', 'allday', '!', 'i', 'hope', 'i', 'didnt', 'piss', 'u', 'off', 'on', 'the', 'phone', 'today', '.', 'if', 'u', 'are', 'up', 'give', 'me', 'a', 'call', 'xxx']\n",
      "AFter tokenizer:  ['freemsg', 'today', \"'s\", 'the', 'day', 'if', 'you', 'are', 'ready', '!', 'i', \"'m\", 'horny', '&', 'live', 'in', 'your', 'town', '.', 'i', 'love', 'sex', 'fun', '&', 'games', '!', 'netcollex', 'ltd', '08700621170150p', 'per', 'msg', 'reply', 'stop', 'to', 'end']\n",
      "AFter tokenizer:  ['is', 'it', 'your', 'yahoo', 'boys', 'that', 'bring', 'in', 'the', 'perf', '?', 'or', 'legal', '.']\n",
      "AFter tokenizer:  ['no', 'need', 'to', 'say', 'anything', 'to', 'me', '.', 'i', 'know', 'i', 'am', 'an', 'outsider']\n",
      "AFter tokenizer:  ['have', 'you', 'ever', 'had', 'one', 'foot', 'before', '?']\n",
      "AFter tokenizer:  ['just', 'got', 'to', '&', 'lt', ';', '#', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['good', '!', 'no', ',', 'don', '‘', 't', 'need', 'any', 'receipts—well', 'done', '!', '(', '…', ')', 'yes', ',', 'please', 'tell', '.', 'what', '‘', 's', 'her', 'number', ',', 'i', 'could', 'ring', 'her']\n",
      "AFter tokenizer:  ['leave', 'it', 'wif', 'me', 'lar', '...', 'ü', 'wan', 'to', 'carry', 'meh', 'so', 'heavy', '...', 'is', 'da', 'num', '98321561', 'familiar', 'to', 'ü', '?']\n",
      "AFter tokenizer:  ['beautiful', 'truth', ':', 'expression', 'of', 'the', 'face', 'could', 'be', 'seen', 'by', 'everyone', '...', 'but', 'the', 'depression', 'of', 'heart', 'could', 'be', 'understood', 'only', 'by', 'the', 'loved', 'ones', '..', 'gud', 'ni8', ';', '-', ')']\n",
      "AFter tokenizer:  ['infact', 'happy', 'new', 'year', '.', 'how', 'are', 'you', 'where', 'are', 'you', 'when', 'are', 'we', 'seeing']\n",
      "AFter tokenizer:  ['in', 'the', 'simpsons', 'movie', 'released', 'in', 'july', '2007', 'name', 'the', 'band', 'that', 'died', 'at', 'the', 'start', 'of', 'the', 'film', '?', 'a-green', 'day', ',', 'b-blue', 'day', ',', 'c-red', 'day', '.', '(', 'send', 'a', ',', 'b', 'or', 'c', ')']\n",
      "AFter tokenizer:  ['that', \"'s\", 'a', 'shame', '!', 'maybe', 'cld', 'meet', 'for', 'few', 'hrs', 'tomo', '?']\n",
      "AFter tokenizer:  ['lol', 'i', 'would', 'but', 'despite', 'these', 'cramps', 'i', 'like', 'being', 'a', 'girl', '.']\n",
      "AFter tokenizer:  ['i', 'can\\x92t', 'wait', 'for', 'cornwall', '.', 'hope', 'tonight', 'isn\\x92t', 'too', 'bad', 'as', 'well', 'but', 'it\\x92s', 'rock', 'night', 'shite', '.', 'anyway', 'i\\x92m', 'going', 'for', 'a', 'kip', 'now', 'have', 'a', 'good', 'night', '.', 'speak', 'to', 'you', 'soon', '.']\n",
      "AFter tokenizer:  ['pls', 'help', 'me', 'tell', 'sura', 'that', 'i', \"'m\", 'expecting', 'a', 'battery', 'from', 'hont', '.', 'and', 'that', 'if', 'should', 'pls', 'send', 'me', 'a', 'message', 'about', 'how', 'to', 'download', 'movies', '.', 'thanks']\n",
      "AFter tokenizer:  ['please', 'call', 'amanda', 'with', 'regard', 'to', 'renewing', 'or', 'upgrading', 'your', 'current', 't-mobile', 'handset', 'free', 'of', 'charge', '.', 'offer', 'ends', 'today', '.', 'tel', '0845', '021', '3680', 'subject', 'to', 't', \"'s\", 'and', 'c', \"'s\"]\n",
      "AFter tokenizer:  ['have', \"n't\", 'found', 'a', 'way', 'to', 'get', 'another', 'app', 'for', 'your', 'phone', ',', 'eh', '?', 'will', 'you', 'go', 'to', 'the', 'net', 'cafe', '?', 'did', 'you', 'take', 'that', 'job', '?', 'geeee', 'i', 'need', 'you', 'babe', '.', 'i', 'crave', 'to', 'see', 'you', '...']\n",
      "AFter tokenizer:  ['i', 'only', 'work', 'from', 'mon', 'to', 'thurs', 'but', 'sat', 'i', 'cant', 'leh', '...', 'booked', 'liao', '...', 'which', 'other', 'day', 'u', 'free', '?']\n",
      "AFter tokenizer:  ['ü', 'comin', 'to', 'fetch', 'us', 'oredi', '...']\n",
      "AFter tokenizer:  ['what', \"'s\", 'nannys', 'address', '?']\n",
      "AFter tokenizer:  ['haf', 'u', 'eaten', '?', 'wat', 'time', 'u', 'wan', 'me', '2', 'come', '?']\n",
      "AFter tokenizer:  ['want', 'a', 'new', 'video', 'phone', '?', '750', 'anytime', 'any', 'network', 'mins', '?', 'half', 'price', 'line', 'rental', 'free', 'text', 'for', '3', 'months', '?', 'reply', 'or', 'call', '08000930705', 'for', 'free', 'delivery']\n",
      "AFter tokenizer:  ['yo', ',', 'call', 'me', 'when', 'you', 'get', 'the', 'chance', ',', 'a', 'friend', 'of', 'mine', 'wanted', 'me', 'to', 'ask', 'you', 'about', 'a', 'big', 'order']\n",
      "AFter tokenizer:  ['this', 'single', 'single', 'answers', 'are', 'we', 'fighting', '?', 'plus', 'i', 'said', 'am', 'broke', 'and', 'you', 'didnt', 'reply']\n",
      "AFter tokenizer:  ['it', 'certainly', 'puts', 'things', 'into', 'perspective', 'when', 'something', 'like', 'this', 'happens']\n",
      "AFter tokenizer:  ['now', 'got', 'tv', '2', 'watch', 'meh', '?', 'u', 'no', 'work', 'today', '?']\n",
      "AFter tokenizer:  ['i', 'felt', 'so', '...', 'not', 'any', 'conveying', 'reason', '..', 'ese', 'he', '...', 'what', 'about', 'me', '?']\n",
      "AFter tokenizer:  ['how', \"'s\", 'it', 'going', '?', 'got', 'any', 'exciting', 'karaoke', 'type', 'activities', 'planned', '?', 'i', \"'m\", 'debating', 'whether', 'to', 'play', 'football', 'this', 'eve', '.', 'feeling', 'lazy', 'though', '.']\n",
      "AFter tokenizer:  ['i', 'told', 'that', 'am', 'coming', 'on', 'wednesday', '.']\n",
      "AFter tokenizer:  ['its', 'ok', ',', 'called', 'mom', 'instead', 'have', 'fun']\n",
      "AFter tokenizer:  ['dear', 'voucher', 'holder', ',', 'to', 'claim', 'this', 'weeks', 'offer', ',', 'at', 'your', 'pc', 'please', 'go', 'to', 'http', ':', '//www.wtlp.co.uk/text', '.', 'ts', '&', 'cs', 'apply', '.']\n",
      "AFter tokenizer:  ['well', 'if', 'i', \"'m\", 'that', 'desperate', 'i', \"'ll\", 'just', 'call', 'armand', 'again']\n",
      "AFter tokenizer:  ['are', 'you', 'at', 'work', 'right', 'now', '?']\n",
      "AFter tokenizer:  ['have', \"n't\", 'heard', 'anything', 'and', 'he', \"'s\", 'not', 'answering', 'my', 'texts', 'so', 'i', \"'m\", 'guessing', 'he', 'flaked', '.', 'that', 'said', 'the', 'jb', 'is', 'fantastic']\n",
      "AFter tokenizer:  ['mmmmmm', '...', 'i', 'love', 'you', ',', 'so', 'much', ',', 'ahmad', '...', 'i', 'ca', \"n't\", 'wait', 'for', 'this', 'year', 'to', 'begin', 'as', 'every', 'second', 'takes', 'me', 'closer', 'to', 'being', 'at', 'your', 'side', '.', 'happy', 'new', 'year', ',', 'my', 'love', '!', '!']\n",
      "AFter tokenizer:  ['pls', 'what', \"'s\", 'the', 'full', 'name', 'of', 'joke', \"'s\", 'school', 'cos', 'fees', 'in', 'university', 'of', 'florida', 'seem', 'to', 'actually', 'be', '&', 'lt', ';', '#', '&', 'gt', ';', 'k.', 'pls', 'holla', 'back']\n",
      "AFter tokenizer:  ['ok', '...', 'but', 'they', 'said', 'i', \"'ve\", 'got', 'wisdom', 'teeth', 'hidden', 'inside', 'n', 'mayb', 'need', '2', 'remove', '.']\n",
      "AFter tokenizer:  ['and', 'pls', 'pls', 'drink', 'plenty', 'plenty', 'water']\n",
      "AFter tokenizer:  ['how', 'are', 'you', 'doing', '.', 'how', \"'s\", 'the', 'queen', '.', 'are', 'you', 'going', 'for', 'the', 'royal', 'wedding']\n",
      "AFter tokenizer:  ['he', \"'s\", 'in', 'lag', '.', 'that', \"'s\", 'just', 'the', 'sad', 'part', 'but', 'we', 'keep', 'in', 'touch', 'thanks', 'to', 'skype']\n",
      "AFter tokenizer:  ['ok', 'lor', 'then', 'we', 'go', 'tog', 'lor', '...']\n",
      "AFter tokenizer:  ['two', 'teams', 'waiting', 'for', 'some', 'players']\n",
      "AFter tokenizer:  ['can', 'ü', 'send', 'me', 'a', 'copy', 'of', 'da', 'report', '?']\n",
      "AFter tokenizer:  ['swhrt', 'how', 'u', 'dey', ',', 'hope', 'ur', 'ok', ',', 'tot', 'about', 'u', '2day.love', 'n', 'miss.take', 'care', '.']\n",
      "AFter tokenizer:  ['ok', 'da', ',', 'i', 'already', 'planned', '.', 'i', 'wil', 'pick', 'you', '.']\n",
      "AFter tokenizer:  ['urgent', '!', 'please', 'call', '0906346330.', 'your', 'abta', 'complimentary', '4', '*', 'spanish', 'holiday', 'or', '£10,000', 'cash', 'await', 'collection', 'sae', 't', '&', 'cs', 'box', '47', 'po19', '2ez', '150ppm', '18+']\n",
      "AFter tokenizer:  ['i', 'just', 'really', 'need', 'shit', 'before', 'tomorrow', 'and', 'i', 'know', 'you', 'wo', \"n't\", 'be', 'awake', 'before', 'like', '6']\n",
      "AFter tokenizer:  ['i', \"'m\", 'good', '.', 'have', 'you', 'registered', 'to', 'vote', '?']\n",
      "AFter tokenizer:  ['hmm', 'ok', ',', 'i', \"'ll\", 'stay', 'for', 'like', 'an', 'hour', 'cos', 'my', 'eye', 'is', 'really', 'sore', '!']\n",
      "AFter tokenizer:  ['dear', 'got', 'bus', 'directly', 'to', 'calicut']\n",
      "AFter tokenizer:  ['mm', 'umma', 'ask', 'vava', 'also', 'to', 'come', 'tell', 'him', 'can', 'play', 'later', 'together']\n",
      "AFter tokenizer:  ['well', 'the', 'general', 'price', 'is', '&', 'lt', ';', '#', '&', 'gt', ';', '/oz', ',', 'let', 'me', 'know', 'if/when/how', 'much', 'you', 'want']\n",
      "AFter tokenizer:  ['each', 'moment', 'in', 'a', 'day', ',', 'has', 'its', 'own', 'value-morning', 'brings', 'hope', ',', 'afternoon', 'brings', 'faith', ',', 'evening', 'brings', 'luv', ',', 'night', 'brings', 'rest', ',', 'wish', 'u', 'find', 'them', 'all', 'today.good', 'morning']\n",
      "AFter tokenizer:  ['&', 'lt', ';', '#', '&', 'gt', ';', 'w', 'jetton', 'ave', 'if', 'you', 'forgot']\n",
      "AFter tokenizer:  ['ok', 'i', \"'m\", 'coming', 'home', 'now', '.']\n",
      "AFter tokenizer:  ['can', 'not', 'use', 'foreign', 'stamps', 'in', 'this', 'country', '.']\n",
      "AFter tokenizer:  ['sorry', ',', 'it', \"'s\", 'a', 'lot', 'of', 'friend-of-a-friend', 'stuff', ',', 'i', \"'m\", 'just', 'now', 'about', 'to', 'talk', 'to', 'the', 'actual', 'guy', 'who', 'wants', 'to', 'buy']\n",
      "AFter tokenizer:  ['cmon', 'babe', ',', 'make', 'me', 'horny', ',', '*', 'turn', '*', 'me', 'on', '!', 'txt', 'me', 'your', 'fantasy', 'now', 'babe', '-', ')', 'im', 'hot', ',', 'sticky', 'and', 'need', 'you', 'now', '.', 'all', 'replies', 'cost', '£1.50', '.', '2', 'cancel', 'send', 'stop']\n",
      "AFter tokenizer:  ['wylie', 'update', ':', 'my', 'weed', 'dealer', 'carlos', 'went', 'to', 'freedom', 'and', 'had', 'a', 'class', 'with', 'lunsford']\n",
      "AFter tokenizer:  ['are', 'you', 'happy', 'baby', '?', 'are', 'you', 'alright', '?', 'did', 'you', 'take', 'that', 'job', '?', 'i', 'hope', 'your', 'fine', '.', 'i', 'send', 'you', 'a', 'kiss', 'to', 'make', 'you', 'smile', 'from', 'across', 'the', 'sea', '...', '*', 'kiss', '*', '*', 'kiss', '*']\n",
      "AFter tokenizer:  ['c', 'movie', 'is', 'juz', 'last', 'minute', 'decision', 'mah', '.', 'juz', 'watch', '2', 'lar', 'but', 'i', 'tot', 'ü', 'not', 'interested', '.']\n",
      "AFter tokenizer:  ['how', 'are', 'you', 'enjoying', 'this', 'semester', '?', 'take', 'care', 'brother', '.']\n",
      "AFter tokenizer:  ['important', 'information', '4', 'orange', 'user', '0796xxxxxx', '.', 'today', 'is', 'ur', 'lucky', 'day', '!', '2', 'find', 'out', 'why', 'log', 'onto', 'http', ':', '//www.urawinner.com', 'there', \"'s\", 'a', 'fantastic', 'prizeawaiting', 'you', '!']\n",
      "AFter tokenizer:  ['get', 'the', 'door', ',', 'i', \"'m\", 'here']\n",
      "AFter tokenizer:  ['lets', 'use', 'it', 'next', 'week', ',', 'princess', ':', ')']\n",
      "AFter tokenizer:  ['or', 'i', 'go', 'home', 'first', 'lar', 'ü', 'wait', '4', 'me', 'lor', '..', 'i', 'put', 'down', 'my', 'stuff', 'first', '..']\n",
      "AFter tokenizer:  ['i', 'want', 'kfc', 'its', 'tuesday', '.', 'only', 'buy', '2', 'meals', 'only', '2.', 'no', 'gravy', '.', 'only', '2', 'mark', '.', '2', '!']\n",
      "AFter tokenizer:  ['no', 'da', ':', ')', 'he', 'is', 'stupid', 'da', '..', 'always', 'sending', 'like', 'this', ':', ')', 'don', 'believe', 'any', 'of', 'those', 'message.pandy', 'is', 'a', 'mental', ':', ')']\n",
      "AFter tokenizer:  ['oi', 'when', 'you', 'gon', 'na', 'ring']\n",
      "AFter tokenizer:  ['missed', 'call', 'alert', '.', 'these', 'numbers', 'called', 'but', 'left', 'no', 'message', '.', '07008009200']\n",
      "AFter tokenizer:  ['i', 'attended', 'but', 'nothing', 'is', 'there', '.']\n",
      "AFter tokenizer:  ['ard', '530', 'like', 'dat', 'lor', '.', 'we', 'juz', 'meet', 'in', 'mrt', 'station', 'then', 'ü', 'dun', 'haf', 'to', 'come', 'out', '.']\n",
      "AFter tokenizer:  ['no', 'dear', 'i', 'was', 'sleeping', ':', '-p']\n",
      "AFter tokenizer:  ['er', 'mw', 'im', 'filled', 'tuth', 'is', 'aight']\n",
      "AFter tokenizer:  ['will', 'be', 'office', 'around', '4', 'pm', '.', 'now', 'i', 'am', 'going', 'hospital', '.']\n",
      "AFter tokenizer:  ['actually', 'i', \"'m\", 'waiting', 'for', '2', 'weeks', 'when', 'they', 'start', 'putting', 'ad', '.']\n",
      "AFter tokenizer:  ['anything', 'lor', 'if', 'they', 'all', 'go', 'then', 'i', 'go', 'lor', '...']\n",
      "AFter tokenizer:  ['u', 'free', 'on', 'sat', 'rite', '?', 'u', 'wan', '2', 'watch', 'infernal', 'affairs', 'wif', 'me', 'n', 'darren', 'n', 'mayb', 'xy', '?']\n",
      "AFter tokenizer:  ['yo', 'you', 'around', '?', 'a', 'friend', 'of', 'mine', \"'s\", 'lookin', 'to', 'pick', 'up', 'later', 'tonight']\n",
      "AFter tokenizer:  ['stupid', 'auto', 'correct', 'on', 'my', 'phone']\n",
      "AFter tokenizer:  ['double', 'eviction', 'this', 'week', '-', 'spiral', 'and', 'michael', 'and', 'good', 'riddance', 'to', 'them', '!']\n",
      "AFter tokenizer:  ['the', 'world', 'suffers', 'a', 'lot', '...', 'not', 'because', 'of', 'the', 'violence', 'of', 'bad', 'people', '.', 'but', 'because', 'of', 'the', 'silence', 'of', 'good', 'people', '!', ',', 'gud', 'night', '....']\n",
      "AFter tokenizer:  ['ok', 'thats', 'cool', '.', 'its', ',', 'just', 'off', 'either', 'raglan', 'rd', 'or', 'edward', 'rd', '.', 'behind', 'the', 'cricket', 'ground', '.', 'gim', 'me', 'ring', 'when', 'ur', 'closeby', 'see', 'you', 'tuesday', '.']\n",
      "AFter tokenizer:  ['buy', 'one', 'egg', 'for', 'me', 'da', '..', 'please', ':', ')']\n",
      "AFter tokenizer:  ['have', 'you', 'started', 'in', 'skye']\n",
      "AFter tokenizer:  ['have', 'you', 'bookedthe', 'hut', '?', 'and', 'also', 'your', 'time', 'off', '?', 'how', 'are', 'you', 'by', 'the', 'way', '?']\n",
      "AFter tokenizer:  ['and', 'several', 'to', 'you', 'sir', '.']\n",
      "AFter tokenizer:  ['u', 'really', 'pig', 'leh', 'sleep', 'so', 'much', '.', 'my', 'dad', 'wake', 'me', 'up', 'at', '10', 'smth', '2', 'eat', 'lunch', 'today', '.']\n",
      "AFter tokenizer:  ['my', 'love', '...', 'i', 'hope', 'your', 'not', 'doing', 'anything', 'drastic', '.', 'do', \"n't\", 'you', 'dare', 'sell', 'your', 'pc', 'or', 'your', 'phone', '...']\n",
      "AFter tokenizer:  ['freemsg', ':', 'our', 'records', 'indicate', 'you', 'may', 'be', 'entitled', 'to', '3750', 'pounds', 'for', 'the', 'accident', 'you', 'had', '.', 'to', 'claim', 'for', 'free', 'reply', 'with', 'yes', 'to', 'this', 'msg', '.', 'to', 'opt', 'out', 'text', 'stop']\n",
      "AFter tokenizer:  ['life', 'style', 'garments', 'account', 'no', 'please', '.']\n",
      "AFter tokenizer:  ['lol', 'wtf', 'random', '.', 'btw', 'is', 'that', 'your', 'lunch', 'break']\n",
      "AFter tokenizer:  ['sez', ',', 'hows', 'u', '&', 'de', 'arab', 'boy', '?', 'hope', 'u', 'r', 'all', 'good', 'give', 'my', 'love', '2', 'evry1', 'love', 'ya', 'eshxxxxxxxxxxx']\n",
      "AFter tokenizer:  ['the', 'lay', 'man', '!', 'just', 'to', 'let', 'you', 'know', 'you', 'are', 'missed', 'and', 'thought', 'off', '.', 'do', 'have', 'a', 'great', 'day', '.', 'and', 'if', 'you', 'can', 'send', 'me', 'bimbo', 'and', 'ugo', \"'s\", 'numbers', ',', 'ill', 'appreciate', '.', 'safe']\n",
      "AFter tokenizer:  ['detroit', '.', 'the', 'home', 'of', 'snow', '.', 'enjoy', 'it', '.']\n",
      "AFter tokenizer:  ['show', 'ur', 'colours', '!', 'euro', '2004', '2-4-1', 'offer', '!', 'get', 'an', 'england', 'flag', '&', '3lions', 'tone', 'on', 'ur', 'phone', '!', 'click', 'on', 'the', 'following', 'service', 'message', 'for', 'info', '!']\n",
      "AFter tokenizer:  ['aight', ',', 'i', \"'m\", 'chillin', 'in', 'a', 'friend', \"'s\", 'room', 'so', 'text', 'me', 'when', 'you', \"'re\", 'on', 'the', 'way']\n",
      "AFter tokenizer:  ['is', 'toshiba', 'portege', 'm100', 'gd', '?']\n",
      "AFter tokenizer:  ['well', 'welp', 'is', 'sort', 'of', 'a', 'semiobscure', 'internet', 'thing']\n",
      "AFter tokenizer:  ['text', 'pass', 'to', '69669', 'to', 'collect', 'your', 'polyphonic', 'ringtones', '.', 'normal', 'gprs', 'charges', 'apply', 'only', '.', 'enjoy', 'your', 'tones']\n",
      "AFter tokenizer:  ['accordingly', '.', 'i', 'repeat', ',', 'just', 'text', 'the', 'word', 'ok', 'on', 'your', 'mobile', 'phone', 'and', 'send']\n",
      "AFter tokenizer:  ['loosu', 'go', 'to', 'hospital', '.', 'de', 'dont', 'let', 'it', 'careless', '.']\n",
      "AFter tokenizer:  ['how', 'much', 'for', 'an', 'eighth', '?']\n",
      "AFter tokenizer:  ['omg', 'joanna', 'is', 'freaking', 'me', 'out', '.', 'she', \"'s\", 'looked', 'thru', 'all', 'my', 'friends', 'to', 'find', 'photos', 'of', 'me', '.', 'and', 'then', 'she', \"'s\", 'asking', 'about', 'stuff', 'on', 'my', 'myspace', 'which', 'i', 'have', \"n't\", 'even', 'logged', 'on', 'in', 'like', 'a', 'year', '.', ':', '/']\n",
      "AFter tokenizer:  ['send', 'ur', 'birthdate', 'with', 'month', 'and', 'year', ',', 'i', 'will', 'tel', 'u', 'ur', 'life', 'partner', \"'s\", 'name', '.', 'and', 'the', 'method', 'of', 'calculation', '.', 'reply', 'must', '.']\n",
      "AFter tokenizer:  ['juz', 'now', 'havent', 'woke', 'up', 'so', 'a', 'bit', 'blur', 'blur', '...', 'can', '?', 'dad', 'went', 'out', 'liao', '...', 'i', 'cant', 'cum', 'now', 'oso', '...']\n",
      "AFter tokenizer:  ['how', 'about', 'clothes', ',', 'jewelry', ',', 'and', 'trips', '?']\n",
      "AFter tokenizer:  ['block', 'breaker', 'now', 'comes', 'in', 'deluxe', 'format', 'with', 'new', 'features', 'and', 'great', 'graphics', 'from', 't-mobile', '.', 'buy', 'for', 'just', '£5', 'by', 'replying', 'get', 'bbdeluxe', 'and', 'take', 'the', 'challenge']\n",
      "AFter tokenizer:  ['aah', '!', 'a', 'cuddle', 'would', 'be', 'lush', '!', 'i', \"'d\", 'need', 'lots', 'of', 'tea', 'and', 'soup', 'before', 'any', 'kind', 'of', 'fumbling', '!']\n",
      "AFter tokenizer:  ['important', 'information', '4', 'orange', 'user', '.', 'today', 'is', 'your', 'lucky', 'day', '!', '2find', 'out', 'why', 'log', 'onto', 'http', ':', '//www.urawinner.com', 'there', \"'s\", 'a', 'fantastic', 'surprise', 'awaiting', 'you', '!']\n",
      "AFter tokenizer:  ['are', 'you', 'plans', 'with', 'your', 'family', 'set', 'in', 'stone', '?']\n",
      "AFter tokenizer:  ['pls', 'dont', 'forget', 'to', 'study']\n",
      "AFter tokenizer:  ['you', \"'ll\", 'never', 'believe', 'this', 'but', 'i', 'have', 'actually', 'got', 'off', 'at', 'taunton', '.', 'wow']\n",
      "AFter tokenizer:  ['den', 'only', 'weekdays', 'got', 'special', 'price', '...', 'haiz', '...', 'cant', 'eat', 'liao', '...', 'cut', 'nails', 'oso', 'muz', 'wait', 'until', 'i', 'finish', 'drivin', 'wat', ',', 'lunch', 'still', 'muz', 'eat', 'wat', '...']\n",
      "AFter tokenizer:  ['she', 'just', 'broke', 'down', 'a', 'list', 'of', 'reasons', 'why', 'nobody', \"'s\", 'in', 'town', 'and', 'i', 'ca', \"n't\", 'tell', 'if', 'she', \"'s\", 'being', 'sarcastic', 'or', 'just', 'faggy']\n",
      "AFter tokenizer:  ['&', 'lt', ';', 'decimal', '&', 'gt', ';', 'm', 'but', 'its', 'not', 'a', 'common', 'car', 'here', 'so', 'its', 'better', 'to', 'buy', 'from', 'china', 'or', 'asia', '.', 'or', 'if', 'i', 'find', 'it', 'less', 'expensive', '.', 'i.ll', 'holla']\n",
      "AFter tokenizer:  ['the', 'greatest', 'test', 'of', 'courage', 'on', 'earth', 'is', 'to', 'bear', 'defeat', 'without', 'losing', 'heart', '....', 'gn', 'tc']\n",
      "AFter tokenizer:  ['sorry', 'im', 'stil', 'fucked', 'after', 'last', 'nite', 'went', 'tobed', 'at', '430', 'got', 'up', '4', 'work', 'at', '630']\n",
      "AFter tokenizer:  ['hey', 'so', 'whats', 'the', 'plan', 'this', 'sat', '?']\n",
      "AFter tokenizer:  ['beauty', 'sleep', 'can', 'help', 'ur', 'pimples', 'too', '.']\n",
      "AFter tokenizer:  ['great', '.', 'hope', 'you', 'are', 'using', 'your', 'connections', 'from', 'mode', 'men', 'also', 'cos', 'you', 'can', 'never', 'know', 'why', 'old', 'friends', 'can', 'lead', 'you', 'to', 'today']\n",
      "AFter tokenizer:  ['natalja', '(', '25/f', ')', 'is', 'inviting', 'you', 'to', 'be', 'her', 'friend', '.', 'reply', 'yes-440', 'or', 'no-440', 'see', 'her', ':', 'www.sms.ac/u/nat27081980', 'stop', '?', 'send', 'stop', 'frnd', 'to', '62468']\n",
      "AFter tokenizer:  ['where', 'to', 'get', 'those', '?']\n",
      "AFter tokenizer:  ['kind', 'of', '.', 'just', 'missed', 'train', 'cos', 'of', 'asthma', 'attack', ',', 'nxt', 'one', 'in', 'half', 'hr', 'so', 'driving', 'in', '.', 'not', 'sure', 'where', 'to', 'park', '.']\n",
      "AFter tokenizer:  ['ball', 'is', 'moving', 'a', 'lot.will', 'spin', 'in', 'last', ':', ')', 'so', 'very', 'difficult', 'to', 'bat', ':', ')']\n",
      "AFter tokenizer:  ['haiyoh', '...', 'maybe', 'your', 'hamster', 'was', 'jealous', 'of', 'million']\n",
      "AFter tokenizer:  ['can', 'you', 'please', 'send', 'me', 'my', 'aunty', \"'s\", 'number']\n",
      "AFter tokenizer:  ['i', \"'m\", 'glad', '.', 'you', 'are', 'following', 'your', 'dreams', '.']\n",
      "AFter tokenizer:  ['i', \"'ve\", 'reached', 'home', 'finally', '...']\n",
      "AFter tokenizer:  ['urgent', '.', 'important', 'information', 'for', '02', 'user', '.', 'today', 'is', 'your', 'lucky', 'day', '!', '2', 'find', 'out', 'why', ',', 'log', 'onto', 'http', ':', '//www.urawinner.com', 'there', 'is', 'a', 'fantastic', 'surprise', 'awaiting', 'you', '!']\n",
      "AFter tokenizer:  ['wn', 'u', 'r', 'hurt', 'by', 'd', 'prsn', 'who', 's', 'close', '2', 'u', ',', 'do', 'fight', 'wit', 'dem', '.', 'coz', 'somtimes', 'dis', 'fight', 'saves', 'a', 'relation', 'bt', 'being', 'quiet', 'leaves', 'nothin', 'in', 'a', 'relation', '..', 'gud', 'eveb-', ')']\n",
      "AFter tokenizer:  ['u', 'can', 'call', 'now', '...']\n",
      "AFter tokenizer:  ['science', 'tells', 'that', 'chocolate', 'will', 'melt', 'under', 'the', 'sunlight', '.', 'please', 'do', \"n't\", 'walk', 'under', 'the', 'sunlight', '.', 'bcoz', ',', 'i', 'do', \"n't\", 'want', 'to', 'loss', 'a', 'sweet', 'friend', '.']\n",
      "AFter tokenizer:  ['yes', '.', 'i', 'come', 'to', 'nyc', 'for', 'audiitions', 'and', 'am', 'trying', 'to', 'relocate', '.']\n",
      "AFter tokenizer:  ['i', 'pocked', 'you', 'up', 'there', 'before']\n",
      "AFter tokenizer:  ['congrats', '.', 'that', \"'s\", 'great', '.', 'i', 'wanted', 'to', 'tell', 'you', 'not', 'to', 'tell', 'me', 'your', 'score', 'cos', 'it', 'might', 'make', 'me', 'relax', '.', 'but', 'its', 'motivating', 'me', 'so', 'thanks', 'for', 'sharing']\n",
      "AFter tokenizer:  ['i', 'wud', 'never', 'mind', 'if', 'u', 'dont', 'miss', 'me', 'or', 'if', 'u', 'dont', 'need', 'me', '..', 'but', 'u', 'wil', 'really', 'hurt', 'me', 'wen', 'u', 'need', 'me', '&', 'amp', ';', 'u', 'dont', 'tell', 'me', '.........', 'take', 'care', ':', '-', ')']\n",
      "AFter tokenizer:  ['hey', 'mr', 'whats', 'the', 'name', 'of', 'that', 'bill', 'brison', 'book', 'the', 'one', 'about', 'language', 'and', 'words']\n",
      "AFter tokenizer:  ['okay', ',', 'good', ',', 'no', 'problem', ',', 'and', 'thanx', '!']\n",
      "AFter tokenizer:  ['for', 'you', 'information', ',', 'ikea', 'is', 'spelled', 'with', 'all', 'caps', '.', 'that', 'is', 'not', 'yelling', '.', 'when', 'you', 'thought', 'i', 'had', 'left', 'you', ',', 'you', 'were', 'sitting', 'on', 'the', 'bed', 'among', 'the', 'mess', 'when', 'i', 'came', 'in', '.', 'i', 'said', 'we', 'were', 'going', 'after', 'you', 'got', 'home', 'from', 'class', '.', 'please', 'do', \"n't\", 'try', 'and', 'bullshit', 'me', '.', 'it', 'makes', 'me', 'want', 'to', 'listen', 'to', 'you', 'less', '.']\n",
      "AFter tokenizer:  ['call', 'me', 'when', 'u', \"'re\", 'done', '...']\n",
      "AFter tokenizer:  ['g.w.r']\n",
      "AFter tokenizer:  ['you', 'best', 'watch', 'what', 'you', 'say', 'cause', 'i', 'get', 'drunk', 'as', 'a', 'motherfucker']\n",
      "AFter tokenizer:  ['kit', 'strip', '-', 'you', 'have', 'been', 'billed', '150p', '.', 'netcollex', 'ltd.', 'po', 'box', '1013', 'ig11', 'oja']\n",
      "AFter tokenizer:  ['please', 'call', '08712402578', 'immediately', 'as', 'there', 'is', 'an', 'urgent', 'message', 'waiting', 'for', 'you']\n",
      "AFter tokenizer:  ['thesmszone.com', 'lets', 'you', 'send', 'free', 'anonymous', 'and', 'masked', 'messages', '..', 'im', 'sending', 'this', 'message', 'from', 'there', '..', 'do', 'you', 'see', 'the', 'potential', 'for', 'abuse', '?', '?', '?']\n",
      "AFter tokenizer:  ['erm', '...', 'woodland', 'avenue', 'somewhere', '.', 'do', 'you', 'get', 'the', 'parish', 'magazine', ',', 'his', 'telephone', 'number', 'will', 'be', 'in', 'there', '.']\n",
      "AFter tokenizer:  ['are', 'there', 'ta', 'jobs', 'available', '?', 'let', 'me', 'know', 'please', 'cos', 'i', 'really', 'need', 'to', 'start', 'working']\n",
      "AFter tokenizer:  ['aiyar', 'hard', '2', 'type', '.', 'u', 'later', 'free', 'then', 'tell', 'me', 'then', 'i', 'call', 'n', 'scold', 'n', 'tell', 'u', '.']\n",
      "AFter tokenizer:  ['yup', 'i', \"'m\", 'free', '...']\n",
      "AFter tokenizer:  ['good', 'good', ',', 'billy', 'mates', 'all', 'gone', '.', 'just', 'been', 'jogging', ',', 'again', '!', 'did', 'enjoy', 'concert', '?']\n",
      "AFter tokenizer:  ['yo', 'come', 'over', 'carlos', 'will', 'be', 'here', 'soon']\n",
      "AFter tokenizer:  ['awww', 'dat', 'is', 'sweet', '!', 'we', 'can', 'think', 'of', 'something', 'to', 'do', 'he', 'he', '!', 'have', 'a', 'nice', 'time', 'tonight', 'ill', 'probably', 'txt', 'u', 'later', 'cos', 'im', 'lonely', ':', '(', 'xxx', '.']\n",
      "AFter tokenizer:  ['i', 'guess', 'it', 'is', 'useless', 'calling', 'u', '4', 'something', 'important', '.']\n",
      "AFter tokenizer:  ['ha', 'ha', '-', 'had', 'popped', 'down', 'to', 'the', 'loo', 'when', 'you', 'hello-ed', 'me', '.', 'hello', '!']\n",
      "AFter tokenizer:  ['he', 'dint', 'tell', 'anything', '.', 'he', 'is', 'angry', 'on', 'me', 'that', 'why', 'you', 'told', 'to', 'abi', '.']\n",
      "AFter tokenizer:  ['it', 'so', 'happens', 'that', 'there', 'r', '2waxsto', 'do', 'wat', 'you', 'want', '.', 'she', 'can', 'come', 'and', 'ill', 'get', 'her', 'medical', 'insurance', '.', 'and', 'she', \"'ll\", 'be', 'able', 'to', 'deliver', 'and', 'have', 'basic', 'care', '.', 'i', \"'m\", 'currently', 'shopping', 'for', 'the', 'right', 'medical', 'insurance', 'for', 'her', '.', 'so', 'just', 'give', 'me', 'til', 'friday', 'morning', '.', 'thats', 'when', 'i.ll', 'see', 'the', 'major', 'person', 'that', 'can', 'guide', 'me', 'to', 'the', 'right', 'insurance', '.']\n",
      "AFter tokenizer:  ['i', 'keep', 'ten', 'rs', 'in', 'my', 'shelf', ':', ')', 'buy', 'two', 'egg', '.']\n",
      "AFter tokenizer:  ['i', 'was', \"n't\", 'well', 'babe', ',', 'i', 'have', 'swollen', 'glands', 'at', 'my', 'throat', '...', 'what', 'did', 'you', 'end', 'up', 'doing', '?']\n",
      "AFter tokenizer:  ['is', 'ur', 'changes', '2', 'da', 'report', 'big', '?', 'cos', 'i', \"'ve\", 'already', 'made', 'changes', '2', 'da', 'previous', 'report', '.']\n",
      "AFter tokenizer:  ['captain', 'is', 'in', 'our', 'room', ':', ')']\n",
      "AFter tokenizer:  ['i', 'ca', \"n't\", 'speak', ',', 'bcaz', 'mobile', 'have', 'problem', '.', 'i', 'can', 'listen', 'you', 'but', 'you', 'can', \"n't\", 'listen', 'my', 'voice', '.', 'so', 'i', 'calls', 'you', 'later', '.']\n",
      "AFter tokenizer:  ['hiya', 'stu', 'wot', 'u', 'up', '2.im', 'in', 'so', 'much', 'truble', 'at', 'home', 'at', 'moment', 'evone', 'hates', 'me', 'even', 'u', '!', 'wot', 'the', 'hell', 'av', 'i', 'done', 'now', '?', 'y', 'wont', 'u', 'just', 'tell', 'me', 'text', 'bck', 'please', 'luv', 'dan']\n",
      "AFter tokenizer:  ['s', '...', 'i', 'will', 'take', 'mokka', 'players', 'only', ':', ')']\n",
      "AFter tokenizer:  ['are', 'you', 'still', 'playing', 'with', 'gautham', '?']\n",
      "AFter tokenizer:  ['hey', 'mr', 'and', 'i', 'are', 'going', 'to', 'the', 'sea', 'view', 'and', 'having', 'a', 'couple', 'of', 'gays', 'i', 'mean', 'games', '!', 'give', 'me', 'a', 'bell', 'when', 'ya', 'finish']\n",
      "AFter tokenizer:  ['k', ',', 'jason', 'says', 'he', \"'s\", 'gon', 'na', 'be', 'around', 'so', 'i', \"'ll\", 'be', 'up', 'there', 'around', '&', 'lt', ';', '#', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['sorry', '.', 'i', 'will', 'be', 'able', 'to', 'get', 'to', 'you', '.', 'see', 'you', 'in', 'the', 'morning', '.']\n",
      "AFter tokenizer:  ['aight', 'well', 'keep', 'me', 'informed']\n",
      "AFter tokenizer:  ['am', 'only', 'searching', 'for', 'good', 'dual', 'sim', 'mobile', 'pa', '.']\n",
      "AFter tokenizer:  ['that', 'seems', 'unnecessarily', 'hostile']\n",
      "AFter tokenizer:  ['dude', 'got', 'a', 'haircut', '.', 'now', 'its', 'breezy', 'up', 'there']\n",
      "AFter tokenizer:  ['congrats', '!', '2', 'mobile', '3g', 'videophones', 'r', 'yours', '.', 'call', '09061744553', 'now', '!', 'videochat', 'wid', 'ur', 'mates', ',', 'play', 'java', 'games', ',', 'dload', 'polyh', 'music', ',', 'noline', 'rentl', '.', 'bx420', '.', 'ip4', '.', '5we', '.', '150pm']\n",
      "AFter tokenizer:  ['1apple/day=no', 'doctor', '.', '1tulsi', 'leaf/day=no', 'cancer', '.', '1lemon/day=no', 'fat', '.', '1cup', 'milk/day=no', 'bone', 'problms', '3', 'litres', 'watr/day=no', 'diseases', 'snd', 'ths', '2', 'whom', 'u', 'care', '..', ':', '-', ')']\n",
      "AFter tokenizer:  ['i', 'thought', 'we', 'were', 'doing', 'a', 'king', 'of', 'the', 'hill', 'thing', 'there', '.']\n",
      "AFter tokenizer:  ['nope', 'i', \"'ll\", 'come', 'online', 'now', '..']\n",
      "AFter tokenizer:  ['also', 'tell', 'him', 'i', 'said', 'happy', 'birthday']\n",
      "AFter tokenizer:  ['y', 'bishan', 'lei', '...', 'i', 'tot', 'ü', 'say', 'lavender', '?']\n",
      "AFter tokenizer:  ['boo', 'what', 'time', 'u', 'get', 'out', '?', 'u', 'were', 'supposed', 'to', 'take', 'me', 'shopping', 'today', '.', ':', '(']\n",
      "AFter tokenizer:  ['now', 'u', 'sound', 'like', 'manky', 'scouse', 'boy', 'steve', ',', 'like', '!', 'i', 'is', 'travelling', 'on', 'da', 'bus', 'home.wot', 'has', 'u', 'inmind', '4', 'recreation', 'dis', 'eve', '?']\n",
      "AFter tokenizer:  ['fyi', 'i', \"'m\", 'taking', 'a', 'quick', 'shower', ',', 'be', 'at', 'epsilon', 'in', 'like', '&', 'lt', ';', '#', '&', 'gt', ';', 'min']\n",
      "AFter tokenizer:  ['on', 'a', 'tuesday', 'night', 'r', 'u', '4', 'real']\n",
      "AFter tokenizer:  ['yes', 'when', 'is', 'the', 'appt', 'again', '?']\n",
      "AFter tokenizer:  ['just', 'got', 'outta', 'class', 'gon', 'na', 'go', 'gym', '.']\n",
      "AFter tokenizer:  ['i', 'want', 'to', 'sent', '&', 'lt', ';', '#', '&', 'gt', ';', 'mesages', 'today', '.', 'thats', 'y.', 'sorry', 'if', 'i', 'hurts']\n",
      "AFter tokenizer:  ['ü', 'all', 'write', 'or', 'wat', '..']\n",
      "AFter tokenizer:  ['ha', '!', 'i', 'would', \"n't\", 'say', 'that', 'i', 'just', 'did', \"n't\", 'read', 'anything', 'into', 'way', 'u', 'seemed', '.', 'i', 'do', \"n't\", 'like', '2', 'be', 'judgemental', '....', 'i', 'save', 'that', 'for', 'fridays', 'in', 'the', 'pub', '!']\n",
      "AFter tokenizer:  ['its', 'a', 'valentine', 'game', '.', '.', '.', 'send', 'dis', 'msg', 'to', 'all', 'ur', 'friends', '.', '.', 'if', '5', 'answers', 'r', 'd', 'same', 'then', 'someone', 'really', 'loves', 'u.', '.', 'ques-', 'which', 'colour', 'suits', 'me', 'the', 'best', '?']\n",
      "AFter tokenizer:  ['hi', ':', ')', 'did', 'you', 'asked', 'to', 'waheeda', 'fathima', 'about', 'leave', '?']\n",
      "AFter tokenizer:  ['enjoy', 'urself', 'tmr', '...']\n",
      "AFter tokenizer:  ['you', 'still', 'around', '?', 'i', 'could', 'use', 'a', 'half-8th']\n",
      "AFter tokenizer:  ['you', 'give', 'us', 'back', 'my', 'id', 'proof', 'and', '&', 'lt', ';', '#', '&', 'gt', ';', 'rs', '.', 'we', 'wont', 'allow', 'you', 'to', 'work', '.', 'we', 'will', 'come', 'to', 'your', 'home', 'within', 'days']\n",
      "AFter tokenizer:  ['ü', 'bot', 'notes', 'oredi', '...', 'cos', 'i', 'juz', 'rem', 'i', 'got', '...']\n",
      "AFter tokenizer:  ['yes', '.', 'rent', 'is', 'very', 'expensive', 'so', 'its', 'the', 'way', 'we', 'save', '.']\n",
      "AFter tokenizer:  ['hows', 'the', 'pain', 'dear', '?', 'y', 'r', 'u', 'smiling', '?']\n",
      "AFter tokenizer:  ['fun', 'fact', ':', 'although', 'you', 'would', 'think', 'armand', 'would', 'eventually', 'build', 'up', 'a', 'tolerance', 'or', 'some', 'shit', 'considering', 'how', 'much', 'he', 'smokes', ',', 'he', 'gets', 'fucked', 'up', 'in', 'like', '2', 'hits']\n",
      "AFter tokenizer:  ['important', 'information', '4', 'orange', 'user', '0789xxxxxxx', '.', 'today', 'is', 'your', 'lucky', 'day', '!', '2find', 'out', 'why', 'log', 'onto', 'http', ':', '//www.urawinner.com', 'there', \"'s\", 'a', 'fantastic', 'surprise', 'awaiting', 'you', '!']\n",
      "AFter tokenizer:  ['great', '.', 'so', 'should', 'i', 'send', 'you', 'my', 'account', 'number', '.']\n",
      "AFter tokenizer:  ['hellogorgeous', ',', 'hows', 'u', '?', 'my', 'fone', 'was', 'on', 'charge', 'lst', 'nitw', 'wen', 'u', 'texd', 'me', '.', 'hopeu', 'ad', 'a', 'nice', 'wkend', 'as', 'im', 'sure', 'u', 'did', 'lookin', '4ward', '2', 'c-in', 'u', '2mrw', 'luv', 'jaz']\n",
      "AFter tokenizer:  ['our', 'dating', 'service', 'has', 'been', 'asked', '2', 'contact', 'u', 'by', 'someone', 'shy', '!', 'call', '09058091870', 'now', 'all', 'will', 'be', 'revealed', '.', 'pobox84', ',', 'm26', '3uz', '150p']\n",
      "AFter tokenizer:  ['ü', 'only', 'send', 'me', 'the', 'contents', 'page', '...']\n",
      "AFter tokenizer:  ['night', 'sweet', ',', 'sleep', 'well', '!', 'i', \"'ve\", 'just', 'been', 'to', 'see', 'the', 'exorcism', 'of', 'emily', 'rose', 'and', 'may', 'never', 'sleep', 'again', '!', 'hugs', 'and', 'snogs', '!']\n",
      "AFter tokenizer:  ['do', \"n't\", 'think', 'about', '``', 'what', 'u', 'have', 'got', \"''\", 'think', 'about', '``', 'how', 'to', 'use', 'it', 'that', 'you', 'have', 'got', \"''\", 'good', 'ni8']\n",
      "AFter tokenizer:  ['i', 'ca', \"n't\", 'right', 'this', 'second', ',', 'got', 'ta', 'hit', 'people', 'up', 'first']\n",
      "AFter tokenizer:  ['evry', 'emotion', 'ds', \"n't\", 'hav', 'words.evry', 'wish', 'ds', \"n't\", 'hav', 'prayrs', '..', 'if', 'u', 'smile', ',', 'd', 'world', 'is', 'wit', 'u.othrwise', 'even', 'd', 'drop', 'of', 'tear', 'ds', \"n't\", 'lik', '2', 'stay', 'wit', 'u.so', 'b', 'happy', '..', 'good', 'morning', ',', 'keep', 'smiling', ':', '-', ')']\n",
      "AFter tokenizer:  ['so', 'what', 'about', 'you', '.', 'what', 'do', 'you', 'remember']\n",
      "AFter tokenizer:  ['ujhhhhhhh', 'computer', 'shipped', 'out', 'with', 'address', 'to', 'sandiago', 'and', 'parantella', 'lane', '.', 'wtf', '.', 'poop', '.']\n",
      "AFter tokenizer:  ['mm', 'yes', 'dear', 'look', 'how', 'i', 'am', 'hugging', 'you', 'both', '.', ':', '-p']\n",
      "AFter tokenizer:  ['i', 'like', 'dis', 'sweater', 'fr', 'mango', 'but', 'no', 'more', 'my', 'size', 'already', 'so', 'irritating', '.']\n",
      "AFter tokenizer:  ['1', 'i', 'do', \"n't\", 'have', 'her', 'number', 'and', '2', 'its', 'gon', 'na', 'be', 'a', 'massive', 'pain', 'in', 'the', 'ass', 'and', 'i', \"'d\", 'rather', 'not', 'get', 'involved', 'if', 'that', \"'s\", 'possible']\n",
      "AFter tokenizer:  ['anytime', 'lor', '...']\n",
      "AFter tokenizer:  ['do', 'you', 'want', 'a', 'new', 'video', 'handset', '?', '750', 'any', 'time', 'any', 'network', 'mins', '?', 'unlimited', 'text', '?', 'camcorder', '?', 'reply', 'or', 'call', 'now', '08000930705', 'for', 'del', 'sat', 'am']\n",
      "AFter tokenizer:  ['ur', 'balance', 'is', 'now', '£600', '.', 'next', 'question', ':', 'complete', 'the', 'landmark', ',', 'big', ',', 'a.', 'bob', ',', 'b.', 'barry', 'or', 'c.', 'ben', '?', '.', 'text', 'a', ',', 'b', 'or', 'c', 'to', '83738.', 'good', 'luck', '!']\n",
      "AFter tokenizer:  ['me', 'fine', '..', 'absolutly', 'fine']\n",
      "AFter tokenizer:  ['k', 'and', 'you', \"'re\", 'sure', 'i', 'do', \"n't\", 'have', 'to', 'have', 'consent', 'forms', 'to', 'do', 'it', ':', 'v']\n",
      "AFter tokenizer:  ['ur', 'tonexs', 'subscription', 'has', 'been', 'renewed', 'and', 'you', 'have', 'been', 'charged', '£4.50', '.', 'you', 'can', 'choose', '10', 'more', 'polys', 'this', 'month', '.', 'www.clubzed.co.uk', '*', 'billing', 'msg', '*']\n",
      "AFter tokenizer:  ['if', 'you', 'do', \"n't\", ',', 'your', 'prize', 'will', 'go', 'to', 'another', 'customer', '.', 't', '&', 'c', 'at', 'www.t-c.biz', '18+', '150p/min', 'polo', 'ltd', 'suite', '373', 'london', 'w1j', '6hl', 'please', 'call', 'back', 'if', 'busy']\n",
      "AFter tokenizer:  ['how', 'much', 'is', 'torch', 'in', '9ja', '.']\n",
      "AFter tokenizer:  ['doing', 'nothing', ',', 'then', 'u', 'not', 'having', 'dinner', 'w', 'us', '?']\n",
      "AFter tokenizer:  ['how', 'are', 'you', '.', 'just', 'checking', 'up', 'on', 'you']\n",
      "AFter tokenizer:  ['done', 'it', 'but', 'internet', 'connection', 'v', 'slow', 'and', 'can', '‘', 't', 'send', 'it', '.', 'will', 'try', 'again', 'later', 'or', 'first', 'thing', 'tomo', '.']\n",
      "AFter tokenizer:  ['mathews', 'or', 'tait', 'or', 'edwards', 'or', 'anderson']\n",
      "AFter tokenizer:  ['yeah', 'sure', 'thing', 'mate', 'haunt', 'got', 'all', 'my', 'stuff', 'sorted', 'but', 'im', 'going', 'sound', 'anyway', 'promoting', 'hex', 'for', '.by', 'the', 'way', 'who', 'is', 'this', '?', 'dont', 'know', 'number', '.', 'joke']\n",
      "AFter tokenizer:  ['no', 'need', 'lar', 'i', 'go', 'engin', '?', 'cos', 'my', 'sis', 'at', 'arts', 'today', '...']\n",
      "AFter tokenizer:  ['thanks', 'honey', 'but', 'still', 'have', \"n't\", 'heard', 'anything', 'i', 'will', 'leave', 'it', 'a', 'bit', 'longer', 'so', 'not', '2', 'crowd', 'him', 'and', 'will', 'try', 'later', '-', 'great', 'advice', 'thanks', 'hope', 'cardiff', 'is', 'still', 'there', '!']\n",
      "AFter tokenizer:  ['do', 'you', 'want', 'a', 'new', 'nokia', '3510i', 'colour', 'phone', 'delivered', 'tomorrow', '?', 'with', '200', 'free', 'minutes', 'to', 'any', 'mobile', '+', '100', 'free', 'text', '+', 'free', 'camcorder', 'reply', 'or', 'call', '8000930705']\n",
      "AFter tokenizer:  [',', 'im', '..', 'on', 'the', 'snowboarding', 'trip', '.', 'i', 'was', 'wondering', 'if', 'your', 'planning', 'to', 'get', 'everyone', 'together', 'befor', 'we', 'go', '..', 'a', 'meet', 'and', 'greet', 'kind', 'of', 'affair', '?', 'cheers', ',']\n",
      "AFter tokenizer:  ['s.i', \"'m\", 'watching', 'it', 'in', 'live', '..']\n",
      "AFter tokenizer:  ['see', 'you', 'then', ',', 'we', \"'re\", 'all', 'christmassy', 'here', '!']\n",
      "AFter tokenizer:  ['k', 'i', \"'m\", 'ready', ',', '&', 'lt', ';', '#', '&', 'gt', ';', '?']\n",
      "AFter tokenizer:  ['what', 'are', 'your', 'new', 'years', 'plans', '?']\n",
      "AFter tokenizer:  ['recpt', '1/3', '.', 'you', 'have', 'ordered', 'a', 'ringtone', '.', 'your', 'order', 'is', 'being', 'processed', '...']\n",
      "AFter tokenizer:  ['baaaaaaaabe', '!', 'wake', 'up', '!', 'i', 'miss', 'you', '!', 'i', 'crave', 'you', '!', 'i', 'need', 'you', '!']\n",
      "AFter tokenizer:  ['only', 'just', 'got', 'this', 'message', ',', 'not', 'ignoring', 'you', '.', 'yes', ',', 'i', 'was', '.', 'shopping', 'that', 'is']\n",
      "AFter tokenizer:  ['dear', ':', '-/', 'why', 'you', 'mood', 'off', '.', 'i', 'cant', 'drive', 'so', 'i', 'brother', 'to', 'drive']\n",
      "AFter tokenizer:  ['when', 'did', 'dad', 'get', 'back', '.']\n",
      "AFter tokenizer:  ['can', 'you', 'tell', 'shola', 'to', 'please', 'go', 'to', 'college', 'of', 'medicine', 'and', 'visit', 'the', 'academic', 'department', ',', 'tell', 'the', 'academic', 'secretary', 'what', 'the', 'current', 'situation', 'is', 'and', 'ask', 'if', 'she', 'can', 'transfer', 'there', '.', 'she', 'should', 'ask', 'someone', 'to', 'check', 'sagamu', 'for', 'the', 'same', 'thing', 'and', 'lautech', '.', 'its', 'vital', 'she', 'completes', 'her', 'medical', 'education', 'in', 'nigeria', '.', 'its', 'less', 'expensive', 'much', 'less', 'expensive', '.', 'unless', 'she', 'will', 'be', 'getting', 'citizen', 'rates', 'in', 'new', 'zealand', '.']\n",
      "AFter tokenizer:  ['yes', 'just', 'finished', 'watching', 'days', 'of', 'our', 'lives', '.', 'i', 'love', 'it', '.']\n",
      "AFter tokenizer:  ['juz', 'go', 'google', 'n', 'search', '4', 'qet', '...']\n",
      "AFter tokenizer:  ['many', 'times', 'we', 'lose', 'our', 'best', 'ones', 'bcoz', 'we', 'are']\n",
      "AFter tokenizer:  ['good', 'friends', 'care', 'for', 'each', 'other', '..', 'close', 'friends', 'understand', 'each', 'other', '...', 'and', 'true', 'friends', 'stay', 'forever', 'beyond', 'words', ',', 'beyond', 'time', '.', 'gud', 'ni8']\n",
      "AFter tokenizer:  ['just', 'getting', 'back', 'home']\n",
      "AFter tokenizer:  ['sorry', ',', 'i', \"'ll\", 'call', 'later', '&', 'lt', ';', '#', '&', 'gt', ';', 'mins']\n",
      "AFter tokenizer:  ['dun', 'need', 'to', 'use', 'dial', 'up', 'juz', 'open', 'da', 'browser', 'n', 'surf', '...']\n",
      "AFter tokenizer:  ['as', 'one', 'of', 'our', 'registered', 'subscribers', 'u', 'can', 'enter', 'the', 'draw', '4', 'a', '100', 'g.b', '.', 'gift', 'voucher', 'by', 'replying', 'with', 'enter', '.', 'to', 'unsubscribe', 'text', 'stop']\n",
      "AFter tokenizer:  ['awesome', ',', 'plan', 'to', 'get', 'here', 'any', 'time', 'after', 'like', '&', 'lt', ';', '#', '&', 'gt', ';', ',', 'i', \"'ll\", 'text', 'you', 'details', 'in', 'a', 'wee', 'bit']\n",
      "AFter tokenizer:  ['take', 'care', 'and', 'sleep', 'well.you', 'need', 'to', 'learn', 'to', 'change', 'in', 'life.you', 'only', 'need', 'to', 'get', 'convinced', 'on', 'that.i', 'will', 'wait', 'but', 'no', 'more', 'conversations', 'between', 'us.get', 'convinced', 'by', 'that', 'time.your', 'family', 'is', 'over', 'for', 'you', 'in', 'many', 'senses.respect', 'them', 'but', 'not', 'overemphasise.or', 'u', 'have', 'no', 'role', 'in', 'my', 'life', '.']\n",
      "AFter tokenizer:  ['for', 'your', 'chance', 'to', 'win', 'a', 'free', 'bluetooth', 'headset', 'then', 'simply', 'reply', 'back', 'with', '``', 'adp', \"''\"]\n",
      "AFter tokenizer:  ['you', 'also', 'didnt', 'get', 'na', 'hi', 'hi', 'hi', 'hi', 'hi']\n",
      "AFter tokenizer:  ['ya', 'but', 'it', 'cant', 'display', 'internal', 'subs', 'so', 'i', 'got', 'ta', 'extract', 'them']\n",
      "AFter tokenizer:  ['if', 'i', 'said', 'anything', 'wrong', 'sorry', 'de', ':', '-', ')']\n",
      "AFter tokenizer:  ['how', 'stupid', 'to', 'say', 'that', 'i', 'challenge', 'god.you', 'dont', 'think', 'at', 'all', 'on', 'what', 'i', 'write', 'instead', 'you', 'respond', 'immed', '.']\n",
      "AFter tokenizer:  ['yeah', 'i', 'should', 'be', 'able', 'to', ',', 'i', \"'ll\", 'text', 'you', 'when', 'i', \"'m\", 'ready', 'to', 'meet', 'up']\n",
      "AFter tokenizer:  ['v', 'skint', 'too', 'but', 'fancied', 'few', 'bevies.waz', 'gona', 'go', 'meet', '&', 'othrs', 'in', 'spoon', 'but', 'jst', 'bin', 'watchng', 'planet', 'earth', '&', 'sofa', 'is', 'v', 'comfey', ';', 'if', 'i', 'dont', 'make', 'it', 'hav', 'gd', 'night']\n",
      "AFter tokenizer:  ['says', 'that', 'he', \"'s\", 'quitting', 'at', 'least5times', 'a', 'day', 'so', 'i', 'wud', \"n't\", 'take', 'much', 'notice', 'of', 'that', '.', 'nah', ',', 'she', 'did', \"n't\", 'mind', '.', 'are', 'you', 'gon', 'na', 'see', 'him', 'again', '?', 'do', 'you', 'want', 'to', 'come', 'to', 'taunton', 'tonight', '?', 'u', 'can', 'tell', 'me', 'all', 'about', '!']\n",
      "AFter tokenizer:  ['when', 'you', 'get', 'free', ',', 'call', 'me']\n",
      "AFter tokenizer:  ['how', 'have', 'your', 'little', 'darlings', 'been', 'so', 'far', 'this', 'week', '?', 'need', 'a', 'coffee', 'run', 'tomo', '?', 'ca', \"n't\", 'believe', 'it', \"'s\", 'that', 'time', 'of', 'week', 'already', '…']\n",
      "AFter tokenizer:  ['still', 'at', 'west', 'coast', '...', 'haiz', '...', 'ü', \"'ll\", 'take', 'forever', 'to', 'come', 'back', '...']\n",
      "AFter tokenizer:  ['mmm', '...', 'fuck', '....', 'merry', 'christmas', 'to', 'me']\n",
      "AFter tokenizer:  ['alright', '.', 'thanks', 'for', 'the', 'advice', '.', 'enjoy', 'your', 'night', 'out', '.', \"i'ma\", 'try', 'to', 'get', 'some', 'sleep', '...']\n",
      "AFter tokenizer:  ['update', 'your', 'face', 'book', 'status', 'frequently', ':', ')']\n",
      "AFter tokenizer:  ['just', 'now', 'saw', 'your', 'message.it', 'k', 'da', ':', ')']\n",
      "AFter tokenizer:  ['was', 'it', 'something', 'u', 'ate', '?']\n",
      "AFter tokenizer:  ['so', 'what', 'did', 'the', 'bank', 'say', 'about', 'the', 'money', '?']\n",
      "AFter tokenizer:  ['aiyar', 'dun', 'disturb', 'u', 'liao', '...', 'thk', 'u', 'have', 'lots', '2', 'do', 'aft', 'ur', 'cupboard', 'come', '...']\n",
      "AFter tokenizer:  ['hey', 'they', 'r', 'not', 'watching', 'movie', 'tonight', 'so', 'i', \"'ll\", 'prob', 'b', 'home', 'early', '...']\n",
      "AFter tokenizer:  ['yar', 'lor', '...', 'how', 'u', 'noe', '?', 'u', 'used', 'dat', 'route', 'too', '?']\n",
      "AFter tokenizer:  ['2mro', 'i', 'am', 'not', 'coming', 'to', 'gym', 'machan', '.', 'goodnight', '.']\n",
      "AFter tokenizer:  ['dont', 'think', 'you', 'need', 'yellow', 'card', 'for', 'uk', 'travel', '.', 'ask', 'someone', 'that', 'has', 'gone', 'before', '.', 'if', 'you', 'do', 'its', 'just', '&', 'lt', ';', '#', '&', 'gt', ';', 'bucks']\n",
      "AFter tokenizer:  ['can', 'u', 'look', '4', 'me', 'in', 'da', 'lib', 'i', 'got', 'stuff', 'havent', 'finish', 'yet', '.']\n",
      "AFter tokenizer:  ['sounds', 'great', '!', 'im', 'going', 'to', 'sleep', 'now', '.', 'have', 'a', 'good', 'night', '!']\n",
      "AFter tokenizer:  ['do', \"n't\", 'b', 'floppy', '...', 'b', 'snappy', '&', 'happy', '!', 'only', 'gay', 'chat', 'service', 'with', 'photo', 'upload', 'call', '08718730666', '(', '10p/min', ')', '.', '2', 'stop', 'our', 'texts', 'call', '08712460324']\n",
      "AFter tokenizer:  ['how', 'come', 'u', 'got', 'nothing', 'to', 'do', '?']\n",
      "AFter tokenizer:  ['nothing', 'will', 'ever', 'be', 'easy', '.', 'but', 'do', \"n't\", 'be', 'looking', 'for', 'a', 'reason', 'not', 'to', 'take', 'a', 'risk', 'on', 'life', 'and', 'love']\n",
      "AFter tokenizer:  ['i', 'want', 'to', 'grasp', 'your', 'pretty', 'booty', ':', ')']\n",
      "AFter tokenizer:  ['i', \"'ve\", 'got', 'it', 'down', 'to', 'a', 'tea', '.', 'not', 'sure', 'which', 'flavour']\n",
      "AFter tokenizer:  ['i', \"'m\", 'going', '2', 'orchard', 'now', 'laready', 'me', 'reaching', 'soon', '.', 'u', 'reaching', '?']\n",
      "AFter tokenizer:  ['dear', 'i', 'am', 'not', 'denying', 'your', 'words', 'please']\n",
      "AFter tokenizer:  ['you', 'know', 'my', 'old', 'dom', 'i', 'told', 'you', 'about', 'yesterday', '?', 'his', 'name', 'is', 'roger', '?', 'he', 'got', 'in', 'touch', 'with', 'me', 'last', 'night', 'and', 'wants', 'me', 'to', 'meet', 'him', 'today', 'at', '2', 'pm']\n",
      "AFter tokenizer:  ['come', 'back', 'to', 'tampa', 'ffffuuuuuuu']\n",
      "AFter tokenizer:  ['2', 'celebrate', 'my', 'b\\x92day', ',', 'y', 'else', '?']\n",
      "AFter tokenizer:  ['merry', 'christmas', 'to', 'u', 'too', 'annie', '!']\n",
      "AFter tokenizer:  ['please', 'tell', 'me', 'you', 'have', 'some', 'of', 'that', 'special', 'stock', 'you', 'were', 'talking', 'about']\n",
      "AFter tokenizer:  ['i', 'sent', 'them', '.', 'do', 'you', 'like', '?']\n",
      "AFter tokenizer:  ['awesome', ',', 'be', 'there', 'in', 'a', 'minute']\n",
      "AFter tokenizer:  ['and', 'that', 'is', 'the', 'problem', '.', 'you', 'walk', 'around', 'in', '``', 'julianaland', \"''\", 'oblivious', 'to', 'what', 'is', 'going', 'on', 'around', 'you', '.', 'i', 'say', 'the', 'same', 'things', 'constantly', 'and', 'they', 'go', 'in', 'one', 'ear', 'and', 'out', 'the', 'other', 'while', 'you', 'go', 'off', 'doing', 'whatever', 'you', 'want', 'to', 'do', '.', 'it', \"'s\", 'not', 'that', 'you', 'do', \"n't\", 'know', 'why', 'i', \"'m\", 'upset', '--', 'it', \"'s\", 'that', 'you', 'do', \"n't\", 'listen', 'when', 'i', 'tell', 'you', 'what', 'is', 'going', 'to', 'upset', 'me', '.', 'then', 'you', 'want', 'to', 'be', 'surprised', 'when', 'i', \"'m\", 'mad', '.']\n",
      "AFter tokenizer:  ['i', \"'ve\", 'told', 'you', 'everything', 'will', 'stop', '.', 'just', 'dont', 'let', 'her', 'get', 'dehydrated', '.']\n",
      "AFter tokenizer:  ['or', 'i', 'guess', '&', 'lt', ';', '#', '&', 'gt', ';', 'min']\n",
      "AFter tokenizer:  ['i', \"'m\", 'home', '.', 'ard', 'wat', 'time', 'will', 'u', 'reach', '?']\n",
      "AFter tokenizer:  ['if', 'you', 'want', 'to', 'mapquest', 'it', 'or', 'something', 'look', 'up', '``', 'usf', 'dogwood', 'drive', \"''\", ',', 'that', \"'s\", 'the', 'tiny', 'street', 'where', 'the', 'parking', 'lot', 'is']\n",
      "AFter tokenizer:  ['aight', 'should', 'i', 'just', 'plan', 'to', 'come', 'up', 'later', 'tonight', '?']\n",
      "AFter tokenizer:  ['die', '...', 'i', 'accidentally', 'deleted', 'e', 'msg', 'i', 'suppose', '2', 'put', 'in', 'e', 'sim', 'archive', '.', 'haiz', '...', 'i', 'so', 'sad', '...']\n",
      "AFter tokenizer:  ['welcome', 'to', 'uk-mobile-date', 'this', 'msg', 'is', 'free', 'giving', 'you', 'free', 'calling', 'to', '08719839835.', 'future', 'mgs', 'billed', 'at', '150p', 'daily', '.', 'to', 'cancel', 'send', '``', 'go', 'stop', \"''\", 'to', '89123']\n",
      "AFter tokenizer:  ['this', 'is', 'wishing', 'you', 'a', 'great', 'day', '.', 'moji', 'told', 'me', 'about', 'your', 'offer', 'and', 'as', 'always', 'i', 'was', 'speechless', '.', 'you', 'offer', 'so', 'easily', 'to', 'go', 'to', 'great', 'lengths', 'on', 'my', 'behalf', 'and', 'its', 'stunning', '.', 'my', 'exam', 'is', 'next', 'friday', '.', 'after', 'that', 'i', 'will', 'keep', 'in', 'touch', 'more', '.', 'sorry', '.']\n",
      "AFter tokenizer:  ['thanks', 'again', 'for', 'your', 'reply', 'today', '.', 'when', 'is', 'ur', 'visa', 'coming', 'in', '.', 'and', 'r', 'u', 'still', 'buying', 'the', 'gucci', 'and', 'bags', '.', 'my', 'sister', 'things', 'are', 'not', 'easy', ',', 'uncle', 'john', 'also', 'has', 'his', 'own', 'bills', 'so', 'i', 'really', 'need', 'to', 'think', 'about', 'how', 'to', 'make', 'my', 'own', 'money', '.', 'later', 'sha', '.']\n",
      "AFter tokenizer:  ['sorry', 'i', 'flaked', 'last', 'night', ',', 'shit', \"'s\", 'seriously', 'goin', 'down', 'with', 'my', 'roommate', ',', 'what', 'you', 'up', 'to', 'tonight', '?']\n",
      "AFter tokenizer:  ['he', 'said', 'i', 'look', 'pretty', 'wif', 'long', 'hair', 'wat', '.', 'but', 'i', 'thk', 'he', \"'s\", 'cutting', 'quite', 'short', '4', 'me', 'leh', '.']\n",
      "AFter tokenizer:  ['cheers', 'for', 'callin', 'babe.sozi', 'culdnt', 'talkbut', 'i', 'wannatell', 'u', 'details', 'later', 'wenwecan', 'chat', 'properly', 'x']\n",
      "AFter tokenizer:  ['hey', 'u', 'still', 'at', 'the', 'gym', '?']\n",
      "AFter tokenizer:  ['much', 'better', 'now', 'thanks', 'lol']\n",
      "AFter tokenizer:  ['nothing', ',', 'smsing', 'u', 'n', 'xy', 'lor', '.', 'sorry', 'lor', 'da', 'guys', 'neva', 'c', 'u', 'in', 'person', 'but', 'they', 'sort', 'of', 'know', 'u', 'lor', '.', 'so', 'u', 'wan', '2', 'meet', 'them', 'xy', 'ask', 'me', '2', 'bring', 'u', 'along', '4', 'our', 'next', 'meeting', '.']\n",
      "AFter tokenizer:  ['lem', 'me', 'know', 'when', 'i', 'can', 'swing', 'by', 'and', 'pick', 'up', ',', 'i', \"'m\", 'free', 'basically', 'any', 'time', 'after', '1', 'all', 'this', 'semester']\n",
      "AFter tokenizer:  ['wa', '...', 'u', 'so', 'efficient', '...', 'gee', '...', 'thanx', '...']\n",
      "AFter tokenizer:  ['3.', 'you', 'have', 'received', 'your', 'mobile', 'content', '.', 'enjoy']\n",
      "AFter tokenizer:  ['s', 'but', 'not', 'able', 'to', 'sleep', '.']\n",
      "AFter tokenizer:  ['want', 'explicit', 'sex', 'in', '30', 'secs', '?', 'ring', '02073162414', 'now', '!', 'costs', '20p/min']\n",
      "AFter tokenizer:  ['we', 'will', 'meet', 'soon', 'princess', '!', 'ttyl', '!']\n",
      "AFter tokenizer:  ['i', \"'ll\", 'pick', 'you', 'up', 'at', 'about', '5.15pm', 'to', 'go', 'to', 'taunton', 'if', 'you', 'still', 'want', 'to', 'come', '.']\n",
      "AFter tokenizer:  ['oh', ':', '-', ')', 'only', '4', 'outside', 'players', 'allowed', 'to', 'play', 'know']\n",
      "AFter tokenizer:  ['i', 'anything', 'lor', '.']\n",
      "AFter tokenizer:  ['erutupalam', 'thandiyachu']\n",
      "AFter tokenizer:  ['y', 'cant', 'u', 'try', 'new', 'invention', 'to', 'fly', '..', 'i', \"'m\", 'not', 'joking.', ',']\n",
      "AFter tokenizer:  ['no', '..', 'its', 'ful', 'of', 'song', 'lyrics', '..']\n",
      "AFter tokenizer:  ['what', 'do', 'u', 'reckon', 'as', 'need', '2', 'arrange', 'transport', 'if', 'u', 'ca', \"n't\", 'do', 'it', ',', 'thanks']\n",
      "AFter tokenizer:  ['true', 'lov', 'n', 'care', 'wil', 'nevr', 'go', 'unrecognized', '.', 'though', 'somone', 'often', 'makes', 'mistakes', 'when', 'valuing', 'it', '.', 'but', 'they', 'will', 'definitly', 'undrstnd', 'once', 'when', 'they', 'start', 'missing', 'it', '.']\n",
      "AFter tokenizer:  ['shopping', '?', 'eh', 'ger', 'i', 'toking', 'abt', 'syd', 'leh', '...', 'haha']\n",
      "AFter tokenizer:  ['what', 'not', 'under', 'standing', '.']\n",
      "AFter tokenizer:  ['have', '*', 'good', 'weekend', '.']\n",
      "AFter tokenizer:  ['miss', 'call', 'miss', 'call', 'khelate', 'kintu', 'opponenter', 'miss', 'call', 'dhorte', 'lage', '.', 'thats', 'd', 'rule', '.', 'one', 'with', 'great', 'phone', 'receiving', 'quality', 'wins', '.']\n",
      "AFter tokenizer:  ['call', 'me', 'when', 'you', 'get', 'the', 'chance', 'plz', '&', 'lt', ';', '3']\n",
      "AFter tokenizer:  ['the', 'new', 'deus', 'ex', 'game', 'comin', 'early', 'next', 'yr']\n",
      "AFter tokenizer:  ['my', 'computer', 'just', 'fried', 'the', 'only', 'essential', 'part', 'we', 'do', \"n't\", 'keep', 'spares', 'of', 'because', 'my', 'fucking', 'idiot', 'roommates', 'looovvve', 'leaving', 'the', 'thing', 'running', 'on', 'full', '&', 'lt', ';', '#', '&', 'gt', ';', '/7']\n",
      "AFter tokenizer:  ['my', 'friend', ',', 'she', \"'s\", 'studying', 'at', 'warwick', ',', 'we', \"'ve\", 'planned', 'to', 'go', 'shopping', 'and', 'to', 'concert', 'tmw', ',', 'but', 'it', 'may', 'be', 'canceled', ',', 'hav', \"n't\", 'seen', 'for', 'ages', ',', 'yeah', 'we', 'should', 'get', 'together', 'sometime', '!']\n",
      "AFter tokenizer:  ['probably', 'a', 'couple', 'hours', 'tops']\n",
      "AFter tokenizer:  ['lol', '..', '*', 'grins', '*', '..', 'i', \"'m\", 'not', 'babe', ',', 'but', 'thanks', 'for', 'thinking', 'of', 'me', '!']\n",
      "AFter tokenizer:  ['man', 'this', 'bus', 'is', 'so', 'so', 'so', 'slow', '.', 'i', 'think', 'you', \"'re\", 'gon', 'na', 'get', 'there', 'before', 'me']\n",
      "AFter tokenizer:  ['hope', 'this', 'text', 'meets', 'you', 'smiling', '.', 'if', 'not', 'then', 'let', 'this', 'text', 'give', 'you', 'a', 'reason', 'to', 'smile', '.', 'have', 'a', 'beautiful', 'day', '.']\n",
      "AFter tokenizer:  ['in', 'case', 'you', 'wake', 'up', 'wondering', 'where', 'i', 'am', ',', 'i', 'forgot', 'i', 'have', 'to', 'take', 'care', 'of', 'something', 'for', 'grandma', 'today', ',', 'should', 'be', 'done', 'before', 'the', 'parade']\n",
      "AFter tokenizer:  ['latest', 'nokia', 'mobile', 'or', 'ipod', 'mp3', 'player', '+£400', 'proze', 'guaranteed', '!', 'reply', 'with', ':', 'win', 'to', '83355', 'now', '!', 'norcorp', 'ltd.£1,50/mtmsgrcvd18+']\n",
      "AFter tokenizer:  ['sms', 'services', '.', 'for', 'your', 'inclusive', 'text', 'credits', ',', 'pls', 'goto', 'www.comuk.net', 'login=', '3qxj9', 'unsubscribe', 'with', 'stop', ',', 'no', 'extra', 'charge', '.', 'help', '08702840625.comuk', '.', '220-cm2', '9ae']\n",
      "AFter tokenizer:  ['nvm', 'take', 'ur', 'time', '.']\n",
      "AFter tokenizer:  ['so', 'wat', \"'s\", 'da', 'decision', '?']\n",
      "AFter tokenizer:  ['wot', 'is', 'u', 'up', '2', 'then', 'bitch', '?']\n",
      "AFter tokenizer:  ['she', 'told', 'to', 'hr', 'that', 'he', 'want', 'posting', 'in', 'chennai', ':', ')', 'because', 'i', \"'m\", 'working', 'here', ':', ')']\n",
      "AFter tokenizer:  ['mobile', 'club', ':', 'choose', 'any', 'of', 'the', 'top', 'quality', 'items', 'for', 'your', 'mobile', '.', '7cfca1a']\n",
      "AFter tokenizer:  ['when', 'are', 'you', 'guys', 'leaving', '?']\n",
      "AFter tokenizer:  ['he', 'neva', 'grumble', 'but', 'i', 'sad', 'lor', '...', 'hee', '...', 'buy', 'tmr', 'lor', 'aft', 'lunch', '.', 'but', 'we', 'still', 'meetin', '4', 'lunch', 'tmr', 'a', 'not', '.', 'neva', 'hear', 'fr', 'them', 'lei', '.', 'ü', 'got', 'a', 'lot', 'of', 'work', 'ar', '?']\n",
      "AFter tokenizer:  ['not', 'able', 'to', 'do', 'anything', '.']\n",
      "AFter tokenizer:  ['ü', 'takin', 'linear', 'algebra', 'today', '?']\n",
      "AFter tokenizer:  ['this', 'weekend', 'is', 'fine', '(', 'an', 'excuse', 'not', 'to', 'do', 'too', 'much', 'decorating', ')']\n",
      "AFter tokenizer:  ['sorry', 'i', 'missed', 'you', 'babe', '.', 'i', 'was', 'up', 'late', 'and', 'slept', 'in', '.', 'i', 'hope', 'you', 'enjoy', 'your', 'driving', 'lesson', ',', 'boytoy', '.', 'i', 'miss', 'you', 'too', '...', '*', 'teasing', 'kiss', '*']\n",
      "AFter tokenizer:  ['now', 'project', 'pa.', 'after', 'that', 'only', 'i', 'can', 'come', '.']\n",
      "AFter tokenizer:  ['money', 'i', 'have', 'won', 'wining', 'number', '946', 'wot', 'do', 'i', 'do', 'next']\n",
      "AFter tokenizer:  ['sure', ',', 'whenever', 'you', 'show', 'the', 'fuck', 'up', '&', 'gt', ';', ':', '(']\n",
      "AFter tokenizer:  ['that', 'was', 'random', 'saw', 'my', 'old', 'roomate', 'on', 'campus', '.', 'he', 'graduated']\n",
      "AFter tokenizer:  ['men', 'always', 'needs', 'a', 'beautiful', ',', 'intelligent', ',', 'caring', ',', 'loving', ',', 'adjustable', ',', 'cooperative', 'wife', '.', 'but', 'the', 'law', 'allows', 'only', 'one', 'wife', '....']\n",
      "AFter tokenizer:  ['that', 'sucks', '.', 'so', 'what', 'do', 'you', 'got', 'planned', 'for', 'your', 'yo', 'valentine', '?', 'i', 'am', 'your', 'yo', 'valentine', 'are', \"n't\", 'i', '?']\n",
      "AFter tokenizer:  ['just', 'got', 'part', 'nottingham', '-', '3', 'hrs', '63miles', '.', 'good', 'thing', 'i', 'love', 'my', 'man', 'so', 'much', ',', 'but', 'only', 'doing', '40mph', '.', 'hey', 'ho']\n",
      "AFter tokenizer:  ['what', 'to', 'think', 'no', 'one', 'saying', 'clearly', '.', 'ok', 'leave', 'no', 'need', 'to', 'ask', 'her', '.', 'i', 'will', 'go', 'if', 'she', 'come', 'or', 'not']\n",
      "AFter tokenizer:  ['hi', 'good', 'mornin', '..', 'thanku', 'wish', 'u', 'd', 'same', '..']\n",
      "AFter tokenizer:  ['do', 'u', 'want', '2', 'meet', 'up', '2morro']\n",
      "AFter tokenizer:  ['actually', 'i', 'decided', 'i', 'was', 'too', 'hungry', 'so', 'i', 'have', \"n't\", 'left', 'yet', ':', 'v']\n",
      "AFter tokenizer:  ['i', \"'ve\", 'sent', 'ü', 'my', 'part', '..']\n",
      "AFter tokenizer:  ['cos', 'i', 'was', 'out', 'shopping', 'wif', 'darren', 'jus', 'now', 'n', 'i', 'called', 'him', '2', 'ask', 'wat', 'present', 'he', 'wan', 'lor', '.', 'then', 'he', 'started', 'guessing', 'who', 'i', 'was', 'wif', 'n', 'he', 'finally', 'guessed', 'darren', 'lor', '.']\n",
      "AFter tokenizer:  ['i', 'want', 'some', 'cock', '!', 'my', 'hubby', \"'s\", 'away', ',', 'i', 'need', 'a', 'real', 'man', '2', 'satisfy', 'me', '.', 'txt', 'wife', 'to', '89938', 'for', 'no', 'strings', 'action', '.', '(', 'txt', 'stop', '2', 'end', ',', 'txt', 'rec', '£1.50ea', '.', 'otbox', '731', 'la1', '7ws', '.', ')']\n",
      "AFter tokenizer:  ['understand', '.', 'his', 'loss', 'is', 'my', 'gain', ':', ')', 'so', 'do', 'you', 'work', '?', 'school', '?']\n",
      "AFter tokenizer:  ['how', 'are', 'u', '?', 'i', 'have', 'missed', 'u', '!', 'i', 'havent', 'been', 'up', '2', 'much', 'a', 'bit', 'bored', 'with', 'the', 'holiday', 'want', '2', 'go', 'bak', '2', 'college', '!', 'sad', 'isnt', 'it', '?', 'xx']\n",
      "AFter tokenizer:  ['hiya', ',', 'probably', 'coming', 'home', '*', 'weekend', 'after', 'next']\n",
      "AFter tokenizer:  ['do', \"n't\", 'forget', 'though', 'that', 'i', 'love', 'you', '....', 'and', 'i', 'walk', 'beside', 'you', '.', 'watching', 'over', 'you', 'and', 'keeping', 'your', 'heart', 'warm', '.']\n",
      "AFter tokenizer:  ['i', 'wish', 'things', 'were', 'different', '.', 'i', 'wonder', 'when', 'i', 'will', 'be', 'able', 'to', 'show', 'you', 'how', 'much', 'i', 'value', 'you', '.', 'pls', 'continue', 'the', 'brisk', 'walks', 'no', 'drugs', 'without', 'askin', 'me', 'please', 'and', 'find', 'things', 'to', 'laugh', 'about', '.', 'i', 'love', 'you', 'dearly', '.']\n",
      "AFter tokenizer:  ['ok', 'both', 'our', 'days', '.', 'so', 'what', 'are', 'you', 'making', 'for', 'dinner', 'tonite', '?', 'am', 'i', 'invited', '?']\n",
      "AFter tokenizer:  ['gr8', 'new', 'service', '-', 'live', 'sex', 'video', 'chat', 'on', 'your', 'mob', '-', 'see', 'the', 'sexiest', 'dirtiest', 'girls', 'live', 'on', 'ur', 'phone', '-', '4', 'details', 'text', 'horny', 'to', '89070', 'to', 'cancel', 'send', 'stop', 'to', '89070']\n",
      "AFter tokenizer:  ['i', 'have', 'no', 'money', '4', 'steve', 'mate', '!', '!']\n",
      "AFter tokenizer:  ['im', 'late', 'tellmiss', 'im', 'on', 'my', 'way']\n",
      "AFter tokenizer:  ['normally', 'i', 'use', 'to', 'drink', 'more', 'water', 'daily', ':', ')']\n",
      "AFter tokenizer:  ['dare', 'i', 'ask', '...', 'any', 'luck', 'with', 'sorting', 'out', 'the', 'car', '?']\n",
      "AFter tokenizer:  ['party', \"'s\", 'at', 'my', 'place', 'at', 'usf', ',', 'no', 'charge', '(', 'but', 'if', 'you', 'can', 'contribute', 'in', 'any', 'way', 'it', 'is', 'greatly', 'appreciated', ')', 'and', 'yeah', ',', 'we', 'got', 'room', 'for', 'one', 'more']\n",
      "AFter tokenizer:  ['urgh', ',', 'coach', 'hot', ',', 'smells', 'of', 'chip', 'fat', '!', 'thanks', 'again', ',', 'especially', 'for', 'the', 'duvet', '(', 'not', 'a', 'predictive', 'text', 'word', ')', '.']\n",
      "AFter tokenizer:  ['hiya', '.', 'how', 'was', 'last', 'night', '?', 'i', \"'ve\", 'been', 'naughty', 'and', 'bought', 'myself', 'clothes', 'and', 'very', 'little', '...', 'ready', 'for', 'more', 'shopping', 'tho', '!', 'what', 'kind', 'of', 'time', 'do', 'you', 'wan', 'na', 'meet', '?']\n",
      "AFter tokenizer:  ['freemsg', 'hi', 'baby', 'wow', 'just', 'got', 'a', 'new', 'cam', 'moby', '.', 'wan', 'na', 'c', 'a', 'hot', 'pic', '?', 'or', 'fancy', 'a', 'chat', '?', 'im', 'w8in', '4utxt', '/', 'rply', 'chat', 'to', '82242', 'hlp', '08712317606', 'msg150p', '2rcv']\n",
      "AFter tokenizer:  ['i', \"'ve\", 'been', 'trying', 'to', 'reach', 'him', 'without', 'success']\n",
      "AFter tokenizer:  ['when', 'you', 'and', 'derek', 'done', 'with', 'class', '?']\n",
      "AFter tokenizer:  ['never', 'y', 'lei', '...', 'i', 'v', 'lazy', '...', 'got', 'wat', '?', 'dat', 'day', 'ü', 'send', 'me', 'da', 'url', 'cant', 'work', 'one', '...']\n",
      "AFter tokenizer:  ['never', 'try', 'alone', 'to', 'take', 'the', 'weight', 'of', 'a', 'tear', 'that', 'comes', 'out', 'of', 'ur', 'heart', 'and', 'falls', 'through', 'ur', 'eyes', '...', 'always', 'remember', 'a', 'stupid', 'friend', 'is', 'here', 'to', 'share', '...', 'bslvyl']\n",
      "AFter tokenizer:  ['hey', 'mate', '.', 'spoke', 'to', 'the', 'mag', 'people', '.', 'we', '‘', 're', 'on', '.', 'the', 'is', 'deliver', 'by', 'the', 'end', 'of', 'the', 'month', '.', 'deliver', 'on', 'the', '24th', 'sept.', 'talk', 'later', '.']\n",
      "AFter tokenizer:  ['haha', ',', 'my', 'friend', 'tyler', 'literally', 'just', 'asked', 'if', 'you', 'could', 'get', 'him', 'a', 'dubsack']\n",
      "AFter tokenizer:  ['hey', '!', 'do', 'u', 'fancy', 'meetin', 'me', 'at', '4', 'at', 'cha', '\\x96', 'hav', 'a', 'lil', 'beverage', 'on', 'me', '.', 'if', 'not', 'txt', 'or', 'ring', 'me', 'and', 'we', 'can', 'meet', 'up', 'l8r', '.', 'quite', 'tired', 'got', 'in', 'at', '3', 'v.pist', ';', ')', 'love', 'pete', 'x', 'x', 'x']\n",
      "AFter tokenizer:  ['great', '.', 'have', 'a', 'safe', 'trip', '.', 'dont', 'panic', 'surrender', 'all', '.']\n",
      "AFter tokenizer:  ['symptoms', 'when', 'u', 'are', 'in', 'love', ':', '``', '1.u', 'like', 'listening', 'songs', '2.u', 'get', 'stopped', 'where', 'u', 'see', 'the', 'name', 'of', 'your', 'beloved', '3.u', 'wo', \"n't\", 'get', 'angry', 'when', 'your']\n",
      "AFter tokenizer:  ['sun', 'ah', '...', 'thk', 'mayb', 'can', 'if', 'dun', 'have', 'anythin', 'on', '...', 'thk', 'have', 'to', 'book', 'e', 'lesson', '...', 'e', 'pilates', 'is', 'at', 'orchard', 'mrt', 'u', 'noe', 'hor', '...']\n",
      "AFter tokenizer:  ['try', 'to', 'do', 'something', 'dear', '.', 'you', 'read', 'something', 'for', 'exams']\n",
      "AFter tokenizer:  ['gettin', 'rdy', 'to', 'ship', 'comp']\n",
      "AFter tokenizer:  ['i', 'am', 'in', 'hospital', 'da', '.', '.', 'i', 'will', 'return', 'home', 'in', 'evening']\n",
      "AFter tokenizer:  ['piss', 'is', 'talking', 'is', 'someone', 'that', 'realise', 'u', 'that', 'point', 'this', 'at', 'is', 'it', '.', '(', 'now', 'read', 'it', 'backwards', ')']\n",
      "AFter tokenizer:  ['think', '+', 'da', '.', 'you', 'wil', 'do', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'awake', 'oh', '.', 'what', \"'s\", 'up', '.']\n",
      "AFter tokenizer:  ['good', 'afternoon', 'my', 'boytoy', '.', 'how', 'goes', 'that', 'walking', 'here', 'and', 'there', 'day', '?', 'did', 'you', 'get', 'that', 'police', 'abstract', '?', 'are', 'you', 'still', 'out', 'and', 'about', '?', 'i', 'wake', 'and', 'miss', 'you', 'babe']\n",
      "AFter tokenizer:  ['how', 'much', 'u', 'trying', 'to', 'get', '?']\n",
      "AFter tokenizer:  ['come', 'around', '&', 'lt', ';', 'decimal', '&', 'gt', ';', 'pm', 'vikky', '..', 'i', \"'m\", 'otside', 'nw', ',', 'il', 'come', 'by', 'tht', 'time']\n",
      "AFter tokenizer:  ['tell', 'me', 'again', 'what', 'your', 'address', 'is']\n",
      "AFter tokenizer:  ['should', 'i', 'buy', 'him', 'a', 'blackberry', 'bold', '2', 'or', 'torch', '.', 'should', 'i', 'buy', 'him', 'new', 'or', 'used', '.', 'let', 'me', 'know', '.', 'plus', 'are', 'you', 'saying', 'i', 'should', 'buy', 'the', '&', 'lt', ';', '#', '&', 'gt', ';', 'g', 'wifi', 'ipad', '.', 'and', 'what', 'are', 'you', 'saying', 'about', 'the', 'about', 'the', '&', 'lt', ';', '#', '&', 'gt', ';', 'g', '?']\n",
      "AFter tokenizer:  ['but', 'you', 'were', 'together', 'so', 'you', 'should', 'be', 'thinkin', 'about', 'him']\n",
      "AFter tokenizer:  ['hiya', 'hows', 'it', 'going', 'in', 'sunny', 'africa', '?', 'hope', 'u', 'r', 'avin', 'a', 'good', 'time', '.', 'give', 'that', 'big', 'old', 'silver', 'back', 'a', 'big', 'kiss', 'from', 'me', '.']\n",
      "AFter tokenizer:  ['at', 'what', 'time', 'should', 'i', 'come', 'tomorrow']\n",
      "AFter tokenizer:  ['wan', 'na', 'have', 'a', 'laugh', '?', 'try', 'chit-chat', 'on', 'your', 'mobile', 'now', '!', 'logon', 'by', 'txting', 'the', 'word', ':', 'chat', 'and', 'send', 'it', 'to', 'no', ':', '8883', 'cm', 'po', 'box', '4217', 'london', 'w1a', '6zf', '16+', '118p/msg', 'rcvd']\n",
      "AFter tokenizer:  ['cha', 'quiteamuzing', 'that\\x92scool', 'babe', ',', 'probpop', 'in', '&', 'cu', 'satthen', 'hunny', '4brekkie', '!', 'love', 'jen', 'xxx', '.', 'psxtra', 'lrg', 'portions', '4', 'me', 'please']\n",
      "AFter tokenizer:  ['omg', 'how', 'did', 'u', 'know', 'what', 'i', 'ate', '?']\n",
      "AFter tokenizer:  ['urgent', '!', 'this', 'is', 'the', '2nd', 'attempt', 'to', 'contact', 'u', '!', 'u', 'have', 'won', '£1000call', '09071512432', 'b4', '300603t', '&', 'csbcm4235wc1n3xx.callcost150ppmmobilesvary', '.', 'max£7', '.', '50']\n",
      "AFter tokenizer:  [':', '(', 'but', 'your', 'not', 'here', '....']\n",
      "AFter tokenizer:  ['not', 'directly', 'behind', '...', 'abt', '4', 'rows', 'behind', 'ü', '...']\n",
      "AFter tokenizer:  ['congratulations', 'ur', 'awarded', '500', 'of', 'cd', 'vouchers', 'or', '125gift', 'guaranteed', '&', 'free', 'entry', '2', '100', 'wkly', 'draw', 'txt', 'music', 'to', '87066']\n",
      "AFter tokenizer:  ['had', 'your', 'contract', 'mobile', '11', 'mnths', '?', 'latest', 'motorola', ',', 'nokia', 'etc', '.', 'all', 'free', '!', 'double', 'mins', '&', 'text', 'on', 'orange', 'tariffs', '.', 'text', 'yes', 'for', 'callback', ',', 'no', 'to', 'remove', 'from', 'records']\n",
      "AFter tokenizer:  ['no', 'plans', 'yet', '.', 'what', 'are', 'you', 'doing', '?']\n",
      "AFter tokenizer:  ['hi', '....', 'my', 'engagement', 'has', 'been', 'fixd', 'on', '&', 'lt', ';', '#', '&', 'gt', ';', 'th', 'of', 'next', 'month', '.', 'i', 'know', 'its', 'really', 'shocking', 'bt', '....', 'hmm', 'njan', 'vilikkam', '....', 't', 'ws', 'al', 'of', 'a', 'sudn', ';', '-', '(', '.']\n",
      "AFter tokenizer:  ['not', 'course', '.', 'only', 'maths', 'one', 'day', 'one', 'chapter', 'with', 'in', 'one', 'month', 'we', 'can', 'finish', '.']\n",
      "AFter tokenizer:  ['wow', 'did', \"n't\", 'think', 'it', 'was', 'that', 'common', '.', 'i', 'take', 'it', 'all', 'back', 'ur', 'not', 'a', 'freak', '!', 'unless', 'u', 'chop', 'it', 'off', ':', '-', ')']\n",
      "AFter tokenizer:  ['noooooooo', 'please', '.', 'last', 'thing', 'i', 'need', 'is', 'stress', '.', 'for', 'once', 'in', 'your', 'life', 'be', 'fair', '.']\n",
      "AFter tokenizer:  ['u', 'have', 'a', 'secret', 'admirer', 'who', 'is', 'looking', '2', 'make', 'contact', 'with', 'u-find', 'out', 'who', 'they', 'r', '*', 'reveal', 'who', 'thinks', 'ur', 'so', 'special-call', 'on', '09065171142-stopsms-08718727870150ppm']\n",
      "AFter tokenizer:  ['i', \"'ll\", 'see', 'if', 'i', 'can', 'swing', 'by', 'in', 'a', 'bit', ',', 'got', 'some', 'things', 'to', 'take', 'care', 'of', 'here', 'firsg']\n",
      "AFter tokenizer:  ['i', 'wanted', 'to', 'wish', 'you', 'a', 'happy', 'new', 'year', 'and', 'i', 'wanted', 'to', 'talk', 'to', 'you', 'about', 'some', 'legal', 'advice', 'to', 'do', 'with', 'when', 'gary', 'and', 'i', 'split', 'but', 'in', 'person', '.', 'i', \"'ll\", 'make', 'a', 'trip', 'to', 'ptbo', 'for', 'that', '.', 'i', 'hope', 'everything', 'is', 'good', 'with', 'you', 'babe', 'and', 'i', 'love', 'ya', ':', ')']\n",
      "AFter tokenizer:  ['have', 'you', 'not', 'finished', 'work', 'yet', 'or', 'something', '?']\n",
      "AFter tokenizer:  ['right', 'it', 'wasnt', 'you', 'who', 'phoned', 'it', 'was', 'someone', 'with', 'a', 'number', 'like', 'yours', '!']\n",
      "AFter tokenizer:  ['it', \"'s\", 'ok', 'i', 'wun', 'b', 'angry', '.', 'msg', 'u', 'aft', 'i', 'come', 'home', 'tonight', '.']\n",
      "AFter tokenizer:  ['i', 'had', 'a', 'good', 'time', 'too', '.', 'its', 'nice', 'to', 'do', 'something', 'a', 'bit', 'different', 'with', 'my', 'weekends', 'for', 'a', 'change', '.', 'see', 'ya', 'soon']\n",
      "AFter tokenizer:  ['yo', 'sorry', 'was', 'in', 'the', 'shower', 'sup']\n",
      "AFter tokenizer:  ['carlos', 'is', 'down', 'but', 'i', 'have', 'to', 'pick', 'it', 'up', 'from', 'him', ',', 'so', 'i', \"'ll\", 'swing', 'by', 'usf', 'in', 'a', 'little', 'bit']\n",
      "AFter tokenizer:  ['full', 'heat', 'pa', ':', '-', ')', 'i', 'have', 'applyed', 'oil', 'pa', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'stuck', 'in', 'da', 'middle', 'of', 'da', 'row', 'on', 'da', 'right', 'hand', 'side', 'of', 'da', 'lt', '...']\n",
      "AFter tokenizer:  ['have', 'you', 'laid', 'your', 'airtel', 'line', 'to', 'rest', '?']\n",
      "AFter tokenizer:  ['hi', 'did', 'u', 'decide', 'wot', '2', 'get', '4', 'his', 'bday', 'if', 'not', 'ill', 'prob', 'jus', 'get', 'him', 'a', 'voucher', 'frm', 'virgin', 'or', 'sumfing']\n",
      "AFter tokenizer:  ['freemsg', ':', 'txt', ':', 'call', 'to', 'no', ':', '86888', '&', 'claim', 'your', 'reward', 'of', '3', 'hours', 'talk', 'time', 'to', 'use', 'from', 'your', 'phone', 'now', '!', 'subscribe6gbp/mnth', 'inc', '3hrs', '16', 'stop', '?', 'txtstop']\n",
      "AFter tokenizer:  ['hey', 'j', '!', 'r', 'u', 'feeling', 'any', 'better', ',', 'hopeso', 'hunny', '.', 'i', 'amnow', 'feelin', 'ill', '&', 'ithink', 'i', 'may', 'have', 'tonsolitusaswell', '!', 'damn', 'iam', 'layin', 'in', 'bedreal', 'bored', '.', 'lotsof', 'luv', 'me', 'xxxx']\n",
      "AFter tokenizer:  ['and', 'i', 'do', \"n't\", 'plan', 'on', 'staying', 'the', 'night', 'but', 'i', 'prolly', 'wo', \"n't\", 'be', 'back', 'til', 'late']\n",
      "AFter tokenizer:  ['thanx', '4', 'puttin', 'da', 'fone', 'down', 'on', 'me', '!', '!']\n",
      "AFter tokenizer:  ['i', 'need', 'an', '8th', 'but', 'i', \"'m\", 'off', 'campus', 'atm', ',', 'could', 'i', 'pick', 'up', 'in', 'an', 'hour', 'or', 'two', '?']\n",
      "AFter tokenizer:  ['oh', '...', 'haha', '...', 'den', 'we', 'shld', 'had', 'went', 'today', 'too', '...', 'gee', ',', 'nvm', 'la', '...', 'kaiez', ',', 'i', 'dun', 'mind', 'goin', 'jazz', 'oso', '...', 'scared', 'hiphop', 'open', 'cant', 'catch', 'up', '...']\n",
      "AFter tokenizer:  ['been', 'running', 'but', 'only', 'managed', '5', 'minutes', 'and', 'then', 'needed', 'oxygen', '!', 'might', 'have', 'to', 'resort', 'to', 'the', 'roller', 'option', '!']\n",
      "AFter tokenizer:  ['we', 'live', 'in', 'the', 'next', '&', 'lt', ';', '#', '&', 'gt', ';', 'mins']\n",
      "AFter tokenizer:  ['y', 'de', 'asking', 'like', 'this', '.']\n",
      "AFter tokenizer:  ['just', 'glad', 'to', 'be', 'talking', 'to', 'you', '.']\n",
      "AFter tokenizer:  ['wat', 'time', 'ü', 'finish', '?']\n",
      "AFter tokenizer:  ['sorry', 'da', '.', 'i', 'gone', 'mad', 'so', 'many', 'pending', 'works', 'what', 'to', 'do', '.']\n",
      "AFter tokenizer:  ['how', 'much', 'you', 'got', 'for', 'cleaning']\n",
      "AFter tokenizer:  ['hows', 'my', 'favourite', 'person', 'today', '?', 'r', 'u', 'workin', 'hard', '?', 'could', \"n't\", 'sleep', 'again', 'last', 'nite', 'nearly', 'rang', 'u', 'at', '4.30']\n",
      "AFter tokenizer:  ['sunshine', 'quiz', '!', 'win', 'a', 'super', 'sony', 'dvd', 'recorder', 'if', 'you', 'canname', 'the', 'capital', 'of', 'australia', '?', 'text', 'mquiz', 'to', '82277.', 'b']\n",
      "AFter tokenizer:  ['ü', 'called', 'dad', 'oredi', '...']\n",
      "AFter tokenizer:  ['good', '.', 'do', 'you', 'think', 'you', 'could', 'send', 'me', 'some', 'pix', '?', 'i', 'would', 'love', 'to', 'see', 'your', 'top', 'and', 'bottom', '...']\n",
      "AFter tokenizer:  ['nvm', '...', 'i', \"'m\", 'going', 'to', 'wear', 'my', 'sport', 'shoes', 'anyway', '...', 'i', \"'m\", 'going', 'to', 'be', 'late', 'leh', '.']\n",
      "AFter tokenizer:  ['sorry', ',', 'i', \"'ll\", 'call', 'later', 'in', 'meeting', '.']\n",
      "AFter tokenizer:  ['this', 'is', 'a', 'long', 'fuckin', 'showr']\n",
      "AFter tokenizer:  ['received', ',', 'understood', 'n', 'acted', 'upon', '!']\n",
      "AFter tokenizer:  ['they', 'finally', 'came', 'to', 'fix', 'the', 'ceiling', '.']\n",
      "AFter tokenizer:  ['u', 'need', 'my', 'presnts', 'always', 'bcz', 'u', 'cant', 'mis', 'love', '.', '``', 'jeevithathile', 'irulinae', 'neekunna', 'prakasamanu', 'sneham', \"''\", 'prakasam', 'ennal', 'prabha', \"'that\", 'mns', 'prabha', \"is'love\", \"'\", 'got', 'it', '.', 'dont', 'mis', 'me', '....']\n",
      "AFter tokenizer:  ['jus', 'finish', 'blowing', 'my', 'hair', '.', 'u', 'finish', 'dinner', 'already', '?']\n",
      "AFter tokenizer:  ['i', \"'m\", 'on', 'the', 'bus', '.', 'love', 'you']\n",
      "AFter tokenizer:  ['lol', '...', 'i', 'knew', 'that', '....', 'i', 'saw', 'him', 'in', 'the', 'dollar', 'store']\n",
      "AFter tokenizer:  ['todays', 'voda', 'numbers', 'ending', 'with', '7634', 'are', 'selected', 'to', 'receive', 'a', '£350', 'reward', '.', 'if', 'you', 'have', 'a', 'match', 'please', 'call', '08712300220', 'quoting', 'claim', 'code', '7684', 'standard', 'rates', 'apply', '.']\n",
      "AFter tokenizer:  ['only', 'saturday', 'and', 'sunday', 'holiday', 'so', 'its', 'very', 'difficult', ':', ')']\n",
      "AFter tokenizer:  ['everybody', 'had', 'fun', 'this', 'evening', '.', 'miss', 'you', '.']\n",
      "AFter tokenizer:  ['got', 'hella', 'gas', 'money', ',', 'want', 'to', 'go', 'on', 'a', 'grand', 'nature', 'adventure', 'with', 'galileo', 'in', 'a', 'little', 'bit', '?']\n",
      "AFter tokenizer:  ['oh', 'wow', 'thats', 'gay', '.', 'will', 'firmware', 'update', 'help']\n",
      "AFter tokenizer:  ['these', 'wo', \"n't\", 'do', '.', 'have', 'to', 'move', 'on', 'to', 'morphine']\n",
      "AFter tokenizer:  ['how', 'come', 'i', 'din', 'c', 'ü', '...', 'yup', 'i', 'cut', 'my', 'hair', '...']\n",
      "AFter tokenizer:  ['k', 'k', 'pa', 'had', 'your', 'lunch', 'aha', '.']\n",
      "AFter tokenizer:  ['captain', 'vijaykanth', 'is', 'doing', 'comedy', 'in', 'captain', 'tv', '..', 'he', 'is', 'drunken', ':', ')']\n",
      "AFter tokenizer:  ['of', 'course', '.', 'i', 'guess', 'god', \"'s\", 'just', 'got', 'me', 'on', 'hold', 'right', 'now', '.']\n",
      "AFter tokenizer:  ['do', 'you', 'hide', 'anythiing', 'or', 'keeping', 'distance', 'from', 'me']\n",
      "AFter tokenizer:  ['havent', '.']\n",
      "AFter tokenizer:  ['you', 'are', 'being', 'ripped', 'off', '!', 'get', 'your', 'mobile', 'content', 'from', 'www.clubmoby.com', 'call', '08717509990', 'poly/true/pix/ringtones/games', 'six', 'downloads', 'for', 'only', '3']\n",
      "AFter tokenizer:  ['sorry', 'i', 'din', 'lock', 'my', 'keypad', '.']\n",
      "AFter tokenizer:  ['are', 'you', 'planning', 'to', 'come', 'chennai', '?']\n",
      "AFter tokenizer:  ['we', 'tried', 'to', 'contact', 'you', 're', 'your', 'reply', 'to', 'our', 'offer', 'of', 'a', 'video', 'phone', '750', 'anytime', 'any', 'network', 'mins', 'half', 'price', 'line', 'rental', 'camcorder', 'reply', 'or', 'call', '08000930705']\n",
      "AFter tokenizer:  ['god', 'created', 'gap', 'btwn', 'ur', 'fingers', 'so', 'dat', 'sum1', 'vry', 'special', 'will', 'fill', 'those', 'gaps', 'by', 'holding', 'ur', 'hands', '..', 'now', 'plz', 'dont', 'ask', 'y', 'he', 'created', 'so', 'much', 'gap', 'between', 'legs', '!', '!', '!']\n",
      "AFter tokenizer:  ['we', 'are', 'okay', '.', 'going', 'to', 'sleep', 'now', '.', 'later']\n",
      "AFter tokenizer:  ['finally', 'it', 'has', 'happened', '..', '!', 'aftr', 'decades', '..', '!', 'beer', 'is', 'now', 'cheaper', 'than', 'petrol', '!', 'the', 'goverment', 'expects', 'us', 'to', '``', 'drink', \"''\", '.', '.', '.', 'but', 'do', \"n't\", '``', 'drive', '``']\n",
      "AFter tokenizer:  ['a', '£400', 'xmas', 'reward', 'is', 'waiting', 'for', 'you', '!', 'our', 'computer', 'has', 'randomly', 'picked', 'you', 'from', 'our', 'loyal', 'mobile', 'customers', 'to', 'receive', 'a', '£400', 'reward', '.', 'just', 'call', '09066380611']\n",
      "AFter tokenizer:  ['where', 'r', 'e', 'meeting', 'tmr', '?']\n",
      "AFter tokenizer:  ['lol', 'yes', '.', 'but', 'it', 'will', 'add', 'some', 'spice', 'to', 'your', 'day', '.']\n",
      "AFter tokenizer:  ['our', 'prasanth', 'ettans', 'mother', 'passed', 'away', 'last', 'night', '.', 'just', 'pray', 'for', 'her', 'and', 'family', '.']\n",
      "AFter tokenizer:  ['k', ',', 'i', \"'ll\", 'work', 'something', 'out']\n",
      "AFter tokenizer:  ['private', '!', 'your', '2003', 'account', 'statement', 'for', 'shows', '800', 'un-redeemed', 's.', 'i.', 'm.', 'points', '.', 'call', '08718738002', 'identifier', 'code', ':', '48922', 'expires', '21/11/04']\n",
      "AFter tokenizer:  ['this', 'message', 'is', 'from', 'a', 'great', 'doctor', 'in', 'india', ':', '-', ')', ':', '1', ')', 'do', 'not', 'drink', 'appy', 'fizz', '.', 'it', 'contains', 'cancer', 'causing', 'age']\n",
      "AFter tokenizer:  ['you', 'call', 'him', 'and', 'tell', 'now', 'infront', 'of', 'them', '.', 'call', 'him', 'now', '.']\n",
      "AFter tokenizer:  ['ok', 'no', 'prob', '...']\n",
      "AFter tokenizer:  ['ladies', 'first', 'and', 'genus', 'second', 'k', '.']\n",
      "AFter tokenizer:  ['no', '.', 'yes', 'please', '.', 'been', 'swimming', '?']\n",
      "AFter tokenizer:  ['mum', 'not', 'going', 'robinson', 'already', '.']\n",
      "AFter tokenizer:  ['ok', 'set', 'let', 'u', 'noe', 'e', 'details', 'later', '...']\n",
      "AFter tokenizer:  ['not', '..', 'tel', 'software', 'name', '..']\n",
      "AFter tokenizer:  ['i', 'send', 'the', 'print', 'outs', 'da', '.']\n",
      "AFter tokenizer:  ['im', 'realy', 'soz', 'imat', 'my', 'mums', '2nite', 'what', 'about', '2moro']\n",
      "AFter tokenizer:  ['when', 'i', 'was', 'born', ',', 'god', 'said', ',', '``', 'oh', 'no', '!', 'another', 'idiot', \"''\", '.', 'when', 'you', 'were', 'born', ',', 'god', 'said', ',', '``', 'oh', 'no', '!', 'competition', \"''\", '.', 'who', 'knew', ',', 'one', 'day', 'these', 'two', 'will', 'become', 'freinds', 'forever', '!']\n",
      "AFter tokenizer:  ['i', 'didnt', 'get', 'ur', 'full', 'msg', '..', 'sometext', 'is', 'missing', ',', 'send', 'it', 'again']\n",
      "AFter tokenizer:  ['probably', 'not', ',', 'i', \"'m\", 'almost', 'out', 'of', 'gas', 'and', 'i', 'get', 'some', 'cash', 'tomorrow']\n",
      "AFter tokenizer:  ['customer', 'service', 'announcement', '.', 'we', 'recently', 'tried', 'to', 'make', 'a', 'delivery', 'to', 'you', 'but', 'were', 'unable', 'to', 'do', 'so', ',', 'please', 'call', '07099833605', 'to', 're-schedule', '.', 'ref:9280114']\n",
      "AFter tokenizer:  ['i', 'forgot', '2', 'ask', 'ü', 'all', 'smth', '..', 'there', \"'s\", 'a', 'card', 'on', 'da', 'present', 'lei', '...', 'how', '?', 'ü', 'all', 'want', '2', 'write', 'smth', 'or', 'sign', 'on', 'it', '?']\n",
      "AFter tokenizer:  ['i', \"'m\", 'leaving', 'my', 'house', 'now', '.']\n",
      "AFter tokenizer:  ['hi', 'babe', 'its', 'chloe', ',', 'how', 'r', 'u', '?', 'i', 'was', 'smashed', 'on', 'saturday', 'night', ',', 'it', 'was', 'great', '!', 'how', 'was', 'your', 'weekend', '?', 'u', 'been', 'missing', 'me', '?', 'sp', 'visionsms.com', 'text', 'stop', 'to', 'stop', '150p/text']\n",
      "AFter tokenizer:  ['ü', 'ready', 'then', 'call', 'me', '...']\n",
      "AFter tokenizer:  ['wewa', 'is', '130.', 'iriver', '255.', 'all', '128', 'mb', '.']\n",
      "AFter tokenizer:  ['it', 'is', 'a', 'good', 'thing', 'i', \"'m\", 'now', 'getting', 'the', 'connection', 'to', 'bw']\n",
      "AFter tokenizer:  ['sry', 'da', '..', 'jst', 'nw', 'only', 'i', 'came', 'to', 'home', '..']\n",
      "AFter tokenizer:  ['that', \"'s\", 'cool', 'he', \"'ll\", 'be', 'here', 'all', 'night', ',', 'lem', 'me', 'know', 'when', 'you', \"'re\", 'around']\n",
      "AFter tokenizer:  ['are', 'you', 'staying', 'in', 'town', '?']\n",
      "AFter tokenizer:  ['haha', 'yeah', ',', '2', 'oz', 'is', 'kind', 'of', 'a', 'shitload']\n",
      "AFter tokenizer:  ['ok', 'u', 'can', 'take', 'me', 'shopping', 'when', 'u', 'get', 'paid', '=d']\n",
      "AFter tokenizer:  ['alright', 'we', \"'ll\", 'bring', 'it', 'to', 'you', ',', 'see', 'you', 'in', 'like', '&', 'lt', ';', '#', '&', 'gt', ';', 'mins']\n",
      "AFter tokenizer:  ['but', 'pls', 'dont', 'play', 'in', 'others', 'life', '.']\n",
      "AFter tokenizer:  ['eatin', 'my', 'lunch', '...']\n",
      "AFter tokenizer:  ['hmmm.but', 'you', 'should', 'give', 'it', 'on', 'one', 'day', '..']\n",
      "AFter tokenizer:  ['did', \"n't\", 'try', ',', 'g', 'and', 'i', 'decided', 'not', 'to', 'head', 'out']\n",
      "AFter tokenizer:  ['ok', 'no', 'prob']\n",
      "AFter tokenizer:  ['surly', 'ill', 'give', 'it', 'to', 'you', ':', '-', ')', 'while', 'coming', 'to', 'review', '.']\n",
      "AFter tokenizer:  ['by', 'march', 'ending', ',', 'i', 'should', 'be', 'ready', '.', 'but', 'will', 'call', 'you', 'for', 'sure', '.', 'the', 'problem', 'is', 'that', 'my', 'capital', 'never', 'complete', '.', 'how', 'far', 'with', 'you', '.', 'how', \"'s\", 'work', 'and', 'the', 'ladies']\n",
      "AFter tokenizer:  ['pls', 'give', 'her', 'the', 'food', 'preferably', 'pap', 'very', 'slowly', 'with', 'loads', 'of', 'sugar', '.', 'you', 'can', 'take', 'up', 'to', 'an', 'hour', 'to', 'give', 'it', '.', 'and', 'then', 'some', 'water', '.', 'very', 'very', 'slowly', '.']\n",
      "AFter tokenizer:  ['urgent', '!', 'your', 'mobile', 'no', '07808726822', 'was', 'awarded', 'a', '£2,000', 'bonus', 'caller', 'prize', 'on', '02/09/03', '!', 'this', 'is', 'our', '2nd', 'attempt', 'to', 'contact', 'you', '!', 'call', '0871-872-9758', 'box95qu']\n",
      "AFter tokenizer:  ['a', 'guy', 'who', 'gets', 'used', 'but', 'is', 'too', 'dumb', 'to', 'realize', 'it', '.']\n",
      "AFter tokenizer:  ['okey', 'dokey', ',', 'i', '‘', 'll', 'be', 'over', 'in', 'a', 'bit', 'just', 'sorting', 'some', 'stuff', 'out', '.']\n",
      "AFter tokenizer:  ['yes', 'fine']\n",
      "AFter tokenizer:  ['i', 'liked', 'the', 'new', 'mobile']\n",
      "AFter tokenizer:  ['anytime', '...']\n",
      "AFter tokenizer:  ['mmmmmmm', '*', 'snuggles', 'into', 'you', '*', '...', '*', 'deep', 'contented', 'sigh', '*', '...', '*', 'whispers', '*', '...', 'i', 'fucking', 'love', 'you', 'so', 'much', 'i', 'can', 'barely', 'stand', 'it', '...']\n",
      "AFter tokenizer:  ['yar', 'but', 'they', 'say', 'got', 'some', 'error', '.']\n",
      "AFter tokenizer:  ['hey', 'anyway', 'i', 'have', 'to', ':', '-', ')']\n",
      "AFter tokenizer:  ['wow', 'so', 'healthy', '.', 'old', 'airport', 'rd', 'lor', '.', 'cant', 'thk', 'of', 'anything', 'else', '.', 'but', 'i', \"'ll\", 'b', 'bathing', 'my', 'dog', 'later', '.']\n",
      "AFter tokenizer:  ['wif', 'my', 'family', 'booking', 'tour', 'package', '.']\n",
      "AFter tokenizer:  ['did', 'you', 'say', 'bold', ',', 'then', 'torch', 'later', '.', 'or', 'one', 'torch', 'and', '2bold', '?']\n",
      "AFter tokenizer:  ['haha', 'awesome', ',', 'i', 'might', 'need', 'to', 'take', 'you', 'up', 'on', 'that', ',', 'what', 'you', 'doin', 'tonight', '?']\n",
      "AFter tokenizer:  ['ya', 'i', 'knw', 'u', 'vl', 'giv', '..', 'its', 'ok', 'thanks', 'kano', '..', 'anyway', 'enjoy', 'wit', 'ur', 'family', 'wit', '1st', 'salary', '..', ':', '-', ')', ';', '-', ')']\n",
      "AFter tokenizer:  ['huh', 'so', 'slow', 'i', 'tot', 'u', 'reach', 'long', 'ago', 'liao', '...', 'u', '2', 'more', 'days', 'only', 'i', '4', 'more', 'leh', '...']\n",
      "AFter tokenizer:  ['thats', 'cool', 'princess', '!', 'i', 'will', 'cover', 'your', 'face', 'in', 'hot', 'sticky', 'cum', ':', ')']\n",
      "AFter tokenizer:  ['big', 'brother', '‘', 's', 'really', 'scraped', 'the', 'barrel', 'with', 'this', 'shower', 'of', 'social', 'misfits']\n",
      "AFter tokenizer:  ['oops', 'i', 'thk', 'i', 'dun', 'haf', 'enuff', '...', 'i', 'go', 'check', 'then', 'tell', 'ü', '..']\n",
      "AFter tokenizer:  ['s', ':', ')', '8', 'min', 'to', 'go', 'for', 'lunch', ':', ')']\n",
      "AFter tokenizer:  ['hey', '.', 'what', 'happened', '?', 'u', 'switch', 'off', 'ur', 'cell', 'd', 'whole', 'day', '.', 'this', 'isnt', 'good', '.', 'now', 'if', 'u', 'do', 'care', ',', 'give', 'me', 'a', 'call', 'tomorrow', '.']\n",
      "AFter tokenizer:  ['k', 'will', 'do', ',', 'addie', '&', 'amp', ';', 'i', 'are', 'doing', 'some', 'art', 'so', 'i', \"'ll\", 'be', 'here', 'when', 'you', 'get', 'home']\n",
      "AFter tokenizer:  ['aiyo', '...', 'her', 'lesson', 'so', 'early', '...', 'i', \"'m\", 'still', 'sleepin', ',', 'haha', '...', 'okie', ',', 'u', 'go', 'home', 'liao', 'den', 'confirm', 'w', 'me', 'lor', '...']\n",
      "AFter tokenizer:  ['forgot', 'to', 'tell', 'ü', 'smth', '..', 'can', 'ü', 'like', 'number', 'the', 'sections', 'so', 'that', 'it', \"'s\", 'clearer', '..']\n",
      "AFter tokenizer:  ['yup', '.', 'anything', 'lor', ',', 'if', 'u', 'dun', 'wan', 'it', \"'s\", 'ok', '...']\n",
      "AFter tokenizer:  ['i', \"'m\", 'home', ',', 'my', 'love', '...', 'if', 'your', 'still', 'awake', '...', '*', 'loving', 'kiss', '*']\n",
      "AFter tokenizer:  ['hello', 'peach', '!', 'my', 'cake', 'tasts', 'lush', '!']\n",
      "AFter tokenizer:  ['free', 'game', '.', 'get', 'rayman', 'golf', '4', 'free', 'from', 'the', 'o2', 'games', 'arcade', '.', '1st', 'get', 'ur', 'games', 'settings', '.', 'reply', 'post', ',', 'then', 'save', '&', 'activ8', '.', 'press', '0', 'key', 'for', 'arcade', '.', 'termsapply']\n",
      "AFter tokenizer:  ['there', \"'ll\", 'be', 'a', 'minor', 'shindig', 'at', 'my', 'place', 'later', 'tonight', ',', 'you', 'interested', '?']\n",
      "AFter tokenizer:  ['jason', 'says', 'it', \"'s\", 'cool', 'if', 'we', 'pick', 'some', 'up', 'from', 'his', 'place', 'in', 'like', 'an', 'hour']\n",
      "AFter tokenizer:  ['had', 'your', 'mobile', '10', 'mths', '?', 'update', 'to', 'the', 'latest', 'camera/video', 'phones', 'for', 'free', '.', 'keep', 'ur', 'same', 'number', ',', 'get', 'extra', 'free', 'mins/texts', '.', 'text', 'yes', 'for', 'a', 'call']\n",
      "AFter tokenizer:  ['i', '(', 'career', 'tel', ')', 'have', 'added', 'u', 'as', 'a', 'contact', 'on', 'indyarocks.com', 'to', 'send', 'free', 'sms', '.', 'to', 'remove', 'from', 'phonebook', '-', 'sms', 'no', 'to', '&', 'lt', ';', '#', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['i', \"'ve\", 'reached', 'already', '.']\n",
      "AFter tokenizer:  ['i', 'dont', 'know', 'ask', 'to', 'my', 'brother', '.', 'nothing', 'problem', 'some', 'thing', 'that', '.', 'just', 'i', 'told', '.']\n",
      "AFter tokenizer:  ['k', ':', ')', 'eng', 'rocking', 'in', 'ashes', ':', ')']\n",
      "AFter tokenizer:  ['wat', 'time', 'r', 'ü', 'going', 'to', 'xin', \"'s\", 'hostel', '?']\n",
      "AFter tokenizer:  ['good', 'morning', 'my', 'dear', 'shijutta', '...........', 'have', 'a', 'great', '&', 'amp', ';', 'successful', 'day', '.']\n",
      "AFter tokenizer:  ['oh', 'k', ':', ')', 'after', 'that', 'placement', 'there', 'ah', '?']\n",
      "AFter tokenizer:  ['not', 'for', 'possession', ',', 'especially', 'not', 'first', 'offense']\n",
      "AFter tokenizer:  ['nt', 'only', 'for', 'driving', 'even', 'for', 'many', 'reasons', 'she', 'is', 'called', 'bbd', '..', 'thts', 'it', 'chikku', ',', 'then', 'hw', 'abt', 'dvg', 'cold', '..', 'heard', 'tht', 'vinobanagar', 'violence', 'hw', 'is', 'the', 'condition', '..', 'and', 'hw', 'ru', '?', 'any', 'problem', '?']\n",
      "AFter tokenizer:  ['i', 'bought', 'the', 'test', 'yesterday', '.', 'its', 'something', 'that', 'lets', 'you', 'know', 'the', 'exact', 'day', 'u', 'ovulate.when', 'will', 'get', '2u', 'in', 'about', '2', 'to', '3wks', '.', 'but', 'pls', 'pls', 'dont', 'fret', '.', 'i', 'know', 'u', 'r', 'worried', '.', 'pls', 'relax', '.', 'also', 'is', 'there', 'anything', 'in', 'ur', 'past', 'history', 'u', 'need', 'to', 'tell', 'me', '?']\n",
      "AFter tokenizer:  ['we', 'have', 'pizza', 'if', 'u', 'want']\n",
      "AFter tokenizer:  ['i', 'keep', 'seeing', 'weird', 'shit', 'and', 'bein', 'all', '``', 'woah', \"''\", 'then', 'realising', 'it', \"'s\", 'actually', 'reasonable', 'and', 'i', \"'m\", 'all', '``', 'oh', \"''\"]\n",
      "AFter tokenizer:  ['many', 'more', 'happy', 'returns', 'of', 'the', 'day', '.', 'i', 'wish', 'you', 'happy', 'birthday', '.']\n",
      "AFter tokenizer:  ['thinking', 'of', 'u', ';', ')', 'x']\n",
      "AFter tokenizer:  ['orh', 'i', 'tot', 'u', 'say', 'she', 'now', 'still', 'dun', 'believe', '.']\n",
      "AFter tokenizer:  ['when', 'you', 'just', 'put', 'in', 'the', '+', 'sign', ',', 'choose', 'my', 'number', 'and', 'the', 'pin', 'will', 'show', '.', 'right', '?']\n",
      "AFter tokenizer:  ['the', 'beauty', 'of', 'life', 'is', 'in', 'next', 'second', '..', 'which', 'hides', 'thousands', 'of', 'secrets', '.', 'i', 'wish', 'every', 'second', 'will', 'be', 'wonderful', 'in', 'ur', 'life', '...', '!', '!', 'gud', 'n8']\n",
      "AFter tokenizer:  ['thanx', 'u', 'darlin', '!', 'im', 'cool', 'thanx', '.', 'a', 'few', 'bday', 'drinks', '2', 'nite', '.', '2morrow', 'off', '!', 'take', 'care', 'c', 'u', 'soon.xxx']\n",
      "AFter tokenizer:  ['if', 'you', \"'re\", 'still', 'up', ',', 'maybe', 'leave', 'the', 'credit', 'card', 'so', 'i', 'can', 'get', 'gas', 'when', 'i', 'get', 'back', 'like', 'he', 'told', 'me', 'to']\n",
      "AFter tokenizer:  ['your', 'weekly', 'cool-mob', 'tones', 'are', 'ready', 'to', 'download', '!', 'this', 'weeks', 'new', 'tones', 'include', ':', '1', ')', 'crazy', 'frog-axel', 'f', '>', '>', '>', '2', ')', 'akon-lonely', '>', '>', '>', '3', ')', 'black', 'eyed-dont', 'p', '>', '>', '>', 'more', 'info', 'in', 'n']\n",
      "AFter tokenizer:  ['well', 'boy', 'am', 'i', 'glad', 'g', 'wasted', 'all', 'night', 'at', 'applebees', 'for', 'nothing']\n",
      "AFter tokenizer:  ['cashbin.co.uk', '(', 'get', 'lots', 'of', 'cash', 'this', 'weekend', '!', ')', 'www.cashbin.co.uk', 'dear', 'welcome', 'to', 'the', 'weekend', 'we', 'have', 'got', 'our', 'biggest', 'and', 'best', 'ever', 'cash', 'give', 'away', '!', '!', 'these', '..']\n",
      "AFter tokenizer:  ['ok', 'lor', '...', 'or', 'u', 'wan', 'me', 'go', 'look', '4', 'u', '?']\n",
      "AFter tokenizer:  ['u', 'wan', '2', 'haf', 'lunch', 'i', \"'m\", 'in', 'da', 'canteen', 'now', '.']\n",
      "AFter tokenizer:  ['do', \"n't\", 'make', 'life', 'too', 'stressfull', '..', 'always', 'find', 'time', 'to', 'laugh', '..', 'it', 'may', 'not', 'add', 'years', 'to', 'your', 'life', '!', 'but', 'surely', 'adds', 'more', 'life', 'to', 'ur', 'years', '!', '!', 'gud', 'ni8', '..', 'swt', 'dreams', '..']\n",
      "AFter tokenizer:  ['hey', ',', 'looks', 'like', 'i', 'was', 'wrong', 'and', 'one', 'of', 'the', 'kappa', 'guys', 'numbers', 'is', 'still', 'on', 'my', 'phone', ',', 'if', 'you', 'want', 'i', 'can', 'text', 'him', 'and', 'see', 'if', 'he', \"'s\", 'around']\n",
      "AFter tokenizer:  ['thanks', '4', 'your', 'continued', 'support', 'your', 'question', 'this', 'week', 'will', 'enter', 'u', 'in2', 'our', 'draw', '4', '£100', 'cash', '.', 'name', 'the', 'new', 'us', 'president', '?', 'txt', 'ans', 'to', '80082']\n",
      "AFter tokenizer:  ['i', \"'m\", 'home', '.', 'doc', 'gave', 'me', 'pain', 'meds', 'says', 'everything', 'is', 'fine', '.']\n",
      "AFter tokenizer:  ['it', \"'s\", 'é', 'only', '$', '140', 'ard', '...', 'é', 'rest', 'all', 'ard', '$', '180', 'at', 'least', '...', 'which', 'is', 'é', 'price', '4', 'é', '2', 'bedrm', '(', '$', '900', ')']\n",
      "AFter tokenizer:  ['me', 'too', '!', 'have', 'a', 'lovely', 'night', 'xxx']\n",
      "AFter tokenizer:  ['prepare', 'to', 'be', 'pleasured', ':', ')']\n",
      "AFter tokenizer:  ['hi', '.', ':', ')', 'technical', 'support.providing', 'assistance', 'to', 'us', 'customer', 'through', 'call', 'and', 'email', ':', ')']\n",
      "AFter tokenizer:  ['if', 'you', 'text', 'on', 'your', 'way', 'to', 'cup', 'stop', 'that', 'should', 'work', '.', 'and', 'that', 'should', 'be', 'bus']\n",
      "AFter tokenizer:  ['whens', 'your', 'radio', 'show', '?']\n",
      "AFter tokenizer:  ['your', 'unique', 'user', 'id', 'is', '1172.', 'for', 'removal', 'send', 'stop', 'to', '87239', 'customer', 'services', '08708034412']\n",
      "AFter tokenizer:  ['i', \"'m\", 'not', 'sure', 'if', 'its', 'still', 'available', 'though']\n",
      "AFter tokenizer:  ['watever', 'relation', 'u', 'built', 'up', 'in', 'dis', 'world', 'only', 'thing', 'which', 'remains', 'atlast', 'iz', 'lonlines', 'with', 'lotz', 'n', 'lot', 'memories', '!', 'feeling', '..']\n",
      "AFter tokenizer:  ['cheers', 'lou', '!', 'yeah', 'was', 'a', 'goodnite', 'shame', 'u', 'neva', 'came', '!', 'c', 'ya', 'gailxx']\n",
      "AFter tokenizer:  ['hi', '..', 'i', 'got', 'the', 'money', 'da', ':', ')']\n",
      "AFter tokenizer:  ['ok', 'then', 'u', 'tell', 'me', 'wat', 'time', 'u', 'coming', 'later', 'lor', '.']\n",
      "AFter tokenizer:  ['u', 'repeat', 'e', 'instructions', 'again', '.', 'wat', \"'s\", 'e', 'road', 'name', 'of', 'ur', 'house', '?']\n",
      "AFter tokenizer:  ['quite', 'lor', '.', 'but', 'dun', 'tell', 'him', 'wait', 'he', 'get', 'complacent', '...']\n",
      "AFter tokenizer:  ['sorry', 'completely', 'forgot', '*', 'will', 'pop', 'em', 'round', 'this', 'week', 'if', 'your', 'still', 'here', '?']\n",
      "AFter tokenizer:  ['u', 'r', 'the', 'most', 'beautiful', 'girl', 'ive', 'ever', 'seen', '.', 'u', 'r', 'my', 'baby', 'come', 'and', 'c', 'me', 'in', 'the', 'common', 'room']\n",
      "AFter tokenizer:  ['o', 'we', 'cant', 'see', 'if', 'we', 'can', 'join', 'denis', 'and', 'mina', '?', 'or', 'does', 'denis', 'want', 'alone', 'time']\n",
      "AFter tokenizer:  ['sen', 'told', 'that', 'he', 'is', 'going', 'to', 'join', 'his', 'uncle', 'finance', 'in', 'cbe']\n",
      "AFter tokenizer:  ['yup', '...', 'hey', 'then', 'one', 'day', 'on', 'fri', 'we', 'can', 'ask', 'miwa', 'and', 'jiayin', 'take', 'leave', 'go', 'karaoke']\n",
      "AFter tokenizer:  ['call', 'me', ',', 'i', 'am', 'senthil', 'from', 'hsbc', '.']\n",
      "AFter tokenizer:  ['especially', 'since', 'i', 'talk', 'about', 'boston', 'all', 'up', 'in', 'my', 'personal', 'statement', ',', 'lol', '!', 'i', 'woulda', 'changed', 'that', 'if', 'i', 'had', 'realized', 'it', 'said', 'nyc', '!', 'it', 'says', 'boston', 'now', '.']\n",
      "AFter tokenizer:  ['indeed', 'and', 'by', 'the', 'way', 'it', 'was', 'either', 'or', '-', 'not', 'both', '!']\n",
      "AFter tokenizer:  ['urgent', '-call', '09066649731from', 'landline', '.', 'your', 'complimentary', '4', '*', 'ibiza', 'holiday', 'or', '£10,000', 'cash', 'await', 'collection', 'sae', 't', '&', 'cs', 'po', 'box', '434', 'sk3', '8wp', '150ppm', '18+']\n",
      "AFter tokenizer:  ['holy', 'living', 'christ', 'what', 'is', 'taking', 'you', 'so', 'long']\n",
      "AFter tokenizer:  ['ü', 'thk', 'of', 'wat', 'to', 'eat', 'tonight', '.']\n",
      "AFter tokenizer:  ['thanx', '.', 'yup', 'we', 'coming', 'back', 'on', 'sun', '.', 'finish', 'dinner', 'going', 'back', '2', 'hotel', 'now', '.', 'time', 'flies', ',', 'we', \"'re\", 'tog', '4', 'exactly', 'a', 'mth', 'today', '.', 'hope', 'we', \"'ll\", 'haf', 'many', 'more', 'mths', 'to', 'come', '...']\n",
      "AFter tokenizer:  ['we', \"'re\", 'on', 'the', 'opposite', 'side', 'from', 'where', 'we', 'dropped', 'you', 'off']\n",
      "AFter tokenizer:  ['yup', '.', 'izzit', 'still', 'raining', 'heavily', 'cos', 'i', \"'m\", 'in', 'e', 'mrt', 'i', 'ca', \"n't\", 'c', 'outside', '.']\n",
      "AFter tokenizer:  ['send', 'me', 'your', 'resume', ':', '-', ')']\n",
      "AFter tokenizer:  ['gd', 'luck', '4', 'ur', 'exams', ':', '-', ')']\n",
      "AFter tokenizer:  ['or', 'u', 'ask', 'they', 'all', 'if', 'next', 'sat', 'can', 'a', 'not', '.', 'if', 'all', 'of', 'them', 'can', 'make', 'it', 'then', 'i', \"'m\", 'ok', 'lor', '.']\n",
      "AFter tokenizer:  ['sorry', 'that', 'was', 'my', 'uncle', '.', 'i.ll', 'keep', 'in', 'touch']\n",
      "AFter tokenizer:  ['saw', 'guys', 'and', 'dolls', 'last', 'night', 'with', 'patrick', 'swayze', 'it', 'was', 'great']\n",
      "AFter tokenizer:  ['urgent', 'this', 'is', 'our', '2nd', 'attempt', 'to', 'contact', 'u.', 'your', '£900', 'prize', 'from', 'yesterday', 'is', 'still', 'awaiting', 'collection', '.', 'to', 'claim', 'call', 'now', '09061702893']\n",
      "AFter tokenizer:  ['santa', 'calling', '!', 'would', 'your', 'little', 'ones', 'like', 'a', 'call', 'from', 'santa', 'xmas', 'eve', '?', 'call', '09077818151', 'to', 'book', 'you', 'time', '.', 'calls1.50ppm', 'last', '3mins', '30s', 't', '&', 'c', 'www.santacalling.com']\n",
      "AFter tokenizer:  ['just', 'come', 'home', '.', 'i', 'do', \"n't\", 'want', 'u', 'to', 'be', 'miserable']\n",
      "AFter tokenizer:  ['i', 'dont', 'know', 'why', 'she.s', 'not', 'getting', 'your', 'messages']\n",
      "AFter tokenizer:  ['its', 'cool', 'but', 'tyler', 'had', 'to', 'take', 'off', 'so', 'we', \"'re\", 'gon', 'na', 'buy', 'for', 'him', 'and', 'drop', 'it', 'off', 'at', 'his', 'place', 'later', 'tonight', '.', 'our', 'total', 'order', 'is', 'a', 'quarter', ',', 'you', 'got', 'enough', '?']\n",
      "AFter tokenizer:  ['the', 'guy', 'at', 'the', 'car', 'shop', 'who', 'was', 'flirting', 'with', 'me', 'got', 'my', 'phone', 'number', 'from', 'the', 'paperwork', 'and', 'called', 'and', 'texted', 'me', '.', 'i', \"'m\", 'nervous', 'because', 'of', 'course', 'now', 'he', 'may', 'have', 'my', 'address', '.', 'should', 'i', 'call', 'his', 'boss', 'and', 'tell', 'him', ',', 'knowing', 'this', 'may', 'get', 'him', 'fired', '?']\n",
      "AFter tokenizer:  ['how', 'do', 'you', 'plan', 'to', 'manage', 'that']\n",
      "AFter tokenizer:  ['er', ',', 'hello', ',', 'things', 'didn', '‘', 't', 'quite', 'go', 'to', 'plan', '–', 'is', 'limping', 'slowly', 'home', 'followed', 'by', 'aa', 'and', 'with', 'exhaust', 'hanging', 'off']\n",
      "AFter tokenizer:  ['sorry', 'for', 'the', 'delay', '.', 'yes', 'masters']\n",
      "AFter tokenizer:  ['call', 'me', 'when', 'u', 'finish', 'then', 'i', 'come', 'n', 'pick', 'u', '.']\n",
      "AFter tokenizer:  ['private', '!', 'your', '2004', 'account', 'statement', 'for', '078498', '*', '*', '*', '*', '7', 'shows', '786', 'unredeemed', 'bonus', 'points', '.', 'to', 'claim', 'call', '08719180219', 'identifier', 'code', ':', '45239', 'expires', '06.05.05']\n",
      "AFter tokenizer:  ['what', \"'s\", 'up', 'my', 'own', 'oga', '.', 'left', 'my', 'phone', 'at', 'home', 'and', 'just', 'saw', 'ur', 'messages', '.', 'hope', 'you', 'are', 'good', '.', 'have', 'a', 'great', 'weekend', '.']\n",
      "AFter tokenizer:  ['do', \"n't\", 'worry', 'though', ',', 'i', 'understand', 'how', 'important', 'it', 'is', 'that', 'i', 'be', 'put', 'in', 'my', 'place', 'with', 'a', 'poorly', 'thought', 'out', 'punishment', 'in', 'the', 'face', 'of', 'the', 'worst', 'thing', 'that', 'has', 'ever', 'happened', 'to', 'me', '.', 'brb', 'gon', 'na', 'go', 'kill', 'myself']\n",
      "AFter tokenizer:  ['honey', ',', 'can', 'you', 'pls', 'find', 'out', 'how', 'much', 'they', 'sell', 'predicte', 'in', 'nigeria', '.', 'and', 'how', 'many', 'times', 'can', 'it', 'be', 'used', '.', 'its', 'very', 'important', 'to', 'have', 'a', 'reply', 'before', 'monday']\n",
      "AFter tokenizer:  ['e', 'admin', 'building', 'there', '?', 'i', 'might', 'b', 'slightly', 'earlier', '...', 'i', \"'ll\", 'call', 'u', 'when', 'i', \"'m\", 'reaching', '...']\n",
      "AFter tokenizer:  ['fyi', 'i', \"'m\", 'at', 'usf', 'now', ',', 'swing', 'by', 'the', 'room', 'whenever']\n",
      "AFter tokenizer:  ['i', 'can', 'call', 'in', '&', 'lt', ';', '#', '&', 'gt', ';', 'min', 'if', 'thats', 'ok']\n",
      "AFter tokenizer:  ['ü', 'no', 'home', 'work', 'to', 'do', 'meh', '...']\n",
      "AFter tokenizer:  ['anything', 'is', 'valuable', 'in', 'only', '2', 'situations', ':', 'first-', 'before', 'getting', 'it', '...', 'second-', 'after', 'loosing', 'it', '...']\n",
      "AFter tokenizer:  ['me', 'too', '.', 'mark', 'is', 'taking', 'forever', 'to', 'pick', 'up', 'my', 'prescription', 'and', 'the', 'pain', 'is', 'coming', 'back', '.']\n",
      "AFter tokenizer:  ['how', \"'s\", 'ur', 'paper', '?']\n",
      "AFter tokenizer:  ['got', 'smaller', 'capacity', 'one', '?', 'quite', 'ex', '...']\n",
      "AFter tokenizer:  ['check', 'out', 'choose', 'your', 'babe', 'videos', '@', 'sms.shsex.netun', 'fgkslpopw', 'fgkslpo']\n",
      "AFter tokenizer:  ['im', 'good', '!', 'i', 'have', 'been', 'thinking', 'about', 'you', '...']\n",
      "AFter tokenizer:  ['u', 'r', 'a', 'winner', 'u', 'ave', 'been', 'specially', 'selected', '2', 'receive', '£1000', 'cash', 'or', 'a', '4', '*', 'holiday', '(', 'flights', 'inc', ')', 'speak', 'to', 'a', 'live', 'operator', '2', 'claim', '0871277810710p/min', '(', '18', ')']\n",
      "AFter tokenizer:  [':', '-', ')', ':', '-', ')']\n",
      "AFter tokenizer:  ['not', 'thought', 'bout', 'it', '...', '||', 'drink', 'in', 'tap', '&', 'spile', 'at', 'seven', '.', '||', 'is', 'that', 'pub', 'on', 'gas', 'st', 'off', 'broad', 'st', 'by', 'canal', '.', '||', 'ok', '?']\n",
      "AFter tokenizer:  ['i', 'am', 'going', 'to', 'sleep', '.', 'i', 'am', 'tired', 'of', 'travel', '.']\n",
      "AFter tokenizer:  ['haha', ',', 'just', 'what', 'i', 'was', 'thinkin']\n",
      "AFter tokenizer:  ['yup', 'but', 'it', \"'s\", 'not', 'giving', 'me', 'problems', 'now', 'so', 'mayb', 'i', \"'ll\", 'jus', 'leave', 'it', '...']\n",
      "AFter tokenizer:  ['lol', 'no', '.', 'just', 'trying', 'to', 'make', 'your', 'day', 'a', 'little', 'more', 'interesting']\n",
      "AFter tokenizer:  ['how', 'long', 'before', 'you', 'get', 'reply', ',', 'just', 'defer', 'admission', 'til', 'next', 'semester']\n",
      "AFter tokenizer:  ['the', 'word', '``', 'checkmate', \"''\", 'in', 'chess', 'comes', 'from', 'the', 'persian', 'phrase', '``', 'shah', 'maat', \"''\", 'which', 'means', ';', '``', 'the', 'king', 'is', 'dead', '..', \"''\", 'goodmorning', '..', 'have', 'a', 'good', 'day', '..', ':', ')']\n",
      "AFter tokenizer:  ['po', 'de', ':', '-', ')', ':', ')', ':', '-', ')', ':', '-', ')', ':', '-', ')', '.', 'no', 'need', 'job', 'aha', '.']\n",
      "AFter tokenizer:  ['rats', '.', 'hey', 'did', 'u', 'ever', 'vote', 'for', 'the', 'next', 'themes', '?']\n",
      "AFter tokenizer:  ['new', 'mobiles', 'from', '2004', ',', 'must', 'go', '!', 'txt', ':', 'nokia', 'to', 'no', ':', '89545', '&', 'collect', 'yours', 'today', '!', 'from', 'only', '£1', '.', 'www.4-tc.biz', '2optout', '087187262701.50gbp/mtmsg18', 'txtauction', '.']\n",
      "AFter tokenizer:  ['i', 'hope', 'your', 'pee', 'burns', 'tonite', '.']\n",
      "AFter tokenizer:  ['oh', 'rite', '.', 'well', 'im', 'with', 'my', 'best', 'mate', 'pete', ',', 'who', 'i', 'went', 'out', 'with', '4', 'a', 'week+', 'now', 'were', '2geva', 'again', '.', 'its', 'been', 'longer', 'than', 'a', 'week', '.']\n",
      "AFter tokenizer:  ['yay', 'ca', \"n't\", 'wait', 'to', 'party', 'together', '!']\n",
      "AFter tokenizer:  ['....', 'photoshop', 'makes', 'my', 'computer', 'shut', 'down', '.']\n",
      "AFter tokenizer:  ['all', 'boys', 'made', 'fun', 'of', 'me', 'today', '.', 'ok', 'i', 'have', 'no', 'problem', '.', 'i', 'just', 'sent', 'one', 'message', 'just', 'for', 'fun']\n",
      "AFter tokenizer:  ['that', \"'s\", 'one', 'of', 'the', 'issues', 'but', 'california', 'is', 'okay', '.', 'no', 'snow', 'so', 'its', 'manageable']\n",
      "AFter tokenizer:  ['private', '!', 'your', '2003', 'account', 'statement', 'for', 'shows', '800', 'un-redeemed', 's.', 'i.', 'm.', 'points', '.', 'call', '08715203652', 'identifier', 'code', ':', '42810', 'expires', '29/10/0']\n",
      "AFter tokenizer:  ['hmmm', '....', 'mayb', 'can', 'try', 'e', 'shoppin', 'area', 'one', ',', 'but', 'forgot', 'e', 'name', 'of', 'hotel', '...']\n",
      "AFter tokenizer:  ['awesome', ',', 'that', 'gon', 'na', 'be', 'soon', 'or', 'later', 'tonight', '?']\n",
      "AFter tokenizer:  ['i', 'need', 'details', 'about', 'that', 'online', 'job', '.']\n",
      "AFter tokenizer:  ['missing', 'you', 'too.pray', 'inshah', 'allah']\n",
      "AFter tokenizer:  ['pls', 'help', 'me', 'tell', 'ashley', 'that', 'i', 'cant', 'find', 'her', 'number', 'oh']\n",
      "AFter tokenizer:  ['s.this', 'will', 'increase', 'the', 'chance', 'of', 'winning', '.']\n",
      "AFter tokenizer:  ['either', 'way', 'works', 'for', 'me', '.', 'i', 'am', '&', 'lt', ';', '#', '&', 'gt', ';', 'years', 'old', '.', 'hope', 'that', 'doesnt', 'bother', 'you', '.']\n",
      "AFter tokenizer:  ['maybe', 'you', 'should', 'find', 'something', 'else', 'to', 'do', 'instead', '?', '?', '?']\n",
      "AFter tokenizer:  ['gain', 'the', 'rights', 'of', 'a', 'wife.dont', 'demand', 'it.i', 'am', 'trying', 'as', 'husband', 'too.lets', 'see']\n",
      "AFter tokenizer:  ['i', 'liked', 'your', 'new', 'house']\n",
      "AFter tokenizer:  ['i', \"'m\", 'fine', '.', 'hope', 'you', 'are', 'also']\n",
      "AFter tokenizer:  ['also', 'north', 'carolina', 'and', 'texas', 'atm', ',', 'you', 'would', 'just', 'go', 'to', 'the', 'gre', 'site', 'and', 'pay', 'for', 'the', 'test', 'results', 'to', 'be', 'sent', '.']\n",
      "AFter tokenizer:  ['same', 'to', 'u', '...']\n",
      "AFter tokenizer:  ['yes', 'baby', '!', 'i', 'need', 'to', 'stretch', 'open', 'your', 'pussy', '!']\n",
      "AFter tokenizer:  ['thanks', 'and', '!', 'or', 'bomb', 'and', 'date', 'as', 'my', 'phone', 'wanted', 'to', 'say', '!']\n",
      "AFter tokenizer:  ['hey', ',', 'a', 'guy', 'i', 'know', 'is', 'breathing', 'down', 'my', 'neck', 'to', 'get', 'him', 'some', 'bud', ',', 'anyway', 'you', \"'d\", 'be', 'able', 'to', 'get', 'a', 'half', 'track', 'to', 'usf', 'tonight', '?']\n",
      "AFter tokenizer:  ['response', 'is', 'one', 'of', 'd', 'powerful', 'weapon', '2', 'occupy', 'a', 'place', 'in', 'others', \"'heart\", \"'\", '...', 'so', ',', 'always', 'give', 'response', '2', 'who', 'cares', '4', 'u', \"''\", '...', 'gud', 'night', '..', 'swt', 'dreams', '..', 'take', 'care']\n",
      "AFter tokenizer:  ['nokia', 'phone', 'is', 'lovly', '..']\n",
      "AFter tokenizer:  ['*', '*', 'free', 'message', '*', '*', 'thanks', 'for', 'using', 'the', 'auction', 'subscription', 'service', '.', '18', '.', '150p/msgrcvd', '2', 'skip', 'an', 'auction', 'txt', 'out', '.', '2', 'unsubscribe', 'txt', 'stop', 'customercare', '08718726270']\n",
      "AFter tokenizer:  ['sorry', 'da', '..', 'today', 'i', 'wont', 'come', 'to', 'play', '..', 'i', 'have', 'driving', 'clas', '..']\n",
      "AFter tokenizer:  ['i', \"'m\", 'really', 'sorry', 'i', 'lit', 'your', 'hair', 'on', 'fire']\n",
      "AFter tokenizer:  ['oh', '!', 'shit', ',', 'i', 'thought', 'that', 'was', 'your', 'trip', '!', 'loooooool', '...', 'that', 'just', 'makes', 'so', 'much', 'more', 'sense', 'now', '...', '*', 'grins', '*', 'and', 'the', 'sofa', 'reference', 'was', '...', 'the', '``', 'sleep', 'on', 'a', 'couch', \"''\", 'link', 'you', 'sent', 'me', '...', 'was', \"n't\", 'that', 'how', 'you', 'went', 'on', 'your', 'trip', '?', 'oh', '...', 'and', 'did', \"n't\", 'your', 'babe', 'go', 'with', 'you', 'for', 'that', 'celebration', 'with', 'your', 'rents', '?']\n",
      "AFter tokenizer:  ['okey', 'dokey', 'swashbuckling', 'stuff', 'what', 'oh', '.']\n",
      "AFter tokenizer:  ['1.', 'tension', 'face', '2.', 'smiling', 'face', '3.', 'waste', 'face', '4.', 'innocent', 'face', '5.terror', 'face', '6.cruel', 'face', '7.romantic', 'face', '8.lovable', 'face', '9.decent', 'face', '&', 'lt', ';', '#', '&', 'gt', ';', '.joker', 'face', '.']\n",
      "AFter tokenizer:  ['dip', \"'s\", 'cell', 'dead', '.', 'so', 'i', 'm', 'coming', 'with', 'him', '.', 'u', 'better', 'respond', 'else', 'we', 'shall', 'come', 'back', '.']\n",
      "AFter tokenizer:  ['well', '.', 'you', 'know', 'what', 'i', 'mean', '.', 'texting']\n",
      "AFter tokenizer:  ['hi', 'dis', 'is', 'yijue', 'i', 'would', 'be', 'happy', 'to', 'work', 'wif', 'ü', 'all', 'for', 'gek1510', '...']\n",
      "AFter tokenizer:  ['lol', '!', 'oops', 'sorry', '!', 'have', 'fun', '.']\n",
      "AFter tokenizer:  ['wat', 'happened', 'to', 'the', 'cruise', 'thing']\n",
      "AFter tokenizer:  ['i', 'know', 'dat', 'feelin', 'had', 'it', 'with', 'pete', '!', 'wuld', 'get', 'with', 'em', ',', 'nuther', 'place', 'nuther', 'time', 'mayb', '?']\n",
      "AFter tokenizer:  ['lyricalladie', '(', '21/f', ')', 'is', 'inviting', 'you', 'to', 'be', 'her', 'friend', '.', 'reply', 'yes-910', 'or', 'no-910', '.', 'see', 'her', ':', 'www.sms.ac/u/hmmross', 'stop', '?', 'send', 'stop', 'frnd', 'to', '62468']\n",
      "AFter tokenizer:  ['the', 'world', \"'s\", 'most', 'happiest', 'frnds', 'never', 'have', 'the', 'same', 'characters', '...', 'dey', 'just', 'have', 'the', 'best', 'understanding', 'of', 'their', 'differences', '...']\n",
      "AFter tokenizer:  ['yeah', 'just', 'open', 'chat', 'and', 'click', 'friend', 'lists', '.', 'then', 'make', 'the', 'list', '.', 'easy', 'as', 'pie']\n",
      "AFter tokenizer:  ['alright', 'tyler', \"'s\", 'got', 'a', 'minor', 'crisis', 'and', 'has', 'to', 'be', 'home', 'sooner', 'than', 'he', 'thought', 'so', 'be', 'here', 'asap']\n",
      "AFter tokenizer:  ['when/where', 'do', 'i', 'pick', 'you', 'up']\n",
      "AFter tokenizer:  ['as', 'usual', 'u', 'can', 'call', 'me', 'ard', '10', 'smth', '.']\n",
      "AFter tokenizer:  ['for', 'many', 'things', 'its', 'an', 'antibiotic', 'and', 'it', 'can', 'be', 'used', 'for', 'chest', 'abdomen', 'and', 'gynae', 'infections', 'even', 'bone', 'infections', '.']\n",
      "AFter tokenizer:  ['poor', 'girl', 'ca', \"n't\", 'go', 'one', 'day', 'lmao']\n",
      "AFter tokenizer:  ['or', 'just', 'do', 'that', '6times']\n",
      "AFter tokenizer:  ['you', 'have', 'to', 'pls', 'make', 'a', 'note', 'of', 'all', 'she.s', 'exposed', 'to', '.', 'also', 'find', 'out', 'from', 'her', 'school', 'if', 'anyone', 'else', 'was', 'vomiting', '.', 'is', 'there', 'a', 'dog', 'or', 'cat', 'in', 'the', 'house', '?', 'let', 'me', 'know', 'later', '.']\n",
      "AFter tokenizer:  ['sounds', 'like', 'there', 'could', 'be', 'a', 'lot', 'of', 'time', 'spent', 'in', 'that', 'chastity', 'device', 'boy', '...', '*', 'grins', '*', '...', 'or', 'take', 'your', 'beatings', 'like', 'a', 'good', 'dog', '.', 'going', 'to', 'lounge', 'in', 'a', 'nice', 'long', 'bath', 'now', '?']\n",
      "AFter tokenizer:  ['its', 'worse', 'if', 'if', 'uses', 'half', 'way', 'then', 'stops', '.', 'its', 'better', 'for', 'him', 'to', 'complete', 'it', '.']\n",
      "AFter tokenizer:  ['miserable', '.', 'they', 'do', \"n't\", 'tell', 'u', 'that', 'the', 'side', 'effects', 'of', 'birth', 'control', 'are', 'massive', 'gut', 'wrenching', 'cramps', 'for', 'the', 'first', '2', 'months', '.', 'i', 'did', \"n't\", 'sleep', 'at', 'all', 'last', 'night', '.']\n",
      "AFter tokenizer:  ['send', 'me', 'the', 'new', 'number']\n",
      "AFter tokenizer:  ['want', 'the', 'latest', 'video', 'handset', '?', '750', 'anytime', 'any', 'network', 'mins', '?', 'half', 'price', 'line', 'rental', '?', 'reply', 'or', 'call', '08000930705', 'for', 'delivery', 'tomorrow']\n",
      "AFter tokenizer:  ['2', 'and', 'half', 'years', 'i', 'missed', 'your', 'friendship', ':', '-', ')']\n",
      "AFter tokenizer:  ['oh', 'for', 'fuck', \"'s\", 'sake', 'she', \"'s\", 'in', 'like', 'tallahassee']\n",
      "AFter tokenizer:  ['haha', ',', 'that', 'was', 'the', 'first', 'person', 'i', 'was', 'gon', 'na', 'ask']\n",
      "AFter tokenizer:  ['ou', 'are', 'guaranteed', 'the', 'latest', 'nokia', 'phone', ',', 'a', '40gb', 'ipod', 'mp3', 'player', 'or', 'a', '£500', 'prize', '!', 'txt', 'word', ':', 'collect', 'to', 'no', ':', '83355', '!', 'ibhltd', 'ldnw15h', '150p/mtmsgrcvd18']\n",
      "AFter tokenizer:  ['taka', 'lor', '.', 'wat', 'time', 'u', 'wan', '2', 'come', 'n', 'look', '4', 'us', '?']\n",
      "AFter tokenizer:  ['*', 'free', '*', 'polyphonic', 'ringtone', 'text', 'super', 'to', '87131', 'to', 'get', 'your', 'free', 'poly', 'tone', 'of', 'the', 'week', 'now', '!', '16', 'sn', 'pobox202', 'nr31', '7zs', 'subscription', '450pw']\n",
      "AFter tokenizer:  ['i', ';', 'm', 'reaching', 'in', 'another', '2', 'stops', '.']\n",
      "AFter tokenizer:  ['no', ',', 'i', '*', 'did', \"n't\", '*', 'mean', 'to', 'post', 'it', '.', 'i', 'wrote', 'it', ',', 'and', 'like', 'so', 'many', 'other', 'times', 'i', \"'ve\", 'ritten', 'stuff', 'to', 'you', ',', 'i', 'let', 'it', 'sit', 'there', '.', 'it', 'was', 'what', 'i', 'was', 'feeling', 'at', 'the', 'time', '.', 'i', 'was', 'angry', '.', 'before', 'i', 'left', ',', 'i', 'hit', 'send', ',', 'then', 'stop', '.', 'it', 'was', \"n't\", 'there', '.', 'i', 'checked', 'on', 'my', 'phone', 'when', 'i', 'got', 'to', 'my', 'car', '.', 'it', 'was', \"n't\", 'there', '.', 'you', 'said', 'you', 'did', \"n't\", 'sleep', ',', 'you', 'were', 'bored', '.', 'so', 'why', 'would', \"n't\", 'that', 'be', 'the', 'time', 'to', 'clean', ',', 'fold', 'laundry', ',', 'etc.', '?', 'at', 'least', 'make', 'the', 'bed', '?']\n",
      "AFter tokenizer:  ['warner', 'village', '83118', 'c', 'colin', 'farrell', 'in', 'swat', 'this', 'wkend', '@', 'warner', 'village', '&', 'get', '1', 'free', 'med', '.', 'popcorn', '!', 'just', 'show', 'msg+ticket', '@', 'kiosk.valid', '4-7/12', '.', 'c', 't', '&', 'c', '@', 'kiosk', '.', 'reply', 'sony', '4', 'mre', 'film', 'offers']\n",
      "AFter tokenizer:  ['will', 'you', 'come', 'online', 'today', 'night']\n",
      "AFter tokenizer:  ['then', 'anything', 'special', '?']\n",
      "AFter tokenizer:  ['i', \"'m\", 'in', 'solihull', ',', '|', 'do', 'you', 'want', 'anything', '?']\n",
      "AFter tokenizer:  ['will', 'do', '.', 'have', 'a', 'good', 'day']\n",
      "AFter tokenizer:  ['we', 'regret', 'to', 'inform', 'u', 'that', 'the', 'nhs', 'has', 'made', 'a', 'mistake.u', 'were', 'never', 'actually', 'born.please', 'report', '2', 'yor', 'local', 'hospital', '2b', 'terminated.we', 'r', 'sorry', '4', 'the', 'inconvenience']\n",
      "AFter tokenizer:  ['love', 'that', 'holiday', 'monday', 'feeling', 'even', 'if', 'i', 'have', 'to', 'go', 'to', 'the', 'dentists', 'in', 'an', 'hour']\n",
      "AFter tokenizer:  ['i', 'am', 'on', 'the', 'way', 'to', 'tirupur', '.']\n",
      "AFter tokenizer:  ['goal', '!', 'arsenal', '4', '(', 'henry', ',', '7', 'v', 'liverpool', '2', 'henry', 'scores', 'with', 'a', 'simple', 'shot', 'from', '6', 'yards', 'from', 'a', 'pass', 'by', 'bergkamp', 'to', 'give', 'arsenal', 'a', '2', 'goal', 'margin', 'after', '78', 'mins', '.']\n",
      "AFter tokenizer:  ['you', \"'ve\", 'already', 'got', 'a', 'flaky', 'parent', '.', \"it'snot\", 'supposed', 'to', 'be', 'the', 'child', \"'s\", 'job', 'to', 'support', 'the', 'parent', '...', 'not', 'until', 'they', \"'re\", 'the', 'ride', 'age', 'anyway', '.', 'i', \"'m\", 'supposed', 'to', 'be', 'there', 'to', 'support', 'you', '.', 'and', 'now', 'i', \"'ve\", 'hurt', 'you', '.', 'unintentional', '.', 'but', 'hurt', 'nonetheless', '.']\n",
      "AFter tokenizer:  ['we', 'took', 'hooch', 'for', 'a', 'walk', 'toaday', 'and', 'i', 'fell', 'over', '!', 'splat', '!', 'grazed', 'my', 'knees', 'and', 'everything', '!', 'should', 'have', 'stayed', 'at', 'home', '!', 'see', 'you', 'tomorrow', '!']\n",
      "AFter tokenizer:  ['just', 'dropped', 'em', 'off', ',', 'omw', 'back', 'now']\n",
      "AFter tokenizer:  ['sitting', 'in', 'mu', 'waiting', 'for', 'everyone', 'to', 'get', 'out', 'of', 'my', 'suite', 'so', 'i', 'can', 'take', 'a', 'shower']\n",
      "AFter tokenizer:  ['re', 'your', 'call', ';', 'you', 'did', \"n't\", 'see', 'my', 'facebook', 'huh', '?']\n",
      "AFter tokenizer:  ['g', 'says', 'you', 'never', 'answer', 'your', 'texts', ',', 'confirm/deny']\n",
      "AFter tokenizer:  ['its', 'so', 'common', 'hearin', 'how', 'r', 'u', '?', 'wat', 'r', 'u', 'doing', '?', 'how', 'was', 'ur', 'day', '?', 'so', 'let', 'me', 'ask', 'u', 'something', 'different', '.', 'did', 'u', 'smile', 'today', '?', 'if', 'not', ',', 'do', 'it', 'now', '....', 'gud', 'evng', '.']\n",
      "AFter tokenizer:  ['oh', 'yah', '...', 'we', 'never', 'cancel', 'leh', '...', 'haha']\n",
      "AFter tokenizer:  ['we', 'can', 'go', '4', 'e', 'normal', 'pilates', 'after', 'our', 'intro', '...']\n",
      "AFter tokenizer:  ['ok', '...', 'let', 'u', 'noe', 'when', 'i', 'leave', 'my', 'house', '.']\n",
      "AFter tokenizer:  ['oh', 'yes', ',', 'why', 'is', 'it', 'like', 'torture', 'watching', 'england', '?']\n",
      "AFter tokenizer:  ['wan', 'na', 'do', 'some', 'art', '?', '!', ':', 'd']\n",
      "AFter tokenizer:  ['just', 'hopeing', 'that', 'wasn', '‘', 't', 'too', 'pissed', 'up', 'to', 'remember', 'and', 'has', 'gone', 'off', 'to', 'his', 'sisters', 'or', 'something', '!']\n",
      "AFter tokenizer:  ['hi', ',', 'the', 'sexychat', 'girls', 'are', 'waiting', 'for', 'you', 'to', 'text', 'them', '.', 'text', 'now', 'for', 'a', 'great', 'night', 'chatting', '.', 'send', 'stop', 'to', 'stop', 'this', 'service']\n",
      "AFter tokenizer:  ['good', 'morning', ',', 'my', 'boytoy', '!', 'how', \"'s\", 'those', 'yummy', 'lips', '?', 'where', \"'s\", 'my', 'sexy', 'buns', 'now', '?', 'what', 'do', 'you', 'do', '?', 'do', 'you', 'think', 'of', 'me', '?', 'do', 'you', 'crave', 'me', '?', 'do', 'you', 'need', 'me', '?']\n",
      "AFter tokenizer:  ['match', 'started.india', '&', 'lt', ';', '#', '&', 'gt', ';', 'for', '2']\n",
      "AFter tokenizer:  ['once', 'free', 'call', 'me', 'sir', '.']\n",
      "AFter tokenizer:  ['hey', 'do', 'you', 'want', 'anything', 'to', 'buy', ':', ')']\n",
      "AFter tokenizer:  ['hey', 'babe', ',', 'how', \"'s\", 'it', 'going', '?', 'did', 'you', 'ever', 'figure', 'out', 'where', 'your', 'going', 'for', 'new', 'years', '?']\n",
      "AFter tokenizer:  ['k', '..', 'k.', ':', ')', 'congratulation', '..']\n",
      "AFter tokenizer:  ['g', 'wants', 'to', 'know', 'where', 'the', 'fuck', 'you', 'are']\n",
      "AFter tokenizer:  ['no', 'it', 'was', 'cancelled', 'yeah', 'baby', '!', 'well', 'that', 'sounds', 'important', 'so', 'i', 'understand', 'my', 'darlin', 'give', 'me', 'a', 'ring', 'later', 'on', 'this', 'fone', 'love', 'kate', 'x']\n",
      "AFter tokenizer:  ['tomarrow', 'i', 'want', 'to', 'got', 'to', 'court', '.', 'at', '&', 'lt', ';', 'decimal', '&', 'gt', ';', '.', 'so', 'you', 'come', 'to', 'bus', 'stand', 'at', '9', '.']\n",
      "AFter tokenizer:  ['ü', 'go', 'home', 'liao', '?', 'ask', 'dad', 'to', 'pick', 'me', 'up', 'at', '6', '...']\n",
      "AFter tokenizer:  ['omg', 'you', 'can', 'make', 'a', 'wedding', 'chapel', 'in', 'frontierville', '?', 'why', 'do', 'they', 'get', 'all', 'the', 'good', 'stuff', '?']\n",
      "AFter tokenizer:  ['i', \"'m\", 'eatin', 'now', 'lor', ',', 'but', 'goin', 'back', 'to', 'work', 'soon', '...', 'e', 'mountain', 'deer', 'show', 'huh', '...', 'i', 'watch', 'b4', 'liao', ',', 'very', 'nice', '...']\n",
      "AFter tokenizer:  ['check', 'mail.i', 'have', 'mailed', 'varma', 'and', 'kept', 'copy', 'to', 'you', 'regarding', 'membership.take', 'care.insha', 'allah', '.']\n",
      "AFter tokenizer:  ['wrong', 'phone', '!', 'this', 'phone', '!', 'i', 'answer', 'this', 'one', 'but', 'assume', 'the', 'other', 'is', 'people', 'i', 'do', \"n't\", 'well']\n",
      "AFter tokenizer:  ['anyway', 'i', 'do', \"n't\", 'think', 'i', 'can', 'secure', 'anything', 'up', 'here', ',', 'lem', 'me', 'know', 'if', 'you', 'want', 'me', 'to', 'drive', 'down', 'south', 'and', 'chill']\n",
      "AFter tokenizer:  ['i', \"'m\", 'already', 'back', 'home', 'so', 'no', 'probably', 'not']\n",
      "AFter tokenizer:  ['hi', 'this', 'is', 'amy', ',', 'we', 'will', 'be', 'sending', 'you', 'a', 'free', 'phone', 'number', 'in', 'a', 'couple', 'of', 'days', ',', 'which', 'will', 'give', 'you', 'an', 'access', 'to', 'all', 'the', 'adult', 'parties', '...']\n",
      "AFter tokenizer:  ['i', 'am', 'in', 'bus', 'on', 'the', 'way', 'to', 'calicut']\n",
      "AFter tokenizer:  ['hi', 'its', 'me', 'you', 'are', 'probably', 'having', 'too', 'much', 'fun', 'to', 'get', 'this', 'message', 'but', 'i', 'thought', 'id', 'txt', 'u', 'cos', 'im', 'bored', '!', 'and', 'james', 'has', 'been', 'farting', 'at', 'me', 'all', 'night']\n",
      "AFter tokenizer:  ['hi', 'baby', 'im', 'sat', 'on', 'the', 'bloody', 'bus', 'at', 'the', 'mo', 'and', 'i', 'wont', 'be', 'home', 'until', 'about', '7:30', 'wan', 'na', 'do', 'somethin', 'later', '?', 'call', 'me', 'later', 'ortxt', 'back', 'jess', 'xx']\n",
      "AFter tokenizer:  ['welcome', 'to', 'select', ',', 'an', 'o2', 'service', 'with', 'added', 'benefits', '.', 'you', 'can', 'now', 'call', 'our', 'specially', 'trained', 'advisors', 'free', 'from', 'your', 'mobile', 'by', 'dialling', '402', '.']\n",
      "AFter tokenizer:  ['i', 'lost', '4', 'pounds', 'since', 'my', 'doc', 'visit', 'last', 'week', 'woot', 'woot', '!', 'now', 'i', \"'m\", 'gon', 'na', 'celebrate', 'by', 'stuffing', 'my', 'face', '!']\n",
      "AFter tokenizer:  ['u', 'coming', 'back', '4', 'dinner', 'rite', '?', 'dad', 'ask', 'me', 'so', 'i', 're', 'confirm', 'wif', 'u', '...']\n",
      "AFter tokenizer:  ['doing', 'my', 'masters', '.', 'when', 'will', 'you', 'buy', 'a', 'bb', 'cos', 'i', 'have', 'for', 'sale', 'and', 'how', \"'s\", 'bf']\n",
      "AFter tokenizer:  ['ahhhh', '...', 'just', 'woken', 'up', '!', 'had', 'a', 'bad', 'dream', 'about', 'u', 'tho', ',', 'so', 'i', 'dont', 'like', 'u', 'right', 'now', ':', ')', 'i', 'didnt', 'know', 'anything', 'about', 'comedy', 'night', 'but', 'i', 'guess', 'im', 'up', 'for', 'it', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'vivek', ':', ')', 'i', 'got', 'call', 'from', 'your', 'number', '.']\n",
      "AFter tokenizer:  ['why', 'did', \"n't\", 'u', 'call', 'on', 'your', 'lunch', '?']\n",
      "AFter tokenizer:  ['what', 'i', 'mean', 'was', 'i', 'left', 'too', 'early', 'to', 'check', ',', 'cos', 'i', \"'m\", 'working', 'a', '9-6', '.']\n",
      "AFter tokenizer:  ['i', 'want', '&', 'lt', ';', '#', '&', 'gt', ';', 'rs', 'da', ':', ')', 'do', 'you', 'have', 'it', '?']\n",
      "AFter tokenizer:  ['i', 'want', 'to', 'see', 'your', 'pretty', 'pussy', '...']\n",
      "AFter tokenizer:  ['dear', 'voucher', 'holder', 'have', 'your', 'next', 'meal', 'on', 'us', '.', 'use', 'the', 'following', 'link', 'on', 'your', 'pc', '2', 'enjoy', 'a', '2', '4', '1', 'dining', 'experiencehttp', ':', '//www.vouch4me.com/etlp/dining.asp']\n",
      "AFter tokenizer:  ['a', 'few', 'people', 'are', 'at', 'the', 'game', ',', 'i', \"'m\", 'at', 'the', 'mall', 'with', 'iouri', 'and', 'kaila']\n",
      "AFter tokenizer:  ['urgent', '!', 'we', 'are', 'trying', 'to', 'contact', 'u.', 'todays', 'draw', 'shows', 'that', 'you', 'have', 'won', 'a', '£2000', 'prize', 'guaranteed', '.', 'call', '09058094507', 'from', 'land', 'line', '.', 'claim', '3030.', 'valid', '12hrs', 'only']\n",
      "AFter tokenizer:  ['you', 'can', 'donate', '£2.50', 'to', 'unicef', \"'s\", 'asian', 'tsunami', 'disaster', 'support', 'fund', 'by', 'texting', 'donate', 'to', '864233', '.', '£2.50', 'will', 'be', 'added', 'to', 'your', 'next', 'bill']\n",
      "AFter tokenizer:  ['future', 'is', 'not', 'what', 'we', 'planned', 'for', 'tomorrow', '.....', '!', 'it', 'is', 'the', 'result', 'of', 'what', 'we', 'do', 'today', '...', '!', 'do', 'the', 'best', 'in', 'present', '...', 'enjoy', 'the', 'future', '.']\n",
      "AFter tokenizer:  ['i', 'will', 'cme', 'i', 'want', 'to', 'go', 'to', 'hos', '2morow', '.', 'after', 'that', 'i', 'wil', 'cme', '.', 'this', 'what', 'i', 'got', 'from', 'her', 'dear', 'what', 'to', 'do', '.', 'she', 'didnt', 'say', 'any', 'time']\n",
      "AFter tokenizer:  ['we', 'are', 'supposed', 'to', 'meet', 'to', 'discuss', 'abt', 'our', 'trip', '...', 'thought', 'xuhui', 'told', 'you', '?', 'in', 'the', 'afternoon', '.', 'thought', 'we', 'can', 'go', 'for', 'lesson', 'after', 'that']\n",
      "AFter tokenizer:  ['hey', 'come', 'online', '!', 'use', 'msn', '...', 'we', 'are', 'all', 'there']\n",
      "AFter tokenizer:  ['i', \"'m\", 'fine', '.', 'hope', 'you', 'are', 'good', '.', 'do', 'take', 'care', '.']\n",
      "AFter tokenizer:  ['oops', 'i', 'was', 'in', 'the', 'shower', 'when', 'u', 'called', '.', 'hey', 'a', 'parking', 'garage', 'collapsed', 'at', 'university', 'hospital', '.', 'see', 'i', \"'m\", 'not', 'crazy', '.', 'stuff', 'like', 'that', 'does', 'happen', '.']\n",
      "AFter tokenizer:  ['aiyo', 'u', 'so', 'poor', 'thing', '...', 'then', 'u', 'dun', 'wan', '2', 'eat', '?', 'u', 'bathe', 'already', '?']\n",
      "AFter tokenizer:  ['yar', '...', 'i', 'tot', 'u', 'knew', 'dis', 'would', 'happen', 'long', 'ago', 'already', '.']\n",
      "AFter tokenizer:  ['you', 'are', 'gorgeous', '!', 'keep', 'those', 'pix', 'cumming', ':', ')', 'thank', 'you', '!']\n",
      "AFter tokenizer:  ['jade', 'its', 'paul', '.', 'y', 'didn\\x92t', 'u', 'txt', 'me', '?', 'do', 'u', 'remember', 'me', 'from', 'barmed', '?', 'i', 'want', '2', 'talk', '2', 'u', '!', 'txt', 'me']\n",
      "AFter tokenizer:  ['spending', 'new', 'years', 'with', 'my', 'brother', 'and', 'his', 'family', '.', 'lets', 'plan', 'to', 'meet', 'next', 'week', '.', 'are', 'you', 'ready', 'to', 'be', 'spoiled', '?', ':', ')']\n",
      "AFter tokenizer:  ['so', 'what', 'u', 'doing', 'today', '?']\n",
      "AFter tokenizer:  ['i', 'said', 'its', 'okay', '.', 'sorry']\n",
      "AFter tokenizer:  ['slept', '?', 'i', 'thinkthis', 'time', '(', '&', 'lt', ';', '#', '&', 'gt', ';', 'pm', ')', 'is', 'not', 'dangerous']\n",
      "AFter tokenizer:  ['networking', 'job', 'is', 'there', '.']\n",
      "AFter tokenizer:  ['goldviking', '(', '29/m', ')', 'is', 'inviting', 'you', 'to', 'be', 'his', 'friend', '.', 'reply', 'yes-762', 'or', 'no-762', 'see', 'him', ':', 'www.sms.ac/u/goldviking', 'stop', '?', 'send', 'stop', 'frnd', 'to', '62468']\n",
      "AFter tokenizer:  ['dont', 'let', 'studying', 'stress', 'you', 'out', '.', 'l8r', '.']\n",
      "AFter tokenizer:  ['that', \"'s\", 'y', 'u', 'haf', '2', 'keep', 'me', 'busy', '...']\n",
      "AFter tokenizer:  ['no', 'rushing', '.', 'i', \"'m\", 'not', 'working', '.', 'i', \"'m\", 'in', 'school', 'so', 'if', 'we', 'rush', 'we', 'go', 'hungry', '.']\n",
      "AFter tokenizer:  ['which', 'channel', ':', '-', ')', ':', '-', ')', ':', ')', ':', '-', ')', '.']\n",
      "AFter tokenizer:  ['so', 'your', 'telling', 'me', 'i', 'coulda', 'been', 'your', 'real', 'valentine', 'and', 'i', 'was', \"n't\", '?', 'u', 'never', 'pick', 'me', 'for', 'nothing', '!', '!']\n",
      "AFter tokenizer:  ['phony', '£350', 'award', '-', 'todays', 'voda', 'numbers', 'ending', 'xxxx', 'are', 'selected', 'to', 'receive', 'a', '£350', 'award', '.', 'if', 'you', 'have', 'a', 'match', 'please', 'call', '08712300220', 'quoting', 'claim', 'code', '3100', 'standard', 'rates', 'app']\n",
      "AFter tokenizer:  ['we', 'made', 'it', '!', 'eta', 'at', 'taunton', 'is', '12:30', 'as', 'planned', ',', 'hope', 'that', '‘', 's', 'still', 'okday', '?', '!', 'good', 'to', 'see', 'you', '!', ':', '-xx']\n",
      "AFter tokenizer:  ['i', \"'m\", 'hungry', 'buy', 'smth', 'home', '...']\n",
      "AFter tokenizer:  ['hey', 'kate', ',', 'hope', 'ur', 'ok', '...', 'will', 'give', 'u', 'a', 'buz', 'wedlunch', '.', 'go', 'outsomewhere', '4', 'adrink', 'in', 'town', '..', 'cud', 'go', '2watershd', '4', 'a', 'bit', '?', 'ppl', 'fromwrk', 'will', 'bthere', '.', 'love', 'petexxx', '.']\n",
      "AFter tokenizer:  ['my', 'drive', 'can', 'only', 'be', 'read', '.', 'i', 'need', 'to', 'write']\n",
      "AFter tokenizer:  ['just', 'looked', 'it', 'up', 'and', 'addie', 'goes', 'back', 'monday', ',', 'sucks', 'to', 'be', 'her']\n",
      "AFter tokenizer:  ['happy', 'new', 'year', '.', 'hope', 'you', 'are', 'having', 'a', 'good', 'semester']\n",
      "AFter tokenizer:  ['esplanade', 'lor', '.', 'where', 'else', '...']\n",
      "AFter tokenizer:  ['can', 'you', 'talk', 'with', 'me', '..']\n",
      "AFter tokenizer:  ['hmph', '.', 'go', 'head', ',', 'big', 'baller', '.']\n",
      "AFter tokenizer:  ['well', 'its', 'not', 'like', 'you', 'actually', 'called', 'someone', 'a', 'punto', '.', 'that', 'woulda', 'been', 'worse', '.']\n",
      "AFter tokenizer:  ['nope', '.', 'since', 'ayo', 'travelled', ',', 'he', 'has', 'forgotten', 'his', 'guy']\n",
      "AFter tokenizer:  ['you', 'still', 'around', '?', 'looking', 'to', 'pick', 'up', 'later']\n",
      "AFter tokenizer:  ['cds', '4u', ':', 'congratulations', 'ur', 'awarded', '£500', 'of', 'cd', 'gift', 'vouchers', 'or', '£125', 'gift', 'guaranteed', '&', 'freeentry', '2', '£100', 'wkly', 'draw', 'xt', 'music', 'to', '87066', 'tncs', 'www.ldew.com1win150ppmx3age16']\n",
      "AFter tokenizer:  ['there', \"'s\", 'someone', 'here', 'that', 'has', 'a', 'year', '&', 'lt', ';', '#', '&', 'gt', ';', 'toyota', 'camry', 'like', 'mr', 'olayiwola', \"'s\", 'own', '.', 'mileage', 'is', '&', 'lt', ';', '#', '&', 'gt', ';', 'k.its', 'clean', 'but', 'i', 'need', 'to', 'know', 'how', 'much', 'will', 'it', 'sell', 'for', '.', 'if', 'i', 'can', 'raise', 'the', 'dough', 'for', 'it', 'how', 'soon', 'after', 'landing', 'will', 'it', 'sell', '.', 'holla', 'back', '.']\n",
      "AFter tokenizer:  ['guess', 'which', 'pub', 'im', 'in', '?', 'im', 'as', 'happy', 'as', 'a', 'pig', 'in', 'clover', 'or', 'whatever', 'the', 'saying', 'is', '!']\n",
      "AFter tokenizer:  ['ill', 'b', 'down', 'soon']\n",
      "AFter tokenizer:  ['oh', 'k.', '.', 'i', 'will', 'come', 'tomorrow']\n",
      "AFter tokenizer:  ['go', 'fool', 'dont', 'cheat', 'others', 'ok']\n",
      "AFter tokenizer:  ['my', 'mobile', 'number.pls', 'sms', 'ur', 'mail', 'id.convey', 'regards', 'to', 'achan', ',', 'amma.rakhesh.qatar']\n",
      "AFter tokenizer:  ['by', 'the', 'way', ',', \"'rencontre\", \"'\", 'is', 'to', 'meet', 'again', '.', 'mountains', 'dont', '....']\n",
      "AFter tokenizer:  ['you', 'have', 'won', 'a', 'guaranteed', '£1000', 'cash', 'or', 'a', '£2000', 'prize', '.', 'to', 'claim', 'yr', 'prize', 'call', 'our', 'customer', 'service', 'representative', 'on', '08714712412', 'between', '10am-7pm', 'cost', '10p']\n",
      "AFter tokenizer:  ['u', 'attend', 'ur', 'driving', 'lesson', 'how', 'many', 'times', 'a', 'wk', 'n', 'which', 'day', '?']\n",
      "AFter tokenizer:  ['uncle', 'g', ',', 'just', 'checking', 'up', 'on', 'you', '.', 'do', 'have', 'a', 'rewarding', 'month']\n",
      "AFter tokenizer:  ['hello', 'boytoy', '!', 'geeee', '...', 'i', \"'m\", 'missing', 'you', 'today', '.', 'i', 'like', 'to', 'send', 'you', 'a', 'tm', 'and', 'remind', 'you', 'i', \"'m\", 'thinking', 'of', 'you', '...', 'and', 'you', 'are', 'loved', '...', '*', 'loving', 'kiss', '*']\n",
      "AFter tokenizer:  ['i', 'think', 'the', 'other', 'two', 'still', 'need', 'to', 'get', 'cash', 'but', 'we', 'can', 'def', 'be', 'ready', 'by', '9']\n",
      "AFter tokenizer:  ['hey', 'gals', '...', 'u', 'all', 'wan', 'na', 'meet', '4', 'dinner', 'at', 'nìte', '?']\n",
      "AFter tokenizer:  ['babe', '!', 'what', 'are', 'you', 'doing', '?', 'where', 'are', 'you', '?', 'who', 'are', 'you', 'talking', 'to', '?', 'do', 'you', 'think', 'of', 'me', '?', 'are', 'you', 'being', 'a', 'good', 'boy', '?', 'are', 'you', 'missing', 'me', '?', 'do', 'you', 'love', 'me', '?']\n",
      "AFter tokenizer:  ['great', '!', 'how', 'is', 'the', 'office', 'today', '?']\n",
      "AFter tokenizer:  ['it', \"'s\", 'cool', ',', 'we', 'can', 'last', 'a', 'little', 'while', '.', 'getting', 'more', 'any', 'time', 'soon', '?']\n",
      "AFter tokenizer:  [':', '-', '(', 'sad', 'puppy', 'noise']\n",
      "AFter tokenizer:  ['yes', 'its', 'possible', 'but', 'dint', 'try', '.', 'pls', 'dont', 'tell', 'to', 'any', 'one', 'k']\n",
      "AFter tokenizer:  ['anyway', 'holla', 'at', 'me', 'whenever', 'you', \"'re\", 'around', 'because', 'i', 'need', 'an', 'excuse', 'to', 'go', 'creep', 'on', 'people', 'in', 'sarasota']\n",
      "AFter tokenizer:  ['where', 'you', '.', 'what', 'happen']\n",
      "AFter tokenizer:  ['i', 'was', 'gon', 'na', 'ask', 'you', 'lol', 'but', 'i', 'think', 'its', 'at', '7']\n",
      "AFter tokenizer:  ['ur', 'cash-balance', 'is', 'currently', '500', 'pounds', '-', 'to', 'maximize', 'ur', 'cash-in', 'now', 'send', 'go', 'to', '86688', 'only', '150p/meg', '.', 'cc', ':', '08718720201', 'hg/suite342/2lands', 'row/w1j6hl']\n",
      "AFter tokenizer:  ['private', '!', 'your', '2003', 'account', 'statement', 'for', 'shows', '800', 'un-redeemed', 's.i.m', '.', 'points', '.', 'call', '08715203685', 'identifier', 'code:4xx26', 'expires', '13/10/04']\n",
      "AFter tokenizer:  ['go', 'chase', 'after', 'her', 'and', 'run', 'her', 'over', 'while', 'she', \"'s\", 'crossing', 'the', 'street']\n",
      "AFter tokenizer:  ['i', \"'d\", 'like', 'to', 'tell', 'you', 'my', 'deepest', 'darkest', 'fantasies', '.', 'call', 'me', '09094646631', 'just', '60p/min', '.', 'to', 'stop', 'texts', 'call', '08712460324', '(', 'nat', 'rate', ')']\n",
      "AFter tokenizer:  ['hey', '...', 'very', 'inconvenient', 'for', 'your', 'sis', 'a', 'not', 'huh', '?']\n",
      "AFter tokenizer:  ['ok', 'i', 'vl', '..', 'do', 'u', 'know', 'i', 'got', 'adsense', 'approved', '..']\n",
      "AFter tokenizer:  ['*', 'was', 'really', 'good', 'to', 'see', 'you', 'the', 'other', 'day', 'dudette', ',', 'been', 'missing', 'you', '!']\n",
      "AFter tokenizer:  ['i', 'want', 'to', 'go', 'to', 'perumbavoor']\n",
      "AFter tokenizer:  ['how', 'many', 'times', 'i', 'told', 'in', 'the', 'stage', 'all', 'use', 'to', 'laugh', '.', 'you', 'not', 'listen', 'aha', '.']\n",
      "AFter tokenizer:  ['(', 'you', 'did', \"n't\", 'hear', 'it', 'from', 'me', ')']\n",
      "AFter tokenizer:  ['thanks', 'for', 'being', 'there', 'for', 'me', 'just', 'to', 'talk', 'to', 'on', 'saturday', '.', 'you', 'are', 'very', 'dear', 'to', 'me', '.', 'i', 'cherish', 'having', 'you', 'as', 'a', 'brother', 'and', 'role', 'model', '.']\n",
      "AFter tokenizer:  ['pls', 'clarify', 'back', 'if', 'an', 'open', 'return', 'ticket', 'that', 'i', 'have', 'can', 'be', 'preponed', 'for', 'me', 'to', 'go', 'back', 'to', 'kerala', '.']\n",
      "AFter tokenizer:  ['natalie', '(', '20/f', ')', 'is', 'inviting', 'you', 'to', 'be', 'her', 'friend', '.', 'reply', 'yes-165', 'or', 'no-165', 'see', 'her', ':', 'www.sms.ac/u/natalie2k9', 'stop', '?', 'send', 'stop', 'frnd', 'to', '62468']\n",
      "AFter tokenizer:  ['she', 'ran', 'off', 'with', 'a', 'younger', 'man', '.', 'we', 'will', 'make', 'pretty', 'babies', 'together', ':', ')']\n",
      "AFter tokenizer:  ['jamster', '!', 'to', 'get', 'your', 'free', 'wallpaper', 'text', 'heart', 'to', '88888', 'now', '!', 't', '&', 'c', 'apply', '.', '16', 'only', '.', 'need', 'help', '?', 'call', '08701213186', '.']\n",
      "AFter tokenizer:  ['o', 'ic', 'lol', '.', 'should', 'play', '9', 'doors', 'sometime', 'yo']\n",
      "AFter tokenizer:  ['dunno', ',', 'my', 'dad', 'said', 'he', 'coming', 'home', '2', 'bring', 'us', 'out', '4', 'lunch', '.', 'yup', 'i', 'go', 'w', 'u', 'lor', '.', 'i', 'call', 'u', 'when', 'i', 'reach', 'school', 'lor', '...']\n",
      "AFter tokenizer:  ['desires-', 'u', 'going', 'to', 'doctor', '4', 'liver', '.', 'and', 'get', 'a', 'bit', 'stylish', '.', 'get', 'ur', 'hair', 'managed', '.', 'thats', 'it', '.']\n",
      "AFter tokenizer:  ['hmmm.still', 'we', 'dont', 'have', 'opener', '?']\n",
      "AFter tokenizer:  ['yeah', 'so', 'basically', 'any', 'time', 'next', 'week', 'you', 'can', 'get', 'away', 'from', 'your', 'mom', '&', 'amp', ';', 'get', 'up', 'before', '3']\n",
      "AFter tokenizer:  ['i', 'will', 'vote', 'for', 'wherever', 'my', 'heart', 'guides', 'me']\n",
      "AFter tokenizer:  ['with', 'my', 'sis', 'lor', '...', 'we', 'juz', 'watched', 'italian', 'job', '.']\n",
      "AFter tokenizer:  ['tick', ',', 'tick', ',', 'tick', '....', 'where', 'are', 'you', '?', 'i', 'could', 'die', 'of', 'loneliness', 'you', 'know', '!', '*', 'pouts', '*', '*', 'stomps', 'feet', '*', 'i', 'need', 'you', '...']\n",
      "AFter tokenizer:  ['lmao', 'you', 'know', 'me', 'so', 'well', '...']\n",
      "AFter tokenizer:  ['am', 'on', 'a', 'train', 'back', 'from', 'northampton', 'so', 'i', \"'m\", 'afraid', 'not', '!', 'i', \"'m\", 'staying', 'skyving', 'off', 'today', 'ho', 'ho', '!', 'will', 'be', 'around', 'wednesday', 'though', '.', 'do', 'you', 'fancy', 'the', 'comedy', 'club', 'this', 'week', 'by', 'the', 'way', '?']\n",
      "AFter tokenizer:  ['goodnight', 'da', 'thangam', 'i', 'really', 'miss', 'u', 'dear', '.']\n",
      "AFter tokenizer:  ['hey', 'next', 'sun', '1030', 'there', \"'s\", 'a', 'basic', 'yoga', 'course', '...', 'at', 'bugis', '...', 'we', 'can', 'go', 'for', 'that', '...', 'pilates', 'intro', 'next', 'sat', '....', 'tell', 'me', 'what', 'time', 'you', 'r', 'free']\n",
      "AFter tokenizer:  ['geeeee', '...', 'your', 'internet', 'is', 'really', 'bad', 'today', ',', 'eh', '?']\n",
      "AFter tokenizer:  ['free', 'video', 'camera', 'phones', 'with', 'half', 'price', 'line', 'rental', 'for', '12', 'mths', 'and', '500', 'cross', 'ntwk', 'mins', '100', 'txts', '.', 'call', 'mobileupd8', '08001950382', 'or', 'call2optout/674']\n",
      "AFter tokenizer:  ['i', 'think', 'i', 'am', 'disturbing', 'her', 'da']\n",
      "AFter tokenizer:  ['sorry', ',', 'i', \"'ll\", 'call', 'you', 'later', '.', 'i', 'am', 'in', 'meeting', 'sir', '.']\n",
      "AFter tokenizer:  ['havent', 'stuck', 'at', 'orchard', 'in', 'my', 'dad', \"'s\", 'car', '.', 'going', '4', 'dinner', 'now', '.', 'u', 'leh', '?', 'so', 'r', 'they', 'free', 'tonight', '?']\n",
      "AFter tokenizer:  ['ok', 'i', 'also', 'wan', '2', 'watch', 'e', '9', 'pm', 'show', '...']\n",
      "AFter tokenizer:  ['i', 'dunno', 'lei', '...', 'like', 'dun', 'haf', '...']\n",
      "AFter tokenizer:  ['but', 'your', 'brother', 'transfered', 'only', '&', 'lt', ';', '#', '&', 'gt', ';', '+', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'pa', '.']\n",
      "AFter tokenizer:  ['i', 'calls', 'you', 'later', '.', 'afternoon', 'onwords', 'mtnl', 'service', 'get', 'problem', 'in', 'south', 'mumbai', '.', 'i', 'can', 'hear', 'you', 'but', 'you', 'can', \"n't\", 'listen', 'me', '.']\n",
      "AFter tokenizer:  ['83039', '62735=£450', 'uk', 'break', 'accommodationvouchers', 'terms', '&', 'conditions', 'apply', '.', '2', 'claim', 'you', 'mustprovide', 'your', 'claim', 'number', 'which', 'is', '15541']\n",
      "AFter tokenizer:  ['talk', 'to', 'g', 'and', 'x', 'about', 'that']\n",
      "AFter tokenizer:  ['hai', 'dear', 'friends', '...', 'this', 'is', 'my', 'new', '&', 'amp', ';', 'present', 'number', '..', ':', ')', 'by', 'rajitha', 'raj', '(', 'ranju', ')']\n",
      "AFter tokenizer:  ['5p', '4', 'alfie', 'moon', \"'s\", 'children', 'in', 'need', 'song', 'on', 'ur', 'mob', '.', 'tell', 'ur', 'm8s', '.', 'txt', 'tone', 'charity', 'to', '8007', 'for', 'nokias', 'or', 'poly', 'charity', 'for', 'polys', ':', 'zed', '08701417012', 'profit', '2', 'charity', '.']\n",
      "AFter tokenizer:  ['as', 'in', 'different', 'styles', '?']\n",
      "AFter tokenizer:  ['win', 'a', '£200', 'shopping', 'spree', 'every', 'week', 'starting', 'now', '.', '2', 'play', 'text', 'store', 'to', '88039.', 'skilgme', '.', 'tscs08714740323', '1winawk', '!', 'age16', '£1.50perweeksub', '.']\n",
      "AFter tokenizer:  ['gud', 'ni8', 'dear', '..', 'slp', 'well', '..', 'take', 'care', '..', 'swt', 'dreams', '..', 'muah', '..']\n",
      "AFter tokenizer:  ['this', 'is', 'the', '2nd', 'attempt', 'to', 'contract', 'u', ',', 'you', 'have', 'won', 'this', 'weeks', 'top', 'prize', 'of', 'either', '£1000', 'cash', 'or', '£200', 'prize', '.', 'just', 'call', '09066361921']\n",
      "AFter tokenizer:  ['well', ',', 'i', \"'m\", 'glad', 'you', 'did', \"n't\", 'find', 'it', 'totally', 'disagreeable', '...', 'lol']\n",
      "AFter tokenizer:  ['guy', ',', 'no', 'flash', 'me', 'now', '.', 'if', 'you', 'go', 'call', 'me', ',', 'call', 'me', '.', 'how', 'madam', '.', 'take', 'care', 'oh', '.']\n",
      "AFter tokenizer:  ['do', 'you', 'want', 'a', 'new', 'nokia', '3510i', 'colour', 'phone', 'deliveredtomorrow', '?', 'with', '300', 'free', 'minutes', 'to', 'any', 'mobile', '+', '100', 'free', 'texts', '+', 'free', 'camcorder', 'reply', 'or', 'call', '08000930705', '.']\n",
      "AFter tokenizer:  ['mark', 'works', 'tomorrow', '.', 'he', 'gets', 'out', 'at', '5.', 'his', 'work', 'is', 'by', 'your', 'house', 'so', 'he', 'can', 'meet', 'u', 'afterwards', '.']\n",
      "AFter tokenizer:  ['keep', 'ur', 'problems', 'in', 'ur', 'heart', ',', \"b'coz\", 'nobody', 'will', 'fight', 'for', 'u.', 'only', 'u', '&', 'amp', ';', 'u', 'have', 'to', 'fight', 'for', 'ur', 'self', '&', 'amp', ';', 'win', 'the', 'battle', '.', '-vivekanand-', 'g', '9t', '..', 'sd', '..', 'ham', 'yeah', ',', 'give', 'me', 'a', 'call', 'if', 'you', \"'ve\", 'got', 'a', 'minute', 'ham', 'hi', 'babe', 'uawake', '?', 'feellikw', 'shit.justfound', 'out', 'via', 'aletter', 'thatmum', 'gotmarried', '4thnov.behind', 'ourbacks', '\\x96', 'fuckinnice', '!', 'selfish', ',', 'deviousbitch.anyway', ',', 'i\\x92l', 'call', 'u', \"''\"]\n",
      "AFter tokenizer:  ['amazing', ':', 'if', 'you', 'rearrange', 'these', 'letters', 'it', 'gives', 'the', 'same', 'meaning', '...', 'dormitory', '=', 'dirty', 'room', 'astronomer', '=', 'moon', 'starer', 'the', 'eyes', '=', 'they', 'see', 'election', 'results', '=', 'lies', 'lets', 'recount', 'mother-in-law', '=', 'woman', 'hitler', 'eleven', 'plus', 'two', '=twelve', 'plus', 'one', 'its', 'amazing', '...', '!', ':', '-', ')']\n",
      "AFter tokenizer:  ['aiya', 'we', 'discuss', 'later', 'lar', '...', 'pick', 'ü', 'up', 'at', '4', 'is', 'it', '?']\n",
      "AFter tokenizer:  ['hey', 'happy', 'birthday', '...']\n",
      "AFter tokenizer:  ['sorry', 'i', 'missed', 'your', 'call', '.', 'can', 'you', 'please', 'call', 'back', '.']\n",
      "AFter tokenizer:  ['omg', 'if', 'its', 'not', 'one', 'thing', 'its', 'another', '.', 'my', 'cat', 'has', 'worms', ':', '/', 'when', 'does', 'this', 'bad', 'day', 'end', '?']\n",
      "AFter tokenizer:  ['good', 'morning', ',', 'im', 'suffering', 'from', 'fever', 'and', 'dysentry', '..', 'will', 'not', 'be', 'able', 'to', 'come', 'to', 'office', 'today', '.']\n",
      "AFter tokenizer:  ['i', 'wont', 'do', 'anything', 'de', '.']\n",
      "AFter tokenizer:  ['what', 'type', 'of', 'stuff', 'do', 'you', 'sing', '?']\n",
      "AFter tokenizer:  ['st', 'andre', ',', 'virgil', \"'s\", 'cream']\n",
      "AFter tokenizer:  ['my', 'fri', 'ah', '...', 'okie', 'lor', ',', 'goin', '4', 'my', 'drivin', 'den', 'go', 'shoppin', 'after', 'tt', '...']\n",
      "AFter tokenizer:  ['gokila', 'is', 'talking', 'with', 'you', 'aha', ':', ')']\n",
      "AFter tokenizer:  ['hi', 'shanil', ',', 'rakhesh', 'here.thanks', ',', 'i', 'have', 'exchanged', 'the', 'uncut', 'diamond', 'stuff.leaving', 'back', '.', 'excellent', 'service', 'by', 'dino', 'and', 'prem', '.']\n",
      "AFter tokenizer:  ['k.k.this', 'month', 'kotees', 'birthday', 'know', '?']\n",
      "AFter tokenizer:  ['but', 'i', \"'m\", 'really', 'really', 'broke', 'oh', '.', 'no', 'amount', 'is', 'too', 'small', 'even', '&', 'lt', ';', '#', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['sorry', 'about', 'that', 'this', 'is', 'my', 'mates', 'phone', 'and', 'i', 'didnt', 'write', 'it', 'love', 'kate']\n",
      "AFter tokenizer:  ['themob', '>', 'hit', 'the', 'link', 'to', 'get', 'a', 'premium', 'pink', 'panther', 'game', ',', 'the', 'new', 'no', '.', '1', 'from', 'sugababes', ',', 'a', 'crazy', 'zebra', 'animation', 'or', 'a', 'badass', 'hoody', 'wallpaper-all', '4', 'free', '!']\n",
      "AFter tokenizer:  ['ah', ',', 'well', 'that', 'confuses', 'things', ',', 'doesnt', 'it', '?', 'i', 'thought', 'was', 'friends', 'with', 'now', '.', 'maybe', 'i', 'did', 'the', 'wrong', 'thing', 'but', 'i', 'already', 'sort', 'of', 'invited', '-tho', 'he', 'may', 'not', 'come', 'cos', 'of', 'money', '.']\n",
      "AFter tokenizer:  ['aight', ',', 'call', 'me', 'once', 'you', \"'re\", 'close']\n",
      "AFter tokenizer:  ['nope', 'thats', 'fine', '.', 'i', 'might', 'have', 'a', 'nap', 'tho', '!']\n",
      "AFter tokenizer:  ['this', 'msg', 'is', 'for', 'your', 'mobile', 'content', 'order', 'it', 'has', 'been', 'resent', 'as', 'previous', 'attempt', 'failed', 'due', 'to', 'network', 'error', 'queries', 'to', 'customersqueries', '@', 'netvision.uk.com']\n",
      "AFter tokenizer:  ['in', 'other', 'news', 'after', 'hassling', 'me', 'to', 'get', 'him', 'weed', 'for', 'a', 'week', 'andres', 'has', 'no', 'money', '.', 'haughaighgtujhyguj']\n",
      "AFter tokenizer:  ['ding', 'me', 'on', 'ya', 'break', 'fassyole', '!', 'blacko', 'from', 'londn']\n",
      "AFter tokenizer:  ['i', 'really', 'need', '2', 'kiss', 'u', 'i', 'miss', 'u', 'my', 'baby', 'from', 'ur', 'baby', '4eva']\n",
      "AFter tokenizer:  ['oh', 'you', 'got', 'many', 'responsibilities', '.']\n",
      "AFter tokenizer:  ['you', 'have', '1', 'new', 'message', '.', 'please', 'call', '08715205273']\n",
      "AFter tokenizer:  ['i', \"'ve\", 'reached', 'sch', 'already', '...']\n",
      "AFter tokenizer:  ['december', 'only', '!', 'had', 'your', 'mobile', '11mths+', '?', 'you', 'are', 'entitled', 'to', 'update', 'to', 'the', 'latest', 'colour', 'camera', 'mobile', 'for', 'free', '!', 'call', 'the', 'mobile', 'update', 'vco', 'free', 'on', '08002986906']\n",
      "AFter tokenizer:  ['u', 'definitely', 'need', 'a', 'module', 'from', 'e', 'humanities', 'dis', 'sem', 'izzit', '?', 'u', 'wan', '2', 'take', 'other', 'modules', '1st', '?']\n",
      "AFter tokenizer:  ['argh', 'why', 'the', 'fuck', 'is', 'nobody', 'in', 'town', ';', '_', ';']\n",
      "AFter tokenizer:  ['get', '3', 'lions', 'england', 'tone', ',', 'reply', 'lionm', '4', 'mono', 'or', 'lionp', '4', 'poly', '.', '4', 'more', 'go', '2', 'www.ringtones.co.uk', ',', 'the', 'original', 'n', 'best', '.', 'tones', '3gbp', 'network', 'operator', 'rates', 'apply', '.']\n",
      "AFter tokenizer:  ['thanks', '.', 'fills', 'me', 'with', 'complete', 'calm', 'and', 'reassurance', '!']\n",
      "AFter tokenizer:  ['aslamalaikkum', '....', 'insha', 'allah', 'tohar', 'beeen', 'muht', 'albi', 'mufti', 'mahfuuz', '...', 'meaning', 'same', 'here', '....']\n",
      "AFter tokenizer:  ['are', 'you', 'driving', 'or', 'training', '?']\n",
      "AFter tokenizer:  ['lol', 'for', 'real', '.', 'she', 'told', 'my', 'dad', 'i', 'have', 'cancer']\n",
      "AFter tokenizer:  ['private', '!', 'your', '2003', 'account', 'statement', 'for', '078']\n",
      "AFter tokenizer:  ['oops', 'i', 'did', 'have', 'it', ',', '&', 'lt', ';', '#', '&', 'gt', ';', '?']\n",
      "AFter tokenizer:  ['not', 'enufcredeit', 'tocall.shall', 'ileave', 'uni', 'at', '6', '+get', 'a', 'bus', 'to', 'yor', 'house', '?']\n",
      "AFter tokenizer:  ['hi', 'chikku', ',', 'send', 'some', 'nice', 'msgs']\n",
      "AFter tokenizer:  ['he', 'is', 'impossible', 'to', 'argue', 'with', 'and', 'he', 'always', 'treats', 'me', 'like', 'his', 'sub', ',', 'like', 'he', 'never', 'released', 'me', '...', 'which', 'he', 'did', 'and', 'i', 'will', 'remind', 'him', 'of', 'that', 'if', 'necessary']\n",
      "AFter tokenizer:  ['after', 'my', 'work', 'ah', '...', 'den', '6', 'plus', 'lor', '...', 'u', 'workin', 'oso', 'rite', '...', 'den', 'go', 'orchard', 'lor', ',', 'no', 'other', 'place', 'to', 'go', 'liao', '...']\n",
      "AFter tokenizer:  ['to', 'the', 'wonderful', 'okors', ',', 'have', 'a', 'great', 'month', '.', 'we', 'cherish', 'you', 'guys', 'and', 'wish', 'you', 'well', 'each', 'day', '.', 'mojibiola']\n",
      "AFter tokenizer:  ['cuz', 'ibored', '.', 'and', 'don', 'wan', 'na', 'study']\n",
      "AFter tokenizer:  ['wot', 'about', 'on', 'wed', 'nite', 'i', 'am', '3', 'then', 'but', 'only', 'til', '9', '!']\n",
      "AFter tokenizer:  ['any', 'way', 'where', 'are', 'you', 'and', 'what', 'doing', '.']\n",
      "AFter tokenizer:  ['that', 'sucks', '.', 'i', \"'ll\", 'go', 'over', 'so', 'u', 'can', 'do', 'my', 'hair', '.', 'you', \"'ll\", 'do', 'it', 'free', 'right', '?']\n",
      "AFter tokenizer:  ['it', \"'s\", 'still', 'not', 'working', '.', 'and', 'this', 'time', 'i', 'also', 'tried', 'adding', 'zeros', '.', 'that', 'was', 'the', 'savings', '.', 'the', 'checking', 'is', '&', 'lt', ';', '#', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['hmm', '...', 'dunno', 'leh', ',', 'mayb', 'a', 'bag', '4', 'goigng', 'out', 'dat', 'is', 'not', 'too', 'small', '.', 'or', 'jus', 'anything', 'except', 'perfume', ',', 'smth', 'dat', 'i', 'can', 'keep', '.']\n",
      "AFter tokenizer:  ['sday', 'only', 'joined.so', 'training', 'we', 'started', 'today', ':', ')']\n",
      "AFter tokenizer:  ['sorry', '*', 'was', 'at', 'the', 'grocers', '.']\n",
      "AFter tokenizer:  ['there', 'are', 'some', 'nice', 'pubs', 'near', 'here', 'or', 'there', 'is', 'frankie', 'n', 'bennys', 'near', 'the', 'warner', 'cinema', '?']\n",
      "AFter tokenizer:  ['you', 've', 'won', '!', 'your', '4', '*', 'costa', 'del', 'sol', 'holiday', 'or', '£5000', 'await', 'collection', '.', 'call', '09050090044', 'now', 'toclaim', '.', 'sae', ',', 'tc', 's', ',', 'pobox334', ',', 'stockport', ',', 'sk38xh', ',', 'cost£1.50/pm', ',', 'max10mins']\n",
      "AFter tokenizer:  ['yup', '...', 'i', 'havent', 'been', 'there', 'before', '...', 'you', 'want', 'to', 'go', 'for', 'the', 'yoga', '?', 'i', 'can', 'call', 'up', 'to', 'book']\n",
      "AFter tokenizer:  ['oh', 'shut', 'it', '.', 'omg', 'yesterday', 'i', 'had', 'a', 'dream', 'that', 'i', 'had', '2', 'kids', 'both', 'boys', '.', 'i', 'was', 'so', 'pissed', '.', 'not', 'only', 'about', 'the', 'kids', 'but', 'them', 'being', 'boys', '.', 'i', 'even', 'told', 'mark', 'in', 'my', 'dream', 'that', 'he', 'was', 'changing', 'diapers', 'cause', 'i', \"'m\", 'not', 'getting', 'owed', 'in', 'the', 'face', '.']\n",
      "AFter tokenizer:  ['yeah', 'i', 'imagine', 'he', 'would', 'be', 'really', 'gentle', '.', 'unlike', 'the', 'other', 'docs', 'who', 'treat', 'their', 'patients', 'like', 'turkeys', '.']\n",
      "AFter tokenizer:  ['now', 'that', 'you', 'have', 'started', 'dont', 'stop', '.', 'just', 'pray', 'for', 'more', 'good', 'ideas', 'and', 'anything', 'i', 'see', 'that', 'can', 'help', 'you', 'guys', 'i.ll', 'forward', 'you', 'a', 'link', '.']\n",
      "AFter tokenizer:  ['hi', 'darlin', 'im', 'on', 'helens', 'fone', 'im', 'gon', 'na', 'b', 'up', 'the', 'princes', '2', 'nite', 'please', 'come', 'up', 'tb', 'love', 'kate']\n",
      "AFter tokenizer:  ['i', \"'m\", 'in', 'office', 'now', 'da', ':', ')', 'where', 'are', 'you', '?']\n",
      "AFter tokenizer:  ['aiyar', 'u', 'so', 'poor', 'thing', '...', 'i', 'give', 'u', 'my', 'support', 'k', '...', 'jia', 'you', '!', 'i', \"'ll\", 'think', 'of', 'u', '...']\n",
      "AFter tokenizer:  ['oh', 'unintentionally', 'not', 'bad', 'timing', '.', 'great', '.', 'fingers', 'the', 'trains', 'play', 'along', '!', 'will', 'give', 'fifteen', 'min', 'warning', '.']\n",
      "AFter tokenizer:  ['get', 'your', 'garden', 'ready', 'for', 'summer', 'with', 'a', 'free', 'selection', 'of', 'summer', 'bulbs', 'and', 'seeds', 'worth', '£33:50', 'only', 'with', 'the', 'scotsman', 'this', 'saturday', '.', 'to', 'stop', 'go2', 'notxt.co.uk']\n",
      "AFter tokenizer:  ['k', '..', 'then', 'come', 'wenever', 'u', 'lik', 'to', 'come', 'and', 'also', 'tel', 'vikky', 'to', 'come', 'by', 'getting', 'free', 'time', '..', ':', '-', ')']\n",
      "AFter tokenizer:  ['pls', 'call', 'me', 'da', '.', 'what', 'happen', '.']\n",
      "AFter tokenizer:  ['happy', 'new', 'year', 'to', 'u', 'and', 'ur', 'family', '...', 'may', 'this', 'new', 'year', 'bring', 'happiness', ',', 'stability', 'and', 'tranquility', 'to', 'ur', 'vibrant', 'colourful', 'life', ':', ')', ':', ')']\n",
      "AFter tokenizer:  ['no', 'problem', 'with', 'the', 'renewal', '.', 'i.ll', 'do', 'it', 'right', 'away', 'but', 'i', 'dont', 'know', 'his', 'details', '.']\n",
      "AFter tokenizer:  ['idk', '.', 'i', \"'m\", 'sitting', 'here', 'in', 'a', 'stop', 'and', 'shop', 'parking', 'lot', 'right', 'now', 'bawling', 'my', 'eyes', 'out', 'because', 'i', 'feel', 'like', 'i', \"'m\", 'a', 'failure', 'in', 'everything', '.', 'nobody', 'wants', 'me', 'and', 'now', 'i', 'feel', 'like', 'i', \"'m\", 'failing', 'you', '.']\n",
      "AFter tokenizer:  ['have', \"n't\", 'left', 'yet', 'so', 'probably', 'gon', 'na', 'be', 'here', 'til', 'dinner']\n",
      "AFter tokenizer:  ['like', '&', 'lt', ';', '#', '&', 'gt', ';', ',', 'same', 'question']\n",
      "AFter tokenizer:  ['my', 'new', 'years', 'eve', 'was', 'ok.', 'i', 'went', 'to', 'a', 'party', 'with', 'my', 'boyfriend', '.', 'who', 'is', 'this', 'si', 'then', 'hey']\n",
      "AFter tokenizer:  ['sir', ',', 'i', 'need', 'velusamy', 'sir', \"'s\", 'date', 'of', 'birth', 'and', 'company', 'bank', 'facilities', 'details', '.']\n",
      "AFter tokenizer:  ['k', 'k', ':', ')', 'sms', 'chat', 'with', 'me', '.']\n",
      "AFter tokenizer:  ['i', 'will', 'come', 'with', 'karnan', 'car', '.', 'please', 'wait', 'till', '6pm', 'will', 'directly', 'goto', 'doctor', '.']\n",
      "AFter tokenizer:  ['no', 'but', 'the', 'bluray', 'player', 'can']\n",
      "AFter tokenizer:  ['ok', '...', 'then', 'r', 'we', 'meeting', 'later', '?']\n",
      "AFter tokenizer:  ['lol', 'no', '.', 'i', 'just', 'need', 'to', 'cash', 'in', 'my', 'nitros', '.', 'hurry', 'come', 'on', 'before', 'i', 'crash', 'out', '!']\n",
      "AFter tokenizer:  ['just', 'send', 'a', 'text', '.', 'we', \"'ll\", 'skype', 'later', '.']\n",
      "AFter tokenizer:  ['ok', 'leave', 'no', 'need', 'to', 'ask']\n",
      "AFter tokenizer:  ['ü', 'still', 'got', 'lessons', '?', 'ü', 'in', 'sch', '?']\n",
      "AFter tokenizer:  ['y', 'she', 'dun', 'believe', 'leh', '?', 'i', 'tot', 'i', 'told', 'her', 'it', \"'s\", 'true', 'already', '.', 'i', 'thk', 'she', 'muz', 'c', 'us', 'tog', 'then', 'she', 'believe', '.']\n",
      "AFter tokenizer:  ['oh', 'did', 'you', 'charge', 'camera']\n",
      "AFter tokenizer:  ['i', '‘', 've', 'got', 'some', 'salt', ',', 'you', 'can', 'rub', 'it', 'in', 'my', 'open', 'wounds', 'if', 'you', 'like', '!']\n",
      "AFter tokenizer:  ['now', 'i', \"'m\", 'going', 'for', 'lunch', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'in', 'school', 'now', 'n', 'i', \"'ll\", 'be', 'in', 'da', 'lab', 'doing', 'some', 'stuff', 'give', 'me', 'a', 'call', 'when', 'ü', 'r', 'done', '.']\n",
      "AFter tokenizer:  ['aight', ',', 'text', 'me', 'tonight', 'and', 'we', \"'ll\", 'see', 'what', \"'s\", 'up']\n",
      "AFter tokenizer:  ['u', '2', '.']\n",
      "AFter tokenizer:  ['water', 'logging', 'in', 'desert', '.', 'geoenvironmental', 'implications', '.']\n",
      "AFter tokenizer:  ['very', 'strange', '.', 'and', 'are', 'watching', 'the', '2nd', 'one', 'now', 'but', 'i', \"'m\", 'in', 'bed', '.', 'sweet', 'dreams', ',', 'miss', 'u']\n",
      "AFter tokenizer:  ['sms', 'auction', '-', 'a', 'brand', 'new', 'nokia', '7250', 'is', 'up', '4', 'auction', 'today', '!', 'auction', 'is', 'free', '2', 'join', '&', 'take', 'part', '!', 'txt', 'nokia', 'to', '86021', 'now', '!']\n",
      "AFter tokenizer:  ['hi', 'hope', 'u', 'r', 'both', 'ok', ',', 'he', 'said', 'he', 'would', 'text', 'and', 'he', 'has', \"n't\", ',', 'have', 'u', 'seen', 'him', ',', 'let', 'me', 'down', 'gently', 'please']\n",
      "AFter tokenizer:  ['babe', '!', 'i', 'fucking', 'love', 'you', 'too', '!', '!', 'you', 'know', '?', 'fuck', 'it', 'was', 'so', 'good', 'to', 'hear', 'your', 'voice', '.', 'i', 'so', 'need', 'that', '.', 'i', 'crave', 'it', '.', 'i', 'ca', \"n't\", 'get', 'enough', '.', 'i', 'adore', 'you', ',', 'ahmad', '*', 'kisses', '*']\n",
      "AFter tokenizer:  ['k', 'sure', 'am', 'in', 'my', 'relatives', 'home', '.', 'sms', 'me', 'de', '.', 'pls', ':', '-', ')']\n",
      "AFter tokenizer:  ['fuuuuck', 'i', 'need', 'to', 'stop', 'sleepin', ',', 'sup']\n",
      "AFter tokenizer:  ['i', \"'m\", 'in', 'town', 'now', 'so', 'i', \"'ll\", 'jus', 'take', 'mrt', 'down', 'later', '.']\n",
      "AFter tokenizer:  ['i', 'just', 'cooked', 'a', 'rather', 'nice', 'salmon', 'a', 'la', 'you']\n",
      "AFter tokenizer:  ['i', 'uploaded', 'mine', 'to', 'facebook']\n",
      "AFter tokenizer:  ['what', 'time', 'u', 'wrkin', '?']\n",
      "AFter tokenizer:  ['ree', 'entry', 'in', '2', 'a', 'weekly', 'comp', 'for', 'a', 'chance', 'to', 'win', 'an', 'ipod', '.', 'txt', 'pod', 'to', '80182', 'to', 'get', 'entry', '(', 'std', 'txt', 'rate', ')', 't', '&', 'c', \"'s\", 'apply', '08452810073', 'for', 'details', '18+']\n",
      "AFter tokenizer:  ['our', 'records', 'indicate', 'u', 'maybe', 'entitled', 'to', '5000', 'pounds', 'in', 'compensation', 'for', 'the', 'accident', 'you', 'had', '.', 'to', 'claim', '4', 'free', 'reply', 'with', 'claim', 'to', 'this', 'msg', '.', '2', 'stop', 'txt', 'stop']\n",
      "AFter tokenizer:  ['oh', 'oh', '...', 'den', 'muz', 'change', 'plan', 'liao', '...', 'go', 'back', 'have', 'to', 'yan', 'jiu', 'again', '...']\n",
      "AFter tokenizer:  ['it', \"'s\", 'wylie', ',', 'you', 'in', 'tampa', 'or', 'sarasota', '?']\n",
      "AFter tokenizer:  ['ok', '...', 'take', 'ur', 'time', 'n', 'enjoy', 'ur', 'dinner', '...']\n",
      "AFter tokenizer:  ['darren', 'was', 'saying', 'dat', 'if', 'u', 'meeting', 'da', 'ge', 'den', 'we', 'dun', 'meet', '4', 'dinner', '.', 'cos', 'later', 'u', 'leave', 'xy', 'will', 'feel', 'awkward', '.', 'den', 'u', 'meet', 'him', '4', 'lunch', 'lor', '.']\n",
      "AFter tokenizer:  ['i', 'like', 'cheap', '!', 'but', 'i', '‘', 'm', 'happy', 'to', 'splash', 'out', 'on', 'the', 'wine', 'if', 'it', 'makes', 'you', 'feel', 'better', '..']\n",
      "AFter tokenizer:  ['she.s', 'fine', '.', 'i', 'have', 'had', 'difficulties', 'with', 'her', 'phone', '.', 'it', 'works', 'with', 'mine', '.', 'can', 'you', 'pls', 'send', 'her', 'another', 'friend', 'request', '.']\n",
      "AFter tokenizer:  ['ugh', 'my', 'leg', 'hurts', '.', 'musta', 'overdid', 'it', 'on', 'mon', '.']\n",
      "AFter tokenizer:  ['call', 'germany', 'for', 'only', '1', 'pence', 'per', 'minute', '!', 'call', 'from', 'a', 'fixed', 'line', 'via', 'access', 'number', '0844', '861', '85', '85.', 'no', 'prepayment', '.', 'direct', 'access', '!', 'www.telediscount.co.uk']\n",
      "AFter tokenizer:  ['wot', 'student', 'discount', 'can', 'u', 'get', 'on', 'books', '?']\n",
      "AFter tokenizer:  ['how', 'come', 'she', 'can', 'get', 'it', '?', 'should', 'b', 'quite', 'diff', 'to', 'guess', 'rite', '...']\n",
      "AFter tokenizer:  ['had', 'your', 'mobile', '11mths', '?', 'update', 'for', 'free', 'to', 'oranges', 'latest', 'colour', 'camera', 'mobiles', '&', 'unlimited', 'weekend', 'calls', '.', 'call', 'mobile', 'upd8', 'on', 'freefone', '08000839402', 'or', '2stoptxt']\n",
      "AFter tokenizer:  ['babe', ',', 'i', \"'m\", 'answering', 'you', ',', 'ca', \"n't\", 'you', 'see', 'me', '?', 'maybe', 'you', \"'d\", 'better', 'reboot', 'ym', '...', 'i', 'got', 'the', 'photo', '...', 'it', \"'s\", 'great', '!']\n",
      "AFter tokenizer:  ['hi.what', 'you', 'think', 'about', 'match', '?']\n",
      "AFter tokenizer:  ['i', 'know', 'you', 'are', 'thinkin', 'malaria', '.', 'but', 'relax', ',', 'children', 'cant', 'handle', 'malaria', '.', 'she', 'would', 'have', 'been', 'worse', 'and', 'its', 'gastroenteritis', '.', 'if', 'she', 'takes', 'enough', 'to', 'replace', 'her', 'loss', 'her', 'temp', 'will', 'reduce', '.', 'and', 'if', 'you', 'give', 'her', 'malaria', 'meds', 'now', 'she', 'will', 'just', 'vomit', '.', 'its', 'a', 'self', 'limiting', 'illness', 'she', 'has', 'which', 'means', 'in', 'a', 'few', 'days', 'it', 'will', 'completely', 'stop']\n",
      "AFter tokenizer:  ['dai', 'i', 'downloaded', 'but', 'there', 'is', 'only', 'exe', 'file', 'which', 'i', 'can', 'only', 'run', 'that', 'exe', 'after', 'installing', '.']\n",
      "AFter tokenizer:  ['it', 'is', 'only', 'yesterday', 'true', 'true', '.']\n",
      "AFter tokenizer:  ['k.k.how', 'is', 'your', 'business', 'now', '?']\n",
      "AFter tokenizer:  ['3', 'pa', 'but', 'not', 'selected', '.']\n",
      "AFter tokenizer:  ['well', 'thats', 'nice', '.', 'too', 'bad', 'i', 'cant', 'eat', 'it']\n",
      "AFter tokenizer:  ['i', 'accidentally', 'brought', 'em', 'home', 'in', 'the', 'box']\n",
      "AFter tokenizer:  ['pls', 'she', 'needs', 'to', 'dat', 'slowly', 'or', 'she', 'will', 'vomit', 'more', '.']\n",
      "AFter tokenizer:  ['i', 'have', 'to', 'take', 'exam', 'with', 'in', 'march', '3']\n",
      "AFter tokenizer:  ['jane', 'babes', 'not', 'goin', '2', 'wrk', ',', 'feel', 'ill', 'after', 'lst', 'nite', '.', 'foned', 'in', 'already', 'cover', '4', 'me', 'chuck', '.', ':', '-', ')']\n",
      "AFter tokenizer:  ['5', 'nights', '...', 'we', 'nt', 'staying', 'at', 'port', 'step', 'liao', '...', 'too', 'ex']\n",
      "AFter tokenizer:  ['if', 'i', 'die', 'i', 'want', 'u', 'to', 'have', 'all', 'my', 'stuffs', '.']\n",
      "AFter tokenizer:  ['oh', 'fuck', '.', 'juswoke', 'up', 'in', 'a', 'bed', 'on', 'a', 'boatin', 'the', 'docks', '.', 'slept', 'wid', '25', 'year', 'old', '.', 'spinout', '!', 'giv', 'u', 'da', 'gossip', 'l8r', '.', 'xxx']\n",
      "AFter tokenizer:  ['i', 're-met', 'alex', 'nichols', 'from', 'middle', 'school', 'and', 'it', 'turns', 'out', 'he', \"'s\", 'dealing', '!']\n",
      "AFter tokenizer:  ['private', '!', 'your', '2003', 'account', 'statement', 'for', '<', 'fone', 'no', '>', 'shows', '800', 'un-redeemed', 's.', 'i.', 'm.', 'points', '.', 'call', '08715203656', 'identifier', 'code', ':', '42049', 'expires', '26/10/04']\n",
      "AFter tokenizer:  ['it', 'means', 'u', 'could', 'not', 'keep', 'ur', 'words', '.']\n",
      "AFter tokenizer:  ['nope', ',', 'i', \"'m\", 'still', 'in', 'the', 'market']\n",
      "AFter tokenizer:  ['i', 'realise', 'you', 'are', 'a', 'busy', 'guy', 'and', 'i', \"'m\", 'trying', 'not', 'to', 'be', 'a', 'bother', '.', 'i', 'have', 'to', 'get', 'some', 'exams', 'outta', 'the', 'way', 'and', 'then', 'try', 'the', 'cars', '.', 'do', 'have', 'a', 'gr8', 'day']\n",
      "AFter tokenizer:  ['hey', 'what', 'how', 'about', 'your', 'project', '.', 'started', 'aha', 'da', '.']\n",
      "AFter tokenizer:  ['ok', 'cool', '.', 'see', 'ya', 'then', '.']\n",
      "AFter tokenizer:  ['am', 'on', 'the', 'uworld', 'site', '.', 'am', 'i', 'buying', 'the', 'qbank', 'only', 'or', 'am', 'i', 'buying', 'it', 'with', 'the', 'self', 'assessment', 'also', '?']\n",
      "AFter tokenizer:  ['someonone', 'you', 'know', 'is', 'trying', 'to', 'contact', 'you', 'via', 'our', 'dating', 'service', '!', 'to', 'find', 'out', 'who', 'it', 'could', 'be', 'call', 'from', 'your', 'mobile', 'or', 'landline', '09064015307', 'box334sk38ch']\n",
      "AFter tokenizer:  ['yeah', 'i', 'can', 'still', 'give', 'you', 'a', 'ride']\n",
      "AFter tokenizer:  ['jay', 'wants', 'to', 'work', 'out', 'first', ',', 'how', \"'s\", '4', 'sound', '?']\n",
      "AFter tokenizer:  ['gud', 'gud', '..', 'k', ',', 'chikku', 'tke', 'care', '..', 'sleep', 'well', 'gud', 'nyt']\n",
      "AFter tokenizer:  ['hmm', 'thinking', 'lor', '...']\n",
      "AFter tokenizer:  ['of', 'course', '!', 'do', \"n't\", 'tease', 'me', '...', 'you', 'know', 'i', 'simply', 'must', 'see', '!', '*', 'grins', '*', '...', 'do', 'keep', 'me', 'posted', 'my', 'prey', '...', '*', 'loving', 'smile', '*', '*', 'devouring', 'kiss', '*']\n",
      "AFter tokenizer:  ['thanks', 'for', 'the', 'temales', 'it', 'was', 'wonderful', '.', 'thank', '.', 'have', 'a', 'great', 'week', '.']\n",
      "AFter tokenizer:  ['thank', 'you', 'princess', '!', 'i', 'want', 'to', 'see', 'your', 'nice', 'juicy', 'booty', '...']\n",
      "AFter tokenizer:  ['have', \"n't\", 'eaten', 'all', 'day', '.', 'i', \"'m\", 'sitting', 'here', 'staring', 'at', 'this', 'juicy', 'pizza', 'and', 'i', 'ca', \"n't\", 'eat', 'it', '.', 'these', 'meds', 'are', 'ruining', 'my', 'life', '.']\n",
      "AFter tokenizer:  ['u', 'come', 'n', 'search', 'tat', 'vid', '..', 'not', 'finishd', '..']\n",
      "AFter tokenizer:  ['k', 'i', \"'m\", 'leaving', 'soon', ',', 'be', 'there', 'a', 'little', 'after', '9']\n",
      "AFter tokenizer:  ['urgent', '!', 'please', 'call', '09061213237', 'from', 'a', 'landline', '.', '£5000', 'cash', 'or', 'a', '4', '*', 'holiday', 'await', 'collection', '.', 't', '&', 'cs', 'sae', 'po', 'box', '177', 'm227xy', '.', '16+']\n",
      "AFter tokenizer:  ['yeah', 'work', 'is', 'fine', ',', 'started', 'last', 'week', ',', 'all', 'the', 'same', 'stuff', 'as', 'before', ',', 'dull', 'but', 'easy', 'and', 'guys', 'are', 'fun', '!']\n",
      "AFter tokenizer:  ['you', 'do', 'your', 'studies', 'alone', 'without', 'anyones', 'help', '.', 'if', 'you', 'cant', 'no', 'need', 'to', 'study', '.']\n",
      "AFter tokenizer:  ['please', 'tell', 'me', 'not', 'all', 'of', 'my', 'car', 'keys', 'are', 'in', 'your', 'purse']\n",
      "AFter tokenizer:  ['i', 'didnt', 'get', 'anything', 'da']\n",
      "AFter tokenizer:  ['ok', '...', 'sweet', 'dreams', '...']\n",
      "AFter tokenizer:  ['well', 'she', \"'s\", 'in', 'for', 'a', 'big', 'surprise', '!']\n",
      "AFter tokenizer:  ['1', 'in', 'cbe', '.', '2', 'in', 'chennai', '.']\n",
      "AFter tokenizer:  ['can', 'help', 'u', 'swoop', 'by', 'picking', 'u', 'up', 'from', 'wherever', 'ur', 'other', 'birds', 'r', 'meeting', 'if', 'u', 'want', '.']\n",
      "AFter tokenizer:  ['if', 'anyone', 'calls', 'for', 'a', 'treadmill', 'say', 'you', \"'ll\", 'buy', 'it', '.', 'make', 'sure', 'its', 'working', '.', 'i', 'found', 'an', 'ad', 'on', 'craigslist', 'selling', 'for', '$', '&', 'lt', ';', '#', '&', 'gt', ';', '.']\n",
      "AFter tokenizer:  ['i', 'absolutely', 'love', 'south', 'park', '!', 'i', 'only', 'recently', 'started', 'watching', 'the', 'office', '.']\n",
      "AFter tokenizer:  ['did', 'you', 'see', 'that', 'film', ':', ')']\n",
      "AFter tokenizer:  ['pls', 'speak', 'with', 'me', '.', 'i', 'wont', 'ask', 'anything', 'other', 'then', 'you', 'friendship', '.']\n",
      "AFter tokenizer:  ['gud', 'ni8.swt', 'drms.take', 'care']\n",
      "AFter tokenizer:  ['hi', 'darlin', 'its', 'kate', 'are', 'u', 'up', 'for', 'doin', 'somethin', 'tonight', '?', 'im', 'going', 'to', 'a', 'pub', 'called', 'the', 'swan', 'or', 'something', 'with', 'my', 'parents', 'for', 'one', 'drink', 'so', 'phone', 'me', 'if', 'u', 'can']\n",
      "AFter tokenizer:  ['anything', 'lar', 'then', 'ü', 'not', 'going', 'home', '4', 'dinner', '?']\n",
      "AFter tokenizer:  ['er', ',', 'enjoyin', 'indians', 'at', 'the', 'mo', '..', 'yep', '.', 'sall', 'good', 'hehe', ';', '>', 'hows', 'bout', 'u', 'shexy', '?', 'pete', 'xx']\n",
      "AFter tokenizer:  ['did', 'u', 'fix', 'the', 'teeth', '?', 'if', 'not', 'do', 'it', 'asap.ok', 'take', 'care', '.']\n",
      "AFter tokenizer:  ['so', 'u', 'wan', '2', 'come', 'for', 'our', 'dinner', 'tonight', 'a', 'not', '?']\n",
      "AFter tokenizer:  ['hello.how', 'u', 'doing', '?', 'what', 'u', 'been', 'up', '2', '?', 'when', 'will', 'u', 'b', 'moving', 'out', 'of', 'the', 'flat', ',', 'cos', 'i', 'will', 'need', 'to', 'arrange', 'to', 'pick', 'up', 'the', 'lamp', ',', 'etc', '.', 'take', 'care', '.', 'hello', 'caroline', '!']\n",
      "AFter tokenizer:  ['its', 'too', 'late', ':', ')', 'but', 'its', 'k.wish', 'you', 'the', 'same', '.']\n",
      "AFter tokenizer:  ['hi', '.', 'hope', 'ur', 'day', '*', 'good', '!', 'back', 'from', 'walk', ',', 'table', 'booked', 'for', 'half', 'eight', '.', 'let', 'me', 'know', 'when', 'ur', 'coming', 'over', '.']\n",
      "AFter tokenizer:  ['oh', 'yeah', 'clearly', 'it', \"'s\", 'my', 'fault']\n",
      "AFter tokenizer:  ['dunno', 'leh', 'cant', 'remember', 'mayb', 'lor', '.', 'so', 'wat', 'time', 'r', 'we', 'meeting', 'tmr', '?']\n",
      "AFter tokenizer:  ['best', 'msg', ':', 'it', \"'s\", 'hard', 'to', 'be', 'with', 'a', 'person', ',', 'when', 'u', 'know', 'that', 'one', 'more', 'step', 'foward', 'will', 'make', 'u', 'fall', 'in', 'love', '..', '&', 'amp', ';', 'one', 'step', 'back', 'can', 'ruin', 'ur', 'friendship', '..', 'good', 'night', ':', '-', ')', '...']\n",
      "AFter tokenizer:  ['urgent', '!', 'your', 'mobile', 'number', 'has', 'been', 'awarded', 'with', 'a', '£2000', 'prize', 'guaranteed', '.', 'call', '09061790126', 'from', 'land', 'line', '.', 'claim', '3030.', 'valid', '12hrs', 'only', '150ppm']\n",
      "AFter tokenizer:  ['vikky', ',', 'come', 'around', '&', 'lt', ';', 'time', '&', 'gt', ';', '..']\n",
      "AFter tokenizer:  ['and', 'how', 'you', 'will', 'do', 'that', ',', 'princess', '?', ':', ')']\n",
      "AFter tokenizer:  ['i', 'have', 'gone', 'into', 'get', 'info', 'bt', 'dont', 'know', 'what', 'to', 'do']\n",
      "AFter tokenizer:  ['yeah', ',', 'probably', 'here', 'for', 'a', 'while']\n",
      "AFter tokenizer:  ['i', \"'m\", 'still', 'pretty', 'weak', 'today', '..', 'bad', 'day', '?']\n",
      "AFter tokenizer:  ['hey', '!', 'do', \"n't\", 'forget', '...', 'you', 'are', 'mine', '...', 'for', 'me', '...', 'my', 'possession', '...', 'my', 'property', '...', 'mmm', '...', '*', 'childish', 'smile', '*', '...']\n",
      "AFter tokenizer:  ['an', 'excellent', 'thought', 'by', 'a', 'misundrstud', 'frnd', ':', 'i', 'knw', 'u', 'hate', 'me', 'bt', 'the', 'day', 'wen', 'u', \"'ll\", 'knw', 'the', 'truth', 'u', \"'ll\", 'hate', 'urself', ':', '-', '(', 'gn', ':', '-', ')']\n",
      "AFter tokenizer:  ['hey', '!', 'congrats', '2u2', '.', 'id', 'luv', '2', 'but', 'ive', 'had', '2', 'go', 'home', '!']\n",
      "AFter tokenizer:  ['dear', 'where', 'you', '.', 'call', 'me']\n",
      "AFter tokenizer:  ['xy', 'trying', 'smth', 'now', '.', 'u', 'eat', 'already', '?', 'we', 'havent', '...']\n",
      "AFter tokenizer:  ['urgent', '!', 'please', 'call', '09061213237', 'from', 'landline', '.', '£5000', 'cash', 'or', 'a', 'luxury', '4', '*', 'canary', 'islands', 'holiday', 'await', 'collection', '.', 't', '&', 'cs', 'sae', 'po', 'box', '177.', 'm227xy', '.', '150ppm', '.', '16+']\n",
      "AFter tokenizer:  ['i', 'donno', 'its', 'in', 'your', 'genes', 'or', 'something']\n",
      "AFter tokenizer:  ['xmas', 'iscoming', '&', 'ur', 'awarded', 'either', '£500', 'cd', 'gift', 'vouchers', '&', 'free', 'entry', '2', 'r', '£100', 'weekly', 'draw', 'txt', 'music', 'to', '87066', 'tnc', 'www.ldew.com1win150ppmx3age16subscription']\n",
      "AFter tokenizer:  ['alex', 'says', 'he', \"'s\", 'not', 'ok', 'with', 'you', 'not', 'being', 'ok', 'with', 'it']\n",
      "AFter tokenizer:  ['are', 'u', 'coming', 'to', 'the', 'funeral', 'home']\n",
      "AFter tokenizer:  ['my', 'darling', 'sister', '.', 'how', 'are', 'you', 'doing', '.', 'when', \"'s\", 'school', 'resuming', '.', 'is', 'there', 'a', 'minimum', 'wait', 'period', 'before', 'you', 'reapply', '?', 'do', 'take', 'care']\n",
      "AFter tokenizer:  ['i.ll', 'hand', 'her', 'my', 'phone', 'to', 'chat', 'wit', 'u']\n",
      "AFter tokenizer:  ['well', 'good', 'morning', 'mr', '.', 'hows', 'london', 'treatin', \"'\", 'ya', 'treacle', '?']\n",
      "AFter tokenizer:  ['i', 'ca', \"n't\", 'make', 'it', 'tonight']\n",
      "AFter tokenizer:  ['about', '&', 'lt', ';', '#', '&', 'gt', ';', 'bucks', '.', 'the', 'banks', 'fees', 'are', 'fixed', '.', 'better', 'to', 'call', 'the', 'bank', 'and', 'find', 'out', '.']\n",
      "AFter tokenizer:  ['i', 'can', '.', 'but', 'it', 'will', 'tell', 'quite', 'long', ',', 'cos', 'i', 'have', \"n't\", 'finish', 'my', 'film', 'yet', '...']\n",
      "AFter tokenizer:  ['pls', 'ask', 'macho', 'how', 'much', 'is', 'budget', 'for', 'bb', 'bold', '2', 'is', 'cos', 'i', 'saw', 'a', 'new', 'one', 'for', '&', 'lt', ';', '#', '&', 'gt', ';', 'dollars', '.']\n",
      "AFter tokenizer:  ['hi', 'missed', 'your', 'call', 'and', 'my', 'mumhas', 'beendropping', 'red', 'wine', 'all', 'over', 'theplace', '!', 'what', 'is', 'your', 'adress', '?']\n",
      "AFter tokenizer:  ['ill', 'be', 'at', 'yours', 'in', 'about', '3', 'mins', 'but', 'look', 'out', 'for', 'me']\n",
      "AFter tokenizer:  ['what', 'you', 'did', 'in', 'leave', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'coming', 'back', 'on', 'thursday', '.', 'yay', '.', 'is', 'it', 'gon', 'na', 'be', 'ok', 'to', 'get', 'the', 'money', '.', 'cheers', '.', 'oh', 'yeah', 'and', 'how', 'are', 'you', '.', 'everything', 'alright', '.', 'hows', 'school', '.', 'or', 'do', 'you', 'call', 'it', 'work', 'now']\n",
      "AFter tokenizer:  ['jolly', 'good', '!', 'by', 'the', 'way', ',', 'will', 'give', 'u', 'tickets', 'for', 'sat', 'eve', '7.30.', 'speak', 'before', 'then', 'x']\n",
      "AFter tokenizer:  ['yeah', ',', 'that', \"'s\", 'what', 'i', 'was', 'thinking']\n",
      "AFter tokenizer:  ['k.k', ':', ')', 'i', \"'m\", 'going', 'to', 'tirunelvali', 'this', 'week', 'to', 'see', 'my', 'uncle', '..', 'i', 'already', 'spend', 'the', 'amount', 'by', 'taking', 'dress', '.so', 'only', 'i', 'want', 'money.i', 'will', 'give', 'it', 'on', 'feb', '1']\n",
      "AFter tokenizer:  ['here', 'got', 'ur', 'favorite', 'oyster', '...', 'n', 'got', 'my', 'favorite', 'sashimi', '...', 'ok', 'lar', 'i', 'dun', 'say', 'already', '...', 'wait', 'ur', 'stomach', 'start', 'rumbling', '...']\n",
      "AFter tokenizer:  ['my', 'sister', 'going', 'to', 'earn', 'more', 'than', 'me', 'da', '.']\n",
      "AFter tokenizer:  ['jus', 'finish', 'watching', 'tv', '...', 'u', '?']\n",
      "AFter tokenizer:  ['k', ',', 'fyi', 'i', \"'m\", 'back', 'in', 'my', 'parents', \"'\", 'place', 'in', 'south', 'tampa', 'so', 'i', 'might', 'need', 'to', 'do', 'the', 'deal', 'somewhere', 'else']\n",
      "AFter tokenizer:  ['good', 'morning', ',', 'my', 'love', '...', 'i', 'go', 'to', 'sleep', 'now', 'and', 'wish', 'you', 'a', 'great', 'day', 'full', 'of', 'feeling', 'better', 'and', 'opportunity', '...', 'you', 'are', 'my', 'last', 'thought', 'babe', ',', 'i', 'love', 'you', '*', 'kiss', '*']\n",
      "AFter tokenizer:  ['kothi', 'print', 'out', 'marandratha', '.']\n",
      "AFter tokenizer:  ['but', 'we', 'havent', 'got', 'da', 'topic', 'yet', 'rite', '?']\n",
      "AFter tokenizer:  ['ok', 'no', 'problem', '...', 'yup', 'i', \"'m\", 'going', 'to', 'sch', 'at', '4', 'if', 'i', 'rem', 'correctly', '...']\n",
      "AFter tokenizer:  ['thanks', ',', 'i', \"'ll\", 'keep', 'that', 'in', 'mind']\n",
      "AFter tokenizer:  ['aah', 'bless', '!', 'how', \"'s\", 'your', 'arm', '?']\n",
      "AFter tokenizer:  ['dear', 'sir', ',', 'salam', 'alaikkum.pride', 'and', 'pleasure', 'meeting', 'you', 'today', 'at', 'the', 'tea', 'shop.we', 'are', 'pleased', 'to', 'send', 'you', 'our', 'contact', 'number', 'at', 'qatar.rakhesh', 'an', 'indian.pls', 'save', 'our', 'number.respectful', 'regards', '.']\n",
      "AFter tokenizer:  ['gal', 'n', 'boy', 'walking', 'in', 'd', 'park', '.', 'gal-can', 'i', 'hold', 'ur', 'hand', '?', 'boy-y', '?', 'do', 'u', 'think', 'i', 'would', 'run', 'away', '?', 'gal-no', ',', 'jst', 'wana', 'c', 'how', 'it', 'feels', 'walking', 'in', 'heaven', 'with', 'an', 'prince', '..', 'gn', ':', '-', ')']\n",
      "AFter tokenizer:  ['what', 'makes', 'you', 'most', 'happy', '?']\n",
      "AFter tokenizer:  ['wishing', 'you', 'a', 'wonderful', 'week', '.']\n",
      "AFter tokenizer:  ['sweet', 'heart', 'how', 'are', 'you', '?']\n",
      "AFter tokenizer:  ['sir', ',', 'waiting', 'for', 'your', 'letter', '.']\n",
      "AFter tokenizer:  ['dude', 'im', 'no', 'longer', 'a', 'pisces', '.', 'im', 'an', 'aquarius', 'now', '.']\n",
      "AFter tokenizer:  ['x', 'course', 'it', '2yrs', '.', 'just', 'so', 'her', 'messages', 'on', 'messenger', 'lik', 'you', 'r', 'sending', 'me']\n",
      "AFter tokenizer:  ['i', 'think', 'steyn', 'surely', 'get', 'one', 'wicket', ':', ')']\n",
      "AFter tokenizer:  ['neither', '[', 'in', 'sterm', 'voice', ']', '-', 'i', \"'m\", 'studying', '.', 'all', 'fine', 'with', 'me', '!', 'not', 'sure', 'the', 'thing', 'will', 'be', 'resolved', ',', 'tho', '.', 'anyway', '.', 'have', 'a', 'fab', 'hols']\n",
      "AFter tokenizer:  ['garbage', 'bags', ',', 'eggs', ',', 'jam', ',', 'bread', ',', 'hannaford', 'wheat', 'chex']\n",
      "AFter tokenizer:  ['no', '.', 'it', \"'s\", 'not', 'pride', '.', 'i', \"'m\", 'almost', '&', 'lt', ';', '#', '&', 'gt', ';', 'years', 'old', 'and', 'should', \"n't\", 'be', 'takin', 'money', 'from', 'my', 'kid', '.', 'you', \"'re\", 'not', 'supposed', 'to', 'have', 'to', 'deal', 'with', 'this', 'stuff', '.', 'this', 'is', 'grownup', 'stuff', '--', 'why', 'i', 'do', \"n't\", 'tell', 'you', '.']\n",
      "AFter tokenizer:  ['sounds', 'better', 'than', 'my', 'evening', 'im', 'just', 'doing', 'my', 'costume', '.', 'im', 'not', 'sure', 'what', 'time', 'i', 'finish', 'tomorrow', 'but', 'i', 'will', 'txt', 'you', 'at', 'the', 'end', '.']\n",
      "AFter tokenizer:  ['my', 'birthday', 'is', 'on', 'feb', '&', 'lt', ';', '#', '&', 'gt', ';', 'da', '.', '.']\n",
      "AFter tokenizer:  ['so', 'when', 'do', 'you', 'wan', 'na', 'gym', '?']\n",
      "AFter tokenizer:  ['you', \"'d\", 'like', 'that', 'would', \"n't\", 'you', '?', 'jerk', '!']\n",
      "AFter tokenizer:  ['are', 'u', 'awake', '?', 'is', 'there', 'snow', 'there', '?']\n",
      "AFter tokenizer:  ['and', 'of', 'course', 'you', 'should', 'make', 'a', 'stink', '!']\n",
      "AFter tokenizer:  ['u', 'r', 'subscribed', '2', 'textcomp', '250', 'wkly', 'comp', '.', '1st', 'wk', '?', 's', 'free', 'question', 'follows', ',', 'subsequent', 'wks', 'charged', '@', '150p/msg.2', 'unsubscribe', 'txt', 'stop', '2', '84128', ',', 'custcare', '08712405020']\n",
      "AFter tokenizer:  ['no', 'go', '.', 'no', 'openings', 'for', 'that', 'room', \"'til\", 'after', 'thanksgiving', 'without', 'an', 'upcharge', '.']\n",
      "AFter tokenizer:  ['when', 'you', 'guys', 'planning', 'on', 'coming', 'over', '?']\n",
      "AFter tokenizer:  ['wat', 'ü', 'doing', 'now', '?']\n",
      "AFter tokenizer:  ['no', 'sir', '.', 'that', \"'s\", 'why', 'i', 'had', 'an', '8-hr', 'trip', 'on', 'the', 'bus', 'last', 'week', '.', 'have', 'another', 'audition', 'next', 'wednesday', 'but', 'i', 'think', 'i', 'might', 'drive', 'this', 'time', '.']\n",
      "AFter tokenizer:  ['do', 'i', '?', 'i', 'thought', 'i', 'put', 'it', 'back', 'in', 'the', 'box']\n",
      "AFter tokenizer:  ['i', \"'m\", 'home', '...']\n",
      "AFter tokenizer:  ['no', 'one', 'interested', '.', 'may', 'be', 'some', 'business', 'plan', '.']\n",
      "AFter tokenizer:  ['yup', 'it', \"'s\", 'at', 'paragon', '...', 'i', 'havent', 'decided', 'whether', '2', 'cut', 'yet', '...', 'hee', '...']\n",
      "AFter tokenizer:  ['good', 'morning', 'princess', '!', 'have', 'a', 'great', 'day', '!']\n",
      "AFter tokenizer:  ['guai', '...', 'ü', 'shd', 'haf', 'seen', 'him', 'when', 'he', \"'s\", 'naughty', '...', 'ü', 'so', 'free', 'today', '?', 'can', 'go', 'jogging', '...']\n",
      "AFter tokenizer:  ['aiyo', 'cos', 'i', 'sms', 'ü', 'then', 'ü', 'neva', 'reply', 'so', 'i', 'wait', '4', 'ü', 'to', 'reply', 'lar', '.', 'i', 'tot', 'ü', 'havent', 'finish', 'ur', 'lab', 'wat', '.']\n",
      "AFter tokenizer:  ['living', 'is', 'very', 'simple', '..', 'loving', 'is', 'also', 'simple', '..', 'laughing', 'is', 'too', 'simple', '..', 'winning', 'is', 'tooo', 'simple', '..', 'but', ',', 'being', \"'simple\", \"'\", 'is', 'very', 'difficult', '...', ';', '-', ')', ':', '-', ')']\n",
      "AFter tokenizer:  ['tell', 'me', 'something', '.', 'thats', 'okay', '.']\n",
      "AFter tokenizer:  ['hmm', '.', 'shall', 'i', 'bring', 'a', 'bottle', 'of', 'wine', 'to', 'keep', 'us', 'amused', '?', 'just', 'joking', '!', 'i', \"'ll\", 'still', 'bring', 'a', 'bottle', '.', 'red', 'or', 'white', '?', 'see', 'you', 'tomorrow']\n",
      "AFter tokenizer:  ['this', 'is', 'ur', 'face', 'test', '(', '1', '2', '3', '4', '5', '6', '7', '8', '9', '&', 'lt', ';', '#', '&', 'gt', ';', ')', 'select', 'any', 'number', 'i', 'will', 'tell', 'ur', 'face', 'astrology', '....', 'am', 'waiting', '.', 'quick', 'reply', '...']\n",
      "AFter tokenizer:  ['hey', ',', 'iouri', 'gave', 'me', 'your', 'number', ',', 'i', \"'m\", 'wylie', ',', 'ryan', \"'s\", 'friend']\n",
      "AFter tokenizer:  ['yep', 'get', 'with', 'the', 'program', '.', 'you', \"'re\", 'slacking', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'in', 'inside', 'office', '..', 'still', 'filling', 'forms.don', 'know', 'when', 'they', 'leave', 'me', '.']\n",
      "AFter tokenizer:  ['i', 'think', 'your', 'mentor', 'is', ',', 'but', 'not', '100', 'percent', 'sure', '.']\n",
      "AFter tokenizer:  ['call', '09095350301', 'and', 'send', 'our', 'girls', 'into', 'erotic', 'ecstacy', '.', 'just', '60p/min', '.', 'to', 'stop', 'texts', 'call', '08712460324', '(', 'nat', 'rate', ')']\n",
      "AFter tokenizer:  ['just', 'trying', 'to', 'figure', 'out', 'when', 'i', \"'m\", 'suppose', 'to', 'see', 'a', 'couple', 'different', 'people', 'this', 'week', '.', 'we', 'said', 'we', \"'d\", 'get', 'together', 'but', 'i', 'did', \"n't\", 'set', 'dates']\n",
      "AFter tokenizer:  ['important', 'message', '.', 'this', 'is', 'a', 'final', 'contact', 'attempt', '.', 'you', 'have', 'important', 'messages', 'waiting', 'out', 'our', 'customer', 'claims', 'dept', '.', 'expires', '13/4/04', '.', 'call', '08717507382', 'now', '!']\n",
      "AFter tokenizer:  ['hi', 'mom', 'we', 'might', 'be', 'back', 'later', 'than', '&', 'lt', ';', '#', '&', 'gt', ';']\n",
      "AFter tokenizer:  ['dating', ':', 'i', 'have', 'had', 'two', 'of', 'these', '.', 'only', 'started', 'after', 'i', 'sent', 'a', 'text', 'to', 'talk', 'sport', 'radio', 'last', 'week', '.', 'any', 'connection', 'do', 'you', 'think', 'or', 'coincidence', '?']\n",
      "AFter tokenizer:  ['lol', ',', 'oh', 'you', 'got', 'a', 'friend', 'for', 'the', 'dog', '?']\n",
      "AFter tokenizer:  ['ok.', ',', 'is', 'any', 'problem', 'to', 'u', 'frm', 'him', '?', 'wats', 'matter', '?']\n",
      "AFter tokenizer:  ['k', 'i', \"'ll\", 'head', 'out', 'in', 'a', 'few', 'mins', ',', 'see', 'you', 'there']\n",
      "AFter tokenizer:  ['i', 'do', \"n't\", 'want', 'you', 'to', 'leave', '.', 'but', 'i', \"'m\", 'barely', 'doing', 'what', 'i', 'can', 'to', 'stay', 'sane', '.', 'fighting', 'with', 'you', 'constantly', 'is', \"n't\", 'helping', '.']\n",
      "AFter tokenizer:  ['the', 'current', 'leading', 'bid', 'is', '151.', 'to', 'pause', 'this', 'auction', 'send', 'out', '.', 'customer', 'care', ':', '08718726270']\n",
      "AFter tokenizer:  ['free', 'entry', 'to', 'the', 'gr8prizes', 'wkly', 'comp', '4', 'a', 'chance', 'to', 'win', 'the', 'latest', 'nokia', '8800', ',', 'psp', 'or', '£250', 'cash', 'every', 'wk.txt', 'great', 'to', '80878', 'http//www.gr8prizes.com', '08715705022']\n",
      "AFter tokenizer:  ['somebody', 'set', 'up', 'a', 'website', 'where', 'you', 'can', 'play', 'hold', 'em', 'using', 'eve', 'online', 'spacebucks']\n",
      "AFter tokenizer:  ['its', 'sunny', 'in', 'california', '.', 'the', 'weather', \"'s\", 'just', 'cool']\n",
      "AFter tokenizer:  ['you', 'have', '1', 'new', 'message', '.', 'call', '0207-083-6089']\n",
      "AFter tokenizer:  ['i', 'can', 'make', 'it', 'up', 'there', ',', 'squeezed', '&', 'lt', ';', '#', '&', 'gt', ';', 'bucks', 'out', 'of', 'my', 'dad']\n",
      "AFter tokenizer:  ['good', 'day', 'to', 'you', 'too.pray', 'for', 'me.remove', 'the', 'teeth', 'as', 'its', 'painful', 'maintaining', 'other', 'stuff', '.']\n",
      "AFter tokenizer:  ['how', 'are', 'you', 'babes', '.', 'hope', 'your', 'doing', 'ok.', 'i', 'had', 'a', 'shit', 'nights', 'sleep', '.', 'i', 'fell', 'asleep', 'at', '5.i\\x92m', 'knackered', 'and', 'i\\x92m', 'dreading', 'work', 'tonight', '.', 'what', 'are', 'thou', 'upto', 'tonight', '.', 'x']\n",
      "AFter tokenizer:  ['how', 'do', 'friends', 'help', 'us', 'in', 'problems', '?', 'they', 'give', 'the', 'most', 'stupid', 'suggestion', 'that', 'lands', 'us', 'into', 'another', 'problem', 'and', 'helps', 'us', 'forgt', 'the', 'previous', 'problem']\n",
      "AFter tokenizer:  ['i', 'will', 'be', 'gentle', 'baby', '!', 'soon', 'you', 'will', 'be', 'taking', 'all', '&', 'lt', ';', '#', '&', 'gt', ';', 'inches', 'deep', 'inside', 'your', 'tight', 'pussy', '...']\n",
      "AFter tokenizer:  ['not', 'much', 'no', 'fights', '.', 'it', 'was', 'a', 'good', 'nite', '!', '!']\n",
      "AFter tokenizer:  ['nt', 'joking', 'seriously', 'i', 'told']\n",
      "AFter tokenizer:  ['watching', 'ajith', 'film', 'ah', '?']\n",
      "AFter tokenizer:  ['ooooooh', 'i', 'forgot', 'to', 'tell', 'u', 'i', 'can', 'get', 'on', 'yoville', 'on', 'my', 'phone']\n",
      "AFter tokenizer:  ['all', 'done', ',', 'all', 'handed', 'in', '.', 'do', \"n't\", 'know', 'if', 'mega', 'shop', 'in', 'asda', 'counts', 'as', 'celebration', 'but', 'thats', 'what', 'i', \"'m\", 'doing', '!']\n",
      "AFter tokenizer:  ['i', 'dont', 'know', 'exactly', 'could', 'you', 'ask', 'chechi', '.']\n",
      "AFter tokenizer:  ['dunno', 'lei', 'shd', 'b', 'driving', 'lor', 'cos', 'i', 'go', 'sch', '1', 'hr', 'oni', '.']\n",
      "AFter tokenizer:  ['as', 'in', 'i', 'want', 'custom', 'officer', 'discount', 'oh', '.']\n",
      "AFter tokenizer:  ['that', \"'s\", 'necessarily', 'respectful']\n",
      "AFter tokenizer:  ['hi', '.', 'hope', 'you', 'had', 'a', 'good', 'day', '.', 'have', 'a', 'better', 'night', '.']\n",
      "AFter tokenizer:  ['and', 'he', \"'s\", 'apparently', 'bffs', 'with', 'carly', 'quick', 'now']\n",
      "AFter tokenizer:  ['hard', 'but', 'true', ':', 'how', 'much', 'you', 'show', '&', 'amp', ';', 'express', 'your', 'love', 'to', 'someone', '....', 'that', 'much', 'it', 'will', 'hurt', 'when', 'they', 'leave', 'you', 'or', 'you', 'get', 'seperated', '...', '!', '鈥┾', '?', '?', '〨ud', 'evening', '...']\n",
      "AFter tokenizer:  ['babes', 'i', 'think', 'i', 'got', 'ur', 'brolly', 'i', 'left', 'it', 'in', 'english', 'wil', 'bring', 'it', 'in', '2mrw', '4', 'u', 'luv', 'franxx']\n",
      "AFter tokenizer:  ['hi', 'babe', 'its', 'me', 'thanks', 'for', 'coming', 'even', 'though', 'it', 'didnt', 'go', 'that', 'well', '!', 'i', 'just', 'wanted', 'my', 'bed', '!', 'hope', 'to', 'see', 'you', 'soon', 'love', 'and', 'kisses', 'xxx']\n",
      "AFter tokenizer:  ['so', 'gd', 'got', 'free', 'ice', 'cream', '...', 'i', 'oso', 'wan', '...']\n",
      "AFter tokenizer:  ['pls', 'give', 'her', 'prometazine', 'syrup', '.', '5mls', 'then', '&', 'lt', ';', '#', '&', 'gt', ';', 'mins', 'later', 'feed', '.']\n",
      "AFter tokenizer:  ['so', 'how', 'many', 'days', 'since', 'then', '?']\n",
      "AFter tokenizer:  ['dear', 'are', 'you', 'angry', 'i', 'was', 'busy', 'dear']\n",
      "AFter tokenizer:  ['yup', 'he', 'msg', 'me', ':', 'is', 'tat', 'yijue', '?', 'then', 'i', 'tot', 'it', \"'s\", 'my', 'group', 'mate', 'cos', 'we', 'meeting', 'today', 'mah', '...', 'i', \"'m\", 'askin', 'if', 'ü', 'leaving', 'earlier', 'or', 'wat', 'mah', 'cos', 'mayb', 'ü', 'haf', 'to', 'walk', 'v', 'far', '...']\n",
      "AFter tokenizer:  ['...', 'are', 'you', 'in', 'the', 'pub', '?']\n",
      "AFter tokenizer:  ['there', 'is', 'a', 'first', 'time', 'for', 'everything', ':', ')']\n",
      "AFter tokenizer:  ['daddy', ',', 'shu', 'shu', 'is', 'looking', '4', 'u', '...', 'u', 'wan', 'me', '2', 'tell', 'him', 'u', \"'re\", 'not', 'in', 'singapore', 'or', 'wat', '?']\n",
      "AFter tokenizer:  ['i', 'ask', 'if', 'u', 'meeting', 'da', 'ge', 'tmr', 'nite', '...']\n",
      "AFter tokenizer:  ['gr8', '.', 'so', 'how', 'do', 'you', 'handle', 'the', 'victoria', 'island', 'traffic', '.', 'plus', 'when', \"'s\", 'the', 'album', 'due']\n",
      "AFter tokenizer:  ['nite', 'nite', 'pocay', 'wocay', 'luv', 'u', 'more', 'than', 'n', 'e', 'thing', '4eva', 'i', 'promise', 'ring', 'u', '2morrowxxxx']\n",
      "AFter tokenizer:  ['east', 'coast']\n",
      "AFter tokenizer:  ['you', 'should', 'get', 'more', 'chicken', 'broth', 'if', 'you', 'want', 'ramen', 'unless', 'there', \"'s\", 'some', 'i', 'do', \"n't\", 'know', 'about']\n",
      "AFter tokenizer:  ['my', 'slave', '!', 'i', 'want', 'you', 'to', 'take', '2', 'or', '3', 'pictures', 'of', 'yourself', 'today', 'in', 'bright', 'light', 'on', 'your', 'cell', 'phone', '!', 'bright', 'light', '!']\n",
      "AFter tokenizer:  ['nope', '.', 'i', 'just', 'forgot', '.', 'will', 'show', 'next', 'week']\n",
      "AFter tokenizer:  ['so', 'how', 'are', 'you', 'really', '.', 'what', 'are', 'you', 'up', 'to', '.', 'how', \"'s\", 'the', 'masters', '.', 'and', 'so', 'on', '.']\n",
      "AFter tokenizer:  ['i', \"'m\", 'at', 'bruce', '&', 'amp', ';', 'fowler', 'now', 'but', 'i', \"'m\", 'in', 'my', 'mom', \"'s\", 'car', 'so', 'i', 'ca', \"n't\", 'park', '(', 'long', 'story', ')']\n",
      "AFter tokenizer:  ['i', 'dont', 'know', 'oh', '.', 'hopefully', 'this', 'month', '.']\n",
      "AFter tokenizer:  ['hi', 'elaine', ',', 'is', 'today', \"'s\", 'meeting', 'confirmed', '?']\n",
      "AFter tokenizer:  ['ok', 'k', '..', 'sry', 'i', 'knw', '2', 'siva', '..', 'tats', 'y', 'i', 'askd', '..']\n",
      "AFter tokenizer:  ['u', 'horrible', 'gal', '...', 'u', 'knew', 'dat', 'i', 'was', 'going', 'out', 'wif', 'him', 'yest', 'n', 'u', 'still', 'come', 'n', 'ask', 'me', '...']\n",
      "AFter tokenizer:  ['oh', 'yeah', '!', 'and', 'my', 'diet', 'just', 'flew', 'out', 'the', 'window']\n",
      "AFter tokenizer:  ['santa', 'calling', '!', 'would', 'your', 'little', 'ones', 'like', 'a', 'call', 'from', 'santa', 'xmas', 'eve', '?', 'call', '09058094583', 'to', 'book', 'your', 'time', '.']\n",
      "AFter tokenizer:  ['you', 'didnt', 'complete', 'your', 'gist', 'oh', '.']\n",
      "AFter tokenizer:  ['er', 'yeah', ',', 'i', 'will', 'b', 'there', 'at', '15:26', ',', 'sorry', '!', 'just', 'tell', 'me', 'which', 'pub/cafe', 'to', 'sit', 'in', 'and', 'come', 'wen', 'u', 'can']\n",
      "AFter tokenizer:  ['if', 'you', 'can', 'make', 'it', 'any', 'time', 'tonight', 'or', 'whenever', 'you', 'can', 'it', \"'s\", 'cool', ',', 'just', 'text', 'me', 'whenever', 'you', \"'re\", 'around']\n",
      "AFter tokenizer:  ['if', 'i', 'was', 'i', 'was', \"n't\", 'paying', 'attention']\n",
      "AFter tokenizer:  ['thanx', 'a', 'lot', '4', 'ur', 'help', '!']\n",
      "AFter tokenizer:  ['you', \"'re\", 'gon', 'na', 'have', 'to', 'be', 'way', 'more', 'specific', 'than', 'that']\n",
      "AFter tokenizer:  ['jesus', 'armand', 'really', 'is', 'trying', 'to', 'tell', 'everybody', 'he', 'can', 'find']\n",
      "AFter tokenizer:  ['i', \"'m\", 'wif', 'him', 'now', 'buying', 'tix', 'lar', '...']\n",
      "AFter tokenizer:  ['mode', 'men', 'or', 'have', 'you', 'left', '.']\n",
      "AFter tokenizer:  ['am', 'slow', 'in', 'using', 'biola', \"'s\", 'fne']\n",
      "AFter tokenizer:  ['what', 'are', 'youdoing', 'later', '?', 'sar', 'xxx']\n",
      "AFter tokenizer:  ['hey', 'i', \"'ve\", 'booked', 'the', '2', 'lessons', 'on', 'sun', 'liao', '...']\n",
      "AFter tokenizer:  ['thank', 'you', '.', 'do', 'you', 'generally', 'date', 'the', 'brothas', '?']\n",
      "AFter tokenizer:  ['by', 'the', 'way', ',', 'make', 'sure', 'u', 'get', 'train', 'to', 'worc', 'foregate', 'street', 'not', 'shrub', 'hill', '.', 'have', 'fun', 'night', 'x']\n",
      "AFter tokenizer:  ['i', 'thought', 'i', \"'d\", 'get', 'him', 'a', 'watch', ',', 'just', 'cos', 'thats', 'the', 'kind', 'of', 'thing', 'u', 'get4an18th', '.', 'and', 'he', 'loves', 'so', 'much', '!']\n",
      "AFter tokenizer:  ['you', 'have', 'won', 'a', 'guaranteed', '32000', 'award', 'or', 'maybe', 'even', '£1000', 'cash', 'to', 'claim', 'ur', 'award', 'call', 'free', 'on', '0800', '.....', '(', '18+', ')', '.', 'its', 'a', 'legitimat', 'efreefone', 'number', 'wat', 'do', 'u', 'think', '?', '?', '?']\n",
      "AFter tokenizer:  ['good', 'morning', '.', 'at', 'the', 'repair', 'shop', '--', 'the', 'only', 'reason', 'i', \"'m\", 'up', 'at', 'this', 'hour', '.']\n",
      "AFter tokenizer:  ['and', 'that', \"'s\", 'fine', ',', 'i', 'got', 'enough', 'bud', 'to', 'last', 'most', 'of', 'the', 'night', 'at', 'least']\n",
      "AFter tokenizer:  ['i', 'am', 'back', '.', 'good', 'journey', '!', 'let', 'me', 'know', 'if', 'you', 'need', 'any', 'of', 'the', 'receipts', '.', 'shall', 'i', 'tell', 'you', 'like', 'the', 'pendent', '?']\n",
      "AFter tokenizer:  ['so', 'that', 'takes', 'away', 'some', 'money', 'worries']\n",
      "AFter tokenizer:  ['aight', 'we', 'can', 'pick', 'some', 'up', ',', 'you', 'open', 'before', 'tonight', '?']\n",
      "AFter tokenizer:  ['latest', 'news', '!', 'police', 'station', 'toilet', 'stolen', ',', 'cops', 'have', 'nothing', 'to', 'go', 'on', '!']\n",
      "AFter tokenizer:  ['sac', 'needs', 'to', 'carry', 'on', ':', ')']\n",
      "AFter tokenizer:  ['just', 'sing', 'hu', '.', 'i', 'think', 'its', 'also', 'important', 'to', 'find', 'someone', 'female', 'that', 'know', 'the', 'place', 'well', 'preferably', 'a', 'citizen', 'that', 'is', 'also', 'smart', 'to', 'help', 'you', 'navigate', 'through', '.', 'even', 'things', 'like', 'choosing', 'a', 'phone', 'plan', 'require', 'guidance', '.', 'when', 'in', 'doubt', 'ask', 'especially', 'girls', '.']\n",
      "AFter tokenizer:  ['what', '?', '?', '?', '?', 'hello', 'wats', 'talks', 'email', 'address', '?']\n",
      "AFter tokenizer:  ['except', 'theres', 'a', 'chick', 'with', 'huge', 'boobs', '.']\n",
      "AFter tokenizer:  ['im', 'just', 'wondering', 'what', 'your', 'doing', 'right', 'now', '?']\n",
      "AFter tokenizer:  ['wishing', 'you', 'a', 'beautiful', 'day', '.', 'each', 'moment', 'revealing', 'even', 'more', 'things', 'to', 'keep', 'you', 'smiling', '.', 'do', 'enjoy', 'it', '.']\n",
      "AFter tokenizer:  ['for', 'the', 'most', 'sparkling', 'shopping', 'breaks', 'from', '45', 'per', 'person', ';', 'call', '0121', '2025050', 'or', 'visit', 'www.shortbreaks.org.uk']\n",
      "AFter tokenizer:  ['if', 'you', 'hear', 'a', 'loud', 'scream', 'in', 'about', '&', 'lt', ';', '#', '&', 'gt', ';', 'minutes', 'its', 'cause', 'my', 'gyno', 'will', 'be', 'shoving', 'things', 'up', 'me', 'that', 'do', \"n't\", 'belong', ':', '/']\n",
      "AFter tokenizer:  ['ok', 'i', 'thk', 'i', 'got', 'it', '.', 'then', 'u', 'wan', 'me', '2', 'come', 'now', 'or', 'wat', '?']\n",
      "AFter tokenizer:  ['txt', ':', 'call', 'to', 'no', ':', '86888', '&', 'claim', 'your', 'reward', 'of', '3', 'hours', 'talk', 'time', 'to', 'use', 'from', 'your', 'phone', 'now', '!', 'subscribe6gbp/mnth', 'inc', '3hrs', '16', 'stop', '?', 'txtstop', 'www.gamb.tv']\n",
      "AFter tokenizer:  ['u', 'goin', 'out', '2nite', '?']\n",
      "AFter tokenizer:  ['i', 'will', 'treasure', 'every', 'moment', 'we', 'spend', 'together', '...']\n",
      "AFter tokenizer:  ['shall', 'i', 'bring', 'us', 'a', 'bottle', 'of', 'wine', 'to', 'keep', 'us', 'amused', '?', 'only', 'joking', '!', 'i', '‘', 'll', 'bring', 'one', 'anyway']\n",
      "AFter tokenizer:  ['http//tms', '.', 'widelive.com/index', '.', 'wml', '?', 'id=820554ad0a1705572711', '&', 'first=true¡c', 'c', 'ringtone¡']\n",
      "AFter tokenizer:  ['urgent', '!', 'last', 'weekend', \"'s\", 'draw', 'shows', 'that', 'you', 'have', 'won', '£1000', 'cash', 'or', 'a', 'spanish', 'holiday', '!', 'call', 'now', '09050000332', 'to', 'claim', '.', 't', '&', 'c', ':', 'rstm', ',', 'sw7', '3ss', '.', '150ppm']\n",
      "AFter tokenizer:  ['i', 'thought', 'slide', 'is', 'enough', '.']\n",
      "AFter tokenizer:  ['well', 'obviously', 'not', 'because', 'all', 'the', 'people', 'in', 'my', 'cool', 'college', 'life', 'went', 'home', ';', '_', ';']\n",
      "AFter tokenizer:  ['ok', 'lor', 'ü', 'reaching', 'then', 'message', 'me', '.']\n",
      "AFter tokenizer:  ['where', \"'s\", 'mummy', \"'s\", 'boy', '?', 'is', 'he', 'being', 'good', 'or', 'bad', '?', 'is', 'he', 'being', 'positive', 'or', 'negative', '?', 'why', 'is', 'mummy', 'being', 'made', 'to', 'wait', '?', 'hmmmm', '?']\n",
      "AFter tokenizer:  ['dhoni', 'have', 'luck', 'to', 'win', 'some', 'big', 'title.so', 'we', 'will', 'win', ':', ')']\n",
      "AFter tokenizer:  ['yes', 'princess', '!', 'i', 'want', 'to', 'please', 'you', 'every', 'night', '.', 'your', 'wish', 'is', 'my', 'command', '...']\n",
      "AFter tokenizer:  ['no', 'probably', '&', 'lt', ';', '#', '&', 'gt', ';', '%', '.']\n",
      "AFter tokenizer:  ['really', 'do', 'hope', 'the', 'work', 'doesnt', 'get', 'stressful', '.', 'have', 'a', 'gr8', 'day', '.']\n",
      "AFter tokenizer:  ['have', 'you', 'seen', 'who', \"'s\", 'back', 'at', 'holby', '?', '!']\n",
      "AFter tokenizer:  ['shall', 'call', 'now', 'dear', 'having', 'food']\n",
      "AFter tokenizer:  ['urgent', 'we', 'are', 'trying', 'to', 'contact', 'you', 'last', 'weekends', 'draw', 'shows', 'u', 'have', 'won', 'a', '£1000', 'prize', 'guaranteed', 'call', '09064017295', 'claim', 'code', 'k52', 'valid', '12hrs', '150p', 'pm']\n",
      "AFter tokenizer:  ['so', 'li', 'hai', '...', 'me', 'bored', 'now', 'da', 'lecturer', 'repeating', 'last', 'weeks', 'stuff', 'waste', 'time', '...']\n",
      "AFter tokenizer:  [',', ',', 'and', 'picking', 'them', 'up', 'from', 'various', 'points', '|', 'going', '2', 'yeovil', '|', 'and', 'they', 'will', 'do', 'the', 'motor', 'project', '4', '3', 'hours', '|', 'and', 'then', 'u', 'take', 'them', 'home', '.', '||', '12', '2', '5.30', 'max', '.', '||', 'very', 'easy']\n",
      "AFter tokenizer:  ['also', 'fuck', 'you', 'and', 'your', 'family', 'for', 'going', 'to', 'rhode', 'island', 'or', 'wherever', 'the', 'fuck', 'and', 'leaving', 'me', 'all', 'alone', 'the', 'week', 'i', 'have', 'a', 'new', 'bong', '&', 'gt', ';', ':', '(']\n",
      "AFter tokenizer:  ['ofcourse', 'i', 'also', 'upload', 'some', 'songs']\n",
      "AFter tokenizer:  ['2p', 'per', 'min', 'to', 'call', 'germany', '08448350055', 'from', 'your', 'bt', 'line', '.', 'just', '2p', 'per', 'min', '.', 'check', 'planettalkinstant.com', 'for', 'info', '&', 't', \"'s\", '&', 'c', \"'s\", '.', 'text', 'stop', 'to', 'opt', 'out']\n",
      "AFter tokenizer:  ['oh', 'thanks', 'a', 'lot', '..', 'i', 'already', 'bought', '2', 'eggs', '..']\n",
      "AFter tokenizer:  ['u', 'studying', 'in', 'sch', 'or', 'going', 'home', '?', 'anyway', 'i', \"'ll\", 'b', 'going', '2', 'sch', 'later', '.']\n",
      "AFter tokenizer:  ['marvel', 'mobile', 'play', 'the', 'official', 'ultimate', 'spider-man', 'game', '(', '£4.50', ')', 'on', 'ur', 'mobile', 'right', 'now', '.', 'text', 'spider', 'to', '83338', 'for', 'the', 'game', '&', 'we', 'll', 'send', 'u', 'a', 'free', '8ball', 'wallpaper']\n",
      "AFter tokenizer:  ['i', 'think', 'if', 'he', 'rule', 'tamilnadu', '..', 'then', 'its', 'very', 'tough', 'for', 'our', 'people', '.']\n",
      "AFter tokenizer:  ['cool', ',', 'we', 'shall', 'go', 'and', 'see', ',', 'have', 'to', 'go', 'to', 'tip', 'anyway', '.', 'are', 'you', 'at', 'home', ',', 'got', 'something', 'to', 'drop', 'in', 'later', '?', 'so', 'lets', 'go', 'to', 'town', 'tonight', '!', 'maybe', 'mum', 'can', 'take', 'us', 'in', '.']\n",
      "AFter tokenizer:  ['good', 'afternoon', ',', 'my', 'love', '...', 'how', 'goes', 'your', 'day', '?', 'how', 'did', 'you', 'sleep', '?', 'i', 'hope', 'your', 'well', ',', 'my', 'boytoy', '...', 'i', 'think', 'of', 'you', '...']\n",
      "AFter tokenizer:  ['yes', '...', 'i', 'trust', 'u', 'to', 'buy', 'new', 'stuff', 'asap', 'so', 'i', 'can', 'try', 'it', 'out']\n",
      "AFter tokenizer:  ['why', 'did', 'i', 'wake', 'up', 'on', 'my', 'own', '&', 'gt', ';', ':', '(']\n",
      "AFter tokenizer:  ['now', 'get', 'step', '2', 'outta', 'the', 'way', '.', 'congrats', 'again', '.']\n",
      "AFter tokenizer:  ['love', 'has', 'one', 'law', ';', 'make', 'happy', 'the', 'person', 'you', 'love', '.', 'in', 'the', 'same', 'way', 'friendship', 'has', 'one', 'law', ';', 'never', 'make', 'ur', 'friend', 'feel', 'alone', 'until', 'you', 'are', 'alive', '....', 'gud', 'night']\n",
      "AFter tokenizer:  ['private', '!', 'your', '2003', 'account', 'statement', 'for', '07808247860', 'shows', '800', 'un-redeemed', 's.', 'i.', 'm.', 'points', '.', 'call', '08719899229', 'identifier', 'code', ':', '40411', 'expires', '06/11/04']\n",
      "AFter tokenizer:  ['apo', 'all', 'other', 'are', 'mokka', 'players', 'only']\n",
      "AFter tokenizer:  ['perhaps', '*', 'is', 'much', 'easy', 'give', 'your', 'account', 'identification', ',', 'so', 'i', 'will', 'tomorrow', 'at', 'uni']\n",
      "AFter tokenizer:  ['wait', '.', 'i', 'will', 'msg', 'after', '&', 'lt', ';', '#', '&', 'gt', ';', 'min', '.']\n",
      "AFter tokenizer:  ['what', 'i', 'told', 'before', 'i', 'tell', '.', 'stupid', 'hear', 'after', 'i', 'wont', 'tell', 'anything', 'to', 'you', '.', 'you', 'dad', 'called', 'to', 'my', 'brother', 'and', 'spoken', '.', 'not', 'with', 'me', '.']\n",
      "AFter tokenizer:  ['god', \"'s\", 'love', 'has', 'no', 'limit', '.', 'god', \"'s\", 'grace', 'has', 'no', 'measure', '.', 'god', \"'s\", 'power', 'has', 'no', 'boundaries', '.', 'may', 'u', 'have', 'god', \"'s\", 'endless', 'blessings', 'always', 'in', 'ur', 'life', '...', '!', '!', 'gud', 'ni8']\n",
      "AFter tokenizer:  ['i', 'want', 'to', 'be', 'inside', 'you', 'every', 'night', '...']\n",
      "AFter tokenizer:  ['machan', 'you', 'go', 'to', 'gym', 'tomorrow', ',', 'i', 'wil', 'come', 'late', 'goodnight', '.']\n",
      "AFter tokenizer:  ['lol', 'they', 'were', 'mad', 'at', 'first', 'but', 'then', 'they', 'woke', 'up', 'and', 'gave', 'in', '.']\n",
      "AFter tokenizer:  ['it', '‘', 's', 'reassuring', ',', 'in', 'this', 'crazy', 'world', '.']\n",
      "AFter tokenizer:  ['just', 'making', 'dinner', ',', 'you', '?']\n",
      "AFter tokenizer:  ['yes', '.', 'please', 'leave', 'at', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'so', 'that', 'at', '&', 'lt', ';', '#', '&', 'gt', ';', 'we', 'can', 'leave']\n",
      "AFter tokenizer:  ['oh', '...', 'okie', 'lor', '...', 'we', 'go', 'on', 'sat', '...']\n",
      "AFter tokenizer:  ['you', 'are', 'a', 'great', 'role', 'model', '.', 'you', 'are', 'giving', 'so', 'much', 'and', 'i', 'really', 'wish', 'each', 'day', 'for', 'a', 'miracle', 'but', 'god', 'as', 'a', 'reason', 'for', 'everything', 'and', 'i', 'must', 'say', 'i', 'wish', 'i', 'knew', 'why', 'but', 'i', 'dont', '.', 'i', \"'ve\", 'looked', 'up', 'to', 'you', 'since', 'i', 'was', 'young', 'and', 'i', 'still', 'do', '.', 'have', 'a', 'great', 'day', '.']\n",
      "AFter tokenizer:  ['ya', ',', 'i', \"'m\", 'referin', 'to', 'mei', \"'s\", 'ex', 'wat', '...', 'no', 'ah', ',', 'waitin', '4', 'u', 'to', 'treat', ',', 'somebody', 'shld', 'b', 'rich', 'liao', '...', 'so', 'gd', ',', 'den', 'u', 'dun', 'have', 'to', 'work', 'frm', 'tmr', 'onwards', '...']\n",
      "AFter tokenizer:  ['miles', 'and', 'smiles', 'r', 'made', 'frm', 'same', 'letters', 'but', 'do', 'u', 'know', 'd', 'difference', '..', '?', 'smile', 'on', 'ur', 'face', 'keeps', 'me', 'happy', 'even', 'though', 'i', 'am', 'miles', 'away', 'from', 'u', '..', ':', '-', ')', 'keep', 'smiling', '..', 'good', 'nyt']\n",
      "AFter tokenizer:  ['by', 'the', 'way', ',', 'i', \"'ve\", 'put', 'a', 'skip', 'right', 'outside', 'the', 'front', 'of', 'the', 'house', 'so', 'you', 'can', 'see', 'which', 'house', 'it', 'is', '.', 'just', 'pull', 'up', 'before', 'it', '.']\n",
      "AFter tokenizer:  ['can', 'you', 'pls', 'send', 'me', 'that', 'company', 'name', '.', 'in', 'saibaba', 'colany']\n",
      "AFter tokenizer:  ['no', '.', 'i', 'dont', 'want', 'to', 'hear', 'anything']\n",
      "AFter tokenizer:  ['you', 'are', 'a', 'big', 'chic', '.', 'common', '.', 'declare']\n",
      "AFter tokenizer:  ['thats', 'cool', '.', 'i', 'want', 'to', 'please', 'you', '...']\n",
      "AFter tokenizer:  ['going', 'to', 'join', 'tomorrow', '.']\n",
      "AFter tokenizer:  ['i', 'want', 'to', 'tell', 'you', 'how', 'bad', 'i', 'feel', 'that', 'basically', 'the', 'only', 'times', 'i', 'text', 'you', 'lately', 'are', 'when', 'i', 'need', 'drugs']\n",
      "AFter tokenizer:  ['private', '!', 'your', '2003', 'account', 'statement', 'for', 'shows', '800', 'un-redeemed', 's.i.m', '.', 'points', '.', 'call', '08718738001', 'identifier', 'code', ':', '49557', 'expires', '26/11/04']\n",
      "AFter tokenizer:  ['total', 'disappointment', ',', 'when', 'i', 'texted', 'you', 'was', 'the', 'craziest', 'shit', 'got', ':', '(']\n",
      "AFter tokenizer:  ['its', 'just', 'the', 'effect', 'of', 'irritation', '.', 'just', 'ignore', 'it']\n",
      "AFter tokenizer:  ['what', 'about', 'this', 'one', 'then', '.']\n",
      "AFter tokenizer:  ['i', 'think', 'that', 'tantrum', \"'s\", 'finished', 'so', 'yeah', 'i', \"'ll\", 'be', 'by', 'at', 'some', 'point']\n",
      "AFter tokenizer:  ['compliments', 'to', 'you', '.', 'was', 'away', 'from', 'the', 'system', '.', 'how', 'your', 'side', '.']\n",
      "AFter tokenizer:  ['happened', 'here', 'while', 'you', 'were', 'adventuring']\n",
      "AFter tokenizer:  ['hey', 'chief', ',', 'can', 'you', 'give', 'me', 'a', 'bell', 'when', 'you', 'get', 'this', '.', 'need', 'to', 'talk', 'to', 'you', 'about', 'this', 'royal', 'visit', 'on', 'the', '1st', 'june', '.']\n",
      "AFter tokenizer:  ['ok', 'which', 'your', 'another', 'number']\n",
      "AFter tokenizer:  ['aiyah', 'ok', 'wat', 'as', 'long', 'as', 'got', 'improve', 'can', 'already', 'wat', '...']\n",
      "AFter tokenizer:  ['want', 'explicit', 'sex', 'in', '30', 'secs', '?', 'ring', '02073162414', 'now', '!', 'costs', '20p/min', 'gsex', 'pobox', '2667', 'wc1n', '3xx']\n",
      "AFter tokenizer:  ['i', 'ca', \"n't\", 'believe', 'how', 'attached', 'i', 'am', 'to', 'seeing', 'you', 'every', 'day', '.', 'i', 'know', 'you', 'will', 'do', 'the', 'best', 'you', 'can', 'to', 'get', 'to', 'me', 'babe', '.', 'i', 'will', 'go', 'to', 'teach', 'my', 'class', 'at', 'your', 'midnight']\n",
      "AFter tokenizer:  ['asked', '3mobile', 'if', '0870', 'chatlines', 'inclu', 'in', 'free', 'mins', '.', 'india', 'cust', 'servs', 'sed', 'yes', '.', 'l8er', 'got', 'mega', 'bill', '.', '3', 'dont', 'giv', 'a', 'shit', '.', 'bailiff', 'due', 'in', 'days', '.', 'i', 'o', '£250', '3', 'want', '£800']\n",
      "AFter tokenizer:  ['yeah', 'it', \"'s\", 'jus', 'rite', '...']\n",
      "AFter tokenizer:  ['armand', 'says', 'get', 'your', 'ass', 'over', 'to', 'epsilon']\n",
      "AFter tokenizer:  ['u', 'still', 'havent', 'got', 'urself', 'a', 'jacket', 'ah', '?']\n",
      "AFter tokenizer:  ['i', \"'m\", 'taking', 'derek', '&', 'amp', ';', 'taylor', 'to', 'walmart', ',', 'if', 'i', \"'m\", 'not', 'back', 'by', 'the', 'time', 'you', \"'re\", 'done', 'just', 'leave', 'the', 'mouse', 'on', 'my', 'desk', 'and', 'i', \"'ll\", 'text', 'you', 'when', 'priscilla', \"'s\", 'ready']\n",
      "AFter tokenizer:  ['hi', 'its', 'in', 'durban', 'are', 'you', 'still', 'on', 'this', 'number']\n",
      "AFter tokenizer:  ['ic', '.', 'there', 'are', 'a', 'lotta', 'childporn', 'cars', 'then', '.']\n",
      "AFter tokenizer:  ['had', 'your', 'contract', 'mobile', '11', 'mnths', '?', 'latest', 'motorola', ',', 'nokia', 'etc', '.', 'all', 'free', '!', 'double', 'mins', '&', 'text', 'on', 'orange', 'tariffs', '.', 'text', 'yes', 'for', 'callback', ',', 'no', 'to', 'remove', 'from', 'records', '.']\n",
      "AFter tokenizer:  ['no', ',', 'i', 'was', 'trying', 'it', 'all', 'weekend', ';', 'v']\n",
      "AFter tokenizer:  ['you', 'know', ',', 'wot', 'people', 'wear', '.', 't', 'shirts', ',', 'jumpers', ',', 'hat', ',', 'belt', ',', 'is', 'all', 'we', 'know', '.', 'we', 'r', 'at', 'cribbs']\n",
      "AFter tokenizer:  ['cool', ',', 'what', 'time', 'you', 'think', 'you', 'can', 'get', 'here', '?']\n",
      "AFter tokenizer:  ['wen', 'did', 'you', 'get', 'so', 'spiritual', 'and', 'deep', '.', 'that', \"'s\", 'great']\n",
      "AFter tokenizer:  ['have', 'a', 'safe', 'trip', 'to', 'nigeria', '.', 'wish', 'you', 'happiness', 'and', 'very', 'soon', 'company', 'to', 'share', 'moments', 'with']\n",
      "AFter tokenizer:  ['well', 'keep', 'in', 'mind', 'i', \"'ve\", 'only', 'got', 'enough', 'gas', 'for', 'one', 'more', 'round', 'trip', 'barring', 'a', 'sudden', 'influx', 'of', 'cash']\n",
      "AFter tokenizer:  ['yeh', '.', 'indians', 'was', 'nice', '.', 'tho', 'it', 'did', 'kane', 'me', 'off', 'a', 'bit', 'he', 'he', '.', 'we', 'shud', 'go', 'out', '4', 'a', 'drink', 'sometime', 'soon', '.', 'mite', 'hav', '2', 'go', '2', 'da', 'works', '4', 'a', 'laugh', 'soon', '.', 'love', 'pete', 'x', 'x']\n",
      "AFter tokenizer:  ['yes', 'i', 'have', '.', 'so', 'that', \"'s\", 'why', 'u', 'texted', '.', 'pshew', '...', 'missing', 'you', 'so', 'much']\n",
      "AFter tokenizer:  ['no', '.', 'i', 'meant', 'the', 'calculation', 'is', 'the', 'same', '.', 'that', '&', 'lt', ';', '#', '&', 'gt', ';', 'units', 'at', '&', 'lt', ';', '#', '&', 'gt', ';', '.', 'this', 'school', 'is', 'really', 'expensive', '.', 'have', 'you', 'started', 'practicing', 'your', 'accent', '.', 'because', 'its', 'important', '.', 'and', 'have', 'you', 'decided', 'if', 'you', 'are', 'doing', '4years', 'of', 'dental', 'school', 'or', 'if', 'you', \"'ll\", 'just', 'do', 'the', 'nmde', 'exam', '.']\n",
      "AFter tokenizer:  ['if', 'you', 'are', \"n't\", 'here', 'in', 'the', 'next', '&', 'lt', ';', '#', '&', 'gt', ';', 'hours', 'imma', 'flip', 'my', 'shit']\n",
      "AFter tokenizer:  ['anything', 'lor', '.', 'juz', 'both', 'of', 'us', 'lor', '.']\n",
      "AFter tokenizer:  ['get', 'me', 'out', 'of', 'this', 'dump', 'heap', '.', 'my', 'mom', 'decided', 'to', 'come', 'to', 'lowes', '.', 'boring', '.']\n",
      "AFter tokenizer:  ['ok', 'lor', '...', 'sony', 'ericsson', 'salesman', '...', 'i', 'ask', 'shuhui', 'then', 'she', 'say', 'quite', 'gd', '2', 'use', 'so', 'i', 'considering', '...']\n",
      "AFter tokenizer:  ['ard', '6', 'like', 'dat', 'lor', '.']\n",
      "AFter tokenizer:  ['why', 'do', \"n't\", 'you', 'wait', \"'til\", 'at', 'least', 'wednesday', 'to', 'see', 'if', 'you', 'get', 'your', '.']\n",
      "AFter tokenizer:  ['huh', 'y', 'lei', '...']\n",
      "AFter tokenizer:  ['reminder', 'from', 'o2', ':', 'to', 'get', '2.50', 'pounds', 'free', 'call', 'credit', 'and', 'details', 'of', 'great', 'offers', 'pls', 'reply', '2', 'this', 'text', 'with', 'your', 'valid', 'name', ',', 'house', 'no', 'and', 'postcode']\n",
      "AFter tokenizer:  ['this', 'is', 'the', '2nd', 'time', 'we', 'have', 'tried', '2', 'contact', 'u.', 'u', 'have', 'won', 'the', '£750', 'pound', 'prize', '.', '2', 'claim', 'is', 'easy', ',', 'call', '087187272008', 'now1', '!', 'only', '10p', 'per', 'minute', '.', 'bt-national-rate', '.']\n",
      "AFter tokenizer:  ['will', 'ü', 'b', 'going', 'to', 'esplanade', 'fr', 'home', '?']\n",
      "AFter tokenizer:  ['pity', ',', '*', 'was', 'in', 'mood', 'for', 'that', '.', 'so', '...', 'any', 'other', 'suggestions', '?']\n",
      "AFter tokenizer:  ['the', 'guy', 'did', 'some', 'bitching', 'but', 'i', 'acted', 'like', 'i', \"'d\", 'be', 'interested', 'in', 'buying', 'something', 'else', 'next', 'week', 'and', 'he', 'gave', 'it', 'to', 'us', 'for', 'free']\n",
      "AFter tokenizer:  ['rofl', '.', 'its', 'true', 'to', 'its', 'name']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message  \\\n",
       "0         0  Go until jurong point, crazy.. Available only ...   \n",
       "1         0                      Ok lar... Joking wif u oni...   \n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3         0  U dun say so early hor... U c already then say...   \n",
       "4         0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                    transformed_text  \n",
       "0  go jurong point crazi avail bugi n great world...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...  \n",
       "3                u dun say earli hor u c alreadi say  \n",
       "4               nah think goe usf live around though  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transformed_text'] = df['Message'].apply(transform_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a6dd0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "tfid = TfidfVectorizer(max_features = 500)\n",
    "X = tfid.fit_transform(df['transformed_text']).toarray()\n",
    "y = df['Category'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0aaf84",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b838b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test , y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa4b190",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01bccb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.0-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\red\\anaconda3\\envs\\mlops\\lib\\site-packages (from xgboost) (2.2.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\red\\anaconda3\\envs\\mlops\\lib\\site-packages (from xgboost) (1.15.2)\n",
      "Downloading xgboost-3.0.0-py3-none-win_amd64.whl (150.0 MB)\n",
      "   ---------------------------------------- 0.0/150.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/150.0 MB 10.5 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 3.9/150.0 MB 9.9 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 6.3/150.0 MB 10.2 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 8.7/150.0 MB 10.4 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 11.0/150.0 MB 10.5 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 13.4/150.0 MB 10.6 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 15.5/150.0 MB 10.6 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 18.1/150.0 MB 10.7 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 19.1/150.0 MB 10.2 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 20.4/150.0 MB 10.2 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 22.5/150.0 MB 9.7 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 23.9/150.0 MB 9.4 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 24.6/150.0 MB 9.1 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 25.2/150.0 MB 8.9 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 26.2/150.0 MB 8.3 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 26.7/150.0 MB 8.0 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 27.8/150.0 MB 7.8 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 28.8/150.0 MB 7.6 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 29.6/150.0 MB 7.5 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 30.4/150.0 MB 7.2 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 31.2/150.0 MB 7.0 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 32.0/150.0 MB 6.9 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 32.8/150.0 MB 6.8 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 34.9/150.0 MB 6.9 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 35.4/150.0 MB 6.9 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 36.2/150.0 MB 6.6 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 36.7/150.0 MB 6.5 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 37.5/150.0 MB 6.3 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 38.3/150.0 MB 6.3 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 38.8/150.0 MB 6.1 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 39.3/150.0 MB 6.0 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 39.8/150.0 MB 5.9 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 40.6/150.0 MB 5.8 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 40.9/150.0 MB 5.7 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 41.2/150.0 MB 5.7 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 41.7/150.0 MB 5.5 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 41.9/150.0 MB 5.5 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 42.2/150.0 MB 5.3 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 42.5/150.0 MB 5.1 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 42.5/150.0 MB 5.1 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 42.7/150.0 MB 4.9 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 42.7/150.0 MB 4.9 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 43.0/150.0 MB 4.8 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 43.0/150.0 MB 4.8 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 43.3/150.0 MB 4.5 MB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 43.3/150.0 MB 4.5 MB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 43.5/150.0 MB 4.4 MB/s eta 0:00:25\n",
      "   ----------- ---------------------------- 43.5/150.0 MB 4.4 MB/s eta 0:00:25\n",
      "   ----------- ---------------------------- 43.8/150.0 MB 4.3 MB/s eta 0:00:25\n",
      "   ----------- ---------------------------- 43.8/150.0 MB 4.3 MB/s eta 0:00:25\n",
      "   ----------- ---------------------------- 44.0/150.0 MB 4.1 MB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 44.0/150.0 MB 4.1 MB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 44.0/150.0 MB 4.1 MB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 44.3/150.0 MB 3.9 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 44.3/150.0 MB 3.9 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 44.3/150.0 MB 3.9 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 44.6/150.0 MB 3.7 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 44.6/150.0 MB 3.7 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 44.6/150.0 MB 3.7 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 44.8/150.0 MB 3.5 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 44.8/150.0 MB 3.5 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 44.8/150.0 MB 3.5 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 45.1/150.0 MB 3.4 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 45.4/150.0 MB 3.4 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 45.9/150.0 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 45.9/150.0 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 46.4/150.0 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 47.4/150.0 MB 3.3 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 48.5/150.0 MB 3.3 MB/s eta 0:00:31\n",
      "   ------------- -------------------------- 49.8/150.0 MB 3.3 MB/s eta 0:00:30\n",
      "   ------------- -------------------------- 51.1/150.0 MB 3.4 MB/s eta 0:00:30\n",
      "   ------------- -------------------------- 52.4/150.0 MB 3.4 MB/s eta 0:00:29\n",
      "   -------------- ------------------------- 54.0/150.0 MB 3.5 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 55.1/150.0 MB 3.5 MB/s eta 0:00:28\n",
      "   --------------- ------------------------ 56.6/150.0 MB 3.5 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 58.2/150.0 MB 3.6 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 59.8/150.0 MB 3.6 MB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 61.6/150.0 MB 3.7 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 63.4/150.0 MB 3.8 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 65.3/150.0 MB 3.8 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 67.1/150.0 MB 3.9 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 68.9/150.0 MB 3.9 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 70.8/150.0 MB 4.0 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 72.6/150.0 MB 4.1 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 74.2/150.0 MB 4.1 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 75.8/150.0 MB 4.1 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 77.6/150.0 MB 4.2 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 79.2/150.0 MB 4.2 MB/s eta 0:00:17\n",
      "   --------------------- ------------------ 81.3/150.0 MB 4.3 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 82.8/150.0 MB 4.3 MB/s eta 0:00:16\n",
      "   ---------------------- ----------------- 84.7/150.0 MB 4.4 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 86.5/150.0 MB 4.4 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 88.3/150.0 MB 4.5 MB/s eta 0:00:14\n",
      "   ------------------------ --------------- 90.4/150.0 MB 4.5 MB/s eta 0:00:14\n",
      "   ------------------------ --------------- 92.5/150.0 MB 4.6 MB/s eta 0:00:13\n",
      "   ------------------------- -------------- 94.9/150.0 MB 4.6 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 96.5/150.0 MB 4.7 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 98.6/150.0 MB 4.7 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 100.4/150.0 MB 4.8 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 102.8/150.0 MB 4.8 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 104.9/150.0 MB 4.9 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 107.2/150.0 MB 4.9 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 109.6/150.0 MB 5.0 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 111.7/150.0 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 113.2/150.0 MB 5.1 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 115.1/150.0 MB 5.1 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 117.2/150.0 MB 5.1 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 119.3/150.0 MB 5.2 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 121.6/150.0 MB 5.2 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 123.7/150.0 MB 5.3 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 125.8/150.0 MB 5.3 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 127.9/150.0 MB 5.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 130.0/150.0 MB 5.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 132.1/150.0 MB 5.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 134.2/150.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 136.3/150.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 138.1/150.0 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 139.7/150.0 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 141.6/150.0 MB 5.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 143.4/150.0 MB 5.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 145.2/150.0 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  147.3/150.0 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  149.2/150.0 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  149.9/150.0 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 150.0/150.0 MB 5.6 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e1b30d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "480eeddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel= \"sigmoid\", gamma  = 1.0)\n",
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "dtc = DecisionTreeClassifier(max_depth = 5)\n",
    "lrc = LogisticRegression(solver = 'liblinear', penalty = 'l1')\n",
    "rfc = RandomForestClassifier(n_estimators = 50, random_state = 2 )\n",
    "abc = AdaBoostClassifier(n_estimators = 50, random_state = 2)\n",
    "bc = BaggingClassifier(n_estimators = 50, random_state = 2)\n",
    "etc = ExtraTreesClassifier(n_estimators = 50, random_state = 2)\n",
    "gbdt = GradientBoostingClassifier(n_estimators = 50, random_state = 2)    \n",
    "xgb  = XGBClassifier(n_estimators = 50, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cffd4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'SVC': svc,\n",
    "    'KNN': knc,\n",
    "    'NB': mnb,\n",
    "    'DT': dtc,\n",
    "    'LR': lrc,\n",
    "    'RF': rfc,\n",
    "    'Adaboost': abc,\n",
    "    'Bgc': bc,\n",
    "    'ETC': etc,\n",
    "    'GBDT': gbdt,\n",
    "    'xgb': xgb\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af717fb",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "004c4d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "def train_classifier(clfs, X_train, y_train, X_test, y_test):\n",
    "    clfs.fit(X_train,y_train)\n",
    "    y_pred = clfs.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    return accuracy , precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5d74b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For:  SVC\n",
      "Accuracy:  0.9757751937984496\n",
      "Precision:  0.9903846153846154\n",
      "\n",
      "For:  KNN\n",
      "Accuracy:  0.936046511627907\n",
      "Precision:  1.0\n",
      "\n",
      "For:  NB\n",
      "Accuracy:  0.9796511627906976\n",
      "Precision:  0.9732142857142857\n",
      "\n",
      "For:  DT\n",
      "Accuracy:  0.937015503875969\n",
      "Precision:  0.8297872340425532\n",
      "\n",
      "For:  LR\n",
      "Accuracy:  0.9699612403100775\n",
      "Precision:  0.9615384615384616\n",
      "\n",
      "For:  RF\n",
      "Accuracy:  0.9748062015503876\n",
      "Precision:  0.9469026548672567\n",
      "\n",
      "For:  Adaboost\n",
      "Accuracy:  0.9273255813953488\n",
      "Precision:  0.8513513513513513\n",
      "\n",
      "For:  Bgc\n",
      "Accuracy:  0.9573643410852714\n",
      "Precision:  0.8738738738738738\n",
      "\n",
      "For:  ETC\n",
      "Accuracy:  0.9718992248062015\n",
      "Precision:  0.9224137931034483\n",
      "\n",
      "For:  GBDT\n",
      "Accuracy:  0.9505813953488372\n",
      "Precision:  0.9523809523809523\n",
      "\n",
      "For:  xgb\n",
      "Accuracy:  0.9680232558139535\n",
      "Precision:  0.9519230769230769\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "for name , clfs in clfs.items():\n",
    "    current_accuracy, current_precision = train_classifier(clfs, X_train, y_train, X_test, y_test)\n",
    "    print()\n",
    "    print(\"For: \", name)\n",
    "    print(\"Accuracy: \", current_accuracy)\n",
    "    print(\"Precision: \", current_precision)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b71573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
